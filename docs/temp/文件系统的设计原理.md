# 文件系统的设计原理

[toc]

## 摘要

这次又是要写文件的上传下载，又是需要对文件进行管理，文件的元数据信息，目录结构，文件夹和文件的管理，我感觉这是一个很重要的东西，想要把文件系统搞懂一点。参考文章：[文件系统的设计原理](https://hrz123.github.io/2020/08/16/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9A%84%E8%AE%BE%E8%AE%A1%E5%8E%9F%E7%90%86/)，这篇写的很好，绝大部分都copy的，但是我还想要了解具体设计的方面的东西，比如有哪些元数据信息，Inode 或则 NameNode 怎么抽象的，目录是啥样的，然后怎么管理的

文件及硬盘管理是计算机操作系统的重要组成部分。让微软走上成功之路的正是微软最早推出的个人电脑 PC 操作系统，这个操作系统叫做 DOS，即 Disk Operating System，硬盘操作系统。我们每天使用电脑都离不开硬盘，硬盘既有大小的限制，通常大一点的硬盘也只是几T，又有速度的限制，快一点的硬盘也不过每秒几百M（现在局域网下的带宽都可以达到几千M，分布式文件系统的重要原因）

文件是存储在硬盘上的，文件的读写速度必然受到硬盘的物理限制，那么如何才能 1 分钟内完成一个 100 T 大文件的遍历呢？

想要知道这个问题的答案，我们就必须知道文件系统的原理。做软件开发的时候，我们经常要和文件系统打交道，而文件系统也是一个软件，了解文件系统的设计原理，可以帮助我们更好的使用文件系统，另外设计文件系统的各种考量，也对我们自己软件设计有诸多简介意义

## 硬盘

硬盘是一种可持久保存、多次读写数据的存储介质。硬盘的形式主要有两种：机械式硬盘、固态硬盘

机械式硬盘的结构，主要包含盘片、主轴、次投币，主轴带动盘片高速旋转，当需要读写盘上的数据的时候，磁头臂会移动磁头到盘片所在的磁道上，磁头读取磁道上的数据。读写数据需要移动磁头，这样一个机械的动作，至少需要花费数毫秒的时间，这是机械式硬盘访问延迟的主要原因。

固态硬盘的读写速度快得多，但是成本也要高得多，因此在生产环境中，最主要的存储介质依然是机械式硬盘。如果一个场景对数据访问速度、存储容量、成本都有较高的要求，那么可以采用固态硬盘和机械式硬盘混合部署的方式

## 文件系统

我们一般不需要直接操作硬盘，而是通过操作系统，以文件的方式对硬盘上的数据进行读写。文件系统将硬盘空间以块为单位进行划分，每个文件占据若干个块，然后通过文件控制块 FCB 记录每个文件占据的硬盘数据块

![img](https://hrz123.github.io/2020/08/16/文件系统的设计原理/文件系统1.png)

<div align='center'>文件系统分块</div>

文件控制块在 Linux 中的角色是 inode，要想访问文件，就必须获得文件的 inode 信息，在 inode 中查找文件数据块索引表，根据索引表中记录的硬盘地址信息访问硬盘，读写数据

inode 中记录着文件权限、所有者、修改时间和文件大小等文件属性信息，以及文件数据块硬盘地址索引。inode 是固定结构的，能够记录的硬盘地址索引数也是固定的，只有 15 个索引。其中前 12 个索引直接记录数据块地址，第 13 个索引记录索引地址，也就是说，索引块指向的硬盘数据块并不直接记录文件数据，而是记录文件数据块的索引表，每个索引表可以记录 256 个索引；第 14 个索引记录二级索引地址，第 15 个索引记录三级索引地址，如下图：

![img](https://hrz123.github.io/2020/08/16/文件系统的设计原理/文件系统2.jpg)

<div align='center'>Inode 文件控制块</div>

每个 inode 最多可以存储 12+256+256*256+256*256*256 个数据块，如果每个数据块的大小为 4k，也就是单个文件最大不超过 70G，而且即使可以扩大数据块大小，文件大小也要受单个硬盘容量的限制。这样的话，对于我们开头提出的一分钟完成 100T 大文件的遍历，Linux 文件系统是无法完成的。

## Inode

[理解Inode](https://www.ruanyifeng.com/blog/2011/12/inode.html)

### inode 的内容、大小和号码

文件存储在硬盘上，硬盘的最小存储单位是扇区（Sector），每个扇区存储 512 字节，但是操作系统读取硬盘的时候，不会一个一个扇区的读取，这样效率太低了，而是一次性读取多个扇区，我们将这多个扇区称为一个块（Block）， 常见大小是 4 kb，也就是 8 个扇区

文件数据都存储在块中了，但是我们必须找到一个地方存储文件的元信息，比如文件的创建者、创建日期、文件的大小等等，这种存储文件元信息的区域就叫做 inode（索引节点）

inode 包含的信息：

- 文件的字节数
- 文件的拥有者 User ID
- 文件的 Group ID
- 文件的读、写、执行权限
- 文件的时间戳：ctime， inode 上一次变动的事件；mtime，文件内容上一次变动的事件；atime，文件上一次打开的时间
- 链接数，既有多少文件名指向这个 inode
- 文件数据 block 的位置

inode 也会消耗硬盘空间，所以硬盘格式化的时候，操作系统自动将硬盘分为两个区域，一个是数据区，存放文件数据；另一个是 inode 区，存放 inode 包含的信息。每个inode节点的大小，一般是128字节或256字节。inode节点的总数，在格式化时就给定，一般是每1KB或每2KB就设置一个inode。假定在一块1GB的硬盘中，每个inode节点的大小为128字节，每1KB就设置一个inode，那么inode table的大小就会达到128MB，占整块硬盘的12.8%。由于每个文件都必须有一个inode，因此有可能发生inode已经用光，但是硬盘还未存满的情况。这时，就无法在硬盘上创建新文件。

每个 inode 都有一个号码，操作系统用 inode 号码来识别不同的文件。Linux 系统内部不适用文件名，而使用 inode 号码来识别文件。对于系统来说，文件名只是 inode 号码便于识别的别称或者绰号。表面上，用户通过文件名打开文件，实际上，系统内部这个过程分为三步：首先，系统找到这个文件名对应的 inode 号码；其次，通过 inode 号码获取 inode 信息；最后，根据 inode 信息，找到文件数据所在的 block，读取数据

由于inode号码与文件名分离，这种机制导致了一些Unix/Linux系统特有的现象。

　　1. 有时，文件名包含特殊字符，无法正常删除。这时，直接删除inode节点，就能起到删除文件的作用。

　　2. 移动文件或重命名文件，只是改变文件名，不影响inode号码。

　　3. 打开一个文件以后，系统就以inode号码来识别这个文件，不再考虑文件名。因此，通常来说，系统无法从inode号码得知文件名。

第3点使得软件更新变得简单，可以在不关闭软件的情况下进行更新，不需要重启。因为系统通过inode号码，识别运行中的文件，不通过文件名。更新的时候，新版文件以同样的文件名，生成一个新的inode，不会影响到运行中的文件。等到下一次运行这个软件的时候，文件名就自动指向新版文件，旧版文件的inode则被回收。

### 目录文件

在 Unix/Linux 系统中，目录（directory）也是一种文件。打开目录，实际上就是打开目录文件。目录文件的结构非常简单，就是一系列目录项（dirent）的列表。每个目录项，有两部分组成：所包含文件的文件名，文件名对应的 inode 号码。ls命令只列出目录文件中的所有文件，ls -i命令列出整个目录文件，即文件名和inode号码。如果要查看文件的详细信息，就必须根据 inode 号码，访问 inode 节点，读取信息。ls -l命令列出文件的详细信息。

理解了上面这些知识，就能理解目录的权限。目录文件的读权限（r）和写权限（w），都是针对目录文件本身。由于目录文件内只有文件名和inode号码，所以如果只有读权限，只能获取文件名，无法获取其他信息，因为其他信息都储存在inode节点中，而读取inode节点内的信息需要目录文件的执行权限（x）。

![img](https://www.ruanyifeng.com/blogimg/asset/201112/bg2011120402.png)

<div align='center'>stat 查看详细信息</div>

![img](https://www.ruanyifeng.com/blogimg/asset/201112/bg2011120403.png)

<div align='center'> df -i 查看inode总数和使用数量</div>

ls命令只列出目录文件中的所有文件名，ls -i命令列出整个目录文件，即文件名和inode号码，ls -i命令列出整个目录文件，即文件名和inode号码（需要目录文件有 x 执行权限）

### 硬、软链接

一般情况下，文件名和 inode 号码是一一对应的关系，但是 Linux 系统允许多个文件名指向同一个 inode。这意味着，可以用不同的文件名访问同样的内容；对文件内容进行修改，回影响到所有文件名；但是删除一个文件名，不影响另一个文件名的访问。这种情况称为硬链接（hard link），ln命令可以创建硬链接

![img](https://www.ruanyifeng.com/blogimg/asset/201112/bg2011120409.png)

<div align='center'>ln 创建硬链接</div>

运行上面这条命令以后，源文件与目标文件的inode号码相同，都指向同一个inode。inode信息中有一项叫做"链接数"，记录指向该inode的文件名总数，这时就会增加1。反过来，删除一个文件名，就会使得inode节点中的"链接数"减1。当这个值减到0，表明没有文件名指向这个inode，系统就会回收这个inode号码，以及其所对应block区域。

目录文件的链接数：创建目录时，默认回生成两个目录项：'.' 和 '..'，前者的 inode 号码就是当前目录的 inode 号码，等同于当前目录的硬链接，后者的 inode 号码就是当前目录的父目录的 inode 号码，等同于父目录的硬链接。

除了硬链接之外，还有一种特殊情况。文件 A 和 文件 B 的 inode 号码虽然不一样，但是文件 A 的内容是文件 B 的路径，读取文件 A 时，系统会自动将访问者导向文件 B（好比是window 中的快捷方式）。因此，无论打开哪一个文件，最终读取的都是文件 B。这时，文件 A 就称为文件 B 的软连接

这意味着，文件A依赖于文件B而存在，如果删除了文件B，打开文件A就会报错："No such file or directory"。这是软链接与硬链接最大的不同：文件A指向文件B的文件名，而不是文件B的inode号码，文件B的inode"链接数"不会因此发生变化。

![img](https://www.ruanyifeng.com/blogimg/asset/201112/bg2011120410.png)

<div align='center'>ln -s 创建软链接</div>



## RAID

RAID(Redundant Array of Independent Disks, 独立硬盘冗余阵列)：利用虚拟化存储技术把多个硬盘组合起来，称为一个或多个硬盘阵列组，目的是提升性能或减少冗余，或者是两者同时提升。

RAID 的核心思路其实是利用文件系统将数据写入硬盘中不同数据块的特性，将多块硬盘上的空闲空间看作一个整体，进行数据写入，也就是说，一个文件的多个数据块可能写入多个硬盘。根据硬盘组织和使用方式不同，常用 RAID 有五种，分别是 RAID 0、RAID 1、RAID 10、RAID 5 和 RAID 6。we

[![img](https://hrz123.github.io/2020/08/16/文件系统的设计原理/文件系统3.jpg)](https://hrz123.github.io/2020/08/16/文件系统的设计原理/文件系统3.jpg)

RAID 0 将一个文件的数据分成 N 片，同时向 N 个硬盘写入，这样单个文件可以存储在 N 个硬盘上，文件容量可以扩大 N 倍，（理论上）读写速度也可以扩大 N 倍。但是使用 RAID 0 的最大问题是文件数据分散在 N 块硬盘上，任何一块硬盘损坏，就会导致数据不完整，整个文件系统全部损坏，文件的可用性极大地降低了。

RAID 1 则是利用两块硬盘进行数据备份，文件同时向两块硬盘写入，这样任何一块硬盘损坏都不会出现文件数据丢失的情况，文件的可用性得到提升。

RAID 10 结合 RAID 0 和 RAID 1，将多块硬盘进行两两分组，文件数据分成 N 片，每个分组写入一片，每个分组内的两块硬盘再进行数据备份。这样既扩大了文件的容量，又提高了文件的可用性。但是这种方式硬盘的利用率只有 50%，有一半的硬盘被用来做数据备份。

RAID 5 针对 RAID 10 硬盘浪费的情况，将数据分成 N-1 片，再利用这 N-1 片数据进行位运算，计算一片校验数据，然后将这 N 片数据写入 N 个硬盘。这样任何一块硬盘损坏，都可以利用校验片的数据和其他数据进行计算得到这片丢失的数据，而硬盘的利用率也提高到 N-1/N。 校验数据这一块建议去了解汉明码，然后 3Blue1Brown 的两个视频讲的特别好，地址：[B站](https://www.bilibili.com/video/BV1WK411N7kz?spm_id_from=333.999.0.0)

RAID 5 可以解决一块硬盘损坏后文件不可用的问题，那么如果两块文件损坏？RAID 6 的解决方案是，用两种位运算校验算法计算两片校验数据，这样两块硬盘损坏还是可以计算得到丢失的数据片。

实践中，使用最多的是 RAID 5，数据被分成 N-1 片并发写入 N-1 块硬盘，这样既可以得到较好的硬盘利用率，也能得到很好的读写速度，同时还能保证较好的数据可用性。使用 RAID 5 的文件系统比简单的文件系统文件容量和读写速度都提高了 N-1 倍，但是一台服务器上能插入的硬盘数量是有限的，通常是 8 块，也就是文件读写速度和存储容量提高了 7 倍，这远远达不到 1 分钟完成 100T 文件的遍历要求。

## 分布式文件系统

我们再回过头看下 Linux 的文件系统：文件的基本信息，也就是文件元信息记录在文件控制块 inode 中，文件的数据记录在硬盘的数据块中，inode 通过索引记录数据块的地址，读写文件的时候，查询 inode 中的索引记录得到数据块的硬盘地址，然后访问数据。

如果将数据块的地址改成分布式服务器的地址？也就是查询得到的数据块地址不只是本机的硬盘容量，还可以是其他服务器的地址，那么文件的存储容量就将是整个分布式服务器集群的硬盘容量，这样还可以在不同的服务器上同时并行读取文件的数据块，文件访问速度也将极大的加快。

这样的文件系统就是分布式文件系统，分布式文件系统的思路其实和 RAID 是一脉相承的，就是将数据分成很多片，同时向 N 台服务器上进行数据写入。针对一片数据丢失就导致整个文件损坏的情况，分布式文件系统也是采取数据备份的方式，将多个备份数据片写入多个服务器，以保证文件的可用性。当然，也可以采用 RAID 5 的方式通过计算校验数据片的方式提高文件可用性。

我们以 Hadoop 分布式文件系统 HDFS 为例，看下分布式文件系统的具体架构设计。

[![img](https://hrz123.github.io/2020/08/16/文件系统的设计原理/文件系统4.png)](https://hrz123.github.io/2020/08/16/文件系统的设计原理/文件系统4.png)

HDFS 的关键组件有两个，一个是 DataNode，一个是 NameNode。

DataNode 负责文件数据的存储和读写操作，HDFS 将文件数据分隔成若干数据块（Block），每个 DataNode 存储一部分数据块，这样文件就分部存储在整个 HDFS 服务器集群中。应用程序客户端（Client）可以并行对这些数据块进行访问，从而使得 HDFS 可以在服务器集群规模上实现数据并行访问，极大地提高了访问速度。在实践中，HDFS 集群的 DataNode 服务器会有很多台，一般在几百台到几千台这样的规模，每台服务器配有数块硬盘，整个集群的存储容量大概在几 PB 到数百 PB。

NameNode 负责整个分布式文件系统的元数据（MetaData）管理，也就是文件路径名、访问权限、数据块的 ID 以及存储位置等信息，相当于 Linux 系统中 inode 的角色。HDFS 为了保证数据的高可用，会将一个数据块复制为多分（缺省情况下为 3 份），并将多份相同的数据块存储在不同的服务器上，甚至不同的机架上。这样当有硬盘损坏，或者某个 DataNode 服务器宕机，甚至某个交换机宕机，导致其存储的数据块不能访问的时候，客户端会查找其备份的数据块进行访问。

有了 HDFS，可以实现单一文件存储几百 T 的数据，再配合大数据计算框架 MapReduce 或者 Spark，可以对这个文件的数据块进行并发计算。也可以使用 Impala 这样的 SQL 引擎对这个文件进行结构化查询，在数千台服务器上并发遍历 100T 的数据，1 分钟都是绰绰有余的。

## 小结

文件系统从简单操作系统文件，到 RAID 再到分布式文件系统，其设计思路其实是具有统一性的。这种统一性方面体现在文件数据如何管理，也就是如何通过文件控制块管理文件的数据，这个文件控制块在 Linux 系统中就是 inode，在 HDFS 中就是 NameNode。

另一方面体现在如何利用更多的硬盘实现越来越大的文件存储需求和越来越快的读写速度需求，也就是将数据分片后同时写入多块硬盘。单服务器我们可以通过 RAID 来实现，多服务器则可以将这些服务器组成一个文件系统集群，共同对外提供文件服务，这时候，数千台服务器的数万块硬盘以单一存储资源的方式对文件使用提供服务，也就是一个文件可以存储数百 T 的数据，并在一分钟完成这样一个大文件的遍历。