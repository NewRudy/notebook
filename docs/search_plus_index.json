{"./":{"url":"./","title":"Introduction","keywords":"","body":"吴天 网名吴天，专业是gis（很小众的一个专业），很菜很菜的一个人，现在还没有什么产出，笔记大部分都是看着一些教程或者优秀博主copy的，一般都写了原创链接，也可能没注意少写了 ​ 由于上传图床的时候有些图片落下了，有些笔记弄丢了，所以有些笔记是有问题的 制作这样一个笔记本的形式是为了自己看，也为了有点动力，希望自己能慢慢完善吧 "},"bigData/BigData-Notes.html":{"url":"bigData/BigData-Notes.html","title":"BigData-Notes","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 前言 块存储、文件存储、对象存储这三者的本质区别 1 大数据处理流程 1.1处理流程 1.2 数据存储 1.3 数据分析 1.4 数据应用 1.5 其他框架 Hadoop 分布式文件存储系统 HDFS 分布式计算框架MapReduce 集群资源管理器YARN Hadoop 单机版环境搭建 Hadoop集群环境搭建 HDFS常用shell命令 HDFS Java API 的使用 基于Zookeeper搭建Hadoop高可用集群 minIO 什么是大数据的技术生态 BigData-Notes github [toc] 前言 块存储、文件存储、对象存储这三者的本质区别 知乎 这三者的本质差别是使用数据的\"用户\"不同：块存储的用户是可以读写块设备的软件系统，例如传统的文件系统、数据库；文件存储的用户是自然人；对象存储的用户则是其它计算机软件 1 大数据处理流程 1.1处理流程 中大型项目通常采用微服务架构进行分布式部署，采集过程不能影响正常业务的开展。多种日志收集工具：Flume， Logstash， Kibana，都能通过简单的配置完成复杂的数据收集和数据聚合 1.2 数据存储 结构化数据（表）、半结构化数据（日志数据、视频、音频），为了解决海量半结构化和非结构化数据的存储，衍生了Hadoop HDFS，KFS，GFS等分布式文件系统，它们能支持结构化、半结构和非结构化数据的存储，并可以通过增加机器进行横向扩展 分布式文件系统完美地解决了海量数据存储的问题，但是一个优秀的数据存储系统需要同时考虑数据存储和访问两方面的问题，比如你希望能够对数据进行随机访问，这是传统的关系型数据库所擅长的，但却不是分布式文件系统所擅长的，那么有没有一种存储方案能够同时兼具分布式文件系统和关系型数据库的优点，基于这种需求，就产生了 HBase、MongoDB。 1.3 数据分析 数据分析：批处理和流处理 批处理：对一段时间内海量的离线数据进行统一的处理，对应的处理框架有 Hadoop MapReduce、Spark、Flink 等； 流处理：对运动中的数据进行处理，即在接收数据的同时就对其进行处理，对应的处理框架有 Storm、Spark Streaming、Flink Streaming 等。 批处理和流处理各有其适用的场景，时间不敏感或者硬件资源有限，可以采用批处理；时间敏感和及时性要求高就可以采用流处理。随着服务器硬件的价格越来越低和大家对及时性的要求越来越高，流处理越来越普遍，如股票价格预测和电商运营数据分析等。 上面的框架都是需要通过编程来进行数据分析，那么如果你不是一个后台工程师，是不是就不能进行数据的分析了？当然不是，大数据是一个非常完善的生态圈，有需求就有解决方案。为了能够让熟悉 SQL 的人员也能够进行数据的分析，查询分析框架应运而生，常用的有 Hive 、Spark SQL 、Flink SQL、 Pig、Phoenix 等。这些框架都能够使用标准的 SQL 或者 类 SQL 语法灵活地进行数据的查询分析。这些 SQL 经过解析优化后转换为对应的作业程序来运行，如 Hive 本质上就是将 SQL 转换为 MapReduce 作业，Spark SQL 将 SQL 转换为一系列的 RDDs 和转换关系（transformations），Phoenix 将 SQL 查询转换为一个或多个 HBase Scan。 1.4 数据应用 数据分析完成后，接下来就是数据应用的范畴，这取决于你实际的业务需求。比如你可以将数据进行可视化展现，或者将数据用于优化你的推荐算法，这种运用现在很普遍，比如短视频个性化推荐、电商商品推荐、头条新闻推荐等。当然你也可以将数据用于训练你的机器学习模型，这些都属于其他领域的范畴，都有着对应的框架和技术栈进行处理，这里就不一一赘述。 1.5 其他框架 上面是一个标准的大数据处理流程所用到的技术框架。但是实际的大数据处理流程比上面复杂很多，针对大数据处理中的各种复杂问题分别衍生了各类框架： 单机的处理能力都是存在瓶颈的，所以大数据框架都是采用集群模式进行部署，为了更方便的进行集群的部署、监控和管理，衍生了 Ambari、Cloudera Manager 等集群管理工具； 想要保证集群高可用，需要用到 ZooKeeper ，ZooKeeper 是最常用的分布式协调服务，它能够解决大多数集群问题，包括首领选举、失败恢复、元数据存储及其一致性保证。同时针对集群资源管理的需求，又衍生了 Hadoop YARN ; 复杂大数据处理的另外一个显著的问题是，如何调度多个复杂的并且彼此之间存在依赖关系的作业？基于这种需求，产生了 Azkaban 和 Oozie 等工作流调度框架； 大数据流处理中使用的比较多的另外一个框架是 Kafka，它可以用于消峰，避免在秒杀等场景下并发数据对流处理程序造成冲击； 另一个常用的框架是 Sqoop ，主要是解决了数据迁移的问题，它能够通过简单的命令将关系型数据库中的数据导入到 HDFS 、Hive 或 HBase 中，或者从 HDFS 、Hive 导出到关系型数据库上。 分类总结： 日志收集框架：Flume、Logstash、Filebeat 分布式文件存储系统：Hadoop HDFS 数据库系统：Mongodb、HBase 分布式计算框架： 批处理框架：Hadoop MapReduce 流处理框架：Storm 混合处理框架：Spark、Flink 查询分析框架：Hive 、Spark SQL 、Flink SQL、 Pig、Phoenix 集群资源管理器：Hadoop YARN 分布式协调服务：Zookeeper 数据迁移工具：Sqoop 任务调度框架：Azkaban、Oozie 集群部署和监控：Ambari、Cloudera Manager Hadoop 分布式文件存储系统 HDFS HDFS 写数据原理 HDFS 读数据原理 HDFS 故障类型和检测方法 读写故障处理 DataNode 故障处理 副本布局策略 分布式计算框架MapReduce map reduce 编程模型 剩下的看不懂，前面的勉强还能当课外了解了 集群资源管理器YARN yarn工作原理 Hadoop 单机版环境搭建 Hadoop 的运行依赖 JDK，需要预先安装 配置SSH免密登录 Hadoop(HDFS)环境搭建 Hadoop(YARN)环境搭建 Hadoop集群环境搭建 集群规划 前置条件 配置免密登录 集群搭建 提交服务到集群 HDFS常用shell命令 HDFS Java API 的使用 基于Zookeeper搭建Hadoop高可用集群 minIO minIO是高性能对象存储 什么是大数据的技术生态 大数据本身是个很宽泛的概念，Hadoop生态圈（或者泛生态圈）基本上都是为了处理超过单机尺度的数据处理而诞生的。你可以把它比作一个厨房所以需要的各种工具。锅碗瓢盆，各有各的用处，互相之间又有重合。你可以用汤锅直接当碗吃饭喝汤，你可以用小刀或者刨子去皮。但是每个工具有自己的特性，虽然奇怪的组合也能工作，但是未必是最佳选择。 Minio 是一种高性能的分布式对象存储服务器，用于大型数据基础设施，是机器学习和其它大数据工作负载下 Hadoop HDFS的理想 s3 兼容替代品 npm install --save-dev @types/minio "},"bigData/Flink.html":{"url":"bigData/Flink.html","title":"Flink.md","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 摘要 概念 数据流编程模型 抽象层次 程序和数据流 并行数据流 窗口 时间 有状态的算子操作 容错检查点 流处理批处理 分布式运行环境 任务和算子链 TaskManager, JobManager, 客户端 任务槽和资源 状态后台 保存点 Flink [toc] 摘要 Apache Flink 是一个用于分布式流和批数据处理的开源平台。Flink 的核心是流数据流引擎，为数据流上的分布式计算提供数据分发，通信和容错。Flink 在流引擎之上构建批处理，覆盖本机迭代支持，托管内存和程序优化。 概念：从Flink的数据流编程模型和分布式运行时环境的基本概念开始。这将有助于您了解文档的其他部分，包括设置和编程指南。我们建议您先阅读这些部分。 教程： 实现并运行DataStream应用程序 设置本地Flink群集 编程指南：您可以阅读我们关于基本API概念和DataStream API或DataSet API的指南，以了解如何编写您的第一个Flink程序。 概念 数据流编程模型 抽象层次 Flink 提供不同级别的抽象来开发流/批处理应用程序： Flink 抽象级别 状态流：它通过Process Function嵌入到DataStream API中。它允许用户自由处理来自一个或多个流的事件，并使用一致的容错状态。此外，用户可以注册事件时间和处理时间回调，允许程序实现复杂的计算。 Core API：大多数应用程序不需要上述低级抽象，而是针对Core API编程， 如DataStream API（有界/无界流）和DataSet API （有界数据集）。这些流畅的API提供了用于数据处理的通用构建块，例如各种形式的用户指定的转换，连接，聚合，窗口，状态等。在这些API中处理的数据类型在相应的编程语言中表示为类。 Table API：Table API是为中心的声明性DSL 表，其可被动态地改变的表（表示流时）。 Table API遵循（扩展）关系模型：表有一个模式连接（类似于在关系数据库中的表）和API提供可比的 算子操作，如选择，项目，连接，分组依据，聚合等 Table API程序以声明方式定义应该执行的逻辑 算子操作，而不是准确指定 算子操作代码的外观。虽然 Table API可以通过各种类型的用户定义函数进行扩展，但它的表现力不如Core API，但使用更简洁（编写的代码更少）。此外， Table API程序还会通过优化程序，在执行之前应用优化规则。 SQL：Flink 提供的最高级别抽象是 SQL，在语义和表达方面类似于 __Table API_，在SQL抽象与 Table API紧密地相互作用，和SQL查询可以通过定义表来执行 Table API。 程序和数据流 Flink 程序的基础构建块是流和转换。从概念上讲，流是（可能永无止境的）数据记录流，而转换是将一个或多个流作为一个或多个流的算子操作。 Flink 数据流 执行时，Flink 程序映射到流数据流，由流和转换算子组成。每个数据流都以一个或多个源开头，并以一个或多个接收器结束。数据流类似于任意有向无环图。通常程序中的转换与数据流中的算子之间存在一对一的对应关系，但是有时一个转换可能包含多个转换算子。 源流和接收器记录在流连接器和批处理连接器文档中。DataStream 算子和DataSet转换中记录了转换。 并行数据流 Flink 中的本质上是并行和分布式的。在执行期间，_流_具有一个或多个流分区，并且每个 _算子_ 具有一个或多个算子子任务。算子子任务彼此独立，并且可以在不同的线程中执行，可能在不同的机器或容器上执行 算子子任务的数量是该特定算子的并行度。流的并行性始终是其生成算子的并行性。同一程序的不同算子可能具有不同的并行级别。 并行计算 流可以以 一对一流 模式或 重新分配流 模式在两个算子之间传输数据： 一对一流：（例如，在上图中的Source_和_map（） 算子之间）保存数据元的分区和排序。这意味着map（） 算子的subtask [1] 将以与Source 算子的subtask [1]生成的顺序相同的顺序看到相同的数据元 重新分配流： （在上面的map（）和_keyBy / window之间，以及 keyBy / window和Sink之间）重新分配流。每个 算子子任务将数据发送到不同的目标子任务，具体取决于所选的转换。实例是 _keyBy（） （其通过散列Keys重新分区），广播（） ，或Rebalance （） （其重新分区随机地）。在重新分配交换中，数据元之间的排序仅保存在每对发送和接收子任务中（例如，map（）的子任务[1] 和子任务[2]keyBy / window）。因此，在此示例中，保存了每个Keys内的排序，但并行性确实引入了关于不同Keys的聚合结果到达接收器的顺序的非确定性。 窗口 聚合事件（计算，总和）在流上的工作方式和批处理方式不同。例如，不可能计算流中的所有数据元，因为流通常是无限的。相反，流上的聚合（计算，总和）等由窗口限定，例如“在最后5分钟内计数”或“最后100个数据元的总和”。 window 可以是时间驱动的（例如：每30秒）或数据驱动的（每100个数据元）。 窗口 时间 当在流程序中引用时间时，可以参考不同的时间概念： 事件时间：创建事件的时间。它通常是由事件中的时间戳描述，例如由生产传感器或生产服务附加。Flink通过时间戳分配器访问事件事件戳 摄取时间：事件在源算子处输入 Flink 数据流的时间 处理时间：执行基于时间的算子操作的每个算子的本地时间 有状态的算子操作 虽然数据流中的许多算子操作只是一次查看一个单独的事件（例如事件解析器），但某些算子操作会记住多个事件（例如窗口算子）的信息，这些算子操作称为有状态 状态算子操作的状态保持在可以被认为是嵌入式键/值存储的状态中。状态被分区并严格地与有状态算子读取的流一起分发 容错检查点 Flink 使用 流重放 和 检查点 的组合实现容错，检查点与每个输入流中的特定点以及每个算子的对应状态相关。通过恢复 算子的状态并从检查点重放事件，可以从检查点恢复流数据流，同时保持一致性（恰好一次处理语义）。 检查点间隔是在执行期间用恢复时间（需要重放的事件的数量）来折衷容错开销的手段。 容错内部的描述提供了有关Flink如何管理检查点和相关主题的更多信息。有关启用和配置检查点的详细信息 流处理批处理 Flink执行批处理程序作为流程序的特殊情况，其中流是有界的（有限数量的数据元）。一个数据集在内部视为数据流。因此，上述概念以相同的方式应用于批处理程序，并且它们适用于流程序，除了少数例外： 批处理程序的容错不使用检查点。通过完全重放流来恢复。这是可能的，因为输入有限。这会使成本更多地用于恢复，但使常规处理更便宜，因为它避免了检查点。 DataSet API中的有状态 算子操作使用简化的内存/核外数据结构，而不是键/值索引。 DataSet API引入了特殊的同步（超级步骤）迭代，这些迭代只能在有界流上进行。有关详细信息，请查看迭代文档。 分布式运行环境 任务和算子链 对于分布式执行，Flink 链 算子子任务一起放入 任务，每个任务由一个线程执行。将算子链接到任务中是一项有用的优化：他可以 Reduce 线程到线程切换和缓冲的开销，并在降低延迟的同时提高整体吞吐量。 并行线程 TaskManager, JobManager, 客户端 Flink 运行时包含两种类型的进程： JobManagers（也称为Masters）：协调分布式执行，它们安排任务，协调检查点，协调故障恢复等 TaskManagers（也叫 Workers）：执行 任务(或者更具体的说：子任务)的数据流，以及缓冲器和交换数据流 JobManagers 和 TaskManagers 可以通过多种方式启动：作为独立集群直接在计算机上，在容器中，由 Yarn 或 Mesos 等资源框架管理。TaskManagers 连接到 JobManagers，宣布自己可用，并被分配工作 任务槽和资源 每个 worker（TaskManager）都是一个 JVM 进程，可以在不同的线程中执行一个或多个子任务。为了控制worker接受的任务数量，worker也有一个任务槽（至少一个） 每个任务槽代表 TaskManager 的固定资源子集。例如，具有三个插槽的 TaskManager 将其 1/3 的托管内存专用于每个插槽。切换资源意味着子任务不会与其它作业的子任务竞争托管内存，而是具有一定数量的保存托管内存。这里不会发生 CPU 隔离，当前插槽只分离任务的托管内存。 通过调整任务槽的数量，用户可以定义子任务如何相互隔离。每个TaskManager 有一个插槽意味着每个任务组在一个单独的JVM中运行（例如，可以在一个单独的容器中启动）。拥有多个插槽意味着更多子任务共享同一个 JVM。同一 JVM 的任务共享TCP连接（通过多路复用）和心跳信息。它们还可以共享数据集和数据结构，从而Reduce 任务开销 默认情况下，Flink 允许子任务共享插槽，即使它们是不同任务的子任务，只要它们来自同一个作业。结果是一个槽可以保存作业的整个管道。允许插槽共享有两个主要好处： Flink 集群需要与作业中使用的最高并行度一样多的插槽。无需计算程序总共包含多少任务（具有不同的并行性） 更容易获得更好的资源利用率。通过插槽共享，将示例中的基本并行性从2增加到6可以充分利用时隙资源，同时确保繁重的子任务在TaskManagers之间公平分配。 根据经验，一个很好的默认任务槽数是 CPU 核心数。使用超线程，每个插槽需要 2 个或更多硬件线程上下文 状态后台 存储键/值索引的确切数据结构取决于所选的状态后台。一个状态后台将数据存储在内存中的哈希映射中，另一个状态后台使用RocksDB作为键/值存储。除了定义保存状态的数据结构之外，状态后台还实现逻辑以获取键/值状态的时间点SNAPSHOT，并将该SNAPSHOT存储为检查点的一部分。 保存点 用Data Stream API编写的程序可以从保存点恢复执行。保存点允许更新程序和Flink群集，而不会丢失任何状态。 保存点是手动触发的检查点，它会获取程序的SNAPSHOT并将其写入状态后台。他们依靠常规的检查点机制。在执行期间，程序会定期在工作节点上创建SNAPSHOT并生成检查点。对于恢复，仅需要最后完成的检查点，并且一旦新的检查点完成，就可以安全地丢弃旧的检查点。 保存点与这些定期检查点类似，不同之处在于它们由用户触发，并且在较新的检查点完成时不会自动过期。可以从命令行或通过REST API取消作业时创建保存点 "},"bigData/Google 三大核心技术及其衍生.html":{"url":"bigData/Google 三大核心技术及其衍生.html","title":"Google 三大核心技术及其衍生.md","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 Google 三大核心技术及其衍生 简介 Google File System（GFS） why hard The Google File System 1. 简介 2. 设计概述 2.3. 架构 2.6. 元数据 2.7 一致性模型 3. 系统交互 4. master 节点操作 5. 容错和判断 Master 容错 Chuck Sever 容错 开源技术 HDFS Colossus 背景 简单理解 MapReduce MapReduce: Simplified Data Processing on Large Clusters 介绍 编程模型 实现 存储位置 结束语 开源技术 Hadoop Mapreduce Spark Percolator/Dremel BigTable Bigtable: A Distributed Storage System for Structured Data 1. 介绍 2. 数据模型 Rows Cols Timestamps 4. 基础组成 5. Tablet Location Tablet 的位置信息 Tablet 管理 读和写请求 表的压缩 Google Earth 开源技术 LevelDB Hbase F1 Spanner Spanner Spanner: Google’s Globally-Distributed Database Borg Kubernetes Flume 开源技术 单一系统 分布式系统 数据工厂时代：大数据平台 数据价值时代：数据中台 发展 [toc] Google 三大核心技术及其衍生 简介 参考自谷歌三篇论文（GFS,MapReduce,BigTable） Google于2003、2004、2006年分别发表了GFS、 MapReduce 和 BigTable 相关的 3 篇论文，其中MapReduce 和 BigTable都是以GFS为基础，这三大基础核心技术构建出了完整的分布式运算架构，也奠定了大数据和云计算的基础。 Google File System(GFS)：可扩展的分布式文件系统，用于大型的、分布式的、对大量数据进行访问的应用。它运行于廉价的普通硬件上，提供容错功能。从根本上说：文件被分割成很多块，使用冗余的方式储存于商用机器集群上。 MapReduce：描述了大数据的分布式计算方式，主要思想是将任务分解然后在多台处理能力较弱的计算节点中同时处理（Map），然后将结果合并从而完成大数据处理（Reduce）。 BigTable：BigTable 是建立在 GFS 和 MapReduce 之上的。每个Table都是一个多维的稀疏图 -------------- 参考自Google大数据三大论文读后感 三篇论文之后，Google继续公布的了一下技术： 2012 Spanner 开源实现（Hadoop）及Google自身的发展，参考自技术硬核】从Google F1 看HTAP数据库的诞生 GFS （HDFS） ---> Colossus MapReduce （MapReduc ---> Spark） ---> Percolator/Dremel BigTable （HBase） ---> F1/Spanner 参考自一文系统梳理Google三驾马车，有机会把这个课程学习了 大数据技术脉络 .jpg) 大数据技术脉络 Google File System（GFS） Google File System（GFS、GoogleFS），一种专有的分布式文件系统，由Google公司开发，运行于Linux平台上，尽管Google在2003年公布了该系统的一些技术细节，但Google并没有将该系统的软件部分开源，2013年，Google公布了Colossus项目，作为下一代的Google文件系统 why hard 为什么分布式存储困难 个人理解：分布式的初衷是利用数百台计算机的资源来同时完成大量工作，获取巨大的性能加成（high performance），所以数据需要分片（sharding）存储在这些机器上。然后服务器会宕机，通信也会出现故障，不可能通过人工来修复错误，我们需要一个自动化的容错系统（fault tolerance）。实现容错的最有用的方法就是复制（replication），其中一个出错了，我们就立刻替上它的副本。但是数据在动态的变化，副本之间的复制不能同步的进行更新，一不小心两个数据的副本会不一致（inconsistency），这时候用户请求的数据取决于用户向哪个副本请求数据。显然我们要避免不一致的问题，为了达到一致性，不同的服务器之间需要通过网络进行额外的交互（Network interaction），这种交互会降低性能（low performance）。 分布式难点 所以说，分布式系统的最大难点就在于各个节点的状态如何同步，也就是 CAP（consistency，availability，partition tolerance）定理 1998年，加州大学的计算机科学家 Eric Brewer 提出，分布式系统有三个指标: Consistency Availability Partition tolerance Eric Brewer 说，这三个指标不可能同时做到。这个结论就叫做 CAP 定理。 前文已经说到，故障总是存在，也即分区容错（Partition tolerance）是无法避免的，剩下的 C、A就只能选择一个。 为什么只能选择一个，举例： 如果保证 G2 的一致性，那么 G1 必须在写操作时，锁定 G2 的读操作和写操作。只有数据同步后，才能重新开放读写。锁定期间，G2 不能读写，可用性不成立。 如果保证 G2 的可用性，那么势必不能锁定 G2，所以一致性不成立。 综上所述，G2 无法同时做到一致性和可用性。系统设计时只能选择一个目标。如果追求一致性，那么无法保证所有节点的可用性；如果追求所有节点的可用性，那就没法做到一致性。 总结来说，我们以为分布式能给我们带来绝大的性能提升，但是因为种种原因（最大的原因就是各个节点的状态如何同步），最终实际上的效果差强人意。 The Google File System 《The Google File System》是 GFS 最经典的论文，没有之一（2003年就有了:cow:)。 原文 翻译1 翻译2 原文简要目录结构： Introduction 简介 Design Overview 设计概述 2.3 Architecture 架构 2.6 Metadata 元数据 2.7 Consistency Model 一致性模型 System Interactions 系统交互 master Operation Master 节点操作 High Availability 容错和判断 简要理解： 1. 简介 参考自翻译2和理解 The Google File System 设计一个通用的分布式文件系统是不现实的，它不仅在实现上异常困难（因为不得不考虑所有应用场景），而且实际使用也难以满足要求（往往存在显而易见的性能或容错瓶颈）。GFS 设计初衷是利用数以千计的廉价机器为MapReduce提供底层可靠且高性能的分布式数据存储，以应对海量离线数据存储与处理的应用场景，比如存储应用程序持续产生的日志流以提供离线日志分析。由此，其设计目标为容错可靠(fault tolerance)、高性能读写(high-performance read&write)以及节约网络带宽(save bandwidth)。 组件故障是常态（the norm rather than the exception）。该文件系统由数百甚至数千台存由廉价普通（commodity）硬件组装的存储机器，并且被大量的客户机器访问。组件的数量和质量几乎保证了任何时间都有一些组件失效甚至有些无法从当前错误中恢复。我们见过由应用bugs，操作系统bugs和人为错误，还有硬盘错误，内存，连接器，网络和电源供应引起的问题。因此，持续监控，错误探测，容错和自动恢复必须集成到系统中。 传统标准下文件都很大。GB级的文件很常见。每个文件通常包含许多应用对象，比如Web文档。当我们通常要处理快速增长数据集组成的数十亿的对象时，不适合用数十亿大约KB大小的文件去管理。因此，设计假设和参数，例如I/O操作，块大小（blocksize）必须被重新审视（revisited）。 大部分文件是因追加数据被突变（mutated）而不是覆盖已有数据。某个文件里的随机写实践上不存在。一旦写入这些文件只会被读取而且经常是顺序读。多种数据都共有（share）这些特征。一些可能组成数据仓库（constitute large repositories）被数据分析程序扫描。一些可能是运行应用持续生成的数据流。一些可能是归档的数据。一些可能是一台机器产出在另一台机器同时或者后面适时（whether simultaneously or later in time）被处理的中间数据， 基于这种大文件访问模式，追加成为性能优化和原子性保证的关注点，与此同时客户端缓存数据块失去了吸引力。 ，综合设计应用和文件系统API，通过增加灵活性，对整个系统有好处。例如，我们放松了（relaxed）GFS的一致性模型来极大的简化了该文件系统且没有对应用施加繁重的负担。我们还引入了一种原子追加操作，这样多个客户端可以对同一文件并发追加，而它们之间不需要额外的同步。本文后面会详细讨论这些。 2. 设计概述 2.3. 架构 参考自理解 Google File System 以往的分布式系统，是没有中心节点的，但是在 GFS 中，我们将 Metadata（元数据，可以理解为控制信息）保存在 Master节点中，将用户需要的数据保存在 Chuck Sever 中， 这样我们可以方便的从 Master 中得知各个 Chuck Sever 的运行情况，同时 Master 不会成为制约这个系统的瓶颈，而且我们可以使用廉价的普通硬件作为 Chuck Sever 一举多得。 系统架构 GFS将整个系统节点分为三类角色: client（客户端） GFS提供给应用程序的访问接口 Master（主服务器） GFS的管理节点，也就是主节点，负责管理整个文件系统 Chuck Sever（数据块服务器） 负责具体的数据存储工作 GFS实现机制： client 首先访问 Master节点，从 Master 那里知道，自己应该去那些 Chuck Sever 那里去读取、写入数据，然后 client 再访问这个 Chuck Sever 去完成数据读写的工作。这样的设计方法实现了控制流和数据流的分离 clinet 和 Master 之间只有控制流，没有数据流，这样就极大的减轻了 Master 的负担。 client 和 Chuck Sever 之间直接传输数据流，同时由于文件被分成多个 Chuck 进行分布式存储， client 可以同时访问多个 Chuck Sever 从而使得整个系统的 I/O 高度并行，系统整体性能得到提升。 GFS特点： 采用中心服务器模型 可以方便地增加 Chuck Sever Master 可以掌握系统内所有 Chuck Sever 的情况，方便进行负载均衡。 不存在元数据的一致性问题 （解释一下，元数据就是存储在 Master 中的信息，一个系统内部会有多个 Master，这些 Master 可以看作彼此的备份。） 不缓存数据 文件操作大部分是流式读写，不存在大量重复读写，使用 Cache 对性能提高不大。 Chuck Sever 上数据存取使用本地文件系统，不用Cache 就不需要考虑缓存一致性的问题。 但是 Master 中的 metadata（元数据） 会缓存。 在用户态下实现 利用 POSIX 编程接口，提高了通用性。 Master 和 Chuck Sever 都以进程的方式运行，单个进行不影响整个操作系统。 GFS和操作系统运行在不同的空间，两者耦合性降低。 2.6. 元数据 Master存储了3种主要类型的元数据：文件和块命名空间（namespace），文件到块的映射和每个块副本的位置。所有元数据保存在master的内存中。前两种类型（namespaces和file-to-块 mapping）也会被通过记录突变（mutations）操作日志（by logging mutations to an operation log）存储在master本地磁盘和复制到远端机器。使用日志使得我们可以简单，可靠地更新master状态和在master崩溃时保持一致性。Master不持久化块位置信息。相反，它在启动时向每个块服务器询问块位置信息，和某个块服务器加入集群时询问。 2.7 一致性模型 参考自翻译2 和 理解 The Google File System GFS的宽松一致性模型支持我们的高度分布式的应用，GFS并没有采用复杂的一致性协议来保证副本数据的一致性，而是通过定义了三种不同的文件状态，并保证在这三种文件状态下，能够使得客户端看到一致的副本。三种状态描述如下： Consitent状态：当chunk被并发执行了操作后，不同的客户端看到的并发执行后的副本内容是一致的 defined状态：在文件处于consistent状态的基础上，还要保证所有客户端能够看到在此期间对文件执行的所有并发操作。即当文件操作并发执行时，如果它们是全局有序执行的（执行过程中没有被打断），则由此产生的文件状态为defined（当然也是consistent）。 undefined状态：如果并发操作文件失败，此时各客户端看到的文件内容不一致，则称文件处于undefined状态，当然也处于inconsistent状态。 文件命名空间突变（比如，文件创建）是原子的。它们只被master处理：命名空间锁保证原子性和正确性（4.1节）；master的操作日志定义全局操作顺序。 突变后文件区域状态 3. 系统交互 写入控制与数据流 我们通过跟随一次写的控制流的步骤解释这个过程: 客户端向master询问哪个块服务器握有这个块的租约和其它副本的位置。如果没有任何块有租约，master选择其中一个副本授予（未显示）。 Master回复首要副本的标识（identity）和其它副本的位置。客户端缓存这个数据用于未来的突变（mutations）。它只有当首要副本变得不可达或者回复说不再握有租约才需要再次联系master。 客户端把数据推到（push）所有的副本。这个操作客户端可以任意顺序。每个块服务器会将数据存储在内部的LRU缓冲缓存直到数据被使用或者老化。通过数据流与控制流解耦，我们可以通过基于网络拓扑调度繁重的数据流而不管哪个块服务器是首要的来改善性能。3.2节会进一步讨论这些。 一旦所有的副本确认收到数据，客户端发送写请求给primary。这个请求标识（identifies）了之前推送到所有副本的数据。Primary给所有收到的突变赋予连贯有序的序号，提供了必要的序列化。它序号应用突变到本地状态。 Primary转发了写请求给所有的二级副本（secondary replicas）。每个副本按照Primary分配的相同序号实施突变。 所有副本回复Primary操作已经完成。 Primary回复客户端。任何副本上的任何错误都会报告给客户端。如果出现错误，primary和任意二级副本子集可能已经被成功写入。（如果写操作在primary上就已经失败了，它就不会被分配序列号和转发。）客户端请求被认为失败了，修改的区域处于不一致状态。我们的客户端代码通过重试失败的突变来处理这样的错误。在重试整个写之前，它会重试步骤(3)到步骤(7)。 如果应用的写很大或者跨块边界，GFS客户端会将其分解成多个写操作。它们都遵循上面所述控制流，但是可能被其它客户端的并发操作交错（interleaved）或者重写（overwritten）。因此，共享文件区域最终可能包含来自不同客户端的片段，虽然这些副本将会是一致的，因为各个操作是完全成功的且在所有副本上是相同顺序的。这使得文件区域处于2.7节所定义的一致但是未定义的状态（consistent but undefined）。 值得注意的技术：记录追加（record append），快照 4. master 节点操作 Master执行所有命名空间操作。 此外，它还管理整个系统中的块复制：它进行放置决策，创建新块及其副本，并协调各种系统范围的活动以保持块完全复制，平衡所有块服务器的负载，并回收未使用的存储。 我们现在讨论这些主题。 命名空间管理和锁：许多Master操作可能需要很长时间：例如，快照操作必须撤消快照覆盖的所有块上的块服务器租约。 我们不希望在运行时推迟其它Master操作。 因此，我们允许多个操作处于活动状态，并在命名空间的区域上使用锁定以确保正确的序列化。 副本放置：最大限度地提高数据的可靠性和可用性，并最大化网络带宽利用率。 垃圾回收：文件被删除后，GFS不会立即回收可用的物理存储。它只惰性地在文件和块级别的常规垃圾收集期间这样做。我们发现这个方法让系统更简单，更可靠。 5. 容错和判断 参考自理解 Google File System Master 容错 Master维护文件系统所有的元数据（metadata），包括名字空间、访问控制信息、从文件到块的映射以及块的当前位置。 另外，每个 Chuck Sever 上都会保存 Chuck 副本的信息，每个 Chuck 默认有三个副本，这样当某个 Chuck 坏了之后，不会影响 Chuck 数据的读取。 当 Master 发生故障时，在磁盘数据保存完好的情况下，可以快速的恢复所有的 metadata。并且为了防止 Master 彻底死机的情况， GFS 还提供了 Master 的远程备份。 Chuck Sever 容错 GFS采用副本的方式实现Chunk Server的容错 每一个Chunk有多个存储副本（默认为三个） 对于每一个Chunk，必须将所有的副本全部写入成功，才视为成功写入 相关的副本出现丢失或不可恢复等情况，Master自动将该副本复制到其他 Chunk Server GFS中的每一个文件被划分成多个Chunk，Chunk的默认大小是64MB 每一个Chunk以Block为单位进行划分，大小为64KB，每一个Block对应一个 32bit 的校验和 开源技术 HDFS Colossus 背景 Colossus 的一些背景知识： 它是下一代 GFS。 其设计增强了存储可扩展性并提高了可用性，以应对数量不断增长的应用程序的大量数据需求。 Colossus 引入了分布式元数据模型，该模型提供了更具可扩展性和高可用性的元数据子系统。 Colossus 架构图 Client Library：客户端库是应用程序或服务与 Colossus 交互的方式，也是整个文件系统中最复杂的部分。 Colossus Control Plane：可扩展的元数据服务，它由许多 Curator 组成。客户直接与策展人交谈以进行控制操作，例如文件创建，并且可以水平扩展。 Metadata database：Curators 将文件系统元数据存储在 Google 的高性能 NoSQL 数据库BigTable 中。构建 Colossus 的最初动机是为了解决我们在尝试适应与搜索相关的元数据时使用 Google 文件系统 (GFS) 遇到的扩展限制。 D File Servers：Colossus 还最大限度地减少了网络上数据的跃点数。 Custodians：在维护数据的持久性和可用性以及整体效率、处理磁盘空间平衡和 RAID 重建等任务方面发挥着关键作用。 简单理解 参考自Google Spanner原理：地球上最大的单一数据库 2013年Google提出的下一代文件系统，而关于Colossus目前为止还没有相关的论文，网上只有一些零散介绍：Colossus。 Colossus也是一个不得不提起的技术。他是第二代GFS，对应开源世界的新HDFS。GFS是著名的分布式文件系统。初代GFS是为批处理设计的。对于大文件很友好，吞吐量很大，但是延迟较高。所以使用他的系统不得不对GFS做各种优化，才能获得良好的性能。那为什么Google没有考虑到这些问题，设计出更完美的GFS ?因为那个时候是2001年，Hadoop出生是在2007年。如果Hadoop是世界领先水平的话，GFS比世界领先水平还领先了6年。 Colossus是第二代GFS。Colossus是Google重要的基础设施，因为他可以满足主流应用对FS的要求。Colossus的重要改进有： 优雅Master容错处理 (不再有2s的停止服务时间) Chunk大小只有1MB (对小文件很友好) Master可以存储更多的Metadata(当Chunk从64MB变为1MB后，Metadata会扩大64倍，但是Google也解决了) Colossus可以自动分区Metadata。使用Reed-Solomon算法来复制，可以将原先的3份减小到1.5份，提高写的性能，降低延迟。客户端来复制数据。具体细节未开源。 MapReduce MapReduce是一个编程模型，也是一个处理和生成超大数据集的算法模型的相关实现。用户首先创建一个Map函数处理一个基于 key/value pair的数据集合，输出中间的基于key/value pair的数据集合；然后再创建一个Reduce函数用来合并所有的具有相同中间key值的中间value值。 MapReduce架构的程序能够在大量的普通配置的计算机上实现并行化处理。这个系统在运行时只关心：如何分割输入数据，在大量计算机组成的 集群上的调度，集群中计算机的错误处理，管理集群中计算机之间必要的通信。采用MapReduce架构可以使那些没有并行计算和分布式处理系统开发经验的 程序员有效利用分布式系统的丰富资源。 MapReduce: Simplified Data Processing on Large Clusters 原文 翻译 原文简要目录结构： 介绍 编程模型 实现 简要理解 介绍 大数据的数据处理一般在概念上容易理解，然后由于输入的数据量巨大，因此想要在可接受的时间内完成运算，只有将这些计算分布在成百上千的主机上。如何处理并行计算、如何分发数据、如何处理错误？所有这些问题综合在一起，需要大量的代码处理，因此也使得原本简单的运算变得难以处理 为了解决上述复杂的问题，我们设计一个新的抽象的问题，使用这个抽象模型，我们摘要表述我们想要执行的简单运算即可，而不必关心并行计算、容错、数据分布、负载均衡等复杂的细节，这些问题都被封装在一个库里面。 大多数运算都包含这样的操作：在输入数据的“逻辑”记录上应用 Map 操作得到一个中间 key/value pair 集合，然后在所有具有相同 key 值的 value 值上应用 Reduce 操作，从而达到合并中间的数据，得到一个想要的结果的目的。使用 MapReduce 模型，再结合用户实现的 Map 和 Reduce 函数，我们就可以非常容易的实现大规模并行化计算，通过 MapReduce 模型自带的 re-execution 功能，也提供了初级的容灾实现方案 MapReduce 的主要贡献是通过简单的接口来实现自动的并行化和大规模的分布式计算，通过使用 MapReduce 模型接口实现在大量普通的 PC 机上高性能计算 编程模型 MapReduce 编程模型的原理是：利用一个 key/value pair 集合来产生一个输出的 key/value pair 集合。 MapReduce 库的用户两个函数表达这个计算：Map 和 Reduce，用户自定义的 Map 函数接受一个输入的 key/value pair 值，然后产生一个中间 key/value pair 值的集合。 MapReduce 库把所有具有相同中间 key 值的中间 value值集合在一起后传递给 Reduce 函数 eg: map(String key, String value): // key: document name // value: document contents for each word w in value: EmitIntermediate(w, “1″); reduce(String key, Iterator values): // key: a word // values: a list of counts int result = 0; for each v in values: result += ParseInt(v); Emit(AsString(result)); 实现 MapReduce 模型有多种实现方式，如何正确选择取决于具体的环境： 小型的共享内存式的机器 大型 NUMA 架构的多处理器的主机 大型的网络连接集群 执行概况 操作流程： 用户程序首先调用 MapReduce 库将输入文件分成 M 个数据片度，每个数据片段的大小一般从 16 MB 到 64 MB，然后用户程序在集群中创建大量的程序副本 这些程序副本中的有一个特殊的程序——master。副本中其它程序都是 worker 程序，由 master 分配任务，有 M 个 Map 任务和 R 个 Reduce 任务被分配， master 将一个 Map 任务或 Reduce 任务分配一个空闲的 worker 被分配了 map 任务的 worker 程序读取相关的输入数据片段，从输入的数据片段中解析出 key/value pair，然后把 key/value pair 传递给用户自定义的 Map 函数，由 Map 函数生成并输出中间 key/value pair，并缓存在内存中 缓存中的 key/value pair 通过分区函数分成 R 个区域，之后中周期性的写入到本地磁盘上。缓存的 key/value pair 在本地磁盘上的存储位置将被回传给 master，由 master 负责把这些存储位置再传送给 Reduce worker 当 Reduce worker 程序接收到master程序发来的数据存储位置信息后，适用 RPC 从 Map worker 所在的主机的磁盘上读取这些缓存数据。当 Reduce worker 读取了所有的中间数据，通过对 key 进行排序后使得具有相同 key 值的数据聚合在一起。 Reduce worker 程序遍历排序后的中间数据，对于每一个唯一的中间 key 值，Reduce worker 程序将这个 key 值和它相关的种中间 value 值的集合传递给用户定义的 Reduce 函数。Reduce 函数的输出被追加到所属分区的输出文件 当所有的 Map 和 Reduce 任务都完成之后，master 唤醒用户程序 Master 数据结构：Master持有一些数据结构，它存储每一个 Map 和 Reduce 任务的状态（空闲、工作中或完成），以及 Worker 机器（非空闲任务的机器）的标识。Master 就像一个数据管道，中间文件存储区域的位置信息通过这个管道从 Map 传递给 Reduce，因此对于每个已经完成 Map 任务，Master存储了 Map 任务产生的 R 个中间文件存储区域的大小和位置。当 Map 任务完成时，Master 接收到位置和大小爱的更新信息，这些信息被逐步递增的推送给那些正在工作的 Reduce 工作 存储位置 在我们的计算运行环境中，网络带宽是一个相当匮乏的资源。我们通过尽量把输入数据(由GFS管理)存储在集群中机器的本地磁盘上来节省网络带 宽。GFS把每个文件按64MB一个Block分隔，每个Block保存在多台机器上，环境中就存放了多份拷贝(一般是3个拷贝)。MapReduce的 master在调度Map任务时会考虑输入文件的位置信息，尽量将一个Map任务调度在包含相关输入数据拷贝的机器上执行；如果上述努力失败 了，master将尝试在保存有输入数据拷贝的机器附近的机器上执行Map任务(例如，分配到一个和包含输入数据的机器在一个switch里的 worker机器上执行)。当在一个足够大的cluster集群上运行大型MapReduce操作的时候，大部分的输入数据都能从本地机器读取，因此消耗 非常少的网络带宽。 结束语 MapReduce编程模型在Google内部成功应用于多个领域。我们把这种成功归结为几个方面：首先，由于MapReduce封装了并行处 理、容错处理、数据本地化优化、负载均衡等等技术难点的细节，这使得MapReduce库易于使用。即便对于完全没有并行或者分布式系统开发经验的程序员 而言；其次，大量不同类型的问题都可以通过MapReduce简单的解决。比如，MapReduce用于生成Google的网络搜索服务所需要的数据、用 来排序、用来数据挖掘、用于机器学习，以及很多其它的系统；第三，我们实现了一个在数千台计算机组成的大型集群上灵活部署运行的MapReduce。这个 实现使得有效利用这些丰富的计算资源变得非常简单，因此也适合用来解决Google遇到的其他很多需要大量计算的问题。 我们也从MapReduce开发过程中学到了不少东西。首先，约束编程模式使得并行和分布式计算非常容易，也易于构造容错的计算环境；其次，网络带 宽是稀有资源。大量的系统优化是针对减少网络传输量为目的的：本地优化策略使大量的数据从本地磁盘读取，中间文件写入本地磁盘、并且只写一份中间文件也节 约了网络带宽；第三，多次执行相同的任务可以减少性能缓慢的机器带来的负面影响（alex注：即硬件配置的不平衡），同时解决了由于机器失效导致的数据丢失问题。 开源技术 Hadoop Mapreduce Spark Percolator/Dremel BigTable Bigtable是一个分布式的结构化数据存储系统，它被设计用来处理海量数据：通常是分布在数千台普通服务器上的PB级的数据。Google的很 多项目使用Bigtable存储数据，包括Web索引、Google Earth、Google Finance。这些应用对Bigtable提出的要求差异非常大，无论是在数据量上（从URL到网页到卫星图像）还是在响应速度上（从后端的批量处理到 实时数据服务）。尽管应用需求差异很大，但是，针对Google的这些产品，Bigtable还是成功的提供了一个灵活的、高性能的解决方案。利用这个模型，用户可以动态的控制数据的分布和格式。 通常GFS用于存储海量数据，文件系统将数据在各个节点冗余复制。在某种程度上MapReduce可以对GFS进行补充，以便充分利用GFS中廉价的服务器所提供的CPU。和GFS一起构成了处理海量数据的核心力量，构建类似于Google的搜索索引也是一样的。但是这两个系统都缺乏实时随机存取数据的能力，在web应用处理方面还有所欠缺。 Bigtable: A Distributed Storage System for Structured Data 原文 翻译 原文简要目录结构： 介绍 数据模型 BigTable 构件 实施 5.1 Tablet的位置 5.2 Tablet 分配 5.3 Tablet 服务 结果感言 1. 介绍 Bigtable已经在超过60个Google的产品和项目上得到了应用，包括 Google Analytics、Google Finance、Orkut、PersonalizedSearch、Writely和Google Earth。这些产品对Bigtable提出了迥异的需求，有的需要高吞吐量的批处理，有的则需要及时响应，快速返回数据给最终用户。它们使用的Bigtable集群的配置也有很大的差异，有的集群只有几台服务器，而有的则需要上千台服务器、存储几百TB的数据。 在很多方面，Bigtable 和数据库很类似，它使用了很多数据库的实现策略。并行数据库和内存数据库，已经具备高可扩展性和高性能，但是 Bigtable 不支持完整的关系型数据模型，与之相反，Bigtable 为客户提供了简单的数据模型，利用这个模型，客户可以动态控制数据的分布和格式。数据的下标是行和列的名字，名字可以是任意的字符串。Bigtable将存储的数据都视为字符串，但是Bigtable本身不去解析这些字符串，通常客户程序会把各种结构化或者半结构化的数据串行化到这些字符串里。通过仔细选择数据的模式，客户可以控制数据的位置相关性。最后，可以通过BigTable的模式参数来控制数据是存放在内存中还是硬盘上 2. 数据模型 Bigtable 是一个稀疏的、分布式的、持久化存储的多维度排序Map，索引key 是行关键字、列关键字和时间戳，值value是一个未经解析的byte数组 (row:string,column:string,time:int64)->string 这里最重要的就是 row 的值，它的长度最大可以为 64KB，对于同一 row 下数据的读写都可以看做是原子的；因为 Bigtable 是按照 row 的值使用字典顺序进行排序的，每一段 row 的范围都会被 Bigtable 进行分区，并交给一个 tablet 进行处理。 Rows 可以是任意的字符串（最大支持 64 kb，但是对大多数用户，10-100个字节就足够了）。对同一个行关键字的读或者写操作都是原子的，这个设计决策能够使用户很容易的理解程序在对同一个行进行并发更新操作的行为 Bigtable 通过行关键字的字典顺序来组织数据。表中的每个行都可以动态分区，每个分区叫做一个\"Tablet\"，Tablet 是数据分布和负载均衡的最小单位 Cols 列是访问控制的基本单位。存放在同一列簇下的所有数据通常都属于同一类型（我们可以把同一列簇下的数据压缩在一起）。列簇在使用之前必须先创建，然后才能在列簇中任何的列关键字下存放数据。列簇创建后，其中的任何一个列关键字下都可以存放数据 Timestamps 在Bigtable 中，表中的每一个数据项都可以包含同一份数据的不同版本，不同版本的数据通过时间戳来索引。Bigtable时间戳的类型是64位整型， 4. 基础组成 BIgtable 是建立在其它的几个 Google 基础构件之上的。BigTable 使用 Google 的分布式文件系统（GFS）存储日志文件和数据文件。BigTable 集群通常运行在一个共享的机器池中，池中的机器还会运行其它的各种各样的分布式应用程序，BigTable的进程通常要和其它应用的进程共享机器。BigTable 依赖集群管理系统来调度任务、管理共享机器上的资源，处理机器的故障以及监视机器的状态 BigTable内部存储数据的文件是GoogleSSTable格式的。SSTable是一个持久化的、排序的、不可更改的Map结构，而Map是一个key-value 映射的数据结构，key和value的值都是任意的Byte串。可以对SSTable进行如下的操作：查询与一个key值相关的value，或者遍历某个 key值范围内的所有的key-value对。从内部看，SSTable是一系列的数据块（通常每个块的大小是64KB，这个大小是可以配置的）。 SSTable使用块索引（通常存储在SSTable的最后）来定位数据块；在打开SSTable的时候，索引被加载到内存。每次查找都可以通过一次磁盘 搜索完成：首先使用二分查找法在内存中的索引里找到数据块的位置，然后再从硬盘读取相应的数据块。也可以选择把整个SSTable都放在内存中，这样就不 必访问硬盘了。 BigTable还依赖一个高可用的、序列化的分布式锁服务组件，叫做Chubby【8】。一个Chubby服务包括了5个活动的副本，其中的一个副本被选为Master，并且处理请求。只有在大多数副本都是正常运行的，并且彼此之间能够互相通信的情况下，Chubby服 务才是可用的。当有副本失效的时候，Chubby使用Paxos算法【9,23】来保证副本的一致性。Chubby提供了一个名字空间，里面包括了目录和 小文件。每个目录或者文件可以当成一个锁，读写文件的操作都是原子的。Chubby客户程序库提供对Chubby文件的一致性缓存。每个Chubby客户 程序都维护一个与Chubby服务的会话。如果客户程序不能在租约到期的时间内重新签订会话的租约，这个会话就过期失效了(alex注：又用到了lease。原文是：Aclient’s session expires if it is unable to renew its session lease within the leaseexpiration time.)。当一个会话失效时，它拥有的锁和打开的文件句柄都失效了。Chubby客户程序可以在文件和目录上注册回调函数，当文件或目录改变、或者会 话过期时，回调函数会通知客户程序。 5. Tablet Location BigTable 包括了三个主要的组件：链接到客户程序中的库、一个Master 服务器和多个 Tablet 服务器。针对系统工作负载的情况，BigTable 可以动态的向集群中添加（或者删除）Tablet 服务器 Master服务器主要负责以下工作：为Tablet服务器分配Tablets、检测新加入的或者过期失效的Table服务器、对Tablet服务器进行负载均衡、以及对保存在GFS上的文件进行垃圾收集。除此之外，它还处理对模式的相关修改操作，例如建立表和列族。 每个Tablet服务器都管理一个Tablet的集合（通常每个服务器有大约数十个至上千个Tablet）。每个Tablet服务器负责处理它所加载的Tablet的读写操作，以及在Tablets过大时，对其进行分割。 一个BigTable集群存储了很多表，每个表包含了一个Tablet的集合，而每个Tablet包含了某个范围内的行的所有相关数据。初始状态 下，一个表只有一个Tablet。随着表中数据的增长，它被自动分割成多个Tablet，缺省情况下，每个Tablet的尺寸大约是100MB到 200MB。 Tablet 的位置信息 Tablet 的层次结构 第一层是一个存储在Chubby中的文件，它包含了Root Tablet的位置信息。Root Tablet包含了一个特殊的METADATA表里所有的Tablet的位置信息。METADATA表的每个Tablet包含了一个用户Tablet的集合。RootTablet实际上是METADATA表的第一个Tablet，只不过对它的处理比较特殊 — Root Tablet永远不会被分割 — 这就保证了Tablet的位置信息存储结构不会超过三层。 在METADATA表里面，每个Tablet的位置信息都存放在一个行关键字下面，而这个行关键字是由Tablet所在的表的标识符和Tablet 的最后一行编码而成的。METADATA的每一行都存储了大约1KB的内存数据。在一个大小适中的、容量限制为128MB的METADATA Tablet中，采用这种三层结构的存储模式，可以标识2^34个Tablet的地址 Tablet 管理 既然在整个 Bigtable 中有着海量的 tablet 服务器以及数据的分片 tablet，那么 Bigtable 是如何管理海量的数据呢？Bigtable 与很多的分布式系统一样，使用一个主服务器将 tablet 分派给不同的服务器节点。 为了减轻主服务器的负载，所有的客户端仅仅通过 Master 获取 tablet 服务器的位置信息，它并不会在每次读写时都请求 Master 节点，而是直接与 tablet 服务器相连，同时客户端本身也会保存一份 tablet 服务器位置的缓存以减少与 Master 通信的次数和频率。 读和写请求 从读写请求的处理，我们其实可以看出整个 Bigtable 中的各个部分是如何协作的，包括日志、memtable 以及 SSTable 文件。 当有客户端向 tablet 服务器发送写操作时，它会先向 tablet 服务器中的日志追加一条记录，在日志成功追加之后再向 memtable 中插入该条记录；这与现在大多的数据库的实现完全相同，通过顺序写向日志追加记录，然后再向数据库随机写，因为随机写的耗时远远大于追加内容，如果直接进行随机写，由于随机写执行时间较长，在写操作执行期间发生设备故障造成数据丢失的可能性相对比较高。 当 tablet 服务器接收到读操作时，它会在 memtable 和 SSTable 上进行合并查找，因为 memtable 和 SSTable 中对于键值的存储都是字典顺序的，所以整个读操作的执行会非常快。 表的压缩 随着写操作的进行，memtable 会随着事件的推移逐渐增大，当 memtable 的大小超过一定的阈值时，就会将当前的 memtable 冻结，并且创建一个新的 memtable，被冻结的 memtable 会被转换为一个 SSTable 并且写入到 GFS 系统中，这种压缩方式也被称作 Minor Compaction。 每一个 Minor Compaction 都能够创建一个新的 SSTable，它能够有效地降低内存的占用并且降低服务进程异常退出后，过大的日志导致的过长的恢复时间。既然有用于压缩 memtable 中数据的 Minor Compaction，那么就一定有一个对应的 Major Compaction 操作。 Bigtable 会在后台周期性地进行 Major Compaction，将 memtable 中的数据和一部分的 SSTable 作为输入，将其中的键值进行归并排序，生成新的 SSTable 并移除原有的 memtable 和 SSTable，新生成的 SSTable 中包含前两者的全部数据和信息，并且将其中一部分标记为删除的信息彻底清除。 Google Earth Google通过一组服务为用户提供了高分辨率的地球表面卫星图像，访问的方式可以使通过基于Web的Google Maps访问接口（maps.google.com），也可以通过Google Earth定制的客户端软件访问。这些软件产品允许用户浏览地球表面的图像：用户可以在不同的分辨率下平移、查看和注释这些卫星图像。这个系统使用一个表 存储预处理数据，使用另外一组表存储用户数据。 数据预处理流水线使用一个表存储原始图像。在预处理过程中，图像被清除，图像数据合并到最终的服务数据中。这个表包含了大约70TB的数据，所以需要从磁盘读取数据。图像已经被高效压缩过了，因此存储在Bigtable后不需要再压缩了。 Imagery表的每一行都代表了一个单独的地理区域。行都有名称，以确保毗邻的区域存储在了一起。Imagery表中有一个列族用来记录每个区域 的数据源。这个列族包含了大量的列：基本上市每个列对应一个原始图片的数据。由于每个地理区域都是由很少的几张图片构成的，因此这个列族是非常稀疏的。 数据预处理流水线高度依赖运行在Bigtable上的MapReduce任务传输数据。在运行某些MapReduce任务的时候，整个系统中每台Tablet服务器的数据处理速度是1MB/s。 这个服务系统使用一个表来索引GFS中的数据。这个表相对较小（大约是500GB），但是这个表必须在保证较低的响应延时的前提下，针对每个数据中心，每秒处理几万个查询请求。因此，这个表必须在上百个Tablet服务器上存储数据，并且使用in-memory的列族。 开源技术 LevelDB LevelDB 是对 Bigtable 论文中描述的键值存储系统的单机版的实现，它提供了一个极其高速的键值存储系统，并且由 Bigtable 的作者 Jeff Dean 和 Sanjay Ghemawat 共同完成，可以说高度复刻了 Bigtable 论文中对于其实现的描述。 Hbase F1 Spanner Spanner 参考自Google Spanner原理：地球上最大的单一数据库 Spanner 是Google的全球级的分布式数据库 (Globally-Distributed Database) 。Spanner的扩展性达到了令人咋舌的全球级，可以扩展到数百万的机器，数已百计的数据中心，上万亿的行。更给力的是，除了夸张的扩展性之外，他还能同时通过同步复制和多版本来满足外部一致性，可用性也是很好的。冲破CAP的枷锁，在三者之间完美平衡。 Spanner是个可扩展，多版本，全球分布式还支持同步复制的数据库。他是Google的第一个可以全球扩展并且支持外部一致的事务。Spanner能做到这些，离不开一个用GPS和原子钟实现的时间API。这个API能将数据中心之间的时间同步精确到10ms以内。因此Spanner是个可扩展，多版本，全球分布式还支持同步复制的数据库。他是Google的第一个可以全球扩展并且支持外部一致的事务。Spanner能做到这些，离不开一个用GPS和原子钟实现的时间API。这个API能将数据中心之间的时间同步精确到10ms以内。因此有几个给力的功能：无锁读事务，原子schema修改，读历史数据无block。有几个给力的功能：无锁读事务，原子schSpanner是个可扩展，多版本，全球分布式还支持同步复制的数据库。他是Google的第一个可以全球扩展并且支持外部一致的事务。Spanner能做到这些，离不开一个用GPS和原子钟实现的时间API。这个API能将数据中心之间的时间同步精确到10ms以内。因此有几个给力的功能：无锁读事务，原子schema修改，读历史数据无block。Spanner是个可扩展，多版本，全球分布式还支持同步复制的数据库。他是Google的第一个可以全球扩展并且支持外部一致的事务。Spanner能做到这些，离不开一个用GPS和原子钟实现的时间API。这个API能将数据中心之间的时间同步精确到10ms以内。因此有几个给力的功能：无锁读事务，原子schema修改，读历史数据无block。Spanner是个可扩展，多版本，全球分布式还支持同步复制的数据库。他是Google的第一个可以全球扩展并且支持外部一致的事务。Spanner能做到这些，离不开一个用GPS和原子钟实现的时间API。这个API能将数据中心之间的时间同步精确到10ms以内。因此有几个给力的功能：无锁读事务，原子schema修改，读历史数据无block。ema修改，读历史数据无block。 Spanner: Google’s Globally-Distributed Database 原文 翻译 Spanner是一个可伸缩、全球化分布的数据库，其由Google设计、构建、并部署。在抽象的最高层，Spanner是一个将数据分片（shard）到分布在全世界的多个数据中心中的跨多个Paxos[21]状态机集合上的数据库。Spanner采用多副本以提供全球化的可用性和地理位置优化；客户端自动地在副本间进行故障转移。在数据总量或服务器的数量变化时，Spanner自动地在机器间重分片数据，并自动地在机器间（甚至在数据中心间）迁移数据来平衡负载和应对故障。按照设计，Spanner扩展到跨数百个数据中心的数百万台机器与数万亿个数据库行。 Borg Kubernetes Flume 开源技术 大数据中台 发展阶段 1、单一系统 2、分布式系统 3、平台化（服务业务，支撑作用） 4、中台化（驱动业务，中枢作用） 单一系统 数据仓库，数据库 分布式系统 上述三篇论文提出一种面向海量数据分析、面向海量异构数据的统御i计算和存储方法，奠定了现代大数据、大规模并行计算的基础。Yahoo对此做了开源实现，就是现在的 Hadoop 演变关系： GFS—->HDFS(2004) Google MapReduce—->Hadoop MapReduce (2004)--> Spark (2014) BigTable—->HBase(2008) 随着Hadoop技术日趋成熟，2010年提出一个新的概念：数据湖（Data Lake）是一个以原始格式存储数据的存储库或系统 2018年提出数据河的概念，避免“数据湖”成为“数据沼泽”，流动的“数据河”是关键。因为大部分使用数据湖的企业在数据真的需要使用的时候，往往因为数据湖中的数据质量太差而无法最终使用。数据只有流动起来，才可以不成为数据沼泽，湖泊只是暂存数据河流的基地。数据流动就意味着所有的数据产生，最终要有它的耕种者和使用者。要让数据有效流动起来，就要建立有效的“数据河”（Data River）。数据河（Data River）就是在由源头产生清晰干净的有效数据（去ETL化，数据源头业务就像生态水源一样，不让污水流下去），通过各个河流网，流向各个数据消费端的架构。 数据工厂时代：大数据平台 大数据平台是面向数据研发场景的，覆盖数据研发的完整链路的数据工作台。就是为了提高数据研发的效率，降低数据研发的门槛，让数据能够在一个设备流水线上快速地完成加工。 大数据平台按照使用场景，分为数据集成、数据开发、数据测试……任务运维，大数据平台的使用对象是数据开发。大数据平台的底层是以 Hadoop 为代表的基础设施，分为计算、资源调度和存储等。 数据存储：HDFS，HBase，Kudu等 数据计算：MapReduce, Spark, Flink 交互式查询：Impala, Presto 在线实时分析：ClickHouse，Kylin，Doris，Druid，Kudu等 资源调度：YARN，Mesos，Kubernetes 任务调度：Oozie，Azakaban，AirFlow等 .... 数据收集，数据迁移，服务协调，安装部署，数据治理等 大数据平台像一条设备流水线，经过大数据平台的加工，原始数据变成了指标，出现在各个报表或者数据产品中。 数据价值时代：数据中台 在应用大数据平台架构的时候，你可能遇到这么个问题：因为烟囱式的开发，不同数据应用可能存在相同应用指标，但是运营可能发现这些数据指标的结果不一致，因为不知道该用谁信任谁而导致运营对数据的信任下降。 数据割裂的另外一个问题，就是大量的重复计算、开发，导致的研发效率的浪费，计算、存储资源的浪费，大数据的应用成本越来越高。 如果你是运营，当你想要一个数据的时候，开发告诉你至少需要一周，你肯定想是不是太慢了，能不能再快一点儿？ 如果你是数据开发，当面对大量的需求的时候，你肯定是在抱怨，需求太多，人太少，活干不完。 如果你是一个企业的老板，当你看到每个月的账单成指数级增长的时候，你肯定觉得这也太贵了，能不能再省一点，要不吃不消了。 这些问题的根源在于，数据无法共享。 2016 年，阿里巴巴率先提出了“大中台，小前台”战略，推出了数据中台。数据中台的核心，是避免数据的重复计算，通过数据服务化，提高数据的共享能力，赋能数据应用。之前，数据是要啥没啥，中间数据难于共享，无法积累。现在建设数据中台之后，要啥有啥，数据应用的研发速度不再受限于数据开发的速度，然后我们就可以根据需求场景，快速孵化出很多数据应用，这些应用让数据产生价值。 总的来说，数据中台吸收了传统数据仓库、数据湖、大数据平台的优势，同时又解决了数据共享的难题，通过数据应用，实现数据价值的落地。 2016 年，阿里巴巴就提出了数据中台建设的核心方法论：OneData 和 OneService，OneData 就是所有数据只加工一次OneService，数据即服务，强调数据中台中的数据应该是通过 API 接口的方式被访问。 现阶段企业数据应用现状： 数据量小的使用 MySQL：Hive数仓，Spark计算引擎的计算结果导出到MySQL 数据量大的使用HBase + ElasticSearch：解决海量数据中的低延迟高效查询 需要多维分析的可能需要 ClickHouse，Kylin，Greenplum：提供现在分析能力 实时性要求高的需要用到 Redis 网易数据中台 发展 谷歌新一代搜索引擎平台和大数据分析核心技术 Google是GFS MapReduce BigTable的缔造者，但Google 新一代搜索引擎平台正逐步用更强计算能力的系统来替换原有系统，新一代搜索引擎平台有几个核心技术系统： 于Percolator的增量处理索引系统来取代MapReduce批处理索引系统，这个索引系统被称作Caffeine，它比MapReduce批处理索引系统搜索更快。 是专为BigTable设计的分布式存储Colossus，也被称为GFS2（二代Google文件系统），它专为建立Caffeine搜索索引系统而用。 是列存储数据库BigTable，但为了更好地支持大数据集的互动分析，Google推出了Dremel和PowerDrill。Dremel被设计用来管理非常大量的大数据集（指数据集的数量和每数据集的规模都大），而PowerDrill则设计用来分析少量的大数据集（指数据集的规模大，但数据集的数量不多）时提供更强大的分析性能。 Google Instant提供服务的实时搜索引擎存储和分析架构 是Pregel，这是谷歌更快捷的网络和图算法。 　　在谷歌新一代搜索引擎平台上，每月40亿小时的视频，4.25亿Gmail用户，150,000,000 GB Web索引，却能实现0.25秒搜索出结果 Google基础云服务 基于Colossus，谷歌为用户提供计算、存储和应用的云服务。计算服务包括计算的引擎（ComputeEngine）和应用APP的引擎(AppEngine)；存储服务包括云存储（CloudStorge）、云SQL(CLoudSQL)、云数据存储（Cloud DataStore）、永久磁盘等服务；云应用服务包括BigQuery、云终端（Cloud Endpoints）、缓冲、队列等 "},"bigData/Hadoop.html":{"url":"bigData/Hadoop.html","title":"Hadoop","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 初学者指南 前言 1. 说明这一切是怎么回事 Hadoop [toc] 初学者指南 地址是 hadoop 初学者指南 前言 以前大型数据集应用复杂分析的能力曾经是大公司和政府机构的专利，但是现在可以通过免费的开源软件（OSS）实现。但由于这一领域似乎很复杂，变化速度也很快，掌握基础知识可能会有点令人望而生畏。这就是这本书的用武之地，它会告诉你 Hadoop 是什么，它是如何工作的，以及你如何使用它从数据中提取价值。 除了对核心 Hadoop 的解释之外，我们还花了几章来探索使用 Hadoop 或与之集成的其它技术。我们的目标不仅是让你了解 Hadoop 是什么，还希望你了解更广泛的技术基础设施的一部分来使用。一种补充技术是使用云计算，特别是亚马逊 Web 服务。在整本书中，将会展示如何使用这些服务来托管你的 Hadoop 工作负载，从而说明你不仅可以处理大量数据，而且实际上不需要购买任何物理硬件就可以实现这一点。 1. 说明这一切是怎么回事 Hadoop 不是在真空中创建的；相反，它的存在是因为创建和使用的数据量呈爆炸式增长，而且这种数据洪流不仅出现在大型跨国公司身上，还出现在小型初创公司身上。 与此同时，其他趋势也改变了软件和系统的部署方式，与更传统的基础设施一起使用云资源，甚至优先使用云资源。 "},"bigData/MinIO.html":{"url":"bigData/MinIO.html","title":"MinIO","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 服务器 部署 为什么说 MinIO 是云原生（cloud-native）的 部署的时候碰到的坑 客户端 SDKS 搭建图床 搭建图床成功 MinIO MinIO MinIO 是兼容 AWS S3 云存储服务的高性能对象存储，为机器学习、分析和应用程序的数据共奏负载构建高性能基础架构 服务器 部署 MinIO 是一个云原生的应用程序，旨在 多租户 环境中以可持续的方式进行扩展。编排（orchestration）平台为 MinIO 的扩展提供了非常好的支撑，MinIO 支持的 orchestration 平台： Docker Swarm Docker Compose Kubernetes DC/OS 为什么说 MinIO 是云原生（cloud-native）的 云原生这个词代表的是一些思想的集合，比如微服务部署，可伸缩，而不是说把一个单体应用改造成容器部署。一个云原生的应用在设计时就考虑了移植性和可伸缩性，而且可以通过简单的复制即可实现水平扩展，现在兴起的编排平台，如 Swarm， Kubernetes 以及 DC/OS，让大规模集群的复制和管理变得前所未有的简单。 容器提供了隔离的应用执行环境，编排平台通过容器管理以及复制功能提供了无缝扩展，MinIO 继承了这些，针对每个租户提供了存储环境的隔离。 MinIO 是建立在云原生的基础上，有纠删码、分布式和共享存储这些特性。MinIO专注于并且只专注于存储，而且做的还不错，它通过编排平台复制一个 MinIO 实例就实现了水平扩展 部署的时候碰到的坑 9000 和 9001 没有区分开，腾讯云开放了9000的端口，但是我们实际上访问的端口是 9001 启动的时候必须指定端口，否则会是一个动态的端口 docker 和 普通的部署并没有什么大的不同（可能是我是单机的情况） 服务器扩容真恶心，碰到了一个问题 lgdisplay 等命令没有响应，reboot 重启并没有什么不同，这个服务器不咋用其实也没啥 客户端 MinIO Client (mc)为ls，cat，cp，mirror，diff，find等UNIX命令提供了一种替代方案。它支持文件系统和兼容Amazon S3的云存储服务（AWS Signature v2和v4）。 Copyls 列出文件和文件夹。 mb 创建一个存储桶或一个文件夹。 cat 显示文件和对象内容。 pipe 将一个STDIN重定向到一个对象或者文件或者STDOUT。 share 生成用于共享的URL。 cp 拷贝文件和对象。 mirror 给存储桶和文件夹做镜像。 find 基于参数查找文件。 diff 对两个文件夹或者存储桶比较差异。 rm 删除文件和对象。 events 管理对象通知。 watch 监听文件和对象的事件。 policy 管理访问策略。 session 为cp命令管理保存的会话。 config 管理mc配置文件。 update 检查软件更新。 version 输出版本信息 SDKS 搭建图床 搭建图床成功 利用Minio搭建私有图床 ，博主写的很好，但是没有用 nginx，好多工具感觉有坑，得慢慢踩，但是现在自己得好好学一些东西了 部署完 minIO 之后需要创建一个自己的桶（bulket），然后设置为 public 下面的代码选择一个放到 typora 即可，建议 python 代码，这个好配置一点 js 代码 /* * typora插入图片调用此脚本，上传图片到图床 */ const path = require('path') // minio for node.js const Minio = require('minio') const { promises } = require('fs') // 解析参数， 获取图片的路径，有可能是多张图片 const parseArgv = () => { const imageList = process.argv.slice(2).map(u => path.resolve(u)) return imageList } // 入口 const uploadImageFile = async (bulkName = 'test', imageList = []) => { // 创建连接 const minioClient = new Minio.Client({ // 这里填写你的minio后台域名 endPoint: '111.229.14.128', port: 9001, useSSL: false, // 下面填写你的accessKey和secretKey accessKey: 'opengms', secretKey: 'opengms517' }) // 开始上传图片 const metaData = {} const tasks = imageList.map(image => { return new Promise(async (resolve, reject) => { try { // 图片重命名，这里采用最简单的，可以根据自己需求重新实现 const name = `${Date.now()}_${path.basename(image)}` // 具体请看Minio的API文档，这里是将图片上传到blog这个bucket上 const res = await minioClient.fPutObject(bulkName, name, image, metaData) resolve(name) } catch (err) { reject(err) } }) }) const result = await Promise.all(tasks) // 返回图片的访问链接 result.forEach(name => { const url = `http://111.229.14.128:9001//test/${name}` // Typora会提取脚本的输出作为地址，将markdown上图片链接替换掉 console.log(url) }) } // 执行脚本 uploadImageFile('test', parseArgv()) python 代码： from minio import Minio import os import time import sys minio_conf = { 'endpoint': '111.229.14.128:9001', 'access_key': 'opengms', 'secret_key': 'opengms517', 'secure': False } def update(bulkName = 'test', fileList = []): minioClient = Minio(**minio_conf) for filePath in fileList: with open(filePath, 'rb') as file: name = str(int(time.time())) + '_' + os.path.basename(filePath) file_stat = os.stat(filePath) minioClient.put_object(bucket_name=bulkName, object_name=name, data=file, length=file_stat.st_size) print('http://111.229.14.128:9001/{0}/{1}'.format(bulkName, name)) if __name__ == '__main__': print(sys.argv[1:]) update('test', sys.argv[1:]) "},"bigData/MongoDB.html":{"url":"bigData/MongoDB.html","title":"MongoDB","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 temp 简介 概念解析 数据库 document collection 基础操作 MongoDB 官方文档 introduction 入门 MongoDB [toc] temp 简介 关系数据库十分流行，遵循ACID特性。 分布式系统由多台计算机和通信的软件组件通过计算机网络连接组成。 NoSQL 用于超大规模数据的存储，数据存储不需要固定的模式，无需多余操作就可以横向扩展 RDBMS vs NoSQL RDBMS - 高度组织化结构化数据 - 结构化查询语言（SQL） (SQL) - 数据和关系都存储在单独的表中。 - 数据操纵语言，数据定义语言 - 严格的一致性 - 基础事务 NoSQL - 代表着不仅仅是SQL - 没有声明性查询语言 - 没有预定义的模式 -键 - 值对存储，列存储，文档存储，图形数据库 - 最终一致性，而非ACID属性 - 非结构化和不可预知的数据 - CAP定理 - 高性能，高可用性和可伸缩性 在计算机科学中, CAP定理（CAP theorem）, 又被称作 布鲁尔定理（Brewer's theorem）, 它指出对于一个分布式计算系统来说，不可能同时满足以下三点: 一致性(Consistency) (所有节点在同一时间具有相同的数据) 可用性(Availability) (保证每个请求不管成功或者失败都有响应) 分隔容忍(Partition tolerance) (系统中任意信息的丢失或失败不会影响系统的继续运作) 概念解析 数据库 数据库名可以是满足以下条件的任意UTF-8字符串。 不能是空字符串（\"\")。 不得含有' '（空格)、.、$、/、\\和\\0 (空字符)。 应全部小写。 最多64字节。 有一些数据库名是保留的，可以直接访问这些有特殊作用的数据库。 admin： 从权限的角度来看，这是\"root\"数据库。要是将一个用户添加到这个数据库，这个用户自动继承所有数据库的权限。一些特定的服务器端命令也只能从这个数据库运行，比如列出所有的数据库或者关闭服务器。 local: 这个数据永远不会被复制，可以用来存储限于本地单台服务器的任意集合 config: 当Mongo用于分片设置时，config数据库在内部使用，用于保存分片的相关信息。 document 文档是一组键值，文档不需要设置相同的字段，相同的字段不需要有相同的数据类型 需要注意的是： 文档中的键/值对是有序的。 文档中的值不仅可以是在双引号里面的字符串，还可以是其他几种数据类型（甚至可以是整个嵌入的文档)。 MongoDB区分类型和大小写。 MongoDB的文档不能有重复的键。 文档的键是字符串。除了少数例外情况，键可以使用任意UTF-8字符。 文档键命名规范： 键不能含有\\0 (空字符)。这个字符用来表示键的结尾。 .和$有特别的意义，只有在特定环境下才能使用。 以下划线\"_\"开头的键是保留的(不是严格要求的)。 collection 文档组 当第一个文档插入的时候，集合就会被创建 db.col.findOne() Capped collections 就是固定大小的collection，具有很高的性能， db.createCollection(\"mycoll\", {capped:true, size:100000}) 基础操作 use [name], db, show dbs, db.dropDatabase(), db.collection.drop(), db.createCollection(name, options) system.indexes, db.mycol2.drop(), MongoDB 官方文档 MongoDB introduction MongoDB 中的一条记录就是一个Documents，它是由字段和值对组成的数据结构。文档类似于 JSON 对象，字段的值包括其它document，array 用文档的优势是： Documents 对应许多编程语言中的原生数据类型 嵌入的 document 和 array 减少了 join 操作的需要 动态的数据结构支持多态性 MongoDB 将 document 存储在 collections，collections 类似于关系数据库中的表，除了 collections，MongoDB 还存储：只读 Views，On-Demand Materialized Views MongoDB 的主要特点是 MongoDB 提供高性能的数据持久化，特别是 对嵌入式数据的模型的支持减少了数据库系统上的 I/O 活动 索引支持更快的查询，并且可以包含来自嵌入式文档和数组的键 丰富的查询语言来支持 CRUD： 数据聚合 文本搜索和地理空间查询 高可用性，MongoDB 的复制工具，称为副本集，提供： 自动的故障转移 数据冗余 可扩展性，MongoDB 提供水平可扩展性作为其核心功能的一部分： 分片在一组计算机集群分布数据 MongoDB 支持基于 shard key 创建数据区域，在平衡集群中，MongoDB 将区域覆盖的读取和写入仅定向到区域内的那些分片 支持多个存储引擎 WiredTiger 存储引擎（包括对静态加密的支持） 内存存储引擎 入门 MongoDB 的云托管服务 Atlas，mongosh 一个更好用的 mongo 的命令行工具？ 基本操作 db 返回当前数据库 show collections 返回当前数据库下所有的 collection use [dbname] 切换数据库，或者创建并切换 插入 db.[collection].insertMany([...]) collection（集合）类似于关系数据库中的表，如果第一次插入没有这个集合，则会创建该集合 查找所有 db.[collection].find({}) 过滤数据，可以使用比较运算符来执行更高级的查询 db.movies.find({ \"awards.wins\" } : {$gt: 100}) db. movies.find({ \"languages\" }: {in: [\"Chiness\"]}) MongoDB 将数据记录存储为文档（特别是 BSON 文档），这些文档收集在集合中，一个数据库存储在一个文件名或更多的集合 MongoDB 视图是一个可查询的对象，其内容由其他集合或视图上的聚合管道定义。MongoDB 不会将视图内容持久化到磁盘，当客户端查询视图时，视图的内容是按需计算的。MongoDB 可以要求客户端具有查询视图的权限，MongoDB 不支持针对视图的写操作 "},"bigData/Nginx.html":{"url":"bigData/Nginx.html","title":"Nginx","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 Nginx简介 反向代理 Nginx入门 Nginx 实战 Http 反向代理 Https反向代理 负载均衡 负载均衡策略 网站有多个webapp的配置 静态站点 搭建文件服务器 解决跨域 资源 Nginx 运维 Nginx配置 Nginx github [toc] Nginx简介 Nginx（engine x）是一款轻量级的web服务器、反向代理服务器及电子邮件（IMAP/POP3）代理服务器 反向代理 反向代理（Reverse Proxy）方式是指以代理服务器来接受Internet上的连接请求，然后将请求转发给内部网络上的服务器，并将从服务器上得到的结果返回internet上请求连接的额客户端，此时代理服务器对外就表现为一个反向代理服务器 Nginx入门 nginx -s stop 快速关闭Nginx，可能不保存相关信息，并迅速终止web服务。 nginx -s quit 平稳关闭Nginx，保存相关信息，有安排的结束web服务。 nginx -s reload 因改变了Nginx相关配置，需要重新加载配置而重载。 nginx -s reopen 重新打开日志文件。 nginx -c filename 为 Nginx 指定一个配置文件，来代替缺省的。 nginx -t 不运行，仅仅测试配置文件。nginx 将检查配置文件的语法的正确性，并尝试打开配置文件 nginx -v 显示 nginx 的版本。 nginx -V 显示 nginx 的版本，编译器版本和配置参数。 如果不想每次都敲命令，可以在 nginx 安装目录下新添一个启动批处理文件startup.bat，双击即可运行。内容如下： @echo off rem 如果启动前已经启动nginx并记录下pid文件，会kill指定进程 nginx.exe -s stop rem 测试配置文件语法正确性 nginx.exe -t -c conf/nginx.conf rem 显示版本信息 nginx.exe -v rem 按照指定配置去启动nginx nginx.exe -c conf/nginx.conf Nginx 实战 Http 反向代理 不考虑复杂的配置，仅仅是完成一个http反向代理 nginx.conf(nginx 的默认配置文件) 配置文件： #运行用户 #user somebody; #启动进程,通常设置成和cpu的数量相等 worker_processes 1; #全局错误日志 error_log D:/Tools/nginx-1.10.1/logs/error.log; error_log D:/Tools/nginx-1.10.1/logs/notice.log notice; error_log D:/Tools/nginx-1.10.1/logs/info.log info; #PID文件，记录当前启动的nginx的进程ID pid D:/Tools/nginx-1.10.1/logs/nginx.pid; #工作模式及连接数上限 events { worker_connections 1024; #单个后台worker process进程的最大并发链接数 } #设定http服务器，利用它的反向代理功能提供负载均衡支持 http { #设定mime类型(邮件支持类型),类型由mime.types文件定义 include D:/Tools/nginx-1.10.1/conf/mime.types; default_type application/octet-stream; #设定日志 log_format main '[$remote_addr] - [$remote_user] [$time_local] \"$request\" ' '$status $body_bytes_sent \"$http_referer\" ' '\"$http_user_agent\" \"$http_x_forwarded_for\"'; access_log D:/Tools/nginx-1.10.1/logs/access.log main; rewrite_log on; #sendfile 指令指定 nginx 是否调用 sendfile 函数（zero copy 方式）来输出文件，对于普通应用， #必须设为 on,如果用来进行下载等应用磁盘IO重负载应用，可设置为 off，以平衡磁盘与网络I/O处理速度，降低系统的uptime. sendfile on; #tcp_nopush on; #连接超时时间 keepalive_timeout 120; tcp_nodelay on; #gzip压缩开关 #gzip on; #设定实际的服务器列表 upstream zp_server1{ server 127.0.0.1:8089; } #HTTP服务器 server { #监听80端口，80端口是知名端口号，用于HTTP协议 listen 80; #定义使用www.xx.com访问 server_name www.helloworld.com; #首页 index index.html #指向webapp的目录 root D:\\01_Workspace\\Project\\github\\zp\\SpringNotes\\spring-security\\spring-shiro\\src\\main\\webapp; #编码格式 charset utf-8; #代理配置参数 proxy_connect_timeout 180; proxy_send_timeout 180; proxy_read_timeout 180; proxy_set_header Host $host; proxy_set_header X-Forwarder-For $remote_addr; #反向代理的路径（和upstream绑定），location 后面设置映射的路径 location / { proxy_pass http://zp_server1; } #静态文件，nginx自己处理 location ~ ^/(images|javascript|js|css|flash|media|static)/ { root D:\\01_Workspace\\Project\\github\\zp\\SpringNotes\\spring-security\\spring-shiro\\src\\main\\webapp\\views; #过期30天，静态文件不怎么更新，过期可以设大一点，如果频繁更新，则可以设置得小一点。 expires 30d; } #设定查看Nginx状态的地址 location /NginxStatus { stub_status on; access_log on; auth_basic \"NginxStatus\"; auth_basic_user_file conf/htpasswd; } #禁止访问 .htxxx 文件 location ~ /\\.ht { deny all; } #错误处理页面（可选择性配置） #error_page 404 /404.html; #error_page 500 502 503 504 /50x.html; #location = /50x.html { # root html; #} } } 启动webapp，注意启动绑定的端口要和nginx中的upstream设置的端口保持一致 更改host，在host文件中添加一条DNS记录 127.0.0.1 www.helloworld.com 启动前文中 startup.bat 的命令 Https反向代理 一些对安全性要求比较高的站点可能会使用HTTPS（一种使用ssl通信标准的安全 HTTP协议） HTTPS的固定端口是443，不同于HTTP的80端口 SSL标准需要引入安全证书，所以在nginx.conf 中你需要指定证书和它对应的key 其它和http反向代理基本一样，只是在 Server 部分配置有些不同 #HTTP服务器 server { #监听443端口。443为知名端口号，主要用于HTTPS协议 listen 443 ssl; #定义使用www.xx.com访问 server_name www.helloworld.com; #ssl证书文件位置(常见证书文件格式为：crt/pem) ssl_certificate cert.pem; #ssl证书key位置 ssl_certificate_key cert.key; #ssl配置参数（选择性配置） ssl_session_cache shared:SSL:1m; ssl_session_timeout 5m; #数字签名，此处使用MD5 ssl_ciphers HIGH:!aNULL:!MD5; ssl_prefer_server_ciphers on; location / { root /root; index index.html index.htm; } } 负载均衡 前面的例子中，代理仅仅指向一个服务器，但是网站在实际运营中，大部分是以集群的方式运行，这时需要使用负载均衡来分流，nginx也可以实现简单的负载均衡能力 假设这样一个应用场景：将应用部署在 192.168.1.11:80、192.168.1.12:80、192.168.1.13:80 三台 linux 环境的服务器上。网站域名叫 www.helloworld.com，公网 IP 为 192.168.1.11。在公网 IP 所在的服务器上部署 nginx，对所有请求做负载均衡处理（下面例子中使用的是加权轮询策略）。 nginx.conf 配置如下： http { #设定mime类型,类型由mime.type文件定义 include /etc/nginx/mime.types; default_type application/octet-stream; #设定日志格式 access_log /var/log/nginx/access.log; #设定负载均衡的服务器列表 upstream load_balance_server { #weigth参数表示权值，权值越高被分配到的几率越大 server 192.168.1.11:80 weight=5; server 192.168.1.12:80 weight=1; server 192.168.1.13:80 weight=6; } #HTTP服务器 server { #侦听80端口 listen 80; #定义使用www.xx.com访问 server_name www.helloworld.com; #对所有请求进行负载均衡请求 location / { root /root; #定义服务器的默认网站根目录位置 index index.html index.htm; #定义首页索引文件的名称 proxy_pass http://load_balance_server ;#请求转向load_balance_server 定义的服务器列表 #以下是一些反向代理的配置(可选择性配置) #proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; #后端的Web服务器可以通过X-Forwarded-For获取用户真实IP proxy_set_header X-Forwarded-For $remote_addr; proxy_connect_timeout 90; #nginx跟后端服务器连接超时时间(代理连接超时) proxy_send_timeout 90; #后端服务器数据回传时间(代理发送超时) proxy_read_timeout 90; #连接成功后，后端服务器响应时间(代理接收超时) proxy_buffer_size 4k; #设置代理服务器（nginx）保存用户头信息的缓冲区大小 proxy_buffers 4 32k; #proxy_buffers缓冲区，网页平均在32k以下的话，这样设置 proxy_busy_buffers_size 64k; #高负荷下缓冲大小（proxy_buffers*2） proxy_temp_file_write_size 64k; #设定缓存文件夹大小，大于这个值，将从upstream服务器传 client_max_body_size 10m; #允许客户端请求的最大单文件字节数 client_body_buffer_size 128k; #缓冲区代理缓冲用户端请求的最大字节数 } } } 负载均衡策略 轮询 加权轮询 最少连接 加权最少连接 IP Hash 普通Hash 网站有多个webapp的配置 当一个网站越来越丰富时，往往需要将一些功能相对独立的模块剥离出来，独立维护，这样的话，通常会有多个webapp 配置多个端口的文件： http { #此处省略一些基本配置 upstream product_server{ server www.helloworld.com:8081; } upstream admin_server{ server www.helloworld.com:8082; } upstream finance_server{ server www.helloworld.com:8083; } server { #此处省略一些基本配置 #默认指向product的server location / { proxy_pass http://product_server; } location /product/{ proxy_pass http://product_server; } location /admin/ { proxy_pass http://admin_server; } location /finance/ { proxy_pass http://finance_server; } } } 静态站点 有时候我们需要配置静态站点（html文件和一堆静态资源） 如果所有的静态资源都放在了 /app/dist 目录下，我们只需要在 nginx.conf 中指定首页以及这个站点的host即可 配置如下： worker_processes 1; events { worker_connections 1024; } http { include mime.types; default_type application/octet-stream; sendfile on; keepalive_timeout 65; gzip on; gzip_types text/plain application/x-javascript text/css application/xml text/javascript application/javascript image/jpeg image/gif image/png; gzip_vary on; server { listen 80; server_name static.zp.cn; location / { root /app/dist; index index.html; #转发任何请求到 index.html } } } 然后，添加 HOST： 127.0.0.1 static.zp.cn 此时，在本地浏览器访问 static.zp.cn ，就可以访问静态站点了。 搭建文件服务器 使用nginx可以快速便捷的搭建一个简易的文件服务器 Nginx中的配置要点： 将 autoindex 开启可以显示目录，默认不开启。 将 autoindex_exact_size 开启可以显示文件的大小。 将 autoindex_localtime 开启可以显示文件的修改时间。 root 用来设置开放为文件服务的根路径。 charset 设置为 charset utf-8,gbk;，可以避免中文乱码问题（windows 服务器下设置后，依然乱码，本人暂时没有找到解决方法）。 一个简化的配置如下： autoindex on;# 显示目录 autoindex_exact_size on;# 显示文件大小 autoindex_localtime on;# 显示文件时间 server { charset utf-8,gbk; # windows 服务器下设置后，依然乱码，暂时无解 listen 9050 default_server; listen [::]:9050 default_server; server_name _; root /share/fs; } 解决跨域 web领域开发中，经常采用前后端分离模式，这种模式下，前端和后端分别是独立的web应用程序，例如后端是Java程序，前端是React或Vue应用，各自独立的webapp在互相访问的时候，势必存在跨域问题，解决跨域问题一般有两种思路： CORS 在后端服务器设置HTTP响应头，把你允许访问的域名中加入 Access-Control-Allow-Origin 中 jsonp 把后端根据请求，构造json数据并返回，前端用jsonp跨域 nginx 根据第一种思路，也提供了一种解决跨域的解决方案： # allow origin list set $ACAO '*'; # set single origin if ($http_origin ~* (www.helloworld.com)$) { set $ACAO $http_origin; } if ($cors = \"trueget\") { add_header 'Access-Control-Allow-Origin' \"$http_origin\"; add_header 'Access-Control-Allow-Credentials' 'true'; add_header 'Access-Control-Allow-Methods' 'GET, POST, OPTIONS'; add_header 'Access-Control-Allow-Headers' 'DNT,X-Mx-ReqToken,Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type'; } if ($request_method = 'OPTIONS') { set $cors \"${cors}options\"; } if ($request_method = 'GET') { set $cors \"${cors}get\"; } if ($request_method = 'POST') { set $cors \"${cors}post\"; } 资源 Nginx 的中文维基 Nginx 开发从入门到精通 nginx-admins-handbook nginxconfig.io - 一款 Nginx 配置生成器 Nginx 运维 window 安装 Linux安装（推荐rpm包方式） Linux开机自启动 Nginx配置 Nginx 的默认配置文件是 nginx.conf nginx -c xx.conf - 以指定文件作为配置文件，启动nginx 配置文件实例 "},"bigData/Spark.html":{"url":"bigData/Spark.html","title":"Spark","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 摘要 Spark 概述 安全 Spark [toc] 摘要 apachen yyds! 学习地址：Spark 2.2.0 中文文档，大概看来一下 Flink，这些都是面向大数据计算的，我也不知道用啥，还不知道怎么用，感觉自己一个人有点摸着石头过河的感觉 Spark 概述 Apache Spark 是一个快速的，通用的集群计算机系统。它对 Java，Scala，Python 和 R 提供了高层 API，并有一个经优化的支持通用执行图计算的引擎。它还支持一组丰富的高级工具，包括用于 SQL 和结构化数据处理的 Spark SQL，用于机器学习的 MLlib，用于图计算的 GraphX 和 Spark Streaming。 安全 默认情况下，Spark中的安全性处于关闭状态。这意味着您默认情况下容易受到攻击。在下载和运行Spark之前，请参阅Spark Security。 "},"bigData/大数据.html":{"url":"bigData/大数据.html","title":"大数据","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 摘要 概述 大数据 [toc] 摘要 开始系统的学习大数据，希望能学快一点，也能早点做出东西来，参考教程：Data Flair 概述 为什么要学习大数据？ 缺口大，很多行业很多领头羊都很重视它，大数据分析为领导者提供了一条获取想法的途径，成为一个数据科学家 什么是大数据分析？ 大数据以数 TB 的数量产生，它变化迅速、形式多样，难以使用 RDBMS 或其它传统技术方法进行处理和管理，大数据解决方案提供了用于在几秒钟内捕获、存储、搜索和分析数据的工具、方法和技术，以找到以前无法获得的创新和竞争收益的关系 "},"course/Hands-On Data Visualization.html":{"url":"course/Hands-On Data Visualization.html","title":"Hands-On Data Visualization","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 前言 Introduction: Why Data Visualization What Can You Believe? Some Pictures Are More Persuasive Different Shades of the Truth Origanization of the Book Chapter 1 Choose Tools to Tell Your Story Hands-On Data Visualization [toc] 前言 在了解 mapshaper.org 和 geojson.io 的过程中看到的一本书，该书探索数据可视化（可能是毕业方向之一），感觉讲的非常好。书籍地址 Introduction: Why Data Visualization 在本书中，我们将通过融合设计原则和一步一步的章节来学习如何创建真实且有意义的数据可视化，以使你的基于分析和论点更具有洞察力和吸引力。正如句子通过来源注释变得更有说服力一样，当与适当的表格、图表或地图配对时，数据驱动会变得更加强大。文字告诉我们故事，但可视化通过将定量、关系或空间模式转化为图像来向我们展示数据故事。当可视化设计得很好时，它们会将我们的注意力吸引到数据中最重要的部分。 如何设计交互式表格、图表和地图，并将它们嵌入到网络中。交互式可视化通过邀请用户与数据交互、探索用户感兴趣的模式、根据需要下载文件并分享结果，来扩大更广泛的受众。数据可视化在互联网上广泛传播，但是快速增长也带来了严重的问题。“信息时代”现在与“虚假信息时代”重叠，几乎人人都可以在网上发布信息，你如何做出明智的决定？当看到关于社会不平等或气候变化等分裂性政策问题的相互矛盾的数据故事时候，你选择相信哪一个？数据可视化照亮了我们追求真理的道路，但它也使我们能够欺骗和撒谎。 What Can You Believe? Point 1：自 1970 年代以来，美国的经济不平等急剧上升。 Point 2：1970 年，按今天的美元计算，美国前 10% 的成年人平均收入约为 135,000 美元，而后 50% 的人平均收入约为 16,500 美元。根据世界不平等数据库的数据，这种不平等差距在接下来的 50 年里急剧扩大，最高阶层的收入攀升至约 350,000 美元，而底部的一半收入几乎没有上升到约 19,000 美元。5 Point 3： 美国收入等级 1970年 2019年 前 10% 136,308 美元 352,815 美元 中间 40% 44,353 美元 76,462 美元 底部 50% 16,515 美元 19,177 美元 注：以 2019 年不变美元表示。20 岁及以上个人的国民收入，在税收和转移之前，但包括养老金缴款和分配。资料来源：世界不平等数据库，2020 年访问 What can you believe? Some Pictures Are More Persuasive Figure 0.1: Figure 0.1: Explore the interactive line chart of US adult income inequality over time. Figure 0.2: Figure 0.2: Explore the alternative version of the interactive line chart of US adult income inequality over time, using the same data as the first version. 图 0.1 和图 0.2 包含了相同的数据，为什么它们看起来如此的不同？不平等差距的显著增长发生了什么，现在似乎已经被消除了，危机消除了吗？还是说这是一个骗局？ 尽管这是同一份数据，但是图 0.2 y 轴上的金额是用对数刻度构建的，这最适合显示指数增长。在 Covid 病毒大流行期间也是使用的对数刻度，它们适当地说明了病例非常高的增长率，当时传统的线性刻度已经很难显示病例的增长了。可是图2使用对数刻度是具有误导性的，因为并没有充分的理由要使用对数刻度来解释这个收入数据，除非制度者是故意想要隐瞒事实。人们可以用图表来阐明真相，也可以用图表来掩盖真相 Different Shades of the Truth Point 4: 美国的收入不平等更为严重，目前最富有的 1% 的人口获得了国民收入的 20%。相比之下，在大多数欧洲国家，最富有的 1% 的人获得的份额较小，在国民收入的 6% 到 15% 之间 Figure 0.3 Figure 0.3: Explore the interactive map of world income inequality, measured by the share of national income held by the top 1 percent of the population, based on the most recent data available. Source: World Inequality Database 2020. Figure 0.4: Figure 0.4: Explore an alternative version of the interactive map of world income inequality, using the same data as the map above. 为什么要用地图而不是表格或者图表了？ 虽然我们可以创建观点 4 的表格或图表，但是这并不是集中快速显示 120 多个国家信息的最有效方法。同时这是空间数据，我们可以将其转换为交互式地图，以帮助用户探索全球的收入水平 图 0.3 是不是比观点 4 更有说服力？ 虽然地图和文本提供了关于美国和欧洲收入不平等的相同数据，按理说并没有区别。但是交互式地图将用户带入了一个强有力的数据故事，它生动地说明了贫富差距，地图上的颜色预示着危机，美国（以及俄罗斯和巴西）的收入不平等在最高水平上以深红色突出显示——前 1% 的人占据了国民收入的 19% 或更多，相比之下，当我们的目光飘向大西洋的时，几乎所有的欧洲国家都是呈现出较浅的米色或橙色，这表明它们的富人在国民收入的占比较小 图 0.3 和 图 0.4 你更相信哪张地图？ 图 0.4 看起来和 图 0.3 是不是有些不同？美国现在不是深红色，而是中蓝色，在光谱上更加接近加拿大和大多数欧洲国家。收入不平等的危机是不是从美国消失了？哪张地图是真的？ 两张地图都没有误导，且都已合理的设计对数据做出真实的解释，尽管它们在我们的眼中产生了截然不同的印象。请仔细看地图的图例。第一张地图将国家分为了三类：小于 13%， 13-19%， 19及以上，而第二张地图以绿蓝色渐变显示整个范围。由于美国的份额为 20.5%，因此在第一张图中，它以最深的红色显示，但在第二张图中，它以中蓝色更接近中间的某个位置。然后，这两张地图同样有效，因为既没有违反地图设计中的明确规则，也没有故意延时数据，人们可能因地图而产生误导，但也有可能对真相进行多幅描绘 数据可视化的解释性是一项严峻的挑战。创建真实而有意义的图表和地图，培养良好设计的原则和深思熟虑的思维习惯，并尝试以身作则。数据可视化相比科学来说，有时更像是一门艺术，我们知道图表和地图可以被操纵，就像是文字一样被用来误导你的观众，我们应该知道常见的欺骗技巧，防止被欺骗的同时避免自己的作品中出现欺骗。我们可能会因为同时存在多个看似正确的答案而沮丧，但是我们需要做的只是不断的寻找更好的答案，而不必期望找到一个正确的答案，尤其是随着可视化和工具的不断发展，新的方式会展示新的答案 Origanization of the Book 该书分为四个部分： 培养关于设想数据故事的基础技能，以及讲述它所需的工具和数据。1-5 章：选择一个工具来讲述你的数据故事；加强你的电子表格技能；查找和质疑你的数据；清理凌乱的数据；进行有意义的比较 使用易于学习的拖放工具构建大量可视化，并找出哪种类型最适合什么样的数据故事。6-9 章：绘制你的数据；映射你的数据；列出你数据的开始与强调的解释；嵌入Web以交互式可视化 使用更加强大的工具，特别是代码模板，这些工具是你可以更好的自定义可视化的外观以及在线托管它们的位置。10-13 章：使用GitHub编辑和托管代码；Chart.js 和 Highchart 模板；Leaflet 地图模板；转换地图数据中的更高级的空间工具 回归到本书的中心主题：用数据讲述真实而有意义的故事，总结你培养的所有可视化技能。14-15 章：学习如何使用图表和地图撒谎，从而更好地讲真话；最后，讲述和展示你的数据故事，数据可视化的目标不仅仅是制作关于数字的图片，而是制作一个真实的叙述，让读者相信你的解释并重视你的解释 该书的目标是让读者学习融合通过交互式数据可视化讲述真实而有意义的故事，同时注意人们可以利用它们来误导的方式。 Chapter 1 Choose Tools to Tell Your Story 如果你对当今可用的大量数字工具感到不知所措，那么你并不孤单。但是当你只是尝试做你的日常工作时，那么跟上最新的技术开发可能会让你感觉干了一份没有报酬的兼职。如果你喜欢尝试不同的选择，那么这将是一个好消息 "},"course/深入理解计算机系统.html":{"url":"course/深入理解计算机系统.html","title":"深入理解计算机系统","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 计算机系统漫游 信息的表示和处理 1. 信息存储 深入理解计算机系统 中文电子版 [toc] 计算机系统漫游 从程序员的角度学习计算机系统是如何工作的。 源程序 hello 程序的源程序是一个比特序列 图1-1 hello 源程序 像 hello.c 这样只由 ASCII 字符构成的文件称为**文本文件**，所有其他文件都称为**二进制文件**。 hello.c 的表示方法说明了一个基本思想∶系统中所有的信息——包括磁盘文件、内存中的程序、内存中存放的用户数据以及网络上传送的数据，都是由一串比特表示的。区分不同数据对象的唯一方法是我们读到这些数据对象时的上下文。比如，在不同的上下文中，一个同样的字节序列可能表示一个整数、浮点数、字符串或者机器指令。 计算机的数字是对真值的有限近似值 - #### 编译过程 ![image-20220106153157053](../image/image-20220106153157053.png) 图1-2 编译过程 系统组成 图1-3 一个典型系统的硬件组成 CPU：中央处理单元；ALU：算术/逻辑单元；PC：程序计数器；USB：通用串行总线 高速缓存 图1-4 高速缓存存储器 利用高速缓存将程序的性能提高一个数量级 - #### 存储器层次 ![image-20220106153127142](../image/image-20220106153127142.png) 图1-5 存储器层次结构 操作系统的抽象表示 操作系统有两个基本功能∶（1）防止硬件被失控的应用程序滥用；（2）向应用程序提供简单一致的机制来控制复杂而又通常大不相同的低级硬件设备。操作系统通过几个基本的抽象概念（进程、虚拟内存和文件）来实现这两个功能。如图 1-11 所示，文件是对 I/O 设备的抽象表示，虚拟内存是对主存和磁盘 I/O 设备的抽象表示，进程则是对处理器、主存和 I/O 设备的抽象表示。我们将依次讨论每种抽象表示。 图1-6 操作系统提供的抽象表示 进程 进程是操作系统对一个正在运行程序的一种抽象。 进程是操作系统对一个正在运行的程序的一种抽象。在一个系统上可以同时运行多个进程，而每个进程都好像在独占地使用硬件。而并发运行，则是说一个进程的指令和另一个进程的指令是交错执行的。在大多数系统中，需要运行的进程数是多于可以运行它们的 CPU 个数的。传统系统在一个时刻只能执行一个程序，而先进的多核处理器同时能够执行多个程序。无论是在单核还是多核系统中，一个 CPU 看上去都像是在并发地执行多个进程，这是通过处理器在进程间切换来实现的。操作系统实现这种交错执行的机制称为上下文切换。 从一个进程到另一个进程的转换是由操作系统内核（kernel）管理的。内核是操作系统代码常驻主存的部分。当应用程序需要操作系统的某些操作时，比如读写文件，它就执行一条特殊的系统调用（system call）指令，将控制权传递给内核。然后内核执行被请求的操作并返回应用程序。注意，内核不是一个独立的进程。相反，它是系统管理全部进程所用代码和数据结构的集合。 图1-7 进程的上下文切换 线程 尽管通常我们认为一个进程只有单一的控制流，但是在现代系统中，一个进程实际上可以由多个称为线程的执行单元组成，每个线程都运行在进程的上下文中，并共享同样的代码和全局数据。由于网络服务器中对并行处理的需求，线程成为越来越重要的编程模型，因为多线程之间比多进程之间更容易共享数据，也因为线程一般来说都比进程更高效。 虚拟内存 虚拟内存是一个抽象概念，它为每个进程提供了一个假象，即每个进程都在独占地使用主存。每个进程看到的内存都是一致的，称为虚拟地址空间。图 1-13 所示的是 Linux 进程的虚拟地址空间（其他 Unix 系统的设计也与此类似）。在 Linux 中，地址空间最上面的区域是保留给操作系统中的代码和数据的，这对所有进程来说都是一样。地址空间的底部区域存放用户进程定义的代码和数据。请注意，图中的地址是从下往上增大的。 图1-8 进程的虚拟地址空间 文件 文件就是文字序列，仅此而已，每个I/O设备都可以看成是一个文件。系统中的所有输入输出都是通过一组称为 Unix I/O 的系统调用读写文件来实现的。 网络通信 系统漫游至此，我们一直是把系统视为一个孤立的硬件和软件的集合体。实际上，现代系统经常通过网络和其他系统连接到一起。从一个单独的系统来看，网络可视为一个 I/O 设备，如图 1-14 所示。当系统从主存复制一串字节到网络适配器时，数据流经过网络到达另一台机器，而不是比如说到达本地磁盘驱动器。相似地，系统可以读取从其他机器发送来的数据，并把数据复制到自己的主存。 图1-9 网络也是一种I/O设备 图1-10 利用 telnet 通过网络远程运行 hello Amdahl 定律 相对性能 图1-11 Amdahl定律 并发和并行 并发（concurrency）是一个通用的概念，指一个同时具有多个活动的系统；而术语并行（parallelism）指的是用并发来使一个系统运行得更快。并行可以在计算机系统的多个抽象层次上运用。在此，我们按照系统层次结构中由高到低的顺序重点强调三个层次。 计算机抽象 图1-12 计算机系统提供的一些抽象 计算机系统中的一个重大主题就是提供不同层次的抽象表示，来隐藏实际实现的复杂性 在学习操作系统时，我们介绍了三个抽象：文件是对 I/O 设备的抽象，虚拟内存是对程序存储器的抽象，而进程是对一个正在运行的程序的抽象。我们再增加一个新的抽象∶ 虚拟机，它提供对整个计算机的抽象，包括操作系统、处理器和程序。 小结 计算机系统是由硬件和系统软件组成的，它们共同协作以运行应用程序。计算机内部的信息被表示为一组组的位，它们依据上下文有不同的解释方式。程序被其他程序翻译成不同的形式，开始时是 ASCII 文本，然后被编译器和链接器翻译成二进制可执行文件。 处理器读取并解释存放在主存里的二进制指令。因为计算机花费了大量的时间在内存、I/O 设备和 CPU 寄存器之间复制数据，所以将系统中的存储设备划分成层次结构——CPU 寄存器在顶部，接着是多层的硬件高速缓存存储器、DRAM 主存和磁盘存储器。在层次模型中，位于更高层的存储设备比低层的存储设备要更快，单位比特造价也更高。层次结构中较高层次的存储设备可以作为较低层次设备的高速缓存。通过理解和运用这种存储层次结构的知识，程序员可以优化C程序的性能。 操作系统内核是应用程序和硬件之间的媒介。它提供三个基本的抽象∶1）文件是对 I/O 设备的抽象；2）虚拟内存是对主存和磁盘的抽象；3）进程是处理器、主存和 I/O 设备的抽象。 最后，网络提供了计算机系统之间通信的手段。从特殊系统的角度来看，网络就是一种 I/O 设备。 信息的表示和处理 1. 信息存储 bit 孤立地讲，单个的位不是非常有用。然而，当把位组合在一起，再加上某种解释 （interpretation），即赋予不同的可能位模式以含意，我们就能够表示任何有限集合的元素。比如，使用一个二进制数字系统，我们能够用位组来编码非负数。通过使用标准的字符码，我们能够对文档中的字母和符号进行编码。在本章中，我们将讨论这两种编码，以及负数表示和实数近似值的编码。 虚拟地址空间 大多数计算机使用 8 位的块，或者字节（byte），作为最小的可寻址的内存单位，而不是访问内存中单独的位。机器级程序将内存视为一个非常大的字节数组，称为虚拟内存（virtual memory）。内存的每个字节都由一个唯一的数字来标识，称为它的地址（address），所有可能地址的集合就称为虚拟地址空间（virtual address space）。顾名思义，这个虚拟地址空间只是一个展现给机器级程序的概念性映像。实际的实现（见第 9 章）是将动态随机访问存储器（DRAM）、闪存、磁盘存储器、特殊硬件和操作系统软件结合起来，为程序提供一个看上去统一的字节数组。 指针 真正理解指针需要查看它们在机器级上的表示以及实现。 "},"course/图说设计模式.html":{"url":"course/图说设计模式.html","title":"图说设计模式","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 目标 看懂UML类图和时序图 泛化关系（generalization） 实现关系（realize） 聚合关系（aggregation） 组合关系（composition） 关联关系（association） 依赖关系（dependency） 时序图（sequence diagram） 创建型模式（creational pattern） 简单工厂模式（simple factory pattern） 图说设计模式 github [toc] 目标 看懂UML类图和时序图 $\\rightarrow$ 创建型模式 $\\rightarrow$ 结构性模式 $\\rightarrow$ 行为型模式 看懂UML类图和时序图 车的类图结果是 $>$ ，表示车是一个抽象类 车有两个继承类：小汽车和自行车，它们之间的关系是实现关系，关系用一个带虚线的空心箭头表示 suv继承小汽车，它们之间的关系是泛化关系，关系用一个带实线的空心箭头表示 轮胎和发动机组成小汽车，是一种组成关系，用带实线的实心箭头表示 学生上学要用到自行车，是一种依赖关系，用带虚线的箭头表示 学生聚合成一个班级，是一种聚合关系，用带实心的空心箭头表示 学生有身份证，是一种关联关系，用实线表示 泛化关系（generalization） 类的集成结构表现在 UML 中： 泛化（generalize）和实现（realize） 集成关系是 $is-a$ 的关系，如果两个对象之间可以用 $is-a$来表示，就是继承关系：自行车是车 泛化关系用一条带实线的空心箭头实线 关系用一个带虚线的空心箭头表示 最终代码中，泛化关系表现为继承非抽象类 实现关系（realize） 实现关系用一个带空心箭头的虚线表示 eg：”车”为一个抽象概念，在现实中并无法直接用来定义对象；只有指明具体的子类(汽车还是自行车)，才 可以用来定义对象（”车”这个类在C++中用抽象类表示，在JAVA中有接口这个概念，更容易理解） 最终代码中，实现关系表现为继承抽象类 聚合关系（aggregation） 聚合关系用一条带空心菱形箭头的直线表示，如下图表示 A 聚合到 B 上，或者说 B 由 A 组成： 聚合关系用于表示实体对象之间的关系，表示整体由部分构成的语义，eg：一个部门由多个员工组成 与组合关系不同的是，整体和部分不是强依赖，即使整体不存在了，部分依然是存在的，eg：部门撤销了，人员不会消失，他们依然存在 组合关系（composition） 组合关系用一条带实现菱形箭头表示，如下图表示 A 组成 B： 与聚合关系一样，组合关系同样表示整体由部分存在的语义：公司由很多个部门存在 但是组合关系hi是一种强依赖关系，如果整体不存在了，则部分也不存在了：公司破产了，部门也无了 关联关系（association） 关联关系用一条直线表示，它表示不同类的对象之间的结构关系，它是一种静态关系，通常与运行状态无关，一般由常识等因素决定的，它一般用来定义对象之间静态的，天然的结构，所以，关联关系是一种“强关联”的关系：乘车人和车票 关联关系默认不强调方向，表示对象之间都相互知道，如果特别强调方向，如下图，表示 A 知道 B， B 不知道 A 在最终代码中，关联对象通常是以成员变量的形式实现的 依赖关系（dependency） 依赖关系用一个带箭头的虚线表示，如下图表示 A 依赖于 B；他描述一个对象在运行期间会用到另一个对象的关系 与关联关系不同的是，它是一种临时的关系，通常在运行期间产生，并且随着运行时的变化，依赖关系也可能发生变化 显然，依赖有方向，双向依赖是一种非常糟糕的结构，我们总是应该保持单向依赖，杜绝双向依赖的产生 在最终代码中，依赖关系体现为为类的构造方法及类方法的传入参数，箭头的指向表示调用关系，依赖关系处理临时知道对方外，还是使用对方的方法和属性 时序图（sequence diagram） 为了展示对象之间的交互细节，都会用到时序图 时序图（sequence diagram）是显示对象之间交互的图，如果这些对象是按时间顺序排列的，时序图显示的是参与交互的对象及其对象之间消息交互的顺序 时序图包括的建模元素有：对象（Actor）、生命线（Lifeline）、控制焦点（Focus of control）、消息（Message）等 创建型模式（creational pattern） 创建型模式对类的实例化过程进行了抽象，能够将软件模块中对象的创建和对象的使用分离。为了使软件的结构更加清晰，外界对于这些对象只需要知道它们共同的接口，而不清楚其具体的实现细节，使整个系统的设计更加符合单一职责原则。 包含模式：简单工程模式、工厂方法模式、抽象工厂模式、建造者模式、原型模式、单例模式 简单工厂模式（simple factory pattern） 模式定义：属于类创建型模式，在简单工厂模式中，可以根据参数的不同返回不同类的实例。简单工厂模式专门定义一个类来负责创建其它类的实例，被创建的实例通常都是具有共同的父类 模式结构： 工厂角色（factory）： 工厂角色负责实现创建所有实例的内部逻辑 抽象产品角色（product）：抽象产品角色是创建所有对象的父类，负责描述所有实例所共有的公共接口 具体产品角色（concreteProduct）：具体产品角色是创建目标，所有创建的对象都充当这个角色的某个具体类的实例 #include \"Factory.h\" #include \"ConcreteProductA.h\" #include \"ConcreteProductB.h\" Product* Factory:createProduct(string proname) { if(\"A\" === proname){ return new ConcreteProductA(); } else if(\"B\" === proname) { return new ConcreteProductB(); } return NULL; } 模式分析 将对象的创建和对象本身业务处理分离可以降低系统的耦合度，使得两者修改起来都相对容易 在调用工厂类的工厂方法时，由于工厂方法是静态方法，使用起来很方便，可以通过类名直接调用，而且只需要传入一个简单的参数即可，在实例开发中，还可以在调用时将所传入的参数保存在XML等格式的配置文件中，修改参数时无须修改任何源码 简单工厂问题的最大问题在于工厂类的职责相对过重，增加新的产品需要修改工厂类的判断逻辑，这一点与开闭原则是相违背的 简单工厂模式的要点在于：当你需要什么，只需要传入一个正确的参数，就可以获取你需要的对象，而无需知道其创建细节 优点 工厂类含有必要的判断逻辑，可以决定在什么时候创建哪一个产品类的实例，客户端可以免除直接创建产品对象的责任，而仅仅“消费”产品；简单工厂模式通过这种做法实现了对责任的分割，它提供专门的工厂类用于创建对象 客户端无须知道所创建的具体产品类的类名，只需要知道具体产品类所对应的参数即可，对于一些复杂的类名，通过简单工厂模式可以减少使用者的记忆量 通过引入配置文件，可以在不修改任何客户端代码的情况下更换和增加新的具体产品类，在一点程度上提高了系统的灵活性 缺点 由于工厂类集中了所产品创建逻辑，一点不能正常工作，整个系统都要受到影响 使用简单工厂模式将会增加系统中类的个数，在一定程度上增加了系统的复杂度和理解难度 系统扩展困难，一旦添加新产品就不得不修改工厂逻辑，在产品类型较多时，有可能造成工厂逻辑过于复杂，不利于系统的扩展和维护 总结 创建型模式对类的实例化过程进行了抽象，能够将对象的创建与对象的使用过程分离。 简单工厂模式又称为静态工厂方法模式，它属于类创建型模式。在简单工厂模式中，可以根据参数的不同返回不同类的实例。简单工厂模式专门定义一个类来负责创建其他类的实例，被创建的实例通常都具有共同的父类。 简单工厂模式包含三个角色：工厂角色负责实现创建所有实例的内部逻辑；抽象产品角色是所创建的所有对象的父类，负责描述所有实例所共有的公共接口；具体产品角色是创建目标，所有创建的对象都充当这个角色的某个具体类的实例。 简单工厂模式的要点在于：当你需要什么，只需要传入一个正确的参数，就可以获取你所需要的对象，而无须知道其创建细节。 简单工厂模式最大的优点在于实现对象的创建和对象的使用分离，将对象的创建交给专门的工厂类负责，但是其最大的缺点在于工厂类不够灵活，增加新的具体产品需要修改工厂类的判断逻辑代码，而且产品较多时，工厂方法代码将会非常复杂。 简单工厂模式适用情况包括：工厂类负责创建的对象比较少；客户端只知道传入工厂类的参数，对于如何创建对象不关心。 "},"font/React.html":{"url":"font/React.html","title":"React","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 Introducing JSX Rendering Elements Conponents and Props State and LifeCycle Handling Events Conditional rendering Lists and keys Forms Lifting state up React consept [toc] Introducing JSX A syntax extension to JavaScript. Rendering Elements An element describes what you want to see on the screen. Conponents and Props function components function Welcome(props) { return Hello, {props.name}; } class components class Welcome extends React.Component { render() { return Hello, {this.props.name}; } } Always start component names with a capital letter. All React components must act like pure functions with respect to their props. State and LifeCycle State is similar to props, but it is private and fully controlled by the component. convert a function component: create an ES6 class with the same name that extends React.Component. Add a simgle empty method to it called render() Move the body into the render Replace props with this.props in the render() body Delete empty function delaration The render method will be called cach time an update happens, but as long as we rendering. Class components should always call the base constructor with props. In applications with many components, it's very important to free up resources taken by the components when they are destroyed. Do not modify state directly, instead use setState() State updates may be asychronous // Wrong this.setState({ counter: this.state.counter + this.props.increment, }) // Correct this.setState((state, props) => { counter: state.counter + props.increment, }) The data flows down. State is not accessible to any component other than the one that owns and sets it, a component may choose to apss its state down as props to its child components. If you imagine a component tree as a water fall of props, each component's state is like an additional water source that joins it at an arbitrary point but also flows down. Handling Events React events are named using camelCase, rather than lowercase With JSX you pass a function as the event handler, rather than a string preventDefault this: bind, arrow function(In most cases, this is fine, if this callback is passed as a prop to lower components, those components might do an extra re-rendering) this.deleteRow(id, e)}>Delete Row Delete Row Conditional rendering function (if) \\ Element variables \\ logical && operator whenever conditions become too complex, it might be a good time to extrct a component. Lists and keys A component that accepts an array of numbers and outputs a list of elements. function NumberList(props) { const numbers = props.numbers; const listItems = numbers.map((number) => {number} ); return ( {listItems} ); } const numbers = [1, 2, 3, 4, 5]; ReactDOM.render( , document.getElementById('root') ); Keys help React identify which items have changed, are added, or are removed. If you choose not to assign an explicit key to list items then React will default to using indexes as keys, however the order of items may change. Keys only make sense in the context of the surrounding array. Forms Form elements naturally keep some internal state. An input form element whose value is controlled by React in this way is called a \"controlled component\". Lifting state up oftern, several components need to reflect the same changing data. We recommend lifting the shared state up to their closest common ancestor. "},"font/Vue.html":{"url":"font/Vue.html","title":"Vue","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 基础 介绍 vue是什么 处理用户输入 条件和循环 组件化应用 应用&组件实例 创建一个组件实例 根组件 组件实例 property 生命周期 模板语法 插值 原始HTML Attribute 使用 js 表达式 指令 参数 动态参数 修饰符 缩写 注意事项 Data Property 和 方法 Data Property 方法 函数防抖和函数节流 就算属性和侦听器 计算属性 computed 侦听器 Class 与 Style 绑定 绑定内联样式 条件渲染 列表渲染 事件处理 表单输入绑定 复选框 单选框 选择框 组件基础 通过prop向子组件传递数据 监听子组件事件 在组件上使用 v-model 其它 npm run dev 和 npm run serve 的区别 Vue 官方教程 [toc] 基础 介绍 vue是什么 有MVVM模式的影响 Vue.js 的核心是一个允许采用简洁的模板语法来声明式地将数据渲染进 DOM 的系统，数据和DOM建立关联，所有的东西都是响应式的 {{message}} 绑定 DOM 文本 v-bind:title 绑定元素的 atribute 处理用户输入 为了交互，v-on 指令添加一个事件监听器，eg： v-on:click v-model 指令，实现表单输入和应用状态之间的双向绑定 条件和循环 v-if 判断条件，不仅可以把数据绑定到 DOM 文本或 attribute，还可以保定到DOM的结构 vue 也提供一个强大的过渡效果系统，可以在vue 插入/更新/删除元素时自动应用过渡效果 v-for 可以绑定数组的数据来渲染一个项目列表 组件化应用 组件系统是 Vue 的另一个重要概念，因为它是一种抽象，允许我们使用小型、独立和通常可复用的组件构建大型应用。 在 Vue 中，组件本质上是一个具有预定义选项的实例。在 Vue 中注册组件很简单：如对 App 对象所做的那样创建一个组件对象，并将其定义在父级组件的 components 选项中 为了将数据从父组件传入子组件，修改一些组件的定义，使之能接受要给prop： app.component('todo-item', { props: ['todo'], template: `{{ todo.text }}` }) Vue 组件与自定义元素非常类似——它是 Web Components 规范的一部分 它们之间主要的不同在于，Vue 组件的数据模型是作为框架的一部分而设计的，而该框架为构建复杂应用提供了很多必要的附加功能。例如响应式模板和状态管理——这两者都没有被该规范所覆盖。 应用&组件实例 创建一个组件实例 每一个vue应用都是通过用 createApp 函数创建一个应用实例开始的 该应用实例是用来在应用中注册全局组件的 应用实例暴露的大多数方法都会返回该同意实例，允许链式 根组件 传递给 createApp 的选项用于配置根组件。当我们挂载应用时，该组件被用作渲染的起点。 与大多数应用方法不同的是，mount 不返回应用本身。相反，它返回的是根组件实例。 组件实例 property 我们认识了 data property。在 data 中定义的 property 是通过组件实例暴露的 还有各种其他的组件选项，可以将用户定义的 property 添加到组件实例中，例如 methods，props，computed，inject 和 setup。我们将在后面的指南中深入讨论它们。组件实例的所有 property，无论如何定义，都可以在组件的模板中访问。 Vue 还通过组件实例暴露了一些内置 property，如 $attrs 和 $emit。这些 property 都有一个 $ 前缀，以避免与用户定义的 property 名冲突 不要在选项 property 或回调上使用箭头函数，比如 created: () => console.log(this.a) 或 vm.$watch('a', newValue => this.myMethod())。因为箭头函数并没有 this，this 会作为变量一直向上级词法作用域查找，直至找到为止，经常导致 Uncaught TypeError: Cannot read property of undefined 或 Uncaught TypeError: this.myMethod is not a function 之类的错误。 生命周期 模板语法 Vue.js 使用了基于 HTML 的模板语法，允许开发者声明式地将 DOM 绑定至底层组件实例的数据。所有 Vue.js 的模板都是合法的 HTML，所以能被遵循规范的浏览器和 HTML 解析器解析。 在底层的实现上，Vue 将模板编译成虚拟 DOM 渲染函数。结合响应性系统，Vue 能够智能地计算出最少需要重新渲染多少组件，并把 DOM 操作次数减到最少。 插值 DOM文本使用 {{}} 进行查实，也可以通过使用 v-once 指令，你也能执行一次性地插值，当数据改变时，插值处的内容不会更新。但请留心这会影响到该节点上的其它数据绑定 原始HTML 双大括号会将数据解释为普通文本 为了输出真正的 html，需要使用 v-html 这个 span 的内容将会被替换成 property 值直接作为 html——会忽略解析property中的数据绑定 所以说组件更适合作为可重用和可组合的基本单位 Attribute v-bind 绑定 html 的 attribute，如果绑定的值是 null 或 undefined， 那么该attribute 将不会包含在渲染的元素上 对于布尔 attribute (它们只要存在就意味着值为 true) 使用 js 表达式 迄今为止，在我们的模板中，我们一直都只绑定简单的 property 键值。但实际上，对于所有的数据绑定，Vue.js 都提供了完全的 JavaScript 表达式支持。 每个绑定只能包含单个表达式，比如赋值语句就不会生效 指令 指令 (Directives) 是带有 v- 前缀的特殊 attribute。指令 attribute 的值预期是单个 JavaScript 表达式 (v-for 和 v-on 是例外情况，稍后我们再讨论)。指令的职责是，当表达式的值改变时，将其产生的连带影响，响应式地作用于 DOM。 参数 一些指令能够接收一个“参数”，在指令名称之后以冒号表示。例如，v-bind 指令可以用于响应式地更新 HTML attribute： ... 另一个例子是 v-on 指令，它用于监听 DOM 事件： ... 动态参数 也可以在指令参数中使用 JavaScript 表达式，方法是用方括号括起来： ... 这里的 attributeName 会被作为一个 JavaScript 表达式进行动态求值，求得的值将会作为最终的参数来使用。例如，如果你的组件实例有一个 data property attributeName，其值为 \"href\"，那么这个绑定将等价于 v-bind:href。 同样地，你可以使用动态参数为一个动态的事件名绑定处理函数： ... 在这个示例中，当 eventName 的值为 \"focus\" 时，v-on:[eventName] 将等价于 v-on:focus 修饰符 修饰符 (modifier) 是以半角句号 . 指明的特殊后缀，用于指出一个指令应该以特殊方式绑定。例如，.prevent 修饰符告诉 v-on 指令对于触发的事件调用 event.preventDefault()： ... 缩写 v-bind 缩写 ... ... ... v-on 缩写 ... ... ... 注意事项 动态参数预期会求出一个字符串，异常情况下值为 null。这个特殊的 null 值可以被显性地用于移除绑定。任何其它非字符串类型的值都将会触发一个警告 动态参数表达式有一些语法约束，因为某些字符，如空格和引号，放在 HTML attribute 名里是无效的。例如： ... 变通的办法是使用没有空格或引号的表达式，或用计算属性替代这种复杂表达式。 模板表达式都被放在沙盒中，只能访问一个受限的列表，如 Math 和 Date。你不应该在模板表达式中试图访问用户定义的全局变量。在 DOM 中使用模板时 (直接在一个 HTML 文件里撰写模板)，还需要避免使用大写字符来命名键名，因为浏览器会把 attribute 名全部强制转为小写： ... 模板表达式都被放在沙盒中，只能访问一个受限的列表，如 Math 和 Date。你不应该在模板表达式中试图访问用户定义的全局变量。 Data Property 和 方法 Data Property 组件的 data 选项是一个函数。Vue 在创建新组件实例的过程中调用此函数。它应该返回一个对象，然后 Vue 会通过响应性系统将其包裹起来，并以 $data 的形式存储在组件实例中。为方便起见，该对象的任何顶级 property 也直接通过组件实例暴露出来： const app = Vue.createApp({ data() { return { count: 4 } } }) const vm = app.mount('#app') console.log(vm.$data.count) // => 4 console.log(vm.count) // => 4 // 修改 vm.count 的值也会更新 $data.count vm.count = 5 console.log(vm.$data.count) // => 5 // 反之亦然 vm.$data.count = 6 console.log(vm.count) // => 6 这些实例property仅在实例首次创建时被添加，所以你需要确保它们在 data 函数返回的对象中 直接将不包含在 data 中的新 property 添加到组件实例是可行的，但是由于不在背后的响应式 $data 对象中，所以 vue的响应式系统不会自动更新它 方法 我们用 methods 选项向组件实例添加方法，它应该是一个包含所需方法的对象： const app = new Vue.createApp({ data() { return {count: 4} } methods: { increment() { this.count++ } } }) const vm = app.mount('#app') vm.increment() vue 自动为 methods 绑定了 this，以便于它始终指向组件实例，这将确保方法在用作事件监听或者回调时保持正确的this 指向 可以直接从模板调用方法，通常换做计算属性会更好，但是在计算属性不可行的情况下，使用方法可能会很有用 函数防抖和函数节流 函数防抖（debounce）：触发事件后在n秒内函数只能执行一次，如果在n秒内又触发了时间，则会重新计算函数执行时间 函数节流：限制一个函数在一定时间内只能执行一次 函数防抖的应用场景： 搜索框搜索输入。只需用户最后一次输入完，再发送请求 手机号、邮箱验证输入检测 窗口大小Resize。只需窗口调整完成后，计算窗口大小。防止重复渲染。 函数节流的应用场景： 滚动加载，加载更多或滚到底部监听 谷歌搜索框，搜索联想功能 高频点击提交，表单重复提交 函数防抖简单实现，在执行目标方法时，会等待一段时间，当又执行相同方法时，若前一个定时任务未执行完，则 clear 掉定时任务，重新定时 const _.debounce = (func, wait) => { let timer; return () => { clearTimeout(timer) timer = setTimeout(func, wait) } } 函数节流简单实现，是为了限制函数一段时间内只能执行一次。因此，通过使用定时任务，延时方法执行，在延时的时间内，方法若被触发 const _.throttle = (func, wait) => { let timer return () => { if(timer) return } timer = setTimeout(() => { func(); timer = null }, wait) } vue没有内置防抖和节流，可以使用 Lodash 等库实现 就算属性和侦听器 计算属性 computed 模板内的表达式非常遍历，但是设计它们的初衷是用于简单计算的，在模板中放入太多的逻辑会让模板难以维护 所以对于任何包含响应式数据的复杂逻辑，你都应该使用计算属性 has hublished books: Vue.createApp({ data() { return { author: { name: 'Johe Dow', books:['Vue 3 - basic guide'] } } }, computed: { // 计算属性的 getter publishedBooksMessage() { return this.author.books.length > 0 ? 'yes': 'no' } } }) 我们可以将函数定义为一个方法而不是一个计算属性，但是计算属性是基于它们的响应依赖关系缓存的，计算属性只在相关响应式依赖发生改变时它们才会重新求值，比如上例，只要authors.books 没有发生改变，多次访问函数，计算属性会立即返回之前的计算结果，而不必再次执行函数 computed： { now() { return Date.now() // 不再更新 } } 为什么需要缓存？假设我们有一个性能开销大的计算属性 list，它需要遍历一个巨大的数组并做大量的计算，然后我们可能又其它的计算属性依赖于 list， 如果没有缓存，我们将不可避免的多次执行 list 的getter，如果不希望有缓存，用method代替 计算属性默认只有getter，不过在需要时可以提供一个setter // ... computed: { fullName: { // getter get() { return this.firstName + ' ' + this.lastName }, // setter set(newValue) { const names = newValue.split(' ') this.firstName = names[0] this.lastName = names[names.length - 1] } } } // ... 侦听器 虽然计算属性在大多数情况下更合适，但有时需要一个自定义的侦听器，通过 watch 提供一个更通用的方法，来响应数据的变化 当需要在数据变化时执行异步或开销较大的操作时，这个方式是最有用的 ask a yes/no question const watchExampleVM = Vue.createApp({ data() { return { question: '', answer: 'Questions usually contain a question mark. ;-)' } }, watch: { // whenever question changes, this function will run question(newQuestion, old Question) { if(newQuestion.indexOf('?') > -1) this.getAnswer() } }, methods: { getAnswer() { this.answer = 'Thinking...' axios .get('https://yesno.wtf/api') .then(response => { this.answer = response.data.answer }) .catch(error => { this.answer = 'Error ' + error }) } } }).mount('#watch-example') 当你有一些数据需要随着其他数据变动而变动，很容易滥用watch，这时候可能有很多重复代码，更好的做法是使用计算属性而不是watch回调 Class 与 Style 绑定 操作元素的 class 列表和内联样式是数据绑定的一个常见需求。因为它们都是 attribute，所以我们可以用 v-bind 处理它们：只需要通过表达式计算出字符串结果即可。不过，字符串拼接麻烦且易错。因此，在将 v-bind 用于 class 和 style 时，Vue.js 做了专门的增强。表达式结果的类型除了字符串之外，还可以是对象或数组。 data() { return { isActive: true, error: null } }, computed: { classObject() { return { active: this.isActive && !this.error, 'text-danger': this.error && this.error.type === 'fatal' } } } 我们可以把一个数组传给 :class，以应用一个 class 列表： 当你在带有单个根元素的自定义组件上使用 class attribute 时，这些 class 将被添加到该元素中。此元素上的现有 class 将不会被覆盖。 绑定内联样式 data() { return { styleObject: { color: 'red', fontSize: '13px' } } } 可以为 style 绑定中的 property 提供一个包含多个值的数组，常用于提供多个带前缀的值，例如： 条件渲染 v-if 指令用于条件性的渲染一块内容，这块内容只会在指令的表达式返回 truthy 值的时候被渲染 vue 也可以用 v-else 添加一个 else块： test no test 因为 v-if 是一个指令，所以必须将它添加到一个元素上，但是如果想切换多个元素呢？此时可以把一个 元素当作一个不可见的包裹元素，并在上面使用 v-if v-else 元素必须紧跟在 v-if 或者 v-else-if 元素后面，否则它将不会被识别 另一个用于条件渲染的元素是 v-show，不同的是v-show始终会被渲染并被保留在 DOM 中，v-show 只是简单的切换元素的display v-show 不支持 v-if 是“真正”的条件渲染，因为它会确保在切换过程中，条件块内的事件监听器和子组件适当地被销毁和重建。 v-if 也是惰性的：如果在初始渲染时条件为假，则什么也不做——直到条件第一次变为真时，才会开始渲染条件块。 相比之下，v-show 就简单得多——不管初始条件是什么，元素总是会被渲染，并且只是简单地基于 CSS 进行切换。 一般来说，v-if 有更高的切换开销，而 v-show 有更高的初始渲染开销。因此，如果需要非常频繁地切换，则使用 v-show 较好；如果在运行时条件很少改变，则使用 v-if 较好。 不推荐同时使用 v-if 和 v-for 列表渲染 v-for 把一个数组渲染成一组元素 v-for 块中可以访问所有父作用域的property，v-for 还支持一个可选的第二个参数 也可以用 of 替代 in 作为分隔符，这个更接近 JavaScript 迭代器的语法 当 Vue 正在更新使用 v-for 渲染的元素列表时，它默认使用“就地更新”的策略。如果数据项的顺序被改变，Vue 将不会移动 DOM 元素来匹配数据项的顺序，而是就地更新每个元素，并且确保它们在每个索引位置正确渲染。 建议在使用 v-for 时提供 key attribute 有时我们想要显示一个数组经过过滤或者排序后的版本，而不实际变更或重置原始数据，这种情况下，可以创建一个计算属性，来返回过滤或排序后的数组 类似于 v-if，你也可以利用带有 v-for 的 来循环渲染一段包含多个元素的内容 在自定义组件上，你可以像在任何普通元素上一样使用 v-for： 然而，任何数据都不会被自动传递到组件里，因为组件有自己独立的作用域。为了把迭代数据传递到组件里，我们要使用 props： 不自动将 item 注入到组件里的原因是，这会使得组件与 v-for 的运作紧密耦合，明确组件数据的来源能够使组件在其它场合重复使用 Add a todo Add const app = Vue.createApp({ data() { return { newTodoText: '', todos: [ { id: 1, title: 'Do the dishes' }, { id: 2, title: 'Take out the trash' }, { id: 3, title: 'Mow the lawn' } ], nextTodoId: 4 } }, methods: { addNewTodo() { this.todos.push({ id: this.nextTodoId++, title: this.newTodoText }) this.newTodoText = '' } } }) app.component('todo-item', { template: ` Remove `, props: ['title'], emits: ['remove'] }) app.mount('#todo-list-example') 事件处理 我们可以通过 v-on 指令（缩写为 @） 来监听 dom 事件 除了直接绑定到一个方法，也可以在内联 JavaScript 语句中调用方法： Say hi Say what Vue.createApp({ methods: { say(message) { alert(message) } } }).mount('#inline-handler') 有时候需要在内联语句处理器中访问原始的dom事件，可以用特殊变量 $event 把它传入方法 事件处理其中可以有多个方法，这些方法由逗号运算符分隔： Submit 在事件处理程序中调用 event.preventDefault() 或 event.stopPropagation() 是非常常见的需求。尽管我们可以在方法中轻松实现这点，但更好的方式是：方法只有纯粹的数据逻辑，而不是去处理 DOM 事件细节。 为了解决这个问题，Vue.js 为 v-on 提供了事件修饰符。之前提过，修饰符是由点开头的指令后缀来表示的。 .stop .prevent .capture .self .once .passive 使用修饰符时，顺序很重要；相应的代码会以同样的顺序产生。因此，用 v-on:click.prevent.self 会阻止所有的点击，而 v-on:click.self.prevent 只会阻止对元素自身的点击。 按键修饰符 系统修饰符 鼠标按钮修饰符 使用 v-on 或 @ 有几个好处： 扫一眼 HTML 模板便能轻松定位在 JavaScript 代码里对应的方法。 因为你无须在 JavaScript 里手动绑定事件，你的 ViewModel 代码可以是非常纯粹的逻辑，和 DOM 完全解耦，更易于测试。 当一个 ViewModel 被销毁时，所有的事件处理器都会自动被删除。你无须担心如何清理它们。 表单输入绑定 你可以用 v-model 指令在表单 、 及 元素上创建双向数据绑定。它会根据控件类型自动选取正确的方法来更新元素。尽管有些神奇，但 v-model 本质上不过是语法糖。它负责监听用户的输入事件来更新数据，并在某种极端场景下进行一些特殊处理。 复选框 单个复选框，绑定到布尔值 多个复选框，绑定到同一个数组 Jack John Mike Checked names: Vue.createApp({ data() { return { checkedNames: [] } } }).mount('#v-model-multiple-checkboxes') 单选框 One Two Picked: Vue.createApp({ data() { return { picked: '' } } }).mount('#v-model-radiobutton') 选择框 Please select one A B C Selected: Vue.createApp({ data() { return { selected: '' } } }).mount('#v-model-select') 组件基础 组件是带有名称的可复用实例，可以将组件进行任意次的服用 组件有两种注册类型：全局注册和局部注册，全局注册可以在应用中的任何组件的模块中使用 通过prop向子组件传递数据 一个组件默认可以拥有任意数量的 prop，无论任何值都可以传递给 prop，可以使用 v-bind 来动态传递 prop。 监听子组件事件 我们可以在组件的 emits 选项中列出已抛出的事件： app.component('blog-post', { props: ['title'], emits: ['enlargeText'] }) 子组件可以通过内建的 $emit 方法并传入事件名称来触发一个事件 enlarge text 在组件上使用 v-model 等价于 当用在组件上时，v-model 则会这样： 其它 npm run dev 和 npm run serve 的区别 npm run dev 是 vue-cli2.0 版本使用的，npm run serve 是 vue-cli3.0 版本使用的 vue-cli2.0： \"dev\": \"webpack-dev-server --inline --progress --config build/webpack.dev.conf.js\", \"start\": \"npm run dev\", \"build\": \"node build/build.js\" } 复制代码 vue-cli3.0： \"serve\": \"vue-cli-service serve --open\", \"build\": \"vue-cli-service build\", \"lint\": \"vue-cli-service lint\" } 遇到一个问题，使用 npm run serve 命令可以启动项目，但会包找不到路径的错误，最后使用 npm run dev 终于解决(使用 npm start 也不行，跳出页面不大对)，以下是配置文件 \"scripts\": { \"serve\": \"vue-cli-service serve\", \"dev\": \"npm run ready && concurrently \\\"npm run serve -- --open\\\" \\\"npm run route watch\\\"\", \"start\": \"node bin/my start\", }, 还是没搞懂，以后启动注意使用的脚手架版本，虽然脚本里面有这个命令，但是的确不一定能启动起来 "},"font/WebSocket.html":{"url":"font/WebSocket.html","title":"WebSocket","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 概念 Frp WebSocket [toc] 知乎 教程 概念 WebSocket是一种通信协议，可在单个TCP连接上进行全双工通信。WebSocket使得客户端和服务器之间的数据交换变得更加简单，允许服务端主动向客户端推送数据。在WebSocket API中，浏览器和服务器只需要完成一次握手，两者之间就可以建立持久性的连接，并进行双向数据传输。 WebSocket.onopen： 连接成功后的回调 WebSocket.onclose： 连接关闭后的回调 WebSocket.onerror： 连接失败后的回调 WebSocket.onmessage： 客户端接收到服务端数据的回调 webSocket.bufferedAmount： 未发送至服务器的二进制字节数 WebSocket.binaryType： 使用二进制的数据类型连接 WebSocket.protocol ： 服务器选择的下属协议 WebSocket.url ： WebSocket 的绝对路径 WebSocket.readyState： 当前连接状态，对应的四个常量 WebSocket.CONNECTING: 0 WebSocket.OPEN: 1 WebSocket.CLOSING: 2 WebSocket.CLOSED: 3 方法： WebSocket.close() 关闭当前连接 WebSocket.send(data) 向服务器发送数据 Frp gitHub doc frp是一种快速反向代理，可帮助您将NAT或防火墙后面的本地服务器公开到Internet。到目前为止，它支持TCP和UDP以及HTTP和HTTPS协议，在这些协议中，请求可以通过域名转发到内部服务。 "},"font/被删的前端游乐园.html":{"url":"font/被删的前端游乐园.html","title":"被删的前端游乐园","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 感想 被删的前端游乐园 博客地址 [toc] 感想 先粗略的看了一遍，写的真的好，前端入门梳理出了前端的大概的东西，被删佬的文字也很吸引人 "},"font/浏览器.html":{"url":"font/浏览器.html","title":"浏览器","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 浏览器事件 async 动态脚本 跨源策略 浏览器 location 对象允许我们读取当前的 url， 并且可以将浏览器重定向到新的 url DOM 将 HTML 表示为标签的树形结构 在 DOM 中， null 就意味着不存在 子节点 子孙元素 childNodes 集合列出了所有子节点，包括文本节点 firstChild lastChild hasChildNodes sibling 可以使用 for of 对集合进行迭代，不能使用 for in 来迭代集合 children 仅作为元素节点的子代的节点 firstElementChild parentElement table.rows 元素的结合 节点属性：type，tag 和 content 可以使用 instanceof 来检查继承 console.log console.dir 给定一个 DOM 节点，我们可以从 nodeName 或者 tagName 属性中来读取它的标签名 innerHTML 可以加入元素进去， outerHTML 属性包含了元素的完整 HTML querySelector querySelectroAll 与 innerHTML 不同，写入 outerHTML 不会改变元素，而是在 DOM 中替换它 innerHTML 仅对元素节点有效， nodeValu 和 data 属性两者在实际使用中作用几乎相同 hidden 与 style=\"display:none\" 做的是相同的事，但是 hidden 更简洁 特性和属性（Attributes and properties），大多数标准的HTML特性（attributes）会自动变成 DOM 对象的属性 // 创建一个div let div = document.createElement('div') div.className = 'alert' div.innerHTML = 'hi' document.body.append(div); before after preappend append node.remove() elem.cloneNode(true) elem.cloneNode(false) elem.innerHTML 会识别标签的， elem.append(document.createTextNode(text)) elem.textContent = text 只是单纯的替换里面的文本 let ul = document.createElement('ul') document.body.append(ul) while(true) { let data = prompt('Enter the text for the list item', ''); if(!data){ break; } let li = document.createElement('li'); li.textContent = data; ul.append(li) } 遍历对象最简单的就是使用递归 将一个对象变成一个列表 let data = { \"Fish\": { \"trout\": {}, \"salmon\": {} }, \"Tree\": { \"Huge\": { \"sequoia\": {}, \"oak\": {} }, \"Flowering\": { \"apple tree\": {}, \"magnolia\": {} } } }; function createTree(container, obj) { container.innerHTML = createTreeText(obj); } function createTreeText(obj) { let li = ''; let ul; for (let key in obj) { li += '' + key + createTreeText(obj[key]) + ''; } if(li) { ul = '' + li + ' 样式和类，相较于将样式写入style属性，我们应该首选通过css类的方式来添加样式，仅当类无法处理时，才选择style属性的方式 elem.className 对应于 class 特性，elem.classList 是一个特殊的对象，它具有 add/remove/toggle 单个类的方法 elem.style 是一个对象，对应与 style 特性中所写的内容 document.body.style.display = 'none' setTimeout(() => document.body.style.display = '', 1000) style属性仅对 style 特性值起作用，而没有任何的css级联，因此我们无法使用 elem.style 读取来自 css 类的任何内容 let computedStyle = getComputedStyle(document.body) alert(computedStyle.marginTop) alert(computedStyle.color) CSS 的全名叫做 Cascading Style Sheets，翻译为层叠样式表，也可以叫做级联样式表，层叠：可以简单理解为冲突的解决方案 计算（computed) 样式值是所有 css规则和 css 继承都应用后的值，这是这是css级联（cascade）的结果，它看起来像是 height: 1em 或 font-size: 125% 解析样式值是最终应用于元素的样式值，单位是固定的，且绝对单位，如 height: 20px 很久以前就有 getComputedStyle 来获取计算值，但事实证明，解析值要方便得多，所以现在getComputedStyle实际上返回的是属性的解析值 注意滚动条，如果没有滚动条，内容宽度将是300px，因为有了滚动条，所以宽度会有所减少 如果元素中有很多文本，并且溢出了，那么浏览器会在 padding-bottom 处显示溢出文本 offsetWidth/Height 这两个属性是最简单的，它们提供了元素的外部 width/height ，换句话说，它的完整大小（包括边框） // 用来检查一个元素是否被隐藏 function isHidden(elem) { return !elem.offsetWidth && !elem.offsetHeight } clientLeft 左边框宽度， clientTop 上边框宽度 为了获取窗口（window）的宽度和高度，我们可以使用document.documentElement 的 clientWidth/clientHeight 大多数情况下，我们需要可用的窗口宽度以绘制或放置某些东西 DOCTYPE 很重要，当 HTML 中没有 时，顶层几何属性的工作方式可能有所不同，在现代 HTML中，我们始终都应该写 DOCTYPE 必须在 DOM 完全构建好之后才能通过 js 滚动页面 大多数 js 方法处理的是以下两种坐标系中的一个： 相对于窗口，类似于 position: fixed ，从窗口的顶部/左侧边缘计算得出，表示为 clientX/clientY 相对于文档，类似于 position: absolute ，从文档的顶部/左侧边缘计算得出， 表示为 pageX/pageY elem.getBoundingClientRect() 返回最小矩形的窗口坐标，属性：x/y 矩形原点相对于窗口的 x/y 坐标，width/height 浏览器事件 为了对事件做出响应，我们可以分配一个处理程序，一个在事件发生时运行的函数，处理程序是在 action 时运行 JavaScript 代码的一种方式，有几种处理程序的方法 HTML 特性 处理程序可以设置在html 中名为 on 的特性（attribute）中 html 特性不是编写大量代码的好地方，因此我们最好创建一个 JavaScript 函数，然后在 html 特性中调用这个函数 html 特性名是大小写不敏感 DOM 属性 我们可以使用 DOM 属性 on 来分配处理程序 elem.onclick = function() { alert('thank you') } elem.onclick = function() { alert('after'); } 移除一个处理程序，赋值 elem.onclick = null 访问元素：this 处理程序中 this 的值是对应的元素，也就是处理元素所在的那个元素 click me 可能出现的错误 button.onclick = sayThanks; button.onclick = sayThanks; // 错误 但在标记中，我们确实需要括号 addEventListener 上述分配处理程序的方式的根本问题是：我们不能为一个事件分配多个处理程序 假如，我们点击一个按钮，一部分想要高亮，一部分想要显示信息，新的dom属性会覆盖现有的dom属性，移除是removeEventListener element.addEventListener(event, handler[, options]); options 具有以下属性的附加可选对象：once capture passive 如果我们不讲函数存储在一个变量，那么我们就无法移除它 function handler1() { alert('thanks!') } function handler2() { alert('thanks again!') } elem.onclick = () => alert('Hello') elem.addEventListener('click', handler1) elem.addEventListener('click', handler2) 有些事件只能通过 addEventListener 处理设置程序，如 DOMContentLoaded 事件对象 elem.onclick = function(event) { alert(event.type + ' at ' + event.currentTarget) alert('coordinates: ' + event.clientX + ':' event.clientY) } event 对象的一些属性：event.type event.currentTarget event.clientX/clientY 无论 addEventListener 怎样，button.onclick 处理程序都会触发 冒泡与捕获 当一个事件发生在一个元素上，它会首先运行在该元素上的处理程序，然后运行其父元素的处理程序，然后一直向上到其它祖先的处理程序 引发事件的那个嵌套层级最深的元素称为目标元素，可以通过 event.target 访问 停止冒泡： event.stopPropagation() 捕获与冒泡允许我们实现一种被称为事件委托的事件处理模式，即如果我们有许多以类似方式处理的元素，我们就不必为每个元素分配一个处理程序，而是将单个处理程序放在它们的共同祖先上 let selectedTd; table.onclick function(event) { // let target = event.target; // if(target.tagName != 'TD') return; let td = event.target.closest('td'); if(!td) return; // 先判断是否存在td if(!table.contains(td)) return; // 判断table中是否有td heightLight(target); } function heightLight(td) { if(selectedTd) { selectedTd.classList.remove('heighlight') } selectedTd = td; selectedTd.classList.add('highlight'); } 委托示例： 标记中的行为 例如，我们想要编写一个有“保存”、“加载”和“搜索”等按钮的菜单。并且，这里有一个具有 save、load 和 search 等方法的对象。如何匹配它们？ 第一个想法可能是为每个按钮分配一个单独的处理程序。但是有一个更优雅的解决方案。我们可以为整个菜单添加一个处理程序，并为具有方法调用的按钮添加 data-action 特性（attribute）： Click to save Save Load Search class Menu{ constructor(elem) { this._elem = elem; elem.onclick = this.onClick.bind(this); } save() {} load() {} search() {} onClick(event) { let action = event.target.dataset.action if(action) { this[action] (); } } } new Menu(menu) 行为： 切换器 点击一个具有 data-toggle-id 特性的元素将显示/隐藏 具有给定id 的元素： show the subscription from your mail: document.addEventListener('click', function(event) { let id = event.target.dataset.toggleId; if(!id) return; let elem = document.getElementById(id); elem.hidden = !elem.hidden }) 树形菜单 将每个树节点的标题都包装到 中。然后我们可以在 :hover 上使用 CSS 样式，并精确地处理文本上的点击事件，因为 的宽度恰好是文本的宽度（与没有宽度不同）。 为 tree 的根节点设置一个处理程序，来处理 标题上的点击事件。 for (let li of tree.querySelectorAll('li')) { let span = document.createElement('span'); li.prepend(span); span.append(span.nextSibling); // move the text node into span } // catch clicks on whole tree tree.onclick = function(event) { if (event.target.tagName != 'SPAN') { return; } let childrenContainer = event.target.parentNode.querySelector('ul'); if (!childrenContainer) return; // no children childrenContainer.hidden = !childrenContainer.hidden; } 许多事件会自动触发浏览器执行某些行为。 点击一个链接 —— 触发导航（navigation）到该 URL。 点击表单的提交按钮 —— 触发提交到服务器的行为。 在文本上按下鼠标按钮并移动 —— 选中文本。 表单熟悉和方法 表单（form）以及 （input）的控件（control）元素有许多特殊的属性和事件 当我们有一个表单之后，任何元素都可以通过命名的集合 form.elements 来获取到 let form = document.forms.my let elem = from.elements.one alert(elem.value) Fieldset 作为 子表单 反向引用 element.form input.value, input.checked, select 有三个重要的属性 options, value, selectedIndex 提交表单时，会触发 submit 事件，它通常用于在将表单发送到服务器之前对表单进行校验，或者中止提交 HTML 页面的生命周期包含三个重要事件： DOMContentLoaded —— 浏览器已完全加载 HTML，并构建了 DOM 树，但像 和样式表之类的外部资源可能尚未加载完成。 load —— 浏览器不仅加载完成了 HTML，还加载完成了所有外部资源：图片，样式等。 beforeunload/unload —— 当用户正在离开页面时。 每个事件都是有用的： DOMContentLoaded 事件 —— DOM 已经就绪，因此处理程序可以查找 DOM 节点，并初始化接口。 load 事件 —— 外部资源已加载完成，样式已被应用，图片大小也已知了。 beforeunload 事件 —— 用户正在离开：我们可以检查用户是否保存了更改，并询问他是否真的要离开。 unload 事件 —— 用户几乎已经离开了，但是我们仍然可以启动一些操作，例如发送统计数据。 当浏览器加载 HTML 时遇到 ... 标签，浏览器就不能继续构建 DOM。它必须立刻执行此脚本。对于外部脚本 也是一样的：浏览器必须等脚本下载完，并执行结束，之后才能继续处理剩余的页面。 这会导致两个重要的问题： 脚本不能访问到位于它们下面的 DOM 元素，因此，脚本无法给它们添加处理程序等。 如果页面顶部有一个笨重的脚本，它会“阻塞页面”。在该脚本下载并执行结束前，用户都不能看到页面内容： 幸运的是，这里有两个 特性（attribute）可以为我们解决这个问题：defer 和 async。 defer 特性仅适用于外部脚本 async async 特性与 defer 有些类似。它也能够让脚本不阻塞页面。但是，在行为上二者有着重要的区别。 async 特性意味着脚本是完全独立的： 浏览器不会因 async 脚本而阻塞（与 defer 类似）。 其他脚本不会等待 async 脚本加载完成，同样，async 脚本也不会等待其他脚本。 DOMContentLoaded 和异步脚本不会彼此等待： DOMContentLoaded 可能会发生在异步脚本之前（如果异步脚本在页面完成后才加载完成） DOMContentLoaded 也可能发生在异步脚本之后（如果异步脚本很短，或者是从 HTTP 缓存中加载的） 动态脚本 此外，还有一种向页面添加脚本的重要的方式。 我们可以使用 JavaScript 动态地创建一个脚本，并将其附加（append）到文档（document）中： let script = document.createElement('script') script.src = ',,,' document.body.append(script) 默认情况下，动态脚本的行为是 异步 的 但是可以设置 script.async = false ，则可以改变这个规则 跨源策略 这里有一条规则： 来自一个网站的脚本无法访问其它网站的内容，更确切的说，一个源（域/端口/协议三者）无法获取另外一个源（origin）的内容 要允许跨域， 标签需要具有 crossorigin 特性，并且远程服务器提供特殊的header 这里有三个级别的跨源访问： 无 crossorigin 特性： 禁止访问 crossorigin='anonymous'： 如果服务器的响应带有包含 * 或我们的源的 header Access-Control-Allow-Origin ，则允许访问，浏览器不会将授权信息和 cookie 发送到远程服务器 crossorigin='use-credentials'： 如果服务器发送带有我们源的header Access-Control-Allow-Origin 和 Access-Control-Allow-Credentilas: true 则允许访问，浏览器会将授权信息和 cookie 发送到远程服务器 通常，图片在被创建时才会被加载。所以，当我们向页面中添加 时，用户不会立即看到图片。浏览器首先需要加载它。 为了立即显示一张图片，我们可以“提前”创建它，像这样： let img = document.creteElement('img') img.src = 'my.jpg' function preloadImages(sources, callback) { let counter = 0; function onLoad() { counter++; if (counter == sources.length) callback(); } for(let source of sources) { let img = document.createElement('img'); img.onload = img.onerror = onLoad; img.src = source; } } // ---------- The test ---------- let sources = [ \"https://en.js.cx/images-load/1.jpg\", \"https://en.js.cx/images-load/2.jpg\", \"https://en.js.cx/images-load/3.jpg\" ]; // add random characters to prevent browser caching for (let i = 0; i "},"font/图解HTTP.html":{"url":"font/图解HTTP.html","title":"图解HTTP","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 temp 了解Web及网络基础 框架 负责传输的IP协议 利用 ARP 协议凭借 MAC 地址进行通信 确保可靠性的 TCP 协议 确保数据能够到达目标 其它 简单的HTTP协议 其它 Content-Type Content-Type 在 HTML 表单中 常见的 Content-Type application/x-www-form-urlencoded multipart/form-data application/json application/xml 和 text/xml Content-Type的使用 request 的 Content-Type response 的 Content-Type 子网划分、子网掩码 基础 网络发展过程 LAN ip地址的定义和分类 定义 分类 特殊的 ip 地址 子网掩码 ip 判断 子网划分 子网划分的概念 c 类子网划分 子网划分步骤 为什么要子网划分 子网划分的优点 子网划分注意事项 图解HTTP [toc] temp TCP/IP： 应用层、传输层、网络层、数据链路层 http请求 分割，标记序号和端口号 MAC地址 IP地址的两个重要的条件： IP地址和MAC地址（Media Access Control Access） ip地址是节点被分配的地址，mac地址是网卡所属的固定地址 ARP协议凭借 MAC地址进行通信，根据通信方的 ip地址就可以反查出对应的 mac地址 tcp提供可靠的字节流服务，为了准确的将数据送到目标，tcp协议采用了三次握手策略： 标有syn的数据包发给你了， 我收到你发给我的数据包了（syn/ack的数据包），明白（发送ack的数据包） DNS（domain name system）服务是和http协议一样位于应用层的协议，它提供域名到ip地址之间的解析服务： 我想访问某网页，把它的IP告诉我吧， 它是xx， 我向xx发送请求了 http协议的职责是生成针对目标web服务器的http请求报文 URI 和 URL(uniform resource locator) 请求报文的构成：方法、uri、协议版本、请求首部字段、内容实体 响应报文的构成：协议版本 状态码 原因短语 响应首部字段 主体 http是一种不保存状态的协议，但是有了Cookie就可以管理状态了 HTTP方法： get：我想访问你的某个资源啊 post：我要把这条信息告诉你 put：我要把这份文件传给你 head：把那个相关的信息告诉我 delete：快把那份文件删掉吧 options：你支持哪些方法哇 connect：让我通过一下吧 必须进行多次通信好累啊，所有连接默认都是持久连接 管线化可以看成是异步吗 cookie技术通过在请求和响应报文中写入cookie信息来控制客户端的状态，cookie会根据从服务端发送的响应报文中的一个叫做set-cookie的首端字段信息，通知客户端保存cookie，下次客户端再往该服务器发送请求时会自动在报文中加入cookie 生成cookie，记住是向谁发送的 啊，原来是刚才那家伙哇 http报文大致可以分为报文首部和报文主题两块 编码以提升传输速率： 紧紧的压缩 多部分对象集合包含的对象如下： multipart/form-data multipart/byteranges range: 把那剩余的部分给我 206 内容协商（content negotiation）返回最合适的内容 状态码告知从服务器端返回结果：2xx，进展很顺利 4xx，5xx似乎不行啊 1正在处理 2正常处理完毕 3重定向 4服务器无法处理请求 5服务器处理请求出错 204 没资源返回 206我只要一部分 301资源的uri已经更新，你也更新一下吧 302资源临时定位到其它位置了，暂时你换个uri访问吧 303uri已经更新，你要按新的来访问吗 304资源已找到，但是不符合要求 307我和302差不多 400 我无法理解这个请求，是不是错了 401我需要认证的 403不允许访问那个资源啊 404服务器上没有该资源啊 500貌似内部资源出故障了 503抱歉，我正在忙呢 状态码和状态经常不一致，有时候后端已经出错了，但是也返回了 200 ok 的状态码 用单台虚拟主机实现多个域名，若是部署在同一个服务器上，它们的ip地址会相同，由于相同的ip地址，所以在发送HTTP请求时必须在host首部内完整指定主机名或域名的uri 通信数据转发程序：代理、网关、隧道 报文首部：在客户端和服务器处理时起至关重要作用的信息几乎都在这里 报文主体：所需要的用户和资源的信息都在这里 HTTP首部字段传递重要信息，首部字段是由首部字段名和字段值组成，中间用： 分隔，首部字段分为以下四种：通用首部字段、请求首部字段、响应首部字段、实体首部字段 端到端首部，逐跳首部 Cache-Control操作缓存的工作机制：如果有缓存请给我、我喜欢你不要对此做缓存 Cache-Control: private：这份缓存只可以提供给那个家伙使用喔 Cache-Control: no-cache：我不要缓存过的，请给我从源服务器那里拿来资源 你可以缓存，但每次使用前先向我确认一下 Cache-Control: max-age=604800：要是缓存没超过一周，就把他给我吧 一周内不必向我确认，你直接支配该缓存就好了 Connection: 控制不在转发给代理的首部字段，管理持久连接：把这个删除后再转发喔 这下我和你的关系结束了 Accept：该字段可通知服务器，用户代理能够处理的媒体类型以及媒体类型的优先级 http + 加密 + 认证 + 完整性 = https websocket 了解Web及网络基础 框架 TCP/IP协议簇分为四层：应用层（FTP（file transition protocol）、DNS（domain name system））、传输层（TCP（transition control protocol）、UDP（user data protocol））、网络层（Internet protocol）、链路层 TCP/IP通信传输流 负责传输的IP协议 TCP/IP协议簇的IP指的就是网络协议，在名称中就占据了一半的位置，可见其重要性。 IP协议是 Internet Protocol，它包括 IP 地址和 MAC(media access control address) IP 地址和 MAC地址的区别 IP协议的作用是把各种数据包传送给对方，而要保证确实传送到对方那里，则需要满足各类条件，其中最重要的两个条件是 IP 地址和 MAC 地址，IP地址指明了节点被分配的地址，MAC地址指明了网卡所属的固定地址 利用 ARP 协议凭借 MAC 地址进行通信 IP 间的通信依赖 MAC 地址，在网络上，通信的双方在同一局域网（LAN）的情况是很少的，通常要经过多次中转才能连接对方。而在进行中转时，会利用下一站中转设备的MAC地址来搜索下一个中转目标。ARP协议通过ip地址反查出mac地址 确保可靠性的 TCP 协议 TCP协议位于传输层，提供可靠的字节流服务 字节流服务：为了方便将大块数据分割以报文段（segment）为单位的数据包进行管理。TCP协议为了更容易传送大数据才把数据分割，而TCP协议能够确认数据最终是否传送给了对方 确保数据能够到达目标 为了确保无误的将数据送达目标处，TCP协议采用了三次握手（three-way handshaking），四次挥手策略 三次握手，四次挥手 其它 DNS（Domain Name System）服务是和HTTP协议一样位于应用层的协议，它提供域名到IP地址之间的解析服务 各种协议与HTTP协议之间的关系 URL(uniform resource locator) 统一资源定位符 URI（uniform resource identifier）统一资源标识符 url 就是使用定位的方式实现 uri 简单的HTTP协议 其它 Content-Type MDN Content-Type 实体头部用于指示资源的 MIME 类型(media type，指示文件类型的字符串) 在响应中，Content-Type 标头告诉客户端实际返回的内容的内容类型；在请求中（如 POST 或 PUT），客户端告诉服务端实际发送的数据类型 句法： Content-Type: text/html; charset=utf-8 Content-Type: multipart/form-data; boundary=something Content-Type 在 HTML 表单中 在通过 HTML form 提交生成的 POST 请求中，请求头的 Content-Type 由 form 元素上的 enctype 属性指定 Submit 请求头看起来像这样（在这里省略了一些 headers）： POST /foo HTTP/1.1 Content-Length: 68137 Content-Type: multipart/form-data; boundary=---------------------------974767299852498929531610575 ---------------------------974767299852498929531610575 Content-Disposition: form-data; name=\"description\" some text ---------------------------974767299852498929531610575 Content-Disposition: form-data; name=\"myFile\"; filename=\"foo.txt\" Content-Type: text/plain (content of the uploaded file foo.txt) ---------------------------974767299852498929531610575 MDN 的内容有点少啊，又看了一下简书的内容， Content-Type 常见的 Content-Type HTML文档标记 ：text/html 普通ASCII 文档标记： text/html JPEG 图片标记：image/jpeg gif 图片编辑：image/gif js文档标记： application/javascript xml文件标记： application/xml application/x-www-form-urlencoded HTTP会将请求参数用 key1 = val1 & key2 = val2 的方式进行组织，并放到请求实体里面，如果是中文或特殊字符则会自动进行URL转码，一般用于表单提交，不支持文件 请求 http 请求报头 multipart/form-data 与 application/x-www-form-urlencoded 不同，这是一个多部分多媒体类型，首先生成了一个 boundary 用于分割不同字段，在请求实体里每个参数以 --------boundary 开始，然后是附加信息和参数名，然后是空行，最后是参数内容。多个参数将会有多个 boundary 块，如果参数是文件会有特别的文件域。最后以 ------boundary- 为结束标志，multipart/form-data 支持文件上传的格式，一般需要上传文件的表单则用该类型 请求参数 http 请求报文 application/json json是一种轻量级的数据格式，以键值对的方式组织的数据，使用这个类型，需要参数本身就是json格式的数据，参数会被直接放到请求实体里，不进行任何处理，服务端/客户端会按json格式解析数据（约定好的情况下） 请求参数 http 请求报文 application/xml 和 text/xml 与application/json类似，这里用的是xml格式的数据，text/xml的话，将忽略xml数据里的编码格式 Content-Type的使用 request 的 Content-Type 一般我们在开发过程中需要注意客户端发送请求（Request）的 Content-Type 设置，特别是使用 ajax 的时候，如果设置得很不准确，很有可能会导致请求失败。比如在 spring 中，如果接口使用了 @RequestBody，spring 强大的自动解析功能，会将请求实体的内容自动转换为 Bean，但前提是请求的 Content-Type 必须设置为 application/json，否则会返回 415 错误 415 unsupported media type，即不支持的媒体类型 建议： 如果是一个 restful 接口（json格式），一般将 Content-Type 设置为 application/json; charset=utf-8 如果是文件上传，一般是设置为 multipart/form-data 如果是普通的表单提交，一般是设置为 application/x-www-form-urlencoded response 的 Content-Type 服务端响应（response）的 Content-Type 最好也保持准确，虽然一般 web 开发中，前端解析响应的数据不会根据 Content-Type，并且服务端一般能自动设置准备的 Content-Type，但是如果乱设置的情况下可能会有些问题，比如导出文件，比如导出文件，打开图片等，如果在 spring 项目里使用 @ResponseBody，spring 会将响应的 Content-Type 设置为 application/json； charset=utf-8；可能会导致文件无法导出 response 的 Content-Type 设置建议： 一般情况下不需要显示设置 如果是文件导出，Content-Type 设置为 mulitpart/form-data，并且添加一个 Content-Disposition 设置为 attachment;fileName =文件.后缀 注：Content-Disposition 是 Content-Type 的扩展，它告诉浏览器弹窗下载框 例子： 未正确设置 response 的 Content-Type 的情况，客户端会将 json 数据当成普通文本 Content-Type: text/html;charset=utf-8 正确设置 response 的Content-Type 的情况，客户端将 json 数据自动解析 Content-Type: application/json; charset=utf-8 子网划分、子网掩码 网络基础知识_子网划分 基础 网络发展过程 计算机与通信的融合过程就是计算机网络的发展过程，利用通信线路把位于不同的点上的多个计算机系统相互连接起来便形成了计算机网络，在网络中，通过功能完善的网络软件的管理，可以共享某些软件、硬件和数据资源。计算机网络的发展经历了三个阶段：具有通信功能的单机系统，具有通信功能的多级系统和计算机网络 LAN 局域网（LAN）的发展：LAN 有三种基本的拓扑结果：总线型，环形，星型，市场提供三种使用的传输介质：双绞线，电缆和光纤 ip地址的定义和分类 定义 ip地址是唯一标识网络上的计算机，ip 由一个 32 位的0，1字符串组成，额也可以点分十进制表示，网络中每个路由或者主机都会拥有一个独一无二的 ip 地址用来区分用户，根据 tcp/ip 协议，连接在 Internet 上的每个设备都必须有一个 ip 地址 ip 地址表示 分类 32bit的ip地址被分为两个部分：网络号（NetWork ID，NID），主机号（Host ID， HID） IPv4定义了5类IP地址：A, B, C, D, E 类 地址分类 地址分类范围 特殊的 ip 地址 网络地址：用于表示网络本身，具有正常的网络号部分，而主机号部分全部为0的ip地址称之为网络地址，如172.16.45.0就是一个B类网络地址 广播地址：用于向网络中的所有的设备进行广播。具有正常的网络号部分，而主机号部分全为1(即255)的ip地址称之为广播地址，如172.16.45.255就是一个B类的网络地址 有限广播地址：指的是32位全位1(即255.255.255.255)的ip地址，用于本网广播 回送地址：网络地址不能以十进制的127作为开头，在地址中数字127保留给系统作为诊断用，称为欢送地址，如127.0.0.1用于回路测试 私有地址：只能在局域网内使用，不能在internet上使用的ip地址称为私有ip地址，私有ip地址有： 10.0.0.0～10.255.255.255，表示一个A类地址 172.16.0.0~172.31.255.255,表示16个B类地址 192.168.0.0～192.168.255.255，表示256个C类地址 0.0.0.0:指已经不是真正意义上的ip地址，它表示的是所有不清楚主机和目的网络，这里的不清楚指的是在本机路由表里没有特定条目指明如何到达 子网掩码 子网掩码是一个 32 位的 2 进制数，其对应网络地址的所有位置都是 1，对应与主机地址的所有位置都是 0。将子网掩码和 IP 地址按位进行逻辑与运算，得到 IP 地址的网络地址，剩下的部分就是主机地址，从而区分出任意 IP 地址中的网络地址和主机地址 子网掩码 ip 判断 子网掩码告知路由器，IP 地址的前多少位是网络地址，后多少位是主机地址，使路由器正确判断任意IP地址是否是本网段的，从而正确的进行路由，例子： 主机1： ip 221.21.160.5 子网掩码：255.255.255.192 主机2： ip 222.21.160.73 子网掩码：255.255.255.192 现在主机1 向 主机 2 发送数据，首先要判断两个主机是否在同一网段，逻辑与运算后，显然前三位的值都是 221.21.160，C 类地址判断前三位是否相同，即可确定2个IP地址是否在同一网段内，但本例中的222.21.160.6与222.21.160.73不在同一网段，因为这两个C类IP地址已经做了子网划分就不能只判断前三位是否相同就确认这两个IP是否在同一网段。其中222.21.160.6在222.21.160.1-222.21.160.62 段，222.21.160.73在222.21.160.65-222.21.160.126 段，所以不在同一网段[2] ，如果要通信需要通过路由器转发。 子网划分 子网划分的概念 子网划分的定义：Internet 组织机构定义了五种 IP 地址，由 A, B, C 三类地址，每个 A 类网络可能由 1600 百多万台主机，它们处于同一广播域，而在同一广播域中由这么多节点是不可能的，网络会因为广播通信而饱和，结果造成大部分地址没有分配出去。可以基于每类的IP网络进一步的分成更小的网络。每个子网由路由器界定并分配一个新的子网网络地址，子网地址是借用基于每类的网络地址的主机部分创建的。划分子网后，通过使用掩码，把子网隐藏起来，使得从外部来看网络没有任何变化。 当我们对一个网络进行子网划分时，基本上就是将它分成小的网络。比如，当一组IP地址指定给一个公司时，公司可能将该网络“分割成”小的网络，每个部门一个。这样，技术部门和管理部门都可以有属于它们的小网络。通过划分子网，我们可以按照我们的需要将网络分割成小网络。这样也有助于降低流量和隐藏网络的复杂性。 子网划分是通过借用 ip 地址的若干位主机位来充当子网地址，从而将原来的网络分为若干个彼此隔离的子网实现的 子网划分 注意： arp 协议通过 ip 地址获取目标主机的mac地址这一过程是使用的广播的方式，这个广播地址就是通过子网地址于子网掩码计算而来的，只有计算出的这一子网内的主机才能收到这个 arp 广播包 子网划分和 vlan 都可以做到隔离广播域，只是子网划分是三层隔离，vlan 是二层隔离 c 类子网划分 c 类网络子网划分 划分子网时，随着子网地址借用主机位数的增多，子网的数目随之增加，而每个子网中的可用主机数逐渐减少。以C类网络为例，原有8位主机位，2的8次方即256个主机地址，默认子网掩码255.255.255.0。借用1位主机位，产生2个子网，每个子网有126个主机地址；借用2位主机位，产生4个子网，每个子网有62个主机地址……每个网中，第一个IP地址（即主机部分全部为0的IP）和最后一个IP（即主机部分全部为1的IP）不能分配给主机使用，所以每个子网的可用IP地址数为总IP地址数量减2；根据子网ID借用的主机位数，我们可以计算出划分的子网数、掩码、每个子网主机数，列表如下： ​ ① 划分子网数 ② 子网位数 ③子网掩码（二进制） ④ 子网掩码（十进制） ⑤ 每个子网主机数 ​ ① 1～2 ② 1 ③ 11111111.11111111.11111111.10000000 ④ 255.255.255.128 ⑤ 126 　　 ① 3～4 ② 2 ③ 11111111.11111111.11111111.11000000 ④ 255.255.255.192 ⑤ 62 　　 ① 5～8 ② 3 ③ 11111111.11111111.11111111.11100000 ④ 255.255.255.224 ⑤ 30 　　 ① 9～16 ② 4 ③ 11111111.11111111.11111111.11110000 ④ 255.255.255.240 ⑤ 14 　　 ① 17～32 ② 5 ③ 11111111.11111111.11111111.11111000 ④ 255.255.255.248 ⑤ 6 　　 ① 33～64 ② 6 ③ 11111111.11111111.11111111.11111100 ④ 255.255.255.252 ⑤ 2 ​ 如上表所示的C类网络中，若子网占用7位主机位时，主机位只剩一位，无论设为0还是1，都意味着主机位是全0或全1。由于主机位全0表示本网络，全1留作广播地址，这时子网实际没有可用主机地址，所以主机位至少应保留2位。 子网划分步骤 确定要划分的子网数以及每个子网的主机数 求出子网数目对应的二进制的位数 N 及主机数目对应的二进制数的位数 M 对该ip地址的原子网掩码，将其主机地址部分的前N位置1(其余全部置0)或后M位置0(其余全置1)即得出该ip地址划分子网后的子网掩码 eg：给 C 类网络 211.168.10.0 划分 5 个子网 22-23-2所以需要3位网络号，主机号为8-3=5 子网掩码为255.255.255.224 每个子网可容纳2**5-2=30台主机 为什么要子网划分 Internet组织机构定义了五种IP地址，用于主机的有A、B、C三类地址。其中A类网络有126个，每个A类网络可能有16，777，214台主机，它们处于同一广播域。而在同一广播域中有这么多结点是不可能的，网络会因为广播通信而饱和，结果造成16，777，214个地址大部分没有分配出去，形成了浪费。而另一方面，随着互连网应用的不断扩大，IP地址资源越来越少。为了实现更小的广播域并更好地利用主机地址中的每一位，可以把基于类的IP网络进一步分成更小的网络，每个子网由路由器界定并分配一个新的子网网络地址,子网地址是借用基于类的网络地址的主机部分创建的。划分子网后，通过使用掩码，把子网隐藏起来，使得从外部看网络没有变化，这就是子网掩码。 很简单的说 就是，一个公司不可能使用254个公网地址，A公司想用6个地址，B公司也想用6个地址，如果把这两个公司的地址都放在一个大网段里面，这两个公司的地址就能够直接互通 子网划分的优点 减少网络流量 提高网络性能 简化管理 易于扩大地理范围 子网划分注意事项 在子网划分时不仅需要考虑目前需要，还应该了解将来需要多说子网和主机。子网掩码使用较多的主机位，可以得到更多子网，节约了ip地址资源，若将来需要更多的子网时，不用再重新分配ip地址，但每个子网的主机数量有限；反之，子网掩码使用较少的主机位，每个子网的主机数允许有更大的增长，但可用子网数有限 一般来说，一个网络中的节点数太多，网络会因为广播通信而饱和，所以网络中的主机数量的增长是有限的，也就是说，在条件允许的情况下，应将更多的主机位用于子网位 "},"gis/GDAL.html":{"url":"gis/GDAL.html","title":"GDAL","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 GDAL简介 什么是GDAL？ 编译gdal C++ Python OGR空间参考 空间参考简介 地图投影 OGR实现空间参考 OGR库说明 Geometry（几何对象） Spatial Reference(空间参考) Feature/Feature Definition（要素/要素定义） Layer（图层） Data Source（数据源） Drivers（格式驱动） GDAL库说明 GDAL数据集总体概况 GDAL常用类说明 GDAL元数据说明 RasterIO使用说明 图像金字塔 颜色表 图像统计信息 GDAL数据格式及配置项说明 GDAL格式扩展说明 栅格格式扩展 矢量格式扩展 实现OGRSFDriver类 从数据源读取数据 GDAL算法的使用说明 GDAL算法处理基础 GDALWarp说明 GDAL坐标转换 GDAL地形分析 格网插值 小碎斑去除 矢量栅格化 栅格矢量化 CPL库介绍 GDAL [toc] GDAL源码剖析与开发共9章分3个部分： 第一部分为前五章，GDAL简介，ORG库，GDAL库以及GDAL的数据格式和配置项 第二部分是6到8章，GDAL的高级使用说明，包括GDAL格式扩展，GDAL算法和CPL库 第三部分是第9章，介绍GDAL工具的使用 GDAL简介 什么是GDAL？ GDAL提供了一系列算法接口，比如矢量栅格化，栅格矢量化，图像校正以及DEM相关的算法接口 GDAL源码目录结构 alg：提供算法的源代码，算法有：DEM生成登高线，图像纠正算法，栅格矢量化，矢量栅格化，格网计算，分类图小碎斑块去除 apps：存放的是GDAL库中提供的一些命令行工具集的源代码，eg：gdalinfo data：配置文件，eg：各种投影文件 doc：帮助文档 frmts：gdal针对不同图像格式解析的源代码 gcore：gdal的灵魂，抽象类的数据集，波段，图像读写接口都在这里面 ogr：emmm，负责读写矢量的 port：gdal库的底层的支持库，基本操作的实现，eg：字符串的操作，文件处理，网页请求，数据库连接，哈希表，字符加密文件压缩等 swig：封装库的工具 编译gdal C++ nmake -f makefile.vc 有坑，gdal3版本以上的编译的时候需要proj库的支持 又重新下载了2.4.1版本的 编译结果： 生成gdal_vs2017.vcxproj这个文件 执行：generate_vcxproj.bat 15.0 64 gdal_vs2017（虽然我是2019的环境，但是好像没有影响） 有这个文件之后就可以编译了 打开该文件，生成解决方案（可能会要求重定解决方案目标）即可 Python python编译就很简单，有环境就行，但是我记得好像有坑，对，就是版本不符合的情况，需要环境对应的版本，所以不能使用conda和pip的方式安装，需要自己下载对应的版本 OGR空间参考 空间参考简介 大地水准面：由静止海水面向大陆延伸所形成的不规则的封闭曲面 地球椭球体：人们选用的一个同大地水准面相近的可以用数学方法来表达的椭球体（规则曲面） 基准面：特定区域内与地球表面极为吻合的椭球体 地图投影 把地球表面的任意点利用一定的数学法则，转换到地图平面上的理论和方法 地理坐标系（GCS) 用于确定地物在地球上位置的坐标系，一般是基于某一个基准面使用三维球面来定义位置。GCS应该包括：角度测量单位、本初子午线、基准面。 投影坐标系（JCS） 投影坐标系是基于地理坐标系的，使用x，y值来描述地球上某个点的位置 OGR实现空间参考 空间参考主要有以下十种表示方法（gdal默认格式为WKT）： 在OGR中，类OGRSpatialReference封装了投影和基准面的定义。 导入坐标系： ImportFromWkt() ImportFromEPSG() ImportFromProj4() ImportFromESRI() ImportFromPCI(, , ) ImportFromUSGS(, ) ImportFromXML() 导出坐标系： ExportToWkt() ExportToPrettyWkt() ExportToProj4() ExportToPCI() ExportToUSGS() ExportToXML() OGR空间参考的转换是基于PROJ4库来实现的。OGR中进行坐标转换的类是OGRCoordinateTransformation，转换的时候先创建一个对象，然后调用Transform方法来进行坐标转换。 对一个几何形状进行投影变换（Linux环境下）： sourceSR = osr.SpatialReference() sourceSR.ImportFromEPSG(32612) #UTM 12N WGS84 targetSR = osr.SpatialReference() targetSR.ImportFromEPSG(4326) #Geo WGS84 coordTrans = osr.CoordinateTransformation(sourceSR, targetSR) geom.Transform(coordTrans) 这个过程很可能会失败，因为它可能使用了PROJ.4库不支持的投影或者转换的几何对象中有一个以上没有定义的数字。 OGR库说明 OGR主要由以下七个部分组成： Geometry：类Geometry (包括OGRGeometry等类)封装了OpenGIS的矢量数据模型，并提供了一些几何操作，WKB(Well Knows Binary)和WKT(Well Known Text)格式之间的相互转换，以及空间参考系统(投影)。 Spatial Reference：类OGRSpatialReference封装了投影和基准面的定义。 Feature：类OGRFeature封装了一个完整feature的定义，一个完整的feature包括一个geometry和geometry的一系列属性。 Feature Definition：类OGRFeatureDefn里面封装了feature的属性，类型、名称及其默认的空间参考系统等。一个OGRFeatureDefn对象通常与一个层(layer)对应。 Layer：类OGRLayer是一个抽象基类，表示数据源类OGRDataSource里面的一层要素(feature)。 Data Source：类OGRDataSource是一个抽象基类，表示含有OGRLayer对象的一个文件或一个数据库。 Drivers：类OGRSFDriver对应于每一个所支持的矢量文件格式。类OGRSFDriver由类OGRSFDriverRegistrar来注册和管理。 Geometry（几何对象） Geometry包括了各种各样的矢量图形 # 创建一个点 point = ogr.Geometry(ogr.wkbPoint) point.AddPoint(1198054.34, 648493.09) # 创建一条线 line = ogr.Geometry(ogr.wkbLineString) line.AddPoint(1116651.439379124, 637392.6969887456) line.AddPoint(1188804.0108498496, 652655.7409537067) line.AddPoint(1226730.3625203592, 634155.0816022386) line.AddPoint(1281307.30760719, 636467.6640211721) # 创建一个面 # 先创建一个ring ring = ogr.Geometry(ogr.wkbLinearRing) ring.AddPoint(1179091.1646903288, 712782.8838459781) ring.AddPoint(1161053.0218226474, 667456.2684348812) # 把ring添加进面 poly = ogr.Geometry(ogr.wkbPolygon) poly.AddGeometry(ring) print(\"point:\\n\",point,\"\\nline:\\n\",line,\"\\npolygon:\\n\",poly) # 从不同格式中创建点 # WKT wkt = \"POINT (1120351.5712494177 741921.4223245403)\" point1 = ogr.CreateGeometryFromWkt(wkt) # WKB wkb = b64decode(\"AIAAAAFBMkfmVwo9cUEjylouFHrhAAAAAAAAAAA=\") point2 = ogr.CreateGeometryFromWkb(wkb) # GeoJSON geojson = \"\"\"{\"type\":\"Point\",\"coordinates\":[108420.33,753808.59]}\"\"\" point3 = ogr.CreateGeometryFromJson(geojson) # GML gml = \"\"\"108420.33,753808.59\"\"\" point4 = ogr.CreateGeometryFromGML(gml) # 打印数据 print(\"point1:\\t\",point1,\"\\tpoint2:\\t\",point2,\"\\npoint3:\\t\",point3,\"\\tpoint4\\t\",point4) Geometry还提供了常用的空间分析方法，如求并、交、缓冲区等（基于GEOS库），但是也有很多空间分析方法也没有实现，如叠加 Spatial Reference(空间参考) OGR的空间参考系统数据模型继承了OpenGIS的WKT格式，还有一个基于PROJ.4库实现的OGRCoordinateTransformation类用以在不同的坐标系中进行转换 Feature/Feature Definition（要素/要素定义） OGRFeature包含了一个OGRGeometry对象，此外还有要素属性、要素ID和要素的类别信息 对于属性表来说，属性的类型、名称是通过OGRFeatureDefn类来定义的，通常一个图层（Layer）对应一个属性表（OGRFeatureDefn），同样类型的要素及其属性表的定义是相同的。 Layer（图层） OGRLayer类用来表示一个数据源中一个图层的所有要素，它包含了从数据源中读取要素的方法，OGRLayer可以认为是从数据源中读写要素数据的途径。 OGRLayer包含顺序和随机的读写数据的方法，时间顺序读取所有的要素（GetNextFeature），空间过滤器按照地理范围来找需要的要素（SetSpatialFileter，只能对一个指定图层），更复杂的Fileter可以执行SQL查询语句 layerSites.SetSpatialFilterRect(460000, 4590000, 490000, 4600000) #SQL过滤 result = dsSites.ExecuteSQL(\"select * from sites where cover = 'grass' order by id desc\") resultFeat = result.GetNextFeature() while resultFeat : printf(resultFeat.GetField('id')) resultFeat = result.GetNextFeature() dsSites.ReleaseResultSet(result) #将查询结果释放 OGRLayer 类和 OGRFeatureDefn类是独立的，但是一个OGRLayer类总是对应一个OGRFeatureDefn类，为什么不将它们合并为一个类呢？ 定义的OGRFeature和OGRFeatureDefn是不需要依赖任何OGRLayer 的，所以他们可以在内存中独立存在而不需要依赖数据源中的某个图层 SF CORBA模型没有图层的概念 Data Source（数据源） 一个DataSource是一系列OGRLayer的组合，通常表示为一个文件。OGRDataSource是一个抽象基类，从该类派生的每个子类都是一种文件格式驱动的实现，我们不能直接实例化该类，而是实例化OGRSFDriver类。 Drivers（格式驱动） 每一个OGRSFDriver对象都是一个OGR支持的一种文件格式的实现，OGRSFDriver对象使用OGRSFDriverRegistrar类来进行注册的。 GDAL库说明 GDAL数据集总体概况 GDAL使用抽象数据模型来解析它所支持的数据格式，抽象数据模型包括以下几部分：数据集（Dataset），坐标系统（Coordinate System），仿射地理坐标转换（Affine GeoTransform），地面控制点（GCPs），元数据（Metadata），子数据集域（Subdatasets Domains），图像结构域（Image_Structure Domain）、RPC域（RPC Domain）、XML域（XML Domian），栅格波段（Raster Band），颜色表（Color Table）和快视图（Overviews） 数据集（Dataset）是有栅格波段和一些相关信息共同组成，在一个数据集中所有波段具有相同的大小，相关信息包括数据的地理坐标、投影信息和一些元数据信息等 坐标系统使用WKT格式来表示，GDAL数据集中有两种方式来表示栅格序列号坐标和地理坐标之间的关系，第一种是利用仿射变换来表示，另外一种是利用GCP（地面控制点）点对来表示，数据集中一般会包含一个仿射地理坐标转换参数或GCP点。GDAL数据模型中不会存储用GCP点对进行图像纠正的转换方程，这个转换方程有应用程序处理 元数据是对数据的辅助说明，与影像在磁盘中的存储方式没有特定关系。 子数据集域是包含有很多个子数据集的字符串列表，提供指向多个影像的指针 图像结构域，与图像的格式及存储机制紧密关联，定义的项目主要有以下几个：compression：数据集或者波段的压缩方式，nbits：当前数据集中一个或多个波段实际占用的比特数，等 RPC域（RPC Domain）：与仿射变换一个作用，都是用来表示图像行列号与空间参考位置间的变换，但是它保存的是有理函数模型的系数 栅格波段（Raster Band），在GDAL中栅格波段使用GDALRasterBand类表示，它表示一个栅格波段、通道或者图层。栅格波段包含以下属性：行列数（可以是金字塔的行列数），数据类型，块大小（通过块读取数据是最高效的方式），元数据，以及一些可选的属性 快视图（Overviews），每个快视图都是一个独立的GDALRasterBand，是通过原始图像进行降采样得到的，用于图像的快速显示。 GDAL常用类说明 GDALDataset是相关栅格波段的集合；GDALDriver是格式化的驱动，这个类的每个实例都支持一种格式，并且管理该格式的相关信息；GDALDriverManager是管理文件格式驱动的注册信息的类；GDALRasterBand是处理一个单波段的栅格数据 GDAL元数据说明 元数据中存储的是对图像数据的描述信息，比如JPG图像中的EXIF信息，HDF数据中的一些描述信息，关于元数据信息可以通过gdalinfo工具进行查看 gdalinfo HYP_50M_SR_W.tif 我们得到的信息有： •图像驱动是“ GTiff / GeoTIFF” •图像尺寸为10800x5400 •图像四个角的坐标 •没有坐标系 RasterIO使用说明 使用GDAL读写图像是最基本的操作了，RasterIO类就是最常用的函数了，RasterIO分为GDALRasterBand类的和GDALDataset类的，两者大多数情况是一致的 图像金字塔 图像金字塔是以多分辨率来解释图像的一种结构，一幅图像的金字塔是一系列以金字塔形状排列的分辨率逐步降低的图像集合。目前遥感图像的金字塔格式主要有两种：rrd格式，ovr格式。 颜色表 颜色表是GDALRasterBand中的一个属性，颜色表的本质是给每一种灰度值设置一个颜色，用以让一个灰度图像变成彩色图像，最常用的就是分类图了，网络地图的矢量切片地图也用颜色表，可以在保持图像色彩不变的情况下大大减少数据量，一般我们认为图像的一个瓦片是一个三波段的PNG图像，实际上它只是一个单波段的带有颜色表的图像。 图像统计信息 图像统计信息包括直方图信息，最大最小值，均值和标准差，在计算统计值的时候，对于大图像的计算量是很大的，所以在第一次计算的时候就把计算的结果信息保存，GDAL使用了一个.aux.xml的辅助文件来将这些信息存储 GDAL数据格式及配置项说明 GDAL库中提供了大多数的图像数据和矢量数据的支持，但是对于某些数据而言，在读写（尤其是创建和更新数据时）时候要按照一定的规则来进行处理，这一章接下来的都是对格式的介绍了，没变要细看 GDAL格式扩展说明 如果算法库是基于GDAL进行编写的，那么要支持一种新的格式，就需要将所有的算法重新编写，这样势必产生大量的重复性工作，但是GDAL提供了格式扩展说明，即使我们处理一些目前GDAL不支持的数据格式，比如自定义的图像个格式，也可以通过GDAL进行格式扩展，使之能够读写自定义的格式，这样就不必修改上层的算法，更新以下GDAL库即可。 栅格格式扩展 一般来说，GDAL对新格式的扩展需要对GDALDataset类和GDALRasterBand类的继承来实现，然后为一个新格式创建一个GDALDriver的实例，然后通过GDALDriverManager类将新格式的驱动进行注册，实现一个新格式的驱动主要包含以下九部分的内容： 从Dataset继承 从RasterBand继承 栅格驱动（Driver） 添加驱动到GDAL中 添加地理参考信息 金字塔（快视图） 创建文件 RawDataset和RawRasterBand类 元数据和其它外部扩展 改代码演示了如何创建一个读取日本地理测量学会定义的DEM数据格式的驱动，网址 Dataset继承：通过重载GDALDataset中的一些虚函数来为驱动重新实现这些特殊功能，但是Open()函数不是基类的虚函数，所以需要一个独立的函数来实现该功能。 先尝试驱动是否支持该类型，如果可以则将所有波段与当前的GDALDataset对象绑定 好复杂，不想看了，自己感觉也用不上 矢量格式扩展 对OGR库扩展的一般流程就是从OGRSFDriver类，OGRDataSource类和OGRLayer类继承三个子类，然后从OGRSFDriver类继承的子类使用OGRSFDriverRegistrar进行注册。 以一个简单的文本存储的点文件格式为例，对OGR库的扩展进行一些说明，主要包括三个方面：实现OGRSFDriver类，从数据源中读取数据，读取图层 实现OGRSFDriver类 实例化函数 void RegisterOGRSPF () { OGRSFDriverRegistrar::GetRegistrar()->RegisterDriver(new OGRSPFDriver()); } 驱动类一般实现对该格式的读取（Open）、创建（CreateDataSource）和删除（DeleteDataSource)，驱动类定义如下： class OGRSPFDriver : public OGRSFDriver{ public:~OGRSPFDeiver(); const char* GetName(); OGRDataSource* GetName(); OGRDataSource* Open(const char*, int); OGRErr DeleteDataSource(const char* pszName); int TestCapability(const char*); } 构造函数使用默认即可： OGRSPFDriver::~OGRSPFDriver(){ } GETName返回一个字符串： OGRSPFDriver::~OGRSPFDriver::GetName(){ return \"SPF\"; } Open函数： OGRDataSource* OGRSPFDriver::Open(const char* pszFileName, int bUpdate){ OGRSPFDataSource* poDS = new OGRSPFDataSource(); if(!poDS->Open(pszFileName, bUpdate)){ delete poDS; return NULL; } else return poDS; } TestCapability()来判断驱动、数据源和图层中的某些功能是否可用，驱动的操作只有创建和删除两种，都返回false即可 int OGRSPFDriver::TestCapaility(const char* pszCap){ return FALSE; } 从数据源读取数据 实现只读的数据驱动，数据源的主要功能就是管理图层，对于SPF格式来说，一个数据源就只有一个图层，所以需要在Open函数中图层的名称进行设置，然后对当前的数据格式进行重写 、、、（又没读下去，我真是废物） GDAL算法的使用说明 GDAL算法进行说明，实现一些常用的图像处理功能 GDAL算法处理基础 大图像处理策略：随着影像的分辨率越来越高，数据愈来愈大，处理大图像最常用的策略是分块，每次只处理一块数据，直到处理完所有的块，常用的分块有：按行分块、按正方形分块和其它矩形分块 按行分块就是一次性处理一行数据，常用于图像邻域无关的算法，比如图像融合、数据拉伸等；如果正方形分块，在处理的时候最右边和最下边的分块可能就是不规则的正方形分块。分块的时候有一个总的原则，分块要尽可能大，这样才能减少图像的I/O次数。 如果处理时间长，所以可以加上一个进度条 GDALWarp说明 GDAL中的Warp类的功能有：图像重采样，图像镶嵌，图像裁切（规则裁切或则AOI裁切），图像校正（RPC、GCP校正），波段合并等 GDALWarp中主要由GDALWarpOperation和GDALWarpOptions两大部分组成，其中前者是用来进行变换操作，后者是构造进行变换操作的选项 图像重投影和后面的投影校正，本质上就是对图像的坐标进行转换，然后进行重采样得到新的图像，它们的步骤基本上是一样的，唯一的区别是坐标转换的函数不同而已 GDAL坐标转换 GDAL中，所有的坐标转换函数都是有统一的形式的，每一种坐标转换都由三个函数组成，分别是create，destroy，transform GDAL地形分析 DEM地形分析中，坡度，坡向，地表粗糙指数，地形方位指数，粗糙度五个算法的实质就是3*3空间卷积算法 格网插值 利用离散的数据点创建一个栅格图像的过程，目前的插值算法由三种：反距离权重插值，移动均值插值，最邻近插值 小碎斑去除 矢量栅格化 栅格矢量化 CPL库介绍 CPL（Common Portability Library）里面封装了大量通用函数，主要有常用的数据结构，文件读写，数据库操作，网络数据读取，多线程等 "},"gis/Geomorphology-Based Hydrological Model.html":{"url":"gis/Geomorphology-Based Hydrological Model.html","title":"Geomorphology-Based Hydrological Model","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 部署与运行 Geomorphology-Based Hydrological Model Blog NetCDF(network Common Data Form)网络通用数据格式是一种面向数组型并适于网络共享的数据的描述和编码标准。目前，NetCDF广泛应用于大气科学、水文、海洋学、环境模拟、地球物理等诸多领域。用户可以借助多种方式方便地管理和操作 NetCDF 数据集。 部署与运行 请在 linux 操作系统中进行部署，下面是简要的部署过程，如遇到问题可以联系 李轶博(li-yb16@mails.tsinghua.edu.cn) 准备工作 准备模型和相关文件 $ export basedir=/WORK/thu_ztcong_1/gbhm $ ls $basedir esmf-intel-mpich3.rc README.md src test 安装依赖 安装 MPICH3, hdf5, netcdf-c, netcdf-fortran, esmf， 可以通过源码编译安装，也可通过系统有包管理器安装dev版本。 下面是 esmf 源码安装的步骤，请根据实际情况调整: $ cd $basedir $ git clone https://github.com/esmf-org/esmf.git $ cd esmf $ git checkout ESMF_7_1_0rp1_beta_snapshot_07 $ source $basedir/esmf-intel-mpich3.rc $ make -j 4 $ make install 编译和运行 在 test 目录中有一测试用算例，编译模型后运行该模拟算例。 $ source $basedir/esmf-intel-mpich3.rc $ cd $basedir/src && make $ cd $basedir/test && mpirun -n 20 $basedir/src/app.exe $basedir/test/config.rc Clock ---------------------------------- currTime = Time ----------------------------------- 2010-01-01T00:00:00 end Time ------------------------------- end Clock ------------------------------ Clock ---------------------------------- ... 结果检查 在 result 文件夹下是结果，包括径流模拟结果和状态变量历史文件。 status.nc 是什么 $ tree $basedir/test/result test/result/ ├── discharge.txt ├── hist │ ├── hist_20100101.nc │ ├── hist_20100102.nc │ ├── hist_20100124.nc │ ├── hist_20100124.nc │ ├── hist_20100124.nc ... 输入数据 pres_201001.nc rain_201001.nc rhum_201001.nc sun_201001.nc temp_201001.nc wind_201001.nc lai lai_2010.nc "},"gis/GIS标准.html":{"url":"gis/GIS标准.html","title":"GIS标准","keywords":"","body":"现在我们有一些点： 点应该在坐标系上（什么坐标系） 为了别人也能用这些点，人与人之间的交流，需要定义一种规范（OGC) 如何保存到计算机中，肯定要用OGC规范了，常用的工具有： 常常保存的格式有：（格式不同一般就是结构不一样） 讲一个常用的工具：GDAL，准确的说法应该是GDAL/OGC wkt规范在GDAL中怎么存的 点在GDAL中怎么存的 点可以了，线和面呢 GIS开发主要看OGC规范 GDAL使用抽象数据模型(abstract data model)来解析它所支持的数据格式，抽象数据模型包括数据集(dataset)，坐标系统，仿射地理坐标转换(Affine Geo Transform)， 大地控制点(GCPs)， 元数据(Metadata)，栅格波段(Raster Band)，颜色表(Color Table)，子数据集域(Subdatasets Domain)，图像结构域(Image_Structure Domain)，XML域(XML:Domains)。 空间矢量数据交换文件由四部分组成： 第一部分为文件头。包含该文件的基本特征数据，如图幅范围、坐标维数、比例尺等。 第二部分为地物类型参数及属性数据结构。地物类型参数包括地物类型代码、地物类型名称、几何类型、属性表名等。属性数据结构包括属性表定义、属性项个数、属性项名、字段描述等。 第三部分为几何图形数据及注记。包含目标标识码、地物类型码、层名、坐标数据等。注记包含了字体、颜色、字型、尺寸、间隔等。 第四部分为属性数据，包含属性表、属性项等。 1.提出3个问题 2.OGC规范（主要讲解WKT） 3.GDAL的介绍和简单操作 4.GeoJSON的介绍 5.结论 GeoJSON支持以下几何类型：Point，LineString， Polygon，MultiPoint，MultiLineString，和MultiPolygon。具有其他属性的几何对象是Feature对象。要素集包含在FeatureCollection对象中。 GIS抽象数据模型=》OGC? GDAL基于OGC? GeoJson基于OGC？ 但是我们测量的结果只是一个.dat格式的文件，所以说我们需要格式的转换。 怎么将测量数据真正应用到实际生产中？ 数据没有了标准就好比坐标没有了坐标系——没有实用价值了 "},"gis/GIS算法基础.html":{"url":"gis/GIS算法基础.html","title":"GIS算法基础","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 Clustering by fast search and find of density peaks 局部密度 聚类算法 wiki 距离 元素可以联系起来 Clustering by fast search and find of density peaks 局部密度 截断距离 一个为离散值，一个为连续值 如果决策图不好的情况 该算法可以作为其它算法的预处理（确定聚类中心的个数及初始的聚类中心） "},"gis/Google Earth Engine.html":{"url":"gis/Google Earth Engine.html","title":"Google Earth Engine","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 Google Earth Engine 参考 网络资源 参考论文 论文1. Google Earth Engine: Planetary-scale geospatial analysis for everyone Abstract 1. Introduction 2. Platform overview 3. The data catalog 4. System architecture 5. Data distribution models 6. Efficiency, performance, and scaling 8. Challenges and future work 涉及技术 评价 论文2. An Overview of Platforms for Big Earth Observation Data Management and Analysis 产品演化路径 现行技术体系 [toc] Google Earth Engine 参考 网络资源 知乎， Google Earth Engine小史 作者就是这个出来的数据科学家，他的专栏的“地球云计算”是我在中文资源能看到的最好的资源，专栏中的一下文章值得看一下，但是后面没有更新了，所有的新的内容也没有了 b站，经典论文的汉译版 GEE相关的最经典的Google Earth Engine: Planetary-scale geospatial analysis for everyone论文的汉译版，但是只翻译了一半，而且有些地方翻译的有问题 PANGEO 用于云原生地球系统分析的封闭平台与开放架构 比较了几个平台 参考论文 Google Earth Engine: Planetary-scale geospatial analysis for everyone GEE最经典的论文 An Overview of Platforms for Big Earth Observation Data Management and Analysis 比较了相关的几个平台，没来及的看 论文1. Google Earth Engine: Planetary-scale geospatial analysis for everyone Abstract Google Earth Engine 是一个基于云计算的星球级地理空间分析平台，它将谷歌庞大的计算能力用于解决各种高影响的社会问题，包括森林砍伐、干旱、疾病、食品安全、水管理、气候监测和环境保护。它在该领域是一个独一无二的综合平台，因为它不仅可以提高了传统遥感科学家分析的能力，还弥补了用户缺乏利用传统超级计算机或大规模商品云计算资源所需的技术能力的鸿沟。 1. Introduction 目前，超级计算机和高性能计算系统逐渐性能过剩，大量级的云计算以商品的形式变得触手可及。与此同时，来自 NASA、 U.S. Geological Survey 和 NOAA 等多个美国政府机构和 European Space Agency 的 PB 级别存档遥感数据已免费对外提供，相应的地理信息数据大量级处理技术（如 TerraLib、Hadoop、GeoSpark 和 GeoMesa）也日臻成熟。 但是要充分利用这些海量数据资源仍然有相当高的技术要求。其中一个主要障碍就是基础的 IT 管理：数据的获取和存储；解析晦涩难懂的文件格式；管理数据库、机器分配、任务和任务队列、CPUs、GPU、网络；使用众多的地理空间数据处理框架等等； 这种负担可能使许多研究人员和业务用户无法使用这些工具，从而限制了研究人员对于海量遥感数据的研究。 针对以上问题，Google Earth Engine（GEE）应运而生。Google Earth Engine是一个基于云的平台，它使人们可以很容易地获得高性能的计算资源来处理非常大的地理空间数据集，不需要先掌握复杂的IT技术。此外，与大多数超级计算中心不同，Earth Engine的设计也是为了帮助研究人员轻松地将他们的成果分享给其他研究人员、政策制定者、非政府组织、现场工作人员，甚至是普通公众。一旦一个算法在地球引擎上被开发出来，用户就可以在Earth Engine的支持下制作系统的数据产品或部署可交互的应用程序，而不需要用户首先成为应用程序开发、网络编程或HTML方面的专家。 由谷歌、卡内基梅隆大学和美国地质调查局联合开发的 GEE 是目前世界上先进的 PB 级地理数据科学分析及可视化平台。GEE 面向用户提供海量卫星影像数据集与地理数据集，包括 40 多年历史卫星影像数据与欧空局的卫星影像数据。同时，GEE 提供基于 JavaScript 和 Python 语言的 API 接口、分析算法与工具，方便用户实现大型数据的处理分析与信息挖掘。 2. Platform overview Google Earth Engine 提供了多个类别 PB 级的可供分析的数据以及高性能并行计算服务，二者均可通过 API 获取及控制，并且 GEE 集成了基于 Web 的 IDE（Interactive Development Environment）使得快速原型实现和结果可视化成为可能。 Google Earth Engine 的数据库保存了大量的公共地理信息数据，包括各类卫星、航拍得到的光学和非光学波长的观测数据、环境变化、天气和气候的预报及后判、地形数据、社会经济学数据等等。所有这些数据都是经过一定预处理且保证不丢失相关信息的可直接使用形式（ready-to-use but information-preserving）。 用户可以使用和分析来自公共目录下的数据，也可以通过 API 调用数据库操作器来添加自己的私人数据库。该操作器是集成到大型并行处理系统的，能够自动划分算力，提供高通量的分析能力。用户既可以通过一个体量很小的 Client Library，也可以通过在该 Client Library 基础上构建的交互开发环境来直接调用这些 API，如图1 所示。 Fig 1. The Earth Engine interactive development environment 用户可以在地球引擎的主页上注册访问，并访问用户界面以及用户指南、教程、实例、培训视频、功能参考和教育课程。虽然之前对GIS、遥感和脚本的经验使其更容易上手。如果有编写脚本的经验会让你更容易上手，但这并不是严格的要求，而且用户指南也是面向用户领域新手的。每个帐户有一个上传个人数据和保存中间产品的配额，任何输入或结果都可以下载供离线使用。 3. The data catalog Google Earth Engine 公共数据目录是一个多维度 PB 级地理信息数据集。主要包括来自 Landsat、Sentinel-1、Sentinel-2 的地球观测遥感完整存档数据，以及诸如气候、地表覆盖数据等其他环境、地理信息和社会经济学数据（如Table 1 所示）。数据量还在以每天近 6000 scenes（时延约 24 小时）的速度持续增加和更新。用户可以直接使用这些公共目录下的数据，也可以通过 REST 交互界面上传自己的私人数据且可以自由选择是否共享给他人。 Earth Engine 运行在一个轻量级的 “图像” 容器中，使用基于 2D 网络栅格波段的简单且高度通用的数据模型。单一谱段的像素点需在数据类型、分辨率和投影上保持一致，但是图像可以包含任意数量的谱段且一幅图中的谱段不需要有统一的数据类型和投影。每幅图也具有相关键值对的元数据来存储诸如图像的拍摄位置、拍摄时间和条件等信息。 相关的图像，比如同一个 Sensor 产出的数据分成一组，构成一个数据集。数据集的高速筛选和分类能力使得用户可以轻松地在数以百万计的图像中搜索和选择满足特定区域、时间和其他标准的数据。 导入 Earth Engine 的数据都会经过预处理以达到快速并有效查询使用的目标。 首先，图片按照原有的投射和分辨率切成瓦片存储到高效且备份的瓦片数据库中。每幅瓦片尺寸为 256×256，这是在载入不需要的数据和预加载额外请求数据之间采取的折衷方案。与传统的 “data cube” 系统不同，这种数据摄入处理能够做到不丢失数据信息：数据仍然保持其原有的投影、分辨率和 bit 位，从而避免了数据在重采样到一个固定网格下而产生解构导致可能会不适用于特定的应用。 另外，为了在计算开发过程中能够快速可视化，每幅图都会对应有降低分辨率的瓦片图组成的金字塔模型存储在对应瓦片图数据库中。金字塔中的每一层都是通过对上一层以 1/2 的比例进行缩减像素采样（向下采样）得来的。在向下采样时，连续值谱段通常采取平均采样模式，而对离散值谱段（例如分类标签）使用最小、模式化、最大或固定采样模式中的一种进行采样。当只需要一幅图的一部分数据在降低分辨率下计算时，只有最合适的金字塔层级下相关的瓦片图才会从数据库中被调取出来供使用。这种指数级缩量方式使得数据能够在不同量级都能够使用而又不用耗费大量的存储，同时也能够满足基于 web 的地图展示。 Table 1. Frequently used datasets in the earth engine data catalog 4. System architecture Earth Engine 是建立在 Google data center 环境下的一系列技术基础之上的。其中包括 Borg 集群管理系统、Bigtable、Spanner 分布式数据库、Colossus（Google File System 的接班者）以及用于并行管道计算的 FlumeJava 框架。另外，Earth Engine 还可以与 Google Fusion Tables（一种基于 web 的数据库，支持带有属性的点、线、多边形等几何类型的数据表）进行互操作。 Fig. 2. A simplified system architecture diagram. 如图 所示。Code Editor 和第三方 Web Apps 可以借助客户端库通过 Web REST API 来向系统发送交互或批量请求。即时请求通过 Front End servers 进行处理并向 Compute Master 发送下一级请求。Compute Master 则负责在 Compute Servers 资源池中进行分布式计算的任务规划。Batch Computation 的运行逻辑与此基本一致，只不过是通过 FlumeJava 框架来管理分布规划。支持这两个计算系统的是一系列的数据服务，包括 Asset Database（存有每幅图的元数据并具有高效筛选能力）。前面提到的 Borg 集群管理软件则负责管理系统的每个组件和每项服务在多用户之间的负载均衡。任何单一用户的请求失败只会导致重新发起查询请求而不会对系统造成其他影响。 向 Earth Engie 发送的请求是基于功能进行整合和求解的。用户通过从 Earth Engine 的 800 多个函数中选取自己需要的组合起来构建自己的数据或数据处理请求，这里面既有用于地理信息处理的简繁不等的数学函数，又有机器学习、图像处理等相关的操作函数。这个算法库使得用户可以通过图像代数方法很轻松地处理图像数据，并且支持高阶的函数比如：map（）和 iterate（）（二者均支持对一系列图像应用随机函数）、reduce（）（用来计算按照区域、滑窗、时域、光谱或其他形式组织的统计数据）。在客户端库中包含的各种类型的函数和算法。 该库的基于图像的函数的大部分是对每个像素进行代数运算，在每个频段或频段之间的基础上运行，涵盖整数和浮点数学运算，逻辑比较，位操作，类型转换，条件替换和用于处理像素数组值化的多维数组操作。另外还包括常见的像素操纵函数，例如表查找，分段线性插值，多项式求解和普遍存在的归一化差异等。该库利用几个预制的机器学习工具包，可以轻松访问 20 多种类型的监督分类，回归和无监督集群，以及用于准确性求解的混淆矩阵操作。对于机器视觉任务，可以使用常见的基于内核的窗口操作，例如卷积，形态操作，距离和纹理分析，以及简单的基于邻域的操作，例如梯度，斜率，宽高比和连通性。其他功能还包括图像和波段元数据操作，投影和重采样操作，屏蔽和裁剪，图像到图像位移和配准以及遥感应用常用的各种专用工具，包括约束光谱分离，区域增长和成本映射操作等等。 用户可以组合这些库函数以构建希望执行的计算描述。该计算描述最终以有向非循环图（DAG）的形式呈现给 Earth Engine，其中每个节点代表一个单一函数或数据访问器的执行，并包含命名函数参数的键 / 值对。实质上，这是一个纯函数式编程环境，而 Earth Engine 利用了函数式语言常用的标准技术，例如参考透明度和惰性求值，以实现显著的优化和效率提升。 用户使用客户端库（目前可用 Python 和 JavaScript 语言）编写 Earth Engine 程序，允许用户使用熟悉的程序式编程范式来描述如何处理图表。客户端库为图像、集合和其他数据类型（如数字，字符串，几何和列表）提供代理对象。用户脚本操纵这些代理对象，这些对象记录操作链并将它们组装成能够表达完整计算的 DAG。然后将此 DAG 发送到 Earth Engine 服务进行求解。 DAG 的求解是通过一系列的图表转换实现的。转换后的子图表如果可能的话会立即进行进一步求解来实现贪婪简化，从而避免冗余计算以及任何并行计算不可用的地方。比如，在子图表中表达式 3+7 会立即被简化成 10 这种值的形式。图中的其他节点会被扩展，例如当求解一个指向图像集合的节点时，它会被扩展为一个图像序列以便后续处理批量化执行。表示复杂处理操作的节点可以采用下一节中描述的分布式处理的几种策略中的任何一种。 Earth Engine 旨在支持快速，交互式探索和分析空间数据，允许用户平移和缩放结果来每次查看图像的一个子集。为此，Earth Engine 使用惰性计算模型，该模型仅允许计算满足当前请求所需的特定部分来进行输出。 举个例子，比如说用户可能希望计算两个季节合成图像之间的差异，进而突出显示由于气候或者积雪引起的变化情况。最简单的实现方式就是通过 Earth Engine 的客户端库拉取两个复合图像的差集。 Listing 1. Computing the difference of median composites from two seasons. 此代码创建了两个过滤的集合，其中一个是 11 月，12 月和 1 月的所有 Landsat 8 图像，另一个是 6 月，7 月和 8 月的所有 Landsat 8 图像。首先计算每个数据集中每个谱段的时域插值（目的是为了最小化云和云阴影的影响），然后减去所得到的复合图像结果来计算值的变化。该计算描述的 DAG 表示如图 所示. The DAG produced for Listing 1 传统（非惰性）计算环境可能会在处理表达式后立即开始计算一个或两个复合材料的像素，这通常需要提前将输入数据集预处理为公共地图投影，分辨率和感兴趣区域。 相反，Earth Engine 采用了不同的方法：它推迟计算输出像素，知道它清楚了解到这些结果是在什么样的情况下是必须的。例如，如果结果当前显示在交互式地图上，则地图的缩放级别和视图边界可以动态地决定输出的投影和分辨率，并且可以将像素计算限制为仅可查看的像素。或者，如果结果当前要被用作另一计算的输入，则该计算可以请求所需像素的适当投影，分辨率和边界。此信息用于动态地自动重新采样和重新投影输入数据，从而可以快速可视化结果或在更复杂的计算中使用该表达式，而无需用户预先指定需要哪些像素。默认情况下，使用输入的最近邻重采样来对所请求的输出投影进行重新投影和重采样（从每个输入的下一个最高分辨率金字塔等级中选择像素），以保持频谱完整性。但是，当用户对如何管理这种重投影有偏好时，他们可以选择精确控制投影网格，并可以选择双线性和双三次采样模式。 这种方式更有助于采用交互模式和迭代模式来开展数据挖掘和算法开发。一旦用户完成算法的开发并想要大规模应用，他们可以向 Earth Engine 提交一个批处理请求来计算得到完整结果并在 Earth Engine 中实例化为一副图像或者是可供下载的多幅图像、表格甚至是视频文件。 Table 2. Earth Engine function summary 5. Data distribution models Earth Engine 库中的功能使用多种内置并行化和数据分布模型来实现高性能。每种模型都针对不同的数据访问模式进行了优化。 5.1. 图像瓦片处理 在遥感中使用的许多光栅处理操作是局部的：任何特定输出像素的计算仅取决于某个固定距离内的输入像素。比如例如频带数学计算或频谱解混，以及诸如卷积或纹理分析的邻域操作等针对但像素的操作。通过将区域细分为区块并独立地计算每个区域，可以很容易地并行处理这些操作。处理每个输出图块通常需要为每个输入仅检索一个或少量图块。这与金字塔输入和合理的缓存相结合，可以在任何要求的比例或投影中快速计算结果。如前所述，输入会根据需要随时重新投影以匹配投影输出的需求。当然，如果用户确定不希望使用向下采样或重新投影输入，则可以在输入的投影和比例中明确指定计算方式。 大多数基于图块的操作都是使用两种策略中的一种在 Earth Engine 中实现的，具体取决于它们的计算成本。 针对成本较高的操作以及一次性计算整个瓦片具有显著优势的操作，会将结果写入瓦片尺寸相匹配的输出缓冲区。 瓦片通常为 256×256 像素，以匹配输入预处理的瓦片大小。 对于成本低的单像素运算，是通过在一个可直接相互调用的图表中执行图像处理的界面中按照每次一个像素来进行。这种结果目的是为了充分利用这些操作在 Java 虚拟机（JVM）环境中执行的优势，该环境具有即时（JIT）编译器，编译器负责提取并编译重复发生的函数调用序列。结果表明，在多数情况下，原始图像操作的任意链式操作都可以像手工编译的代码一样有效地执行。 5.2. 空间聚合 正如某些类别的计算本质上是局部的，其他类别本质上是非局部的，例如区域或全局统计的计算，光栅到矢量的转换，或者采样图像以训练分类器。 这些操作或它们的一部分通常仍然可以并行执行，但计算最终结果需要将许多子结果聚合在一起。 例如，计算整个图像的平均值可以通过细分图像，在每个部分上并行计算和计数，然后对这些部分和计数求和来得到所需结果。 在 Earth Engine 中，这些类型的计算使用分散 - 聚集模型作为分布式进程执行。需要执行聚合的空间区域会被划分为子区域分配给分布式算力资源池中的算力单元以便进行批量求解。 每个算力单元获取或计算所需的输入像素，然后运行所需的累积操作以计算其部分结果。 这些结果将被发送回主计算器进行此计算，该计算将它们组合并将结果转换为最终形式。 例如，当计算平均值时，每个算力单元将计算总和与计数，主运算收集并汇总这些中间结果，并以总和除以总计数得到最终计算结果。 5.3. 流式聚合 处理大型遥感数据集的另一个常见操作是时间序列分析。应用在空间上的相同统计聚合操作也可以应用于计算整个图像堆栈中随着时间变化的像素级变化情况。 这些操作都是通过瓦片组合来实现的。以前述方式使用延迟图像求解并行计算得到每个瓦片的输出。在每个瓦片图内，针对每个像素都会执行聚合操作。来自输入图像集合的像素数据是批量请求的，并且通过单像素聚合器进行一次性 “流式传输”。 与输出瓦片相交的所有输入处理完成后，就会在每个像素处都应用最终转换以生成输出结果。 对于具有小中间状态的聚合（比如计算最小值），该分布模型可以做到快速且有效。但是对于不具有中间状态的聚合来说，可能就会非常耗费内存（比如计算 Pearson 的相关性，就需要在计算最终结果之前在每个像素上都存储完整的数据序列）。不过，只要瓦片的大小是明显小于完整图像的，那么即使是非常大的数据集合，流式传输仍然可以做到非常快。例如，对于 Lansat5、7、8 的完整数据集堆栈，包含超过 500 万张图片，在任意一点都只有少于 2000 张瓦片的深度，平均来看其实只有 500 张的深度。 5.4. 缓存以及常见的子表达式消除 Earth Engine 中的许多处理操作的成本和数据密集度都非常高，因此避免冗余计算将回事非常有价值的。例如，在地图上查看结果的单个用户将触发对输出区块的多个独立请求，所有输出区块经常依赖于一个或多个公共的子表达式，例如大空间聚合或监督分类器的训练等。为了避免重新计算先前已经请求的值，使用子图的散列作为高速缓存键将成本较高的的中间结果存储在分布式的高速缓存中。虽然多个用户可能共享缓存中的项目，但两个独立用户独立地进行相同查询的情况并不常见。但是，单个用户在增量算法开发期间重复相同的查询并因此受益于这种缓存机制就是非常常见的了。在单个查询的分布式执行期间，高速缓存还用作共享存储器的形式，存储对应于查询的子图的中间结果。 当对相同计算的后续请求到达时，较早的计算可能已经完成或者仍可能正在进行中。在开始成本高昂的操作之前，会优先去检索缓存并返回之前计算的结果。为了处理早期计算仍在进行中的情况，所有计算都是通过少量计算主服务器发送给分布式算力单元的。这些服务器会在任何给定时刻跟踪群集中正在执行的计算。当新查询到达时，如果它依赖于某些正在进行的计算，该查询将会直接加入原始查询序列中去以等待计算完成。如果计算主机出现失败，则正在进行的计算的处理可能会丢失，这种情况下可能会允许启动冗余计算，但前提是在现有计算任务完成之前就重新请求查询。 6. Efficiency, performance, and scaling 地球引擎利用常规的图像处理的Java即时编译器（JIT）的优势来优化每个像素操作链的执行。为了评估JIT编译器带来的效率提升，我们进行了一系列的实验来比较三种执行模式的性能：使用JIT编译器在Java中运行一个计算图。 使用JIT编译器在Java中执行一个计算图；使用一个类似的在C++中的通用包运行一个图；最后，编写了专门的本地C++ 代码，所有相同的调用是直接进行的，而不是通过一个图，从而避免了函数的虚拟化。五个测试案例，每个案例都测试了不同类型的图像计算图，结果如下 SingleNode: 一个简单的图，其单一节点由一个图像数据缓冲器组成。这个测试简单地计算了一个缓冲区中所有数值的总和。 NormalizedDifference: 这个图计算两个输入缓冲区的差异。这个小图的场景总共包含五个节点：两个输入节点，一个和，一个积和一个商。 DeepProduct: 一个由64个二进制产品节点组成的链的图，计算65个输入节点的乘积。 DeepCosineSum: 一个结构与DeepProduct相同的图。但每个节点都计算更复杂的二进制运算cos(a + b)。 SumOfProducts: 一个计算40个输入的所有成对积的总和的图。这个图有40个输入节点，780个积注，以及一棵由779个和节点组成的树。这里的节点总数比输入节点的数量要多得多，这使我们能够评估原始操作复杂图的性能。我们可以在固定数量的输入数据上评估复杂的原始操作图的性能，这是一个常见的现实世界的场景。 这些测试都是基于 Intel Sandy Bridge 公司的 2.6 GHz处理器的单线程执行环境的配置，在一个256×256像素点上进行的，该配置代表了商业云数据中心环境，并且禁用所有非必要的系统服务以尽量减少剖析噪音。表3的结果显示，在这些测试案例中，5个中有4个使用JIT编译器的效果超过了C++中类似的通用包，其中有1个案例中JIT编译器的效果甚至超过了直接用C++代码写的效果 Table 3. Results from Java JIT vs. C++ efficiency tests. 6.1 系统吞吐量性能 在Google数据中心有着丰富的CPU，在该环境下，原始效率虽然也很重要，但是更重要是如何在许多机器上有效的分配复杂的计算，Earth Engine 的大部分性能是基于它有能力代表用户调集和管理大量的CPU。单一的硬件即使通过代码或者查询优化，最终也会达到一个上限，但是可以利用的额外的计算资源很少有限制，从而可以达到更高的上限。 经过实验证明Earth Engine 可以以横向的尺度缩放，如 Fig.4 所示。在这次测试中，两幅大的在这个测试中，两个大型的Landsat 图像集图像被重新投影到一个共同的投影坐标系上， 在每个像素的基础上进行时间上的汇总，并在空间上汇总成一个数字，同时改变每次运行的CPU数量。这两个数据集包括从 2014.1.01 到 2016-12-31 的所有的 Lanssta 8 Level-1T图像，图像覆盖美国本土（26,961个场景，1.21万亿像素）和非洲（77,528个场景，3.14万亿像素）。测试是使用共享的生产资源运行了几天，即使捕捉到自然变化。结果显示，吞吐量与机器的数量几乎呈线性扩展。 Fig. 4. Horizontal scaling tests results. Application Earth Engine 正广泛应用于各个领域，涵盖全球森林变化，全球地表水变化、作物产量估算、稻田制图、城市测绘、洪水测绘、火灾恢复和疟疾风险绘图等等不同主题。它还被整合到许多第三方应用中，例如分析物种栖息地范围（Map of Life）、监测气候（Climate Engine）和评估土地利用变化（Collect Earth）等等。这些应用中的一些细节将说明 Earth Engine 的能力是如何被利用的。 Hansen 使用从广泛的数据集中生成的决策树，描述了2000年至2012年的森林范围、损失和增加的特点。他利用从大量的训练数据中产生的决策树和大量的陆地卫星场景中计算出的深层指标，对2000年至2012年的森林范围进行了描述。数据目录支持的过滤操作将当时研究期间的生长季节场景的130万个陆地卫星场景减少到654,178个。这些影像通过云层、云影和水进行筛选，并将其从原始的 Landsat 数字转换为规范化的大气顶部反射率。系统自动处理所有必要的数据访问、格式转换、制图和重新取样。利用 API 中的操作计算输入指标，例如每个波段的百分位值和反射率的线性回归值与图像日期的线性回归。这些指标与训练数据一起。被用来生成决策树，这些决策树被应用于指标来产生最终的输出数据。这些结果被用于出版，并作为地球引擎目录的一部分提供给其他人去进一步分析。 之后许多包括科学界和业务界的其它用户，都成功的在 Hansen 的基础上利用 Earth Engine 产生了其它成果。 Global Forest Watch 将其纳入使用地球引擎的交互式分析应用程序，以进行即时的汇总统计计算。Joshi 使用Earth Engine 来 追踪老虎栖息地的变化，提取每年保护区内的森林损失，并发现最适合野生老虎数量翻番的地区也是保护得最好的地区。 在其它例子中，Lovell 将数百个作物模型的模拟结果与植被指数联系起来，例如绿色叶绿素植被指数（GCVI），这些指数可通过卫星数据进行测量。然后，他们将模拟产量与测量的植物指数和生长季节早期的天气相关联。这就产生了一个早/晚日期的每一对组合的回归系数表。他们在每个像素的基础上使用 Earth Engine 选择早晚的最佳Landsat场景，使用 Earth Engine 的 SimpleCloudScore 功能自动去除多云场景，计算 GCVI 值，最终得到最高GCVI 的场景。一旦为一个特定的像素确定了最好的一对陆地卫星场景，存储在地球引擎和GCVI中的天气数据就可以用来计算预测的产量。这个方法被应用于美国中西部大约675万公顷的玉米和大豆田，计算出2008到2012年的年产量。每年每10,000平方公里的总计算量大约在2分钟内完成。 8. Challenges and future work 使用Earth Engine的一个好处是，用户几乎完全不需要考虑在并行处理中工作的细节。该系统处理并隐藏了如何管理计算的几乎每一个方面，包括资源分配、并行性、数据分配和重试。这些决定纯粹是管理性的，它们都不会影响查询的结果，只会影响查询的速度。从这些细节中解放出来的代价是用户无法影响它们：系统完全负责决定如何运行一个计算。这导致了一些有趣的在系统的设计和使用方面都有一些有趣的挑战。 8.1. 规模化挑战 Earth Engine系统作为一个整体可以管理及其庞大的计算，但其底层基础设施最终是由低端服务器组成的集群。在这种环境下，配置任意大的机器的选项是不可取的，而且对可以带入任何单个服务器的数据量有一个硬性限制。这意味着用户只能通过使用Earth Engine库中提供的并行处理语言来表达大型计算，而一些非并行的操作根本无法在这个环境中有效执行。此外，要求使用Earth Engine 来表达也意味着现有的算法和工作流程必须被转换为使用Earth Engine API 来利用这个平台。 Earth Engine设计的API能轻松的表达极大的计算。例如，它可以只用几行代码就可以请求聚合一个全球8000亿像素的Hansen森林覆盖图：虽然这种计算是很直接简单的，但是只是从存储中检索所有的输入像素也会涉及到大量的资源和时间。通过在广泛的空间尺度上对大型数据集进行链式操作，很容易表达成本相差很多的查询，并描述即使在先进的并行计算环境中也不可行的计算。 由于地球引擎是一种共享的计算资源，因此限制和其他防御措施是必要的，以确保用户不会垄断系统。对于交互式会话，Earth Engine 对请求的最大持续时间目前为270秒、每个用户同时请求的总数量为40，同时一些复杂操作如空间聚合的同时执行次数限制为25。虽然交互式计算有一个时间限制，但是该限制足够在一个单一的工作流程中完成以下工作：检索覆盖加利福尼亚和内华达州一年的所有Landsat 8图像（1177个场景），用它们来计算最大NDVI综合指数，并由此得出17个IGBP土地覆盖等级（73.5万平方公里）中每个等级的平均峰值-NDVI（735000km^2）。这个例子的大部分时间是花在传输全分辨率的空间聚合的原始像素，简单地创建和显示最大NDVI的合成，只需几秒钟就能完成。 当在批处理环境中调用查询时没有限制，在批处理的情况下，更大数量级的工作可以直接运行。但是当一个请求涉及到基于瓦片的计算时，每台机器所能容纳的数量仍然是有限的，因为这些计算不能用目前的数据模型进行流化或进一步的分布。这些内存限制并不会直接的转换为空间和时间上的限制，但是这类请求的最大尺寸有一个经验：每个像素的堆栈深度不超过2000字节。目前RPC和缓冲系统有一个在互动情况或者批处理都存在的额外的限制：缓存的单个对象大小不能超过100MB。这个限制最常发生在聚合操作输出的很大的情况下，当我们提取数据来训练一个机器学习算法时，它可能会限制训练集中的总点数。 批量作业是独立运行的，这使得它们很难对彼此产生负面的影响，但是为了防止垄断，作业仍然使用一个共享的排队系统进行管理，在负荷大的情况下，工作可能会在队列中等待，直到资源变得可用。 8.2.计算模型不匹配 虽然可并行化的操作在遥感领域非常普遍。但是有许多其他的操作是不能并行化的，或者是不能被Earth Engine中的并行计算结构所容纳的。该平台很适合于每个像素和有限邻域的操作，如带状数学、形态学操作、光谱解混、模板匹配和纹理分析，以及这些操作的长链（数百到数千）。它还高度优化了可应用于流式数据的统计操作，如计算图像的时间序列堆栈的统计数据，并且可以轻松地处理非常深的堆栈（eg: 数以百万、亿万计的像素）。但是它对于以下情况表现很差：局部数值可能受到任意距离的输入影响的操作，如分水岭分析或经典的聚类算法；需要同时掌握大量数据的操作，如训练许多经典的机器学习模型；以及涉及长周期迭代的操作，如有限元分析或基于代理的模型。此外，一些数据密集型模型需要大量的数据，而这些数据在地球引擎中并不存在，这可能需要大量的工作来准备数据。 这些计算技术仍然可以在地球引擎中应用。但往往有很大的限制。将Earth Engine扩展到支持新的计算模型是一个活跃的研究和开发领域。用户如果遇到不符合地球引擎计算模型的问题，可以在谷歌云平台的其他地方运行计算。平台中的其他地方运行计算，以利用靠近底层数据的计算，同时还可以利用Earth Engine的数据目录、预处理、后处理和可视化的优势。 8.3.C/S 编程模型 Earth Engine的用户往往不熟悉客户机-服务器编程模型。所以Earth Engine的客户端库试图提供一个更熟悉的程序化编程环境。但这可能导致用户忘记他们不是本地编程，本身并未执行任何计算，这时候会导致一些混乱。整个操作链是由客户端的代理对象记录，并发送到服务器上执行，但这意味着不可能将Earth Engine库的调用与标准的本地的处理习惯混合在一起。这些习惯包括一些基本的语言功能，如依赖计算值的条件语句和循环，以及标准的数值包。用户仍然可以使用这些外部工具，但他们不能把它们直接应用到地球引擎的代理对象上，这有时会导致导致混乱。幸运的是，这些编程错误通常 一旦发现就很容易解决。 值得注意的是，这种风格的编程模型在大规模云计算中正变得越来越普遍，同时它也被用于TensorFlow中构建和执行图。 8.4. 提高技术水平 Earth Engine不仅让监测、跟踪和管理地球环境和资源成为可能，而且变得容易，从而在社会最需要的地方取得一定进展。为了跟踪和管理地球的环境和资源，不仅需要提供大量的数据和计算能力，还需要提供越来越复杂的分析技术的同时也易于使用。 因此，我们正在进行一些实验：整合深度学习技术，并促使可扩展的基础设施（如谷歌计算引擎和BigQuery）能轻松访问。 涉及技术 Introduction 地理信息数据的处理技术： TerraLib、 Hadoop、GeoSpark 和 GeoMesa The data catalog Earth Engine 运行在一个\"图像\"容器（？） 瓦片数据库 金字塔模型 System architecture Borg 集群管理系统 Bigtable Spanner 分布式数据库 Colossus（Google File System 的接班者） 并行管道计算的 FlumeJava 框架 Google Fusion Tables（一种基于 web 的数 据库，支持带有属性的点、线、多边形等几何类型的数据表） 进行互操作 Compute Master进行任务规划 计算描述DAG Data distribution models Geodata Pipleline：地理数据处理链线，有人喜欢叫工作流（workflow），有人喜欢叫processing（数据处理），都可以。Pipe是从Linux过来的概念，意思是将上一个命令的输出作为下一个命令的输出。这样的话数据处理结果是文件、还是字符流、还是数据库就都被抽象掉了。我很喜欢这个概念，因为遥感数据里也是各种类型文件、各种处理，比较乱，用pipeline比workflow一类的宽泛概念要强得多（流应该是gee中很重要的一个设计） 子表达式消除 Efficiency, performance, and scaling JIT编译器 Challenges and future work C/S 编程模型 谷歌计算引擎 BigQuery 评价 谷歌在构建这个工具方面投入了大量的工程专业知识。它确实是一个令人惊叹且令人印象深刻的平台，并导致了许多重要的科学发现. 当我们在 2013 年第一次开始考虑大地球数据时，我们了解了 GEE，并立即认为这就是未来：我们都会迁移到 GEE。那显然没有发生。虽然 GEE 对许多科学家来说显然是一个有价值的工具，但事实仍然是该平台是封闭的——它不是开源的。它由谷歌控制。他们决定它可以做什么和不可以做什么，哪些数据集可用，如何分配资源等等（他们当然对科学界非常慷慨。）但 GEE 从根本上说是一个卫星图像平台。有许多类型的地球系统数据和分析方法在 GEE 中根本不可能实现，科学界也没有明显的方法来改变这一事实。您也不能在自己的服务器上安装 GEE。 随着封闭平台的发展，很难击败 GEE。但其他人正在尝试。 论文2. An Overview of Platforms for Big Earth Observation Data Management and Analysis 产品演化路径 产品演化路径必然离不开产品的历史，但是设计GEE的历史技术没有找到相关了网络资源 历史发展 Graphics 公司使用了什么技术 Keyhole公司使用了什么技术，Google通过它一下子拥有了巨大的地图服务 刚开始 GEE 只是为了 Landsat数据的处理，怎么设计的，用了什么技术 现行技术体系 第二篇论文讲的就是这个，但是还没来得及细看 "},"gis/Landsat影像格式.html":{"url":"gis/Landsat影像格式.html","title":"Landsat影像格式","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 Landsat8 文件名称含义 文件名 卫星数据类型 产品分类Collection Category 数据夹文件内容 共14个文件 数据处理（gdal） Landsat影像格式 文件说明：https://earth.esa.int/documents/10174/679851/LANDSAT_Products_Description_Document.pdf Landsat8 文件名称含义 文件名 卫星数据类型 LC = Combined（both OLI and TIRS data） LO = OLI data only . Pixel Size : OLI Multispectral bands 30 meters || OLI panchromatic band 15 meters LT = TIRS data only Pixel Size : TIRS Thermal bands: 100 meters (resampled to 30 meters to match multispectral bands 产品分类Collection Category Tier1(T1) - 包括最高质量的Level-1 Precision Terrain(L1TP)地面数据，地理坐标已配准，误差满足(RMSE Tier2(T2) - 包括没有达到L1TP标准的影像，包括Level-1 Systematic Terrain(L1GT)和Systematic(L1GS)影像 Real-Time(RT) - 尚未进行改正处理的新影像。 数据夹文件内容 共14个文件 ​ ①文本文件：分为_ANG与_MTL两个 ​ _ANG Angle，是对影像的投影方式，等等数据的记录，应该可以拿来做几何 ​ _MTL _MeTadata File影像元数据介绍 ​ ③影像文件：均为tif格式，11个波段文件，因为Landsat 8 有两个传感器11个波点，一个BQA影像 数据处理（gdal） // 图像信息 gdalinfo [图像路径] // 图像融合 gdal_merge.py [-o out_filename] [-of out_format] [-co NAME=VALUE]* [-ps pixelsize_x pixelsize_y] [-tap] [-separate] [-q] [-v] [-pct] [-ul_lr ulx uly lrx lry] [-init \"value [value...]\"] [-n nodata_value] [-a_nodata output_nodata_value] [-ot datatype] [-createonly] input_files // 裁剪 "},"gis/NetCDF.html":{"url":"gis/NetCDF.html","title":"NetCDF","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 GMT(Generic Mapping Tools) NetCDF NetCDF(network Common Data Form)网络通用数据格式是一种面向数组型并适于网络共享的数据的描述和编码标准。目前，NetCDF广泛应用于大气科学、水文、海洋学、环境模拟、地球物理等诸多领域。用户可以借助多种方式方便地管理和操作 NetCDF 数据集。 GMT(Generic Mapping Tools) GMT具有强大的绘图功能和数据处理功能 绘图方面，GMT支持绘制多种类型的底图：除30多种地图投影外，还有笛卡尔线性坐标轴、对数轴、指数轴、极坐标系；支持绘制统计直方图、等值线图、2D网格图以及3D视角图等；也支持绘制线段、海岸线、国界、多种符号、图例、色标、文字等。 数据处理方面，GMT具有数据筛选、重采样、时间序列滤波、二维网格滤波、三维网格插值、多项式拟合、线性回归分析等功能。 知乎，gis数据格式 2017.12.01 wiki,gis文件格式 file format list "},"gis/OSMnx.html":{"url":"gis/OSMnx.html","title":"OSMnx","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 OSMnx的作用 图或网络中的中心性 点度中心性（degree centrality） 中介中心性（betweenness centrality） 接近中心性（closeness centrality） 特征向量中心性（eigenvector centrality） 有向图和PageRank 小结 OSMnx [toc] OSMnx的作用 OSMnx example tour This notebook provides a quick tour of some of OSMnx's key features including how to: download/model street networks calculate stats visualize centrality impute speeds/travel times and calculate shortest path attach and visualize elevation data and edge grades download/model other infrastructure types download points of interest data 图或网络中的中心性 博客 图或网络中的中心性：点度中心性、中介中心性、接近中心性、特征向量中心性、PageRank 点度中心性（degree centrality） 背后的假设是重要的节点就是拥有许多连接的节点（你的社会关系越多，你的影响力就越强） 在上面的蝴蝶结网络中，节点D的连接数是6，和网络中的所有人都建立了直接联系，其他节点的连接数都是3，因此节点D的点度中心性最高。整个网络一共有7个节点，意味着每个人最多可以有6个社会关系。因此，节点D的点度中心性是6/6=1，其他节点的点度中心性是3/6=0.5。 中介中心性（betweenness centrality） 如果一个成员位于其它成员的多条最短路径上，那么该成员就是核心成员，就具有较大的中介中心性。计算网络中任意两个结点的所有最短路径，如果这些最短路径中很多条都经过了某个节点，那么就认为这个节点的中介中心性搞 中介中心性的现实意义 鲍勃徘徊在两个女人之间，他贪恋爱丽丝的美丽和谈吐，亦无法舍弃卡若琳娜的乐天和无忧无虑。但他必须小心谨慎，生怕自己在其中任何一个人面前露馅，这样的关系充满了压力和焦虑 银行家以5%的利率接受A公司的存款，以7%的利率贷款给B公司，这样的关系给银行家带来了巨大的利益。它的前提是，市场中的A公司和B公司不能直接接触，或至少无法轻易地找到对方 鲍勃和银行家的故事尽管截然不同，但他们都处于一种被称为被禁止的三元组(forbidden triad)的关系中，需要确保三元组的末端不能直接联系。没有联系就像网络中出现了一个洞，因此也被称为结构洞。 接近中心性（closeness centrality） 点度中兴性仅仅利用了网络的局部特征，即节点的连接数有多少，但一个人连接数多，并不代表他处于网络的核心位置。接近中心性和中介中心性一样，都利用了整个网络的特征，即一个节点在整个结构中所处的位置。如果节点到图中其它节点的最短距离都很小，那么它的接近中心性就很高，相比中介中心性，接近中心性更接近几何上的中心位置 特征向量中心性（eigenvector centrality） 特征向量中心性的基本思想是，一个节点的中心性是相邻节点中心性的函数。也就是说，与你连接的人越重要，你也就越重要。 有向图和PageRank PageRank是衡量有向网络中节点重要性的重要指标 我们将万维网抽象成有向图：（1）每个网页抽象成一个节点，假设有A、B、C、D四个节点；（2）用户通过超链接在网页之间跳转，这种跳转是有方向的（directed），从网页A跳转到网页B不代表可以从网页B链接到网页A，这种节点之间的有方向的连接被抽象成有方向的边。整个网络构成一个有向图。 你可以很轻易地找到最受欢迎的网页。但是，PageRank的思想认为，指标最好还需要考虑到指向你的那些网页。也就是说，来自受欢迎的网页的跳转应该重于不太受欢迎的网页的跳转。这就是PageRank思想的精华，Google就是利用这一思想来给网站排名的。这里的思想依据和特征向量中心性其实是一致的。 小结 点度中心性：一个人的社会关系越多，他/她就越重要 中介中心性：如果一个成员处于其他成员的多条最短路径上，那么该成员就是核心成员 接近中心性：一个人跟所有其他成员的距离越近，他/她就越重要 特征向量中心性：与你连接的人社会关系越多，你就越重要 PageRank：来自受欢迎的网页的跳转应该重于不太受欢迎的网页的跳转 "},"gis/城市规划中人性、人文和人本的关系.html":{"url":"gis/城市规划中人性、人文和人本的关系.html","title":"城市规划中人性、人文和人本的关系","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 城市规划中人性、人文、人本的理解 城市塑造人的思想 城市日积月累的文化 城市的核心在人 城市规划中人性、人文、人本的思考 城市规划中人性、人文和人本的关系 城市规划中人性、人文、人本的理解 城市塑造人的思想 人性：人普遍所以具有的心理属性 人是一根会思考的芦苇，人的生命像芦苇一样脆弱，但是他会思考。在城市这一头巨兽中，我们会思考，思考生活中的小事，思考我们对这个城市的想法，思考很多很多的事情。我认为城乡规划中的人性应该是人如何去塑造了我们生活这个城市，这个城市又如何塑造了我们的人性。 直到高中以前看到城中村，第一印象总是这是一个脏乱差的地方，这里生活的人应该不会很幸福。然后会基于这一点做出一些自以为是的思考，如：全部拆了重新修成高楼大厦多好、城中村的人是不是都是钉子户，城中村的人怎么就不知道治理一下呢。后来开始上大学，思想稍微成熟一点之后，再看到城关村，又有了一些新的想法。事物的存在必定有它存在的理由，不是谁都能住进舒适的小洋房的，底层大众很多，当活下去是一个困难的事情的时候，谁会把活得好作为第一考虑的事呢。当中国经济在腾飞，一座座高楼在拔地而起，谁会去考虑城市里面的人是不是都愿意承载这个城市的重量呢？城中村固然是一个严重影响城市风貌，不符合人民生活的地方，但这些“城中村”有着它存在的历史价值，这是来城市打工人、生活落魄的者的幸福港湾了。我的看法之所以会有着巨大的改变，我觉得最重要的就是屁股决定了脑袋，我从这个一个城市里的高中生成为了一个城市里的大学生，我的思考被城市的许许多多东西所改变着。 城乡规划中的人性是人对城市的思考，是这个城市对不同阶层不同背景的人的思想塑造。大多数的人和城市有着很高的相关性，他们的人性或多或少的正在被自己生活的城市塑造着。用一句文艺点的话说，城市是个大戏台，众生在城市里面唱着戏。 城市日积月累的文化 人文：人类社会的各种文化现象 每个人每一天都离不开衣、食、住、行四个字，作为城市的重要组成元素的人，人们的衣食住行慢慢演化出了城市中的服饰文化、饮食文化、建筑文化、交通文化。当然，人除了衣食住行，有些人可能还有自己的教育、宗教信仰、工作等待，在这些部分人的文化中也会演化出城市的形形色色的文化。至今，每个城市都有着自己巨大的框架，有着不同的缤纷与华丽，却不一定拥有着自己的巨大框架匹配的人文品质和人文情怀。就和人一样，不同的人过着属于自己的人生，但不是所有人都有着情怀。 深圳，简称“深”，别称鹏城，我们从历史课本上学到的知识就是深圳乘着改革开放的春风，一夜从一个小渔村发展成了一个国际大都市，但是鲜有人讨论深圳这座城市的文化。提起北京，我们会想到这是我们的首都，是一座历史悠久的城市；提起维也纳，我们甚至一点都不知道它的样子，但是我们的概念会离不开音乐二字；提起巴黎，我们会想到时尚和艺术······那么，现在让我们来提一提深圳，我们会想到什么呢？一个城市的巨大框架，可能能在十年二十年的时间建立起来，它的高楼大厦会像树杈一样蓬勃生长，它的交通路线会像树根一样密密麻麻，这个城市会很快的长成一棵参天大树，但是这个城市有什么特色吗？如果这棵参天大树是长在了寺庙，来寺庙参拜的人们会把写有愿望的红绳系上它的枝桠，日积月累，我们就可以说这棵树是一棵许愿树。一个城市，如果有了许许多多的“红绳”，这个“红绳”可以是任何东西，可以是科技、文化、教育等宽泛的东西，甚至可以是斗牛、足球、篮球等一些小东西，这些“红绳”多了之后，我们就可以说这个城市有了某某文化了。这种内蕴性的东西不是一时能做出来的，就像罗马也不是一天建成的一样。 城市的核心在人 人本：以人为本的思想 人本主义作为近年来新起的词，在各式各样的的法律法规中频繁出现，城市规划中的人本思想不再是新鲜的事 物。但是一个实际性的问题一直出现在电影、音乐、文学作品中，也被无数的人问过：我生活的城市是谁的城市？ 我生活的房子，如果有了一个房产证，我可以认为这个房子是我的。但是城市是没有城市证的，那么这个城市应该是谁的呢？古希腊时期，人本主义对人类社会的普遍关怀在城市建设中得到了体现，庙宇遍布希腊各地，人们不仅在庙宇中举办各种宗教活动，而且还通过庙宇举行各种活动。关于城市的定义：城市是为美好生活而维持很小规模的一个社区。现在的城市不只是一个小小的社区，一个个大社区的人是一个个的节点，节点又会有一个或多个小中心。但是一个好的城市的设计，应该是以人为本，充分考虑人的内在和外在需求的产物。人本主义的城市要又公众的参与，每个人都是城市的主人。随着信息时代的到来,我们有理由相信，新技术的支持及城市规划本身的需要将使“人本” 得到发展，“城市让生活更美好”是一种正在实现的理念，而不只是一种美好愿景。 城市规划中人性、人文、人本的思考 我认为，城市规划中，人本是出发点，人性是灵魂，人文是结果，这三者是息息相关且不可分割的。人本是根，如果一个城市，一个人类的生活环境都没将人考虑进去，这个产物必然不合适现实规律，是一个本末倒置的东西。人性是人与城市的互相作用，人按照自己的意愿去塑造自己的城市，城市给予人相应的反馈，人性也是这个城市的品性，是这个城市中最宝贵的东西。人本是一种文化，是城市和城市中的人奋斗的产物，是一种传承与信仰，我们可以说，当人文的氛围随着时间开始积淀，开始让城市的人们活在某一种状态之中的时候，这个城市就是一个活的城市，活在这个城市中的人是又信仰的。 人是一个简单又复杂的东西，我们也总是对自己生活的地方有着复杂的情感。哲学有三个难题，我是谁，我从哪来，我又将到哪去。也许城市也会有自己的疑问吧，城市会想自己是谁，自己从哪来的，我以后又将是什么样子。人性，人文，人本可能就是城市的哲学与根吧。愿我的城市以人为本，我们塑造城市，城市塑造我们的人性，最终能演化出一种文化，一种生生不息的传承。 "},"gis/地理大数据探索.html":{"url":"gis/地理大数据探索.html","title":"地理大数据探索","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 起因 地理信息科学到底是地理学的核心还是外缘 地理大数据探索 [toc] 起因 起因是自己GEE调研报告，了解了大数据与云计算的起源，具体内容参考Google三大技术及其衍生和调研报告，大概清楚了大数据、分布式、云计算的2015年前的发展。诚然，大数据云计算的时代，和地理的关系又是什么样的呢。中间偶然看到一个专栏：地球云计算（专栏前半段讲的可以，后半段都是具体技术去了），讲的很好。然后在作者的github上看到了一句话，感觉很有意思： $$ Data\\ Geoscienc \\neq Geodata\\ science\\ Geospatial\\ ML \\neq ML\\ using\\ Geo\\ Features\\ Only\\ insights\\ can\\ save\\ yourself\\ from\\ information\\ overload. $$ 引用自奋进号历险记（下） 地学计算是计算密集型还是数据密集型？地学计算的数据量的确大，大家为了操作问题，得先找能算、能把数据处理出来的方法，不得不简单粗暴一些，由此就会掩盖了地学问题的复杂实质。深度学习和机器学习已经云化了，大数据现在都处理什么对象呢：人脸、车牌、数字、语音、文本。但是实际上的真实地表不应该比这个复杂多了吗，不是不能密集计算，但是解不出，算不完。 目前的复杂计算问题，很大程度上还是基础学科方面的，人们为了解决数值的、动力的、动态的、高复杂性的、演化性的问题，发展了很多方法和模型，设置了不同的初始条件、驱动变量，放到机器里面一顿猛算、模拟，这种模拟很大程度上也只是在丰富人们的知识，或者像是一些工程模拟一样，节省下材料和人工 地学问题，是一种高复杂性问题，像生命科学一样，人们也许永远也搞不清楚这背后的机理、分异，但是可以用不断收集到的地表数据去充实材料，去提取规模，让机器去强化，标识某些规律和信息，这就是说，地学问题就像是一只被沉重肉身束缚在表相之下的巨兽，一旦笼子被突破，宅男马上变成猛男。 老实说，现在不都是通过大量的实验或者模拟来增强自身的知识，而且很多东西也的的确确只是数据密集型（还是大量异构数据密集型），高复杂性的问题很难由我们这种小人物来完成的，比如气候变暖，就是通过 IPCC 成百上千的科学家工作几年才有一些报告结果，这些东西还只是定性的，黑箱的，怎么转为定量的已经不是搞技术的能做的了。 地理信息科学到底是地理学的核心还是外缘 地理信息科学:地理学的核心或是外缘 地理学碰上“大数据”：热反应与冷思考 刚开始是地理信息系统，这是一个采集、管理、分析、表达、模拟地理空间数据的系统，研究揭示地理现象和要素的分布形态、相互作用、动态演化和驱动机理，从而服务于地理空间决策支持。Goodchild（1992）提出了地理信息科学的概念 "},"gis/地理信息安全技术与进展心得体会.html":{"url":"gis/地理信息安全技术与进展心得体会.html","title":"地理信息安全技术与进展心得体会","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 地理大数据的安全保护尤为重要 位置服务应用有隐患 无人机监管逐渐加强 地图标注无序威胁国家安全 地图水印信息隐藏与加密技术方法 地理信息安全技术与进展心得体会 地理大数据的安全保护尤为重要 作为半个互联网人，我们都被大量关于数据存储和处理的时髦词汇轰炸过了： NoSQL、区块链、分布式、大数据、云服务、MapReduce、实时······这些听起来很牛皮的词总是让人不明觉厉但又不知其意，但是归根结底，这些词都是围绕着如何高效安全存储与数据服务这一核心主题的。数据越来越“大”的同时，数据安全问题日益严重。作为完整的地信人，我们深知技术的发展给地信领域带来了全新的动力，深刻的影响着社会发展和人们的日常生活，但是地理信息产业具有促发展与保安全的双重属性，维护地理信息安全是促进地理信息产业发展的前提，没有国家安全就没有产业的可持续发展。 位置服务应用有隐患 当前很多应用在使用时，都会询问用户是否“允许使用位置服务定位应用”。据2016年12月腾讯位置服务团队宣布的数据显示，其定位服务日均调用量突破500亿次，峰值突破520亿次，覆盖用户数6.8亿人，其调用量是2012年同期的25倍。在物流行业、O2O、智能出行、警务安全和运动健康等均有涉及。这仅是腾讯一家的数据，由此可见当前社会对位置服务需求量的巨大。当前人们常用的社交、出行、旅游、购物、健康等众多应用都要必须开启或记录位置信息，严重依赖位置信息技术，如果不做好安全防范，则暗藏一定的安全风险，轻则隐私泄露，重则失密泄密。例如，2014年，苹果手机的定位服务曾引起社会争议。在苹果手机的定位服务里有一项“常去地点”功能为默认开启状态，在这里可以看到用户所有去过的地方、停留时间、前往次数等数据，还能在地图上显示。对于重视隐私的用户，就会担忧这些数据是否存在隐患，以及是否会被用作他途。另据近期解放军报报道，有士兵通过手机软件预订外卖，不仅暴露了个人信息，连营区位置也被精准定位。还有部队人员训练后，在朋友圈里展示自己的训练成果，当点开他发布的运动轨迹时，营区的周边信息也一览无遗。看似种种方便的举动，却违反了安全保密规定，军事部门对这些有失泄密隐患的手机软件已高度重视。在大数据时代，通过对各种应用收集而来的用户位置、轨迹等数据的分析，特定用户的活动特点可被精确掌握，敏感地理信息可被精准定位，这对地理信息安全监管工作提出了新的挑战。 无人机监管逐渐加强 无人机行业近年来高速发展，不仅在测量测绘、航空摄影、遥感地图、应急救灾等专业领域大显身手，而且随着无人机的越来越小型化和越来越低廉的价格，消费级无人机市场也迅速升温，走入了百姓的日常生活。 由于人们的法律意识淡薄和实际操作技能差的原因，关于无人机航摄活动影响空防安全的事件屡屡见报，但这只是无人机安全隐患的一方面。很多使用者在不具备航空摄影测绘资质且未申请空域的情况下，往往有意无意地进行航空测绘活动，涉嫌非法测绘地图。 按照测绘方面的有关规定，使用测绘型无人机必须取得相关资质，每次使用起飞前，必须进行审批、报告，向空管部门和测绘主管部门报告飞行区域、高度、经纬度。如果使用无人机进行的测绘涉及到国家秘密，还会受到保密等相关部门的依法惩处。2016年4月14日，北京国遥星图航空科技有限公司员工在无航拍资质、未申请空域的情况下，操纵无人机进行非法航拍测绘，被发现后，公司法人和操作人员均被判处有期徒刑。 地图标注无序威胁国家安全 2005年，Google公司推出了谷歌地球（Google Earth）全球动态地图，它把卫星照片、航空照相和GIS布置在一个地球的三维模型上。用户可以通过客户端软件，免费浏览全球各地的高清晰度卫星图片。 好奇的网民们发现，在这里不仅能发现世界上各大城市、风景点，同时还能清晰地看到在市面出版发行的地图上，没有标出的涉及国家机密的隐蔽设施或军事建筑。有专家认为，根据这些解析度很高的卫星成像地图可以计算出相应数据，从而掌握一些重要设施的建筑位置和外形资料，有泄露国家机密的隐患。 如果说在目前卫星满天飞的情况下，卫星图片已经可以公开获得，那些可以看见的军事设施已不是什么秘密，不具备重要价值，但Google Earth的“标注”功能，即可以在地图上标注具体位置的信息，可以使得一些未被发现的隐秘地点暴露在大众面前。 科技的发展，使得人人都能参与到地图标注中来。据媒体报道，美国人柯蒂斯·梅尔文从2006年开始，利用多方搜集的资料，对朝鲜全境地图进行标注，包括餐厅、学校、医院、集市、全国电网图、铁路网图、精确行政区划界乃至领导人官邸等，至今仍在更新，成为“全球除情报机构外最全面的朝鲜地图信息库”。 而在我国，有些军事爱好者乐于在谷歌地图上标注军事设施的地点，甚至详细到了部队具体驻地、军事基地具体坐标。也有的地图爱好者，在标注时不经意间泄露了身边敏感地区的位置，而相应的卫星地图往往会被替换成更新的高清图，引发网友的“更正”热情。 2010年，一个名为“月光论坛”的网站，其中很多军事爱好者把大量涉及国家军事的地理坐标和信息，如机场、舰艇码头等在谷歌地图上标注出来，这是一起典型的地理信息涉密行为，已经得到当地主管部门的查办。月光论坛出现的问题并不是个例，还有很多网络社区也存在同样问题，不仅是军用机场、导弹阵地、雷达阵地、海军港口、部队驻地的准确位置和坐标，甚至连中南海、西昌卫星发射中心的地标文件都被人在谷歌地图上发布。 军事专家认为，这种行为导致有的互联网地图其作用甚至超过了某些军事侦察卫星，让人不费吹灰之力就能得到一些需要花费数年才能得到的测绘信息，给国家安全带来了隐患。这不仅是谷歌地球软件自身服务功能引发的泄密，也是用户在使用过程中的行为导致的泄密。 地理信息数据泄密，也同样可以带来商业上的损失。曾经中国某重要能源公司所属3万多口油井的地理坐标和储量信息的数据库，被国外公司非法获得，直接威胁到了我国相关行业的经济利益。还有我国900兆瓦以上装机容量的200多座电站的具体位置的地标文件，也被网友发布到网上，这些都直接影响到我国的国家安全。 由此可见，地理信息安全就在我们身边，在我们不经意的一举一动之间。作为社会大众，我们在享受地理信息带来种种便利的同时，不仅要保护好自己的个人隐私数据，更要提高安全认识，从战略高度上来看待地理信息安全。往往可能只是好奇或者炫耀之举，但可能帮了一些别有用心之徒，更是泄露了国家机密。 地图水印信息隐藏与加密技术方法 到目前为止，国内外数字水印技术的研究主要集中在图像、视频和声音等多媒体信息的版权保护上，在GIS空间数据中，通过隐藏水印信息并对其加密、压缩以实现其安全保护的研究还很少，这是数字水印技术应用的一个新领域、新尝试，也是GIS空间数据安全管理方法中一项具有挑战性的创新技术研究。GIS空间数据水印信息文件隐藏与文件加密是对GIS空间图形数据实行安全保护的两种核心方法，两者对数据的保护都可转化为对水印密钥的保护，因此，GIS空间数据水印信息隐藏技术可以沿袭传统加密与信息隐藏技术的一些基本思想和概念，但两者采用的保护信息的手段是不相同的。GIS空间数据数字水印信息隐藏技术是把一个具有版权意义的水印信息隐藏在普通GIS空间数据文件中，申明数据生产单位的版权及该数据的使用权属，从而达到利用技术手段间接保护GIS空间数据版权的目的。采用数字水印信息隐藏技术需满足如下条件：GIS空间数据中隐藏的水印信息不能直接被数据用户感知；水印信息的隐藏不影响GIS空间数据的使用；隐藏的水印信息必须具有很高的鲁棒性，即隐藏在GIS空间数据中的水印信息难以被非法数据用户擅自干扰或去除。 在地理数据数字水印技术研究中，需要着重考虑地理数据本身结构的特点，基于数字水印思想，进行地理数据数字水印模型和算法的深入研究。地理数据总体可分为矢量地理数据、栅格地理数据、数字高程模型(DEM)数据这3类，因此地理数据数字水印技术的研究主要围绕这3类数据开展进行。矢量地理数据是通过点、线、面及其组合体实现对地理空间要素的描述，并记录对象的属性信息，具有空间信息和属性信息的并存特征。地理坐标作为矢量地理数据中空间信息的载体，也为水印信息提供了一定的承载空间。从水印嵌入域划分，矢量地理数据数字水印算法主要分为基于空间域的水印算法和基于变换域的水印算法。栅格数据在存储方式与表现形式上与普通图像数据具有相似性，因而对于栅格地理数据水印算法的研究在一定程度上可以借鉴普通图像的水印算法。然而栅格地理数据在量测、精度与空间分析等方面又具有自身的特性与应用需求，使得栅格地理数据的水印算法设计需要考虑栅格地理数据自身特性，不能照搬普通图像水印算法。按照数据类型的不同，栅格地理数据的数字水印算法研究可分为遥感影像数字水印算法和栅格地图数字水印算法。遥感影像具有数据量大、纹理丰富、多波段等特点，因此在研究遥感影像的数字水印算法时，需要充分考虑遥感影像的数据特征。考虑到抗差性的需求，目前遥感影像的水印算法主要为变换域算法。DEM是地形表面形态的数字化表示，有着数据精度要求高、组织方式多样、空间特性强的特点。从DEM的数据组织方式的角度，DEM可分为规则格网DEM和不规则三角网DEM，因此DEM的数字水印算法同样可分为规则格网DEM数字水印算法和不规则三角网数字水印算法。 随着地理数据应用价值的日益凸显、地理数据共享需求的日益旺盛，地理数据的安全问题变得愈发不容忽视。数字水印和加密控制作为地理数据安全保护方面的前沿技术，在地理数据安全保护中扮演着重要的、不可替代的角色。面对大数据时代的地理数据，只有深刻分析地理数据安全特征，不断深入挖掘与研究数据安全的关键理论，紧跟信息技术的前沿思想和潮流，结合实际推动技术手段的应用、扩展、融合与完善，才能真正发挥数字水印和加密控制对于地理数据的安全保护作用，实现地理数据的安全共享与交换。 "},"gis/面向地理共享与集成的数据适配方法研究.html":{"url":"gis/面向地理共享与集成的数据适配方法研究.html","title":"面向地理共享与集成的数据适配方法研究","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 摘要 绪论 第二章 地理模型数据规格及其结构化描述方法 面向共享与集成的地理模型特征 地理模型共享与集成的特征 地理模型规格的常用描述方法 基于元数据的描述方法 面向地理处理服务的数据描述方法 面向集成建模研究的数据描述方法 面向虚拟环境仿真的数据描述方法 现有方法的总结与分析 面向地理模型运行的数据规格结构化描述方法 地理模型数据规格的形式及结构描述 地理模型数据接口的统一映射方法 地理模型数据接口的统一映射 模型自定义格式映射机制 数据内容与分隔符抽象 基于状态机的自定义格式映射 地理模型数据的重构方法 地理模型数据的重构需求 与实现无关的信息内容重构 与实现相关的数据组织重构 地理模型数据重构方法库 基于统一数据视图的数据重构 数据重构方法的原子操作设计 数据重构方法的统一接口设计 地理模型数据的基本重构方法 面向地理模型运行的数据适配方案 路线 面向地理共享与集成的数据适配方法研究 作者：乐老师 时间：2016.3 摘要 地理模型的共享与集成在具体的实现与应用时，最终都要面对模型能否正确运行的问题。模型的正确运行与数据有着直接的关系：必须通过输入数据来驱动模型运行，通过输出数据来获得计算结果。由于模型本身所定义的数据规格与模型使用者所提供的数据之间往往并不直接匹配，针对模型运行的数据兼容性处理成为了模型应用过程中繁琐而关键的工作。在跨学科跨领域背景下的开放式地理模型共享与集成中，这种从原始数据向模型的数据规格之间的适配问题更加突出，也亟需解决。 本文以模型使用者正确理解地理模型的数据规格为切入点，通过设计地理模型数据规格的结构化描述方法，实现模型的数据需求的无歧义传递。在此基础上，提出了一套完整的模型数据适配方法，通过模型数据接口的统一映射和数据重构方法库的建立，形成融合数据表达、数据接口映射与数据重构的数据适配方案，从而将模型构建、数据处理和模型集成应用之间解耦。 主要研究内容与结论如下： 地理模型数据规格的结构化描述 地理模型数据接口的统一映射 地理模型数据重构方法库的构建 地理模型数据适配方案的构建 四个研究内容之间相互联系又相互解耦，模型数据规格的描述是整个研究的基础，模型数据接口的统一映射为数据适配提供统一的数据视图，数据重构方法为数据适配提供可组合可重用的方法组件，最终形成了同样可共享的数据适配方案资源。在开放式网络环境中的构建原型系统，对数据适配资源的组织管理服务、共享平台门户和辅助应用工具进行了相应的实现，验证了数据规格描述、数据接口映射、数据重构等方法的可行性。通过典型目标驱动的集成模拟实验和典型探索驱动的综合模拟实验，对数据适配方法的实用性进行了验证。 绪论 即使数据蕴含了模型运行所需要的全部信息，数据规格的微小差异都将导致程序不能正确运行。 地理模型数据的这种控制性、决定性作用使得数据转换成为驱动模型运行重要而繁琐的工作。地理信息领域对于空间数据的不兼容问题进行过一系列的研究，包括开发相关的数据转换系统、制定统一的数据格式和交换标准、开发统一的数据访问API等等工作，开源领域的GDAL/OGR、SDO，商业领域的FME、SDX+、OGC/TC211的相关标准都是这些工作的部分成果，空间数据的兼容性问题得到一定程度的解决。然而，地理模型所提出的数据兼容性问题涉及的层面比传统空间数据所面临的兼容性问题具有更大的综合性和复杂性：首先，地理模型的专业性使得其依赖的数据不单纯是经典的空间数据形态，其数据模型、结构和编码表现为对建模原理、领域传统和实现策略的多重依赖；其次，地理模型的数据交换，往往代表了物质、能量的传递，支撑参数表达的时空离散结构和尺度往往成为这种不兼容性的一部分；第三，地理模型数据蕴含的语义与约束是模型正确运行的必要条件，比如数据的量纲、单位等，即使数据结构完全一致，这些差异依然会导致模型执行无法得到正确的结果。第四，地理模型的输入、输出和控制参数会依赖模型的实现策略通过接口参数、内存结构、数据文件、数据库等不同的编码机制进行传递。第五，模型数据的处理往往需要在运行时完成，这又与具体运行环境有极大的相关性。 因而，目前亟需找到一种具有高度柔性的数据适配方法，在模型知识共享层次能够适应于不同领域的地理模型，在模型集成运行层次能够动态配制出地理模型所需要的数据，从而降低综合地理模拟研究过程中的协作难度，提高异构地理模型共享、重用与集成的便捷度。 本文所研究的地理模型数据适配方法，其核心目标是提供解除模型运行与数据规格之间紧密耦合关系的工具，在数据蕴含足够的信息的前提下，通过对模型的输入、输出、控制数据进行解析表达，对数据的时空离散、组织结构、量纲/单位、编码方法等方面进行重构和映射，便捷的实现模型与数据的匹配。 另一方面，数据作为地理空间信息建模的重要内容，为了适应于不同的应用和表达需求，诸多数据模型和数据格式被设计和发展。地理信息领域经典的数据模型以矢量和栅格表达为基础，相关的发展有对象数据模型、场数据模型、矢-栅一体化数据模型、三维数据模型、时空数据模型、几何代数的多维统一数据模型等（Molenaar，1990；Egenhofer，1991；李德仁，1997；Brown，1998；吴立新，2007；俞肇元，2013；Yuan et al., 2013）。基于这些空间数据模型发展而成的相关数据格式常常被具体的地理模型采用为其输入/输出数据的格式，如GeoTIFF，ASCII Grid，NetCDF，Shapefile等数据格式。不同的地理模型开发者针对所研究的对象，并结合自身的编码习惯，从空间信息领域中常用的数据格式中，选择一种数据格式作为模型执行程序关联的数据格式，形成默认的数据交互接口。 地理模型数据的异构性特征并不仅仅体现在数据格式这个层次上，在进行综合地理模拟的过程中，来自不同学科不同领域的地理模型数据通常具有其复杂的语义属性特征 为了实现不同系统间的数据交换，不同领域制定了大量的数据交换格式和交换方法。总的来说分为以下几类： 成熟的商业软件提供的公开数据交换格式 国家制定的空间数据转换标准，以标准数据格式实现数据交换 国家及不同领域的组织参与制定的统一地理数据模型 第二章 地理模型数据规格及其结构化描述方法 地理模型是对地理过程与机理的抽象与表达 面向共享与集成的地理模型特征 在本文中，服务于构建一个能够支撑复杂地理问题求解的综合地理模拟情景，所涉及的“地理模型”是指能够在特定计算平台上执行相关计算的“实体” 地理模型的运行特征： 开发模式方面： 基于过程函数的开发模式 面向对象的开发模式 组件插件式的开发模式 面向服务的开发模式（SOA) 总结起来，无论是在开发模式，运行平台还是执行风格方面，地理模型在程序运行方面的异构性特征都较为突出。 地理模型共享与集成的特征 通过地理模型的分类体系和元数据信息描述，建模研究者可以通过统一的入口便捷的访问到所需的地理模型资源；在此基础上，建模研究者需要能够利用模型资源、驱动模型程序计算，这就涉及到地理模型异构的运行特征。考虑到地理模型在执行接口和数据接口上的差异性，按照特定的模型封装方法对异构的地理模型进行统一的包装，进而形成标准化的模型组件，是当前地理模型共享、集成建模框架等相关研究领域的常用方法。在某一个集成建模框架中，根据其所提供的模型封装标准，能够将异构的地理模型包装成在该建模框架内可以统一调用、组合、连接的模型组件；另一方面，地理模型作为网络服务来发布和共享时，还需要与网络服务的消息通信机制和数据传输方法相结合，形成面向服务的地理模型封装。虽然封装方法各有不同，但地理模型封装的主要目标是屏蔽模型程序执行的异构性，使之能够按照统一的方法调用，这在技术理念上与地理模型的组件插件式开发模式也是一致的。 主要有两种方式来实现这种模型集成工作。一种是通过代码编写的方式，在集成程序中引入不同的地理模型资源，调用其执行接口，按照其数据接口提供相应的数据，并在模型与模型之间的流转中加入定制式的数据处理。另一种是通过科学工作流的方式，制定模型间连接、组合、循环、嵌套的基本框架，将模型资源按照“节点”的方式插入到配置的工作流中； 按照地理模型的特定运行需求来准备数据，首先就需要能够正确理解模型对数据的需求；从用户使用地理模型的角度，这种数据需求可以归结为模型的数据规格。 从地理模型计算运行的一般特征出发，地理模型数据可分为输入数据、输出数据和运行控制数据。模型数据规格的一个最直接的体现就是数据格式。 xml（Extensible Markup Language）格式 XML 被设计为传输和存储数据，其焦点是数据的内容。HTML 被设计用来显示数据，其焦点是数据的外观。 从模型数据参数的描述，到数据接口的封装，再到数据参数的传递和交换，这三者贯穿于整个地理模型共享和集成过程，三者既各有分工，又内在联系。通过地理模型的集成来进行综合的地理模拟需要在科学原理正确、物理机制合理的基础上进行，而最终制约这个“集成了的地理模型”能否正确运行的一个关键要素就是地理模型数据。 模型数据规格的表现形式： 自定义的数据格式：如文本文件，二进制文件，数据库等；在特定的地理模型程序中，如果读取的是自定义数据格式，则读取的规则和数据内容的组织必须完全一致。 领域通用的数据格式：如Shapefile，ASCII Grid，NetCDF，GeoTIFF等；这种数据格式往往是结合领域应用特征，具有特定数据模型支撑的数据格式。 内存变量形式：如主函数的命令参数，API函数的参数序列等。 常用的数据组织形式： 常用特定的分隔符来区别不同的数值。 数据头和数据体是常用的组织方法。 数组、键值对和数据表是常用的数据结构。 数据内容中通常含有一些注释字符串。 数据规格的内蕴信息 地理模型规格的常用描述方法 基于元数据的描述方法 在地理信息领域，元数据的内容除了对一般属性信息的描述之外，还需要能够提供空间的相关信息。 面向地理处理服务的数据描述方法 在地理信息处理服务相关的研究中，也没有直接采用元数据标准来描述地理信息服务中的数据信息。最为典型和常用的WPS规范（Web Processing Service）是OGC继WFS（Web Feature Service），WMS（Web Mapping Service），WCS（Web Coverage Service）推出的关于地理处理网络服务的规范。在此规范中，地理模型被当做一个个GeoProcessing来管理。 面向集成建模研究的数据描述方法 OpenMI的设计理念是提供一种组件式开发模型的接口标准，规定了模型运行时各模型之间交换数据应遵循的规范。在OpenMI中，模型数据的描述并没有采用某一种元数据规范，也没有利用WPS中的DataType方法，而是直接面向模型的计算和模型集成时的数据交换。 OpenMI作为被OGC认可并推广的地理模型集成标准，其对模型数据的描述是直接面向模型集成计算的，侧重于数据在程序执行层面跟模型需求的匹配。如前文所述，地理模型的正确运行并不仅仅依赖于数据类型和文件格式匹配，模型对数据内蕴的语义相关信息同样提出了限制条件。而OpenMI在数据的语义信息描述方面，仅通过简单的字符串描述，其描述能力显得较为不足。 面向虚拟环境仿真的数据描述方法 基于环境数据编码和语义信息关联的方式，在方法上能够有效的实现地理模型数据的语义描述。基于SEDRIS规范可以用结构化的方法描述出数据的内容和逻辑组织，且数据内容中的每个要素都可以进行灵活扩展；通过节点之间的自由组合，理论上可以实现任意数据内容的表达。但将SEDRIS应用到地理模型的共享与集成中时，这种由组织容器类-环境数据类-要素类构成的数据组织模式相比于WPS和OpenMI而言又过于繁琐和复杂。而且地理模型的共享与集成涉及到大量跨学科跨领域的概念和知识，在这个层次上EDCS的兼容性还比较欠缺。此外，地理模型对数据内容的约束性信息虽然可以通过EDCS中的相关概念条目得以体现，但诸如数据取值范围、数据单位量纲之类的信息并没有能够很好的体现出来。 现有方法的总结与分析 综上所述，在模型数据规格描述的方法层面，利用层次化的组合来描述模型数据的内容结构信息成为当前公认的有效方法；无论是在地理处理服务领域，集成建模领域，还是在虚拟环境仿真领域，复杂多样的数据内容结构都采用这种方法来描述。信息关联的方式也普遍被用于数据内容的信息附加，比如单位量纲信息、空间参考信息、语义概念信息等均可以采用标签关联、URL地址关联的方式进行描述。这几种方法中，基于元数据的方法更侧重于数据的相关属性信息的表达；WPS基于地理处理网络服务的应用需求，结合网络数据传输的特点，对数据的描述直观、简练；OpenMI作为集成建模的规范，相比于其他方法而言，对空间离散网格和时间步长等信息的描述更为全面；SEDRIS面向综合环境仿真的研究目标，与其他方法相比，在数据的语义概念信息方面设计了系统的描述方法。 但是现有的方法大多集中于数据本身的信息，跟模型运行相关的语义和约束信息较少地融入到其中。虽然不同的数据格式能够利用后缀名和URL关联的方式加以描述，但这种方式却难以适应于地理建模领域中纷繁多样的自定义数据格式。在地理模型的共享与集成过程中，由于涉及到多个学科领域的异构地理模型，对于模型数据规格的描述应该是独立于具体的技术平台。地理模型相关联的数据既有空间数据，也有非空间数据，既可以是一个简单的数值，也可以是一组相互引用的数据文件，所以对模型数据规格的描述应具有较强的扩展性和灵活性。 面向地理模型运行的数据规格结构化描述方法 基于以上对地理模型共享与集成中数据规格描述方法的分析，本研究从模型使用者需要了解某个地理模型能够正确运行的数据需求出发，探索地理模型数据规格的结构化描述方法。本文作者在对分布式地理建模环境的多年追踪研究中，设计了统一数据表达-交换模型（Universal Data Description eXchange Model，UDX），该模型借鉴结构化程序设计方法中使用有限结构元素表达任意程序算法的思路，力图通过构造式的方法来实现地理模型数据规格的描述，并支撑数据描述和具体数据内容的直接映射。本文从模型使用者理解地理模型、获取地理模型运行所需数据条件的角度，针对地理模型数据规格的描述需求，对统一数据表达-交换模型进行扩展。 变量类型有：原子类型（Atomic）、数组类型（List）、组合类型（Union） 在统一数据表达-交换模型中，主要有两个基本元素：节点（Node）与核（Kernel）。Node负责组织模型数据的结构，每个Node都拥有自己的名称（Name）和子节点（NodeChildren）；在NodeChildren中又包含了相应的节点及其子节点。通过这种层次化的组织，能够灵活的构造出各种数据结构。Kernel负责对具体数据的存储，其中Kernel的数据类型由DTKernel来管理。总体上，Node控制数据的组织结构，Kernel管理数据的具体类型和内容。 对于DTKernel而言，主要有三大类：简单数值类型（DTKValue），数组类型（DTKValueList）和复杂容器类型（DTKContainer）。这三大类Kernel可以分别对应到W3C规范所定义的原子类型，数组类型和组合类型。 一个节点的Kernel属于DTKValue或者DTKValueList类型，则该节点都不可以拥有子节点。而节点的Kernel属于DTKContainer类型时，则该节点可以拥有任意个数的子节点。在DTKContainer中，有四种具体的容器类型：DTKStructure，DTKList，DTKKeyValue，DTKTable。 eg： 地理模型数据规格的形式及结构描述 在数据内容的组织结构上，统一数据表达-交换模型包含两个主要实现。一个是统一数据表达UDX Schema，还有一个是统一数据交换UDX Data，两者共同构成了统一数据表达-交换模型的内容。UDX Schema和UDX Data两者在结构层次是同构的，都是基于统一的Node-Kernel结构。而UDX Schema负责对模型数据内容进行详尽的描述，UDX Data则是严格匹配于UDX Schema的具体数据内容。 对于地理模型数据，UDX Data是具体数据内容的存储，UDX Schema则对地理模型数据规格在形式和结构层面的描述。 如上所述，基于统一数据表达-交换模型可以进行构造式的数据描述，但这种Node-Kernel结构的UDX Schema只是在形式和结构层面描述了地理模型的数据规格，数据内容的内蕴信息并没有描述。 （没看完） 地理模型数据接口的统一映射方法 地理模型数据接口的统一映射 虽然地理模型的数据接口在外观上表现出来的是某种格式的数据文件、某种类型的变量，但在内容上则是对特定信息的依赖 领域通用数据格式都会有其相应的数据读写API（Application Programable Interface）；利用数据读写API可以控制数据内容，能够在数据的表现形式（即数据格式）和程序内存布局之间进行完整地转换。 从数据储存和数据读写API的模式考虑，领域通用数据格式主要有两种： 一种是数据内容与数据读写API一致的数据格式 这种数据格式中的数据内容可以是变化的，但是其组织的模式是固定的（第几行代表什么数据，前多个字符是什么数据，这些都是固定的）；读取这种数据格式需要严格按照某个特定的数据读取方案，典型的如ASCII Grid格式，GeoTIFF格式，WKT格式，WKB格式，DXF格式，3ds格式，BIL格式，BIP格式，BSQ格式等； 一种是数据内容与数据读写API不一致的数据格式 如XML（Extensible Markup Language）格式和JSON格式（JavaScript Object Notation），这两种数据格式都是在建模领域中常用的数据格式，但是XML和JSON提供的是上层的数据组织方法，对于特定的地理模型而言，需要根据自身的需要定制出相应的结构。比如说GML就是基于XML结构对空间矢量数据的一种实现，GeoJSON是对JSON在空间矢量数据的一种实现。另外还有结构表（Table）类型数据格式，如Excel、关系数据库等. 原始的领域通用数据格式到基于Node-Kernel结构的UDX Data之间，可以通过API函数和数据节点操作两者的映射来进行直接的交换。 eg: 传统的数据转换方法会从一种数据格式的文件转变为新的数据文件，而原始数据格式与UDX Data之间的转换不会产生新的数据文件 本文设计了数据格式映射方法库，支撑地理模型提供者将所构建的UDX Data与API函数映射的结果积累下来，成为可共享的资源。 模型自定义格式映射机制 数据内容与分隔符抽象 基于状态机的自定义格式映射 模型自定义格式的数据文件中包含的数据内容通常按照各种不同的形式进行组织，将其映射到UDX Data的Node-Kernel结构时，最直接的方法就是进行顺序的逻辑判断（如If-Else，Switch-Case等语句），但在面对诸多不确定组织的数据文件时，这种逻辑判断往往会变得非常庞杂。状态机是一种在信息技术领域中的经典设计模式，应用程序开发中也经常使用此方法来简化复杂的事务处理流程。常用的OpenGL库，其底层设计就采用了状态机的原理，通过有限的接口函数实现各种各样的三维渲染效果。 (也没看完，重点是后面感觉与我想看的没有多大关系了) 设计某种特定的数据格式来将所有地理模型的数据接口都转换为该格式，这种方法在满足几个地理模型应用需求的同时，在面对广泛的跨学科跨领域的地理模型时又产生了难以适用的问题。UDX是一种构造式的数据表达元模型，通过对信息内容的灵活组装，可以配置出与不同数据结构相对应的UDX Data 本章从数据接口的内外存实现策略方面将地理模型数据接口主要分为领域通用数据格式、模型自定义数据格式和编程语言相关的内存结构。针对领域通用数据格式，设计了可扩展的数据格式映射方法，并由此设计了数据格式映射方法库。针对模型自定义数据格式，设计了基于分隔符-状态机的自定义数据格式统一映射方法。针对语言相关的内存结构，设计了基于扩展注释的内存变量映射方法。 地理模型数据的重构方法 地理建模从现实世界→概念模型→逻辑模型→源代码→可执行程序→数据IO接口→程序运行，经过多层的信息传递和转化，人们对地理世界语义的理解在源代码阶段已经相当弱化 尤其是在不同地理模型集成的过程中，模型输入输出数据之间存在着单位、坐标系、空间剖分、数据组织结构等诸多方面的不统一 在第三章将模型数据接口映射到所构建的统一数据视图的基础上，本章主要研究如何通过有效的、可重用的数据重构方法来生成对于模型运行而言合理的数据，由此驱动模型正确执行并支撑模型之间集成运行。 地理模型数据的重构需求 与实现无关的信息内容重构 在这个例子中所涉及的“矢-栅转换”就是一种典型的与实现无关的信息内容层次的数据重构。 与实现相关的数据组织重构 地理模型数据重构方法库 基于统一数据视图的数据重构 对于模型数据的重构，最直接的方式就是通过编写相应的程序代码来实现源数据与目标数据规格之间的匹配；但这种方式导致模型数据适配工作只能在较低水平上重复，无法形成通用方法和工作成果积累。将地理模型数据接口统一映射到UDX的Node-Kernel结构上，能够为整个地理模型重构工作放置到一个统一的数据视图之上，可以屏蔽数据的内外存组织的异构性。在Node-Kernel结构支撑的统一数据视图上，所进行的数据重构工作将会转变为以节点操作为主导的信息内容处理。 数据重构方法的原子操作设计 数据重构方法的统一接口设计 地理模型数据的基本重构方法 传统的数据处理方法都是严格依赖于特定的内存数据模型的，而基于Node-Kernel结构能够将复杂的数据重构统一到以数据节点操作为基础的信息组装上来。通过UDX Schema和UDX Data两者之间的关联，设计了数据节点的原子操作函数，从数据结构层次和数据内容层次实现了构建数据内容框架ConstructFrame函数、连接节点LinkNode函数、单个数值的获取/设置函数和对数组元素的获取/添加函数。通过数据节点的原子操作函数的组合嵌套可以更为便捷的构建不同的数据重构方法，本章进而设计了数据重构方法的统一接口，用以包装不同的数据重构逻辑，对外提供统一的调用接口。通过对数据重构方法统一地描述，设计了数据重构方法资源的组织管理方法，从而支撑构建一个开放共享的数据重构方法库。 面向地理模型运行的数据适配方案 （后面都没看了，等有机会再看吧） 路线 地球系统作为一个复杂的巨系统，其综合性和复杂性特征导致了难以基于单一模型来解释其中的所有现象与过程。因此，地理模型的共享与集成逐渐成为了地理学综合研究的普遍方法。 地理模型的共享与集成在具体的实现与应用时，最终都要面对模型能否正确运行的问题。模型的正确运行与数据有着直接的关系，针对模型运行的数据兼容性处理成为了模型应用过程中繁琐而关键的工作。 以模型使用者正确理解地理模型的数据规格为切入点，通过设计地理模型数据规格的结构化描述方法（表现形式、内容结构和内蕴信息），实现模型的数据需求的无歧义传递。 在此基础上，提出了一套完整的模型数据适配方法，通过模型数据接口的统一映射和数据重构方法库的建立，形成融合数据表达（Node-Kernel结构)、数据接口映射（地理模型数据Node-Kernel结构的映射）与数据重构（地理模型数据重构方法库）的数据适配方案(要素组织、数据规格匹配和数据接入的设计)，从而将模型构建、数据处理和模型集成应用之间解耦。 另外，这种基于Node-Kernel的地理模型应用和集成运行，对于某个特定的地理模型而言似乎增加了数据处理的过程。但在综合地理模拟中，涉及到多个不确定的地理模型之间的集成与运行，通过直接的数据格式转换虽然能够方便于某一个特定模型的运行，但对于整个集成模拟应用又造成了新的不便：首先体现在广泛的自定义格式难以直接进行转换，模型使用者在不了解数据内容的前提下进行的数据转换往往具有尝试性，增加了模型使用的不便；其次，模型相关的数据格式多种多样，同源的信息可以表现为异构的数据组织，孤立的数据转换难以避免重复的代码编写；还有，异构地理模型的集成不仅仅只是对数据格式的简单转换，其中涉及到的大量信息的抽取和重构，特定数据格式支撑下的数据处理成果难以形成积累，也难以重用。 "},"gis/遥感技术解决地理问题.html":{"url":"gis/遥感技术解决地理问题.html","title":"遥感技术解决地理问题","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 土地利用遥感制图 土地利用快速分类 遥感技术在土地利用中的应用 工业革命以来，人类生产方式的改变深刻的影响着全球的发展，工业化、城市化正深刻影响着全球土地利用空间格局并影响到区域和国家生态与环境状况[1]，人类对于土地的改造是前所未有的巨大，这些巨大的改变急需一种能定量的统计和观测手段，由此诞生了一个新兴的领域——遥感。遥感通过对地观测短时间内能获取了大范围的海量数据，通过这些海量数据科学家们建立起了完整的土地利用/覆盖变化遥感监测与数据分析技术路线,以及独特的分类体系和动态区划体系。遥感是一种地理空间技术，它对地球陆地、大气和水生生态系统发出和反射的电磁 (EM) 辐射进行采样，以便在不进行物理接触的情况下检测和监测区域的物理特征。这种数据收集方法通常涉及基于飞机和基于卫星的传感器技术，这些技术分为无源传感器或有源传感器。遥感技术的蓬勃发展支撑起了土地利用研究的半边天。比如：中国科学院组织开展了全国范围以遥感手段为主的土地资源调查，建立了全国1:10万多时相土地利用数据库、针对全球尺度，美国地质调查局为国际地圈与生物圈计划建立 IGBP DISCover 数据集[2] ，美国马里兰大 学开发了全球土地覆盖数据UMD数据集[3] ，欧盟联合研究中心制作了GLC数据集[4] ，美国波士顿大学基于MODIS影像生产了MCD12Q1数据集[5]，欧洲空间局制备了GlobCover数据集[6] 和CCI-LC数据集[7] ，中国清华大学研制了 FROM-GLC 数据集[8] 。遥感使从危险或无法进入的地区收集数据成为可能，这在现代社会中越来越重要。它取代了速度较慢、成本高昂的地面数据收集，为日常应用提供了对极大区域的快速和重复覆盖，从天气预报到自然灾害或气候变化的报告。 遥感也是一种无障碍的方法，允许用户在不干扰目标区域或对象的情况下，在异地收集数据并进行数据处理和GIS分析。遥感领域的知识浩如烟海，本文重点回顾了遥感技术在土地利用遥感制图和土地利用快速分类方面的应用，列举了近期比较经典的实际应用。 土地利用遥感制图 遥感制图是指通过对遥感图像目视判读或利用图像处理系统对各种遥感信息进行增强与几何纠正并加以识别、分类和制图的过程。遥感图像有航空遥感图像和卫星遥感图像，制图方式有计算机制图与常规制图。目前应用最多及着重研究的是利用Landsat的MSS图像制图。由于多波段的卫星图像具有信息量丰富、现势性强，利用它编图周期短等优点，在制图方面得到了广泛的应用。 土地利用遥感制图结果是支撑全球气候变化和区域可持续发展等领域科学研究不可或缺的重要基础数据，而制图精度 方面的评价信息则决定土地利用遥感制图结果的完整性、可靠性、可用性、可控性和可传播性[9]。比如侯西勇在中国海岸带土地利用遥感制图及精度评价一文中描述的：以时间序列的 Landsat 多波段卫星影像为主要数据源，采用目视判读、图斑勾绘与编码以及时序动态更新的技术途径进行多时相中国海岸带土地利用遥感制图，这一技术方案能够获得精度较优的多时相土地利用分类数据产品，在支持中国海 岸带土地利用变化监测和研究方面是行之有效的[9]。在中国湿地初步遥感制图及相关地理特征分析一文中，作者通过1999～2002年累积的597幅Landsat ETM+遥感影像为数据源,采用人工目视解译为主,同时结合全国高程、土壤、土地利用和Google Earth数据,对全国9ha以上的水面、沼泽等湿地进行了初步遥感制图.在此基础上,利用1km分辨率的全国地形高程数据,1:100万土壤数据、植被数据和1:400万的气候区划数据对湿地分布进行了相关地理特征分析[10]。雷海梅、张晓楠等人在2套30 m分辨率土地覆被遥感数据类别精度及空间一致性特征研究中以中国研发的2套30米分辨率全球尺 度土地覆被数据Globeland30和FROM-GLC-Hierarchy数据为研究对象，以国际组织发布的验证数据为参考，从国家、区域及类别尺度进行了比较和评价，探索了空间一致性随地形的变化特征。结果表明： 2套数据的林地、耕地、水体三种类别均具有较高的分类精度，Globeland30的草地具有较高的用户精度和制图精度，林业、农业及水资源领域研究可以选择二者作为基础数据源，草地科学研究可以选择 Globeland30作为基础数据源。2套数据的类别空间不一致性与高程具有典型的正相关，其不一致比例随着高程的增加明显增大，在1500 m以上区域，二者的类别不一致性比例最大，达到了42.91%；二者类 别不一致性区域主要位于2~15度之间，其面积接近占60%，2度以下区域不一致性最低，约占7.09%。 研究表明地形条件是影响大尺度土地覆被制图的重要因素，因此，未来应进一步加强高海拔及景观异质 性区域土地覆被分类算法的研发[11]。 土地覆被数据是自然资源管理、城市规划、气候模拟、环境保护建模等领域的重要信息，对其进行精度评价并揭示其类别混淆特征对于众多科学领域具有重要意义。土地利用多功能具有多层次性和区域性，应针对不同的区域背 景和研究尺度建立相应的分类与评价指标体系。将土地利用功能与土地利用结构相联系,，并将评价尺度延伸至地块这一微观尺度， 拓展和丰富了土地利用多功能研究的范围与内容，为土地利用多功能研究提供新的思路和途径。 土地利用快速分类 现代遥感技术快速发展，推动了遥感技术在水土保持监测中的广 泛应用。土地利用 / 覆盖变化是针对地表各种地物动态变化的反映，对 水土流失动态监测具有重要意义[12]。遥感数据源的丰富也对数据源的快 速应用提出了挑战，目视解译精度虽高，但是效率低下，监督分类方法可以实现快速的土地利用分类，为后续的水土保持动 态监测提供基础数据，但是现有的监督分类方法主要是以传统 的模式识别技术为基础，如最大似然分类器、K －近邻法等， 这些方法的分类精度均建立在趋于无穷大的样本基础上，否则难以取得较为理想的效果[12]。 快速分类对遥感技术的要求更高，对遥感图像的精度和分类的算法有着严格的要求。高分辨率卫星，数据分辨率可达米级或亚米级，它提供的影像精度就很高。国产高分辨率卫星经过十多年的快速发展，已形成庞大的观测体系，主要包括高分一号、高分二号、高分三号（雷达卫星）、高分四号（静止轨道卫星）、高分五号（高光谱卫星）、高分六号、资源系列卫星、环境系列卫星、高景一号、天绘卫星、实践9号等。国外高分辨率卫星起步早，体系更为庞大，观测能力也更强，目前常用的包括Worldview系列、GeoEye系列、Quickbird卫星、Ikonos卫星、Planet系列卫星等。李恒凯针对东江流域地物斑块破碎、湖泊河流众多等因素影响其地物分类精度的问题，以 GF-1 遥感影像为数据源， 采用面向对象的分类方法，结合模糊分类和 CART 决策树分类法获取研究区土地利用分类信息[13]。山区地物类型复杂多样,传统计算机分类难以有效克服“同物异谱”或“同谱异物”等现象,分类后“椒盐现象”严重，陈波以川西南攀枝花市的部分山区为实验区,使用IKONOS高分辨率遥感影像，采用面向对象分类方法，在ERDAS9.2、ENVI4.8和eCognition8.0等软件平台支持下，以多尺度分割后的对象为单元,辅以纹理特征、形状因子、地形因子等特征参与分类过程,实现了对实验区土地利用信息的提取[14]。胡龙飞以提高土地覆盖分类制图的质量为出发点，充分利用多源遥感数据，构建了全面的特征空间,包括空间特征(如纹理、形状等)、时间特征(时间序列特征)和光谱特征;在时间、空间和光谱三个维度较全面的考虑了多源遥感数据优势、建立了丰富的特征信息。并在建立特征空间的过程中,利用现有工具对多光谱数据与合成孔径雷达数据进行了必要的预处理,以减弱遥感数据受到的天气、大气散射和传感器灵敏度等问题的影响[15]。快速、准确获取耕地数量及其分布信息是研究耕地时空格局和生态效应的基础，也是及时制定应对粮食问题对策的迫切需求。近年来，随着卫星遥感技术的迅猛发展，遥感以其宏观性、实时性以及经济性为耕地信息快速获取提供了可能性。随着传感器数量不断增加，遥感影像时间分辨率、空间分辨率及光谱分辨率不断提高，分类算法的不断涌现，基于多源遥感数据，集成智能分类算法识别耕地将成为必然的发展趋势[16]。森林在生态系统服务中起着重要作用，例如提供清洁空气、保护生物栖息地以及减少全球温室气体的排放等。全球森林变化数据集（Global Forest Change，GFC）每年以30 m的高空间分辨率绘制森林覆盖变化图，成为监测森林覆盖时空变化特征的有效工具。王淑静利用谷歌地球引擎（Google Earth Engine，GEE），基于GFC产品，结合线性回归方法和空间自相关理论对西南地区2001~2019年森林变化情况进行研究表明：政策因素在土地利用方式转变过程中发挥着重要作用，林业活动和农业扩张是影响损失现象发生的主要驱动因素，今后制定森林保护和管理战略时应充分考虑多方面因素造成的森林损失现象，研究结果可以为森林监测和保护提供更科学的指导[18]。为有效地监测复杂区域生态环境治理成效，,研究大范围复杂地区土地利用遥感自动、快速提取方法，应构建适于研究区土地利用变化分析的分类系统；其次，采用地理分区综合遥感分类法对青海高原东部农业区进行土地利用遥感分类制图[19]。 土地利用/土地覆被变化是全球变化研究中的一个重要内容，而土地利用/土地覆被分类又是研究土 地覆被变化的重要前提，它既影响着分类结果的表达，也决定着分类数据的应用领域[20]。土地覆盖/土地利用已成为开展土地利用变化预测、自然灾害防治、土地利用管理与规划、环境保护等一系列重要工作的关键而又基本的任务之一。随着遥感技术和地理分析模型的发展，利用遥感数据监测土地覆盖/土地利用的状态和动态变化已成为最快速、最可靠、最有效的方法之一。 [1] 刘纪远, 张增祥, 张树文, 颜长珍, 吴世新, 李仁东, 匡文慧, 史文娇, 黄麟, 宁佳, 董金玮. 中国土地利用变化遥感研究的回顾与展望——基于陈述彭学术思想的引领[J]. 地球信息科学学报, 2020, 22(4): 680-687.DOI:10.12082/dqxxkx.2020.200052 [ 2 ] Loveland T R, Reed B C, Brown J F, et al. Development of a global land cover characteristics database and IGBP DIS Cover from 1 km AVHRR data[J]. International Journal of Remote Sensing, 2000,21(6-7):1303-1330. [ 3] Hansen M C, Reed B. A comparison of the IGBP DISCover and University of Maryland 1 km global land cover products[J]. International Journal of Remote Sensing, 2000,21(6-7):1365-1373. [ 4 ] Bartholomé E, Belward A S. GLC2000: A new approach to global land cover mapping from Earth observation data [J]. International Journal of Remote Sensing, 2005,26(9): 1959-1977. [ 5 ] Friedl M A, McIver D K, Hodges J C F, et al. Global land cover mapping from MODIS: Algorithms and early results [J]. Remote Sensing of Environment, 2002,83:287-302. [ 6 ] 宁佳,张树文,蔡红艳,等. MODIS 和 GLOBCOVER 全球 土地覆盖数据集对比分析——以黑龙江流域为例[J].地 球信息科学学报,2012,14(2):240-249. [ Ning J, Zhang S W, Cai H Y, et al. A comparative analysis of the MODIS land cover data sets and Globcover land cover data sets in Heilongjiang Basin[J]. Journal of Geo- information Science, 2012,14(2):240-249. ] [7] Li W, Ciais P, MacBean N, et al. Major forest changes and land cover transitions based on plant functional typesderived from the ESA CCI Land Cover product[J]. International Journal of Applied Earth Observation and Geoinformation, 2016,47:30-39. [8] 宫鹏,张伟,俞乐,等.全球地表覆盖制图研究新范式[J].遥 感学报,2016,20(5):1002-1016. [ Gong P, Zhang W, Yu L, et al. New research paradigm for global land cover mapping [J]. Journal of Remote Sensing, 2016,20(5):1002-1016. ] [9] 侯西勇, 邸向红, 侯婉, 等. 中国海岸带土地利用遥感制图及精度评价[J]. 2018. [10] 邸向红, 侯西勇, 吴莉. 中国海岸带土地利用遥感分类系统研究[J]. 2014. [11] Lei H, Zhang X, Sun Q, et al. The Category Accuracy and Spatial Consistence Characteristic Analysis for Two 30 m Resolution Land Cover Products in China[J]. 2020. [12] 黄超, 史超, 李书, 等. 高分辨率影像在水土保持土地利用快速分类中的应用[J]. 中国科技信息, 2019, 8. [13] 李恒凯, 吴娇, 王秀丽. 基于 GF-1 影像的东江流域面向对象土地利用分类[J]. 农业工程学报, 2018, 34(10): 245-252. [14] 陈波, 胡玉福, 喻攀, 等. 基于纹理和地形辅助的山区土地利用信息提取研究[J]. 地理与地理信息科学, 2017, 33(1): 1-7. [15] 胡龙飞. 基于多源遥感数据的土地覆盖分类方法研究[D]. 重庆邮电大学, 2019. [16] 熊曦柳, 胡月明, 文宁, 等. 耕地遥感识别研究进展与展望[J]. 农业资源与环境学报, 2020, 37(6): 856-865. [17] 张帅华. 基于 Landsat 影像的郑州市土地利用时空演变及驱动力分析[D]. 东华理工大学, 2017. [18] 王淑静, 赖佩玉, 郝斌飞, 等. 西南地区 2001~ 2019 年森林损失特征遥感监测与时空分析[J]. 遥感技术与应用, 2021, 36(3): 552-563. [19] 曾永年, 靳文凭, 何丽丽, 等. 青海高原东部农业区土地利用遥感分类制图[J]. 农业工程学报, 2012, 28(16): 225-231. [20] 张景华, 封志明, 姜鲁光. 土地利用/土地覆被分类系统研究进展[J]. 资源科学, 2011, 6. "},"gis/最小二乘法.html":{"url":"gis/最小二乘法.html","title":"最小二乘法","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 摘要 1 最小二乘法简介 1.1 最小二乘法的历史背景 1.2 最小二乘法原理 2 最小二乘法在拟合中的应用 2.1 线性拟合 2.2非线性拟合 2.3 拟合模型 3 基于最小二乘法拟合曲线的简单实践 基于最小二乘法拟合曲线 摘要 最小二乘法不应该只是简单的线性参数估计 1 最小二乘法简介 1.1 最小二乘法的历史背景 最小二乘法发展于天文学和大地测量学领域，科学家和数学家尝试为大航海探索时期的海洋航行挑战提供解决方案。准确描述天体的行为是船舰在大海洋上航行的关键，水手不能再依靠陆上目标导航作航行。1801年，意大利天文学家朱塞普·皮亚齐发现了第一颗小行星谷神星。经过40天的追踪观测后，由于谷神星运行至太阳背后，使得皮亚齐失去了谷神星的位置。随后全世界的科学家利用皮亚齐的观测数据开始寻找谷神星，但是根据大多数人计算的结果来寻找谷神星都没有结果。当年24岁的高斯也计算了谷神星的轨道。奥地利天文学家海因里希·奥伯斯根据高斯计算出来的轨道重新发现了谷神星。高斯使用的最小二乘法的方法发表于1809年他的著作《天体运动论》中，而法国科学家勒让德于1806年独立发现“最小二乘法”，但因不为世人所知而没没无闻。两人曾为谁最早创立最小二乘法原理发生争执。1829年，高斯提供了最小二乘法的优化效果强于其他方法的证明，见高斯-马尔可夫定理。 相关回归分析、方差分析和线性模型理论等数理统计学的几大分支都以最小二乘法为理论基础[1]。作为其进一步发展或纠正其不足而采取的对策，不少近现代的数理统计学分支也是在最小二乘法基础上衍生出来的[1]。正如美国统计学家斯蒂格勒 (s．M．Stigler)所说，“最小二乘法之于数理统计学犹如微积分之于数学”[2]。最小二乘法创立的历史过程充满着丰富的科学思想，这些对今 日的数学创造仍有着重要的启示意义。 1.2 最小二乘法原理 最小二乘法（least squares method）是一种数学优化建模方法，它通过最小化误差的平方和来寻求数据的最佳函数匹配，通过最小二乘法可以简便的求得未知数据，并使得所求值和实际数据之间的误差的平方和最小。 假设我们对某一变量$x$或多个变量$x_1,x_2...x_n$构成的相关变量$y$感兴趣，我们用$q$个独立变量或则$p$个系数拟合出如下的函数模型（参数b是为了使所选择的函数模型同观测值y相匹配），一般情况下，观测值多于选择参数： $$ y_m = f(x_1,x_2,...,x_q;b_1,b_2,...,b_p) $$ 然后最重要的是怎么判断不用拟合的质量。高斯和勒让德的给出的解决方案是：假设测量误差的平均值为0，令每一个测量误差对应一个变量并与其它测量误差不相关（随机无关），假设在测量误差中绝对不含系统误差，即它们都是是纯偶然误差(有固定的方差)，误差围绕真值波动。除此之外，测量误差符合正态分布，这保证了偏差值在最后的结果$y$上忽略不计。确定拟合的标准应该被重视，并小心选择，较大误差的测量值应被赋予较小的权[1]。并建立如下规则：被选择的参数，应该使算出的函数曲线与观测值之差的平方和最小。用函数表示为： $$ min\\sum_{i=0}^n(y_m-y_i)^2 $$ 2 最小二乘法在拟合中的应用 最小二乘法是从误差拟合角度对回归模型进行参数估计或 系统辨识，并在参数估计、系统辨识以及预测、预报等众多领域中得到极为广泛的应用[3]。然而大多同学对最小二乘法的认识都比较模糊，仅仅把最小二乘法理解为简单的线性参数估计[2]。在一般情况下，最小二乘法通常用于求解使用一阶泰勒级数展开线性化的一组非线性方程。求解非线性方程是一个使用牛顿法的迭代过程。收敛速度取决于解的初始猜测的质量。非线性最小二乘法通常称为束调整，因为解的初始估计值的所有值都一起修改（在束中调整）。这种技术有时也称为高斯-牛顿法。一般最小二乘法可用于求解一组未知数的一组方程。唯一的要求是方程的数量至少与未知数一样多。如果方程是线性的，最小二乘法将产生未知数的直接解。如果方程不是线性的，则需要对未知数进行初始猜测，结果是 对初始参数的调整。重复此操作直到结果收敛（调整变得非常接近于零）。线性的最小二乘问题发生在统计回归分析中；它有一个封闭形式的解决方案。非线性的问题通常经由迭代细致化来解决；在每次迭代中，系统由线性近似，因此在这两种情况下核心演算是相同的。 2.1 线性拟合 对于线性方程组，最小二乘法将产生未知数的直接解。线性情况在数学上与使用零作为所有参数的初始猜测来执行调整的一般情况相同。收敛只需要一次迭代。 方程必须是以下形式： $$ F_i(x_1, x_2,...,x_n)=a_1x_1+a_2x_2+...+a_nx_n=k_i $$ 因此雅可比矩阵$J$是 变量$y$与$n$个变量$x_1,x_2,...x_n$的内在联系是线性的，即： $$ y=a0+\\sum{i=0}^n(a_ix_i) $$ 设$xi$的第$i$次观测值为$x{ij}$，对应的函数值为$y_i(i=1,2,...,m)$，则函数的偏差平方和为： $$ s=\\sum{i=1}^m(y_i-y_i^1)=\\sum{i=1}^m(y_i-a_0-a_1x)^2 $$ 将实验数据$(x_{ij}, y_j)$代入上式可得$a_0,a_1,a_2,...,a_3$。 2.2非线性拟合 但是实际的科学实验得到的数据$(x_i,y_i)$的因变量$x$与自变量$y$之间可能根本不存在线性关系，此时可以考虑用一个$n$次多项式来拟合$y$与$x$之间的函数关系[4]。对于$n$次多项式来说，我们需要将它化为我们前面已经已经介绍的线性形式。如果方程个数$n$大于未知量个数$m$的方程组成为超定方程组，如果数学模型是最常用的代数多项式，则称为代数多项式拟合[5]。但是更多的曲线拟合均不能通过变量变换转换为线性拟合问题，如： $$ y = a+bln(x/c) $$ $$ y=a+bx^c $$ $$ y=a+b2^x $$ 关于非线性拟合问题 ，可以利用Taylor展开，逐次线性化 ，亦即对拟合参数逐次逼近，以得到问题的解答[6]。然而，非线性问题这样处理的难点，远不是需要大量的反复计算，而是迭代过程发散，也就是说 ，当迭代初值选择得不好时，Taylor展 开完全失真 ，致使迭代值不是逼近真值，而是远离真值 [7]。 通常我们选择的是迭代法： (1) 给定某个初始值$x_0$； (2) 对于第$k$次迭代，寻求一个增量$\\Delta x_k$，使得$||f(x_k+\\Delta x_k)||_2^2$达到最小值； (3) 若$\\Delta x_k$足够小，则停止； (4) 否则，另 $x_(k+1)=x_k+\\Delta x_k$，返回第2步 这让求解导函数为零的问题变成了一个不断寻找下降增量 ∆xk 的问题。以下就是寻找增量的方法。 考虑第k次迭代，想要寻找∆xk，最直接的方法是将目标函数F(x)在xk附近进行泰勒展开： $$ F(x_k+\\Delta x_k) = F(x_k) + J(x_k)^T\\Delta x_k + 1/2\\Delta x_k^TH(x_k)\\Delta x_k $$ 其中$J(x_k)$是关于$F(x)$的一阶导数(梯度、雅可比(Jacobian)矩阵)，$H(x_k)$则是二阶导数(海塞(Hessian)矩阵)。如果上式中只保留一阶项，则称为一阶梯度法或最快下降法，取$\\Delta x=-J(x_k)$，即增量的方向为梯度的反方向，通常还设置一个步长$\\lambda$。如果保留二阶项，则成为二阶梯度法或牛顿法。 一阶梯度法过于贪心，容易走出锯齿路线，反而增加了迭代次数；而二阶梯度法则需要计算目标函数的 H 矩阵，这在问题规模较大时非常困难，我们通常倾向于避免 H 的计算[8] [9]。在最小二乘法的线性拟合的方法中，高斯牛顿法和列文伯格—马夸尔特方法是两种比较经典的方法 2.3 拟合模型 我们知道多项式曲线拟合是一种较常用的数据处理方法,但当数据点较多时,只采用一种多项式曲线函数拟合所有数据点难以取得较好的拟合效果。但是数据拟合方法有很多，例如对数曲线拟合，反函数曲线拟合，二次曲线拟合，三次曲线拟合 ，幂函数曲线拟合 ，指数曲线拟合等。一般先观察散点图来确定曲线 的类型，不过散点图都是相关关系的粗略表示，有时候散点图可能与几种曲线都很接近，这时建立相应的经验函数可能都是合理的，但由于选择不同的曲线 ，得到同一个问题的多不同经验函数，一般我们需要确定怎样从这些经验函数中选择最优的一个[10] 。吴宗敏提出用几种函数进行拟合，计算历史数据点实测值和拟合值的误差平方和最小的为最优经验函数[11]。但是该方法存在一定问题：误差平方和最小，但误差波动较大，即一些点误差很小 ，一些点误差相对较大 。以该问题作为出发点，刘霞提出了一种新的确定经验函数的方法，用几种不同的函数进行拟合 ，从中选取最优的经验函数 ，最优经验函数确定的条件如下[10]：(1) 历史数据点误差为正和误差为负的个数之差小于适应性参数；(2) 计算误差的方差，方差最小的为最优的拟合函数。杨岚通过动态优化方法确定主成分数可提高所建立数学模型的预测效果，与交互验证方法选择主成分数方法相比较，动态优化方法确定的主成分数能够得到更好的预测结果，该方法能有效提高偏最小二乘数学模型的预测效果，是建立具有更好适应性数学模型的有效方法[12]。在最小二乘曲线拟合中,自变量的误差常常被略而不计，丁克良提出采用正交最小二乘法拟合曲线，该方法以正交距离残差平方和极小为准则，同时顾及了因变量和自变量的误差；基于间接平差原理详细推导了相关模型和算法，计算表明采用正交最小二乘法拟合曲线,拟合效果整体上优于普通最小二乘法[13]。 常见的曲线拟合模型有：对数函数、指数函数、幂函数、逻辑回归、多项式、Holt-Winters预测。其中Holt-Winters 预测使用 TIBCO Spotfire Enterprise Runtime for R 来计算对时间序列或可强制为时间序列的任何事物的 Holt-Winters 筛选。这是以指数方式对时间序列的级别、趋势和季节分量进行加权移动平均值筛选。所选的平滑参数用于最小化一步向前预测误差平方和。但是如何能得到一个更好的拟合模型还有待研究。 3 基于最小二乘法拟合曲线的简单实践 1、拟合多项式为：$y = a_0 + a_1x + a_2x^2 + ... + a_kx^k$ 2、求每个点到曲线的距离之和：$Loss = ∑(yi - (a_0 + a_1x + a_2x^2 + ... + a_kx^k))^2$ 3、最优化Loss函数，即求Loss对a0,a1,...ak的偏导数为0 3.1、数学解法——求解线性方程组： 整理最优化的偏导数矩阵为：X：含有xi的系数矩阵，A：含有ai的系数矩阵，Y：含有yi的系数矩阵 求解：XA=Y中的A矩阵 3.2、迭代解法——梯度下降法： 计算每个系数矩阵A[k]的梯度，并迭代更新A[k]的梯度 A[k] = A[k] - (learn_rate * gradient) 简单线性拟合 多项式拟合 实现方法为最小二乘法和求解线性方程组，误差下降为：0.6290094844905918 参考文献 [1] 贾小勇, 徐传胜, 白欣. 最小二乘法的创立及其思想方法[J]. 西北大学学报: 自然科学版, 2006, 36(3): 507-511. [2] LANCASTER H 0．Encyclopediaofstatisticalscience [J]．NewYork：Wiley，1988． [3] 邹乐强. 最小二乘法原理及其简单应用[J]. 科技信息, 2010 (23): 282-283. [4] 陆健. 最小二乘法及其应用[J]. 中国西部科技, 2007 (9): 19-21. [5] 王新和, 程世洲. 曲线拟合的最小二乘法[D]. , 2004. [6] 概率统计计算．科学出版社，2009． [7] 邢书珍, 邢天奇. 非线性最小二乘拟合的计算方法[J]. 中国铁道科学, 1995, 16(3): 64-71. [8] 高翔.视觉SLAM14讲 [9] 皮皮蒋.线性最小二乘和非线性最小二乘. https://www.jianshu.com/p/bf6ec56e26bd [10] 刘霞, 王运锋. 基于最小二乘法的自动分段多项式曲线拟合方法研究[J]. 科学技术与工程, 2014 (3): 55-58. [11] 吴宗敏.散乱数 据拟合的模 型、方法和理论．北京：科学出版社，2007 [12] 杨岚, 冯新泸. 动态优化偏最小二乘模型的建立与应用[J]. 后勤工程学院学报, 2008, 24(2): 75-77. [13] 丁克良, 欧吉坤, 赵春梅. 正交最小二乘曲线拟合法[J]. 测绘科学, 2007, 32(3): 18-19. "},"languages/Go.html":{"url":"languages/Go.html","title":"Go","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 基础 Go [toc] 菜鸟 基础 go 语言特色： 内存管理、数组安全、编译迅速 go 语言被设计成一门应用于搭载 Web 服务器，存储集群或类似用途的巨型中央服务器的系统编程语言 对于高性能分布式系统领域而言， go 语言有着更高的开发效率，它提供了海量并行的支持 go 语言结构： 包声明 引入包 函数 变量 语句&表达式 注释 当标识符（包括常量、变量、类型、函数名、结构字段等等）以一个大写字母开头，那么使用这种形式的标识符的对象就可以被外部包的代码所使用，如果该标识符是以小写字母开头，则对包外是不可见的 fmt.Sprintf 格式化字符串并赋值给新串 声明变量的一般形式是使用 var 关键字 变量没有初始化就会设置为 0 值 fmt.Println 和 fmt.Printf 是不一样的 := 是一个声明变量 intVal := 1 声明一个局部变量必须要使用， 声明的全局变量可以不使用 常量的定义格式 const b = \"abc\" or const b string = \"abc\" 常量可以做枚举： const( Unknown = 0 Fmale = 1 Male = 2 ) 常量可以用 len(), cap(), unsafe.Sizeof() 函数计算表达式 iota，特殊常量，可以认为是一个可以被编译器修改的常量 "},"languages/Java.html":{"url":"languages/Java.html","title":"Java","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 java_temp temp 快速导出接口文档 前言 JapiDocs swagger + knife4j 开源方案 [toc] java_temp temp java 中String直接赋值字符串和new String的区别， == 为false，equals结果为true，如果放在同一个hash中只能放一个 String A = \"abc\" 会在常量池子中找是否已经有了，如果没有它就会重新开辟一片空间，然后所有这么赋值的地址其实都是相同的 String str = new String(\"abc\") 这么赋值的是再次构造一个String对象，从堆中重新new一块内存，再把指针赋给栈，==是判断地址，则明显会不相同的 data method 现在的编辑的bug：打开编辑页面没有把数据读出来，detail框有问题 http 错误 2xx 成功 200 正常；请求已完成。 201 正常；紧接 POST 命令。 202 正常；已接受用于处理，但处理尚未完成。 203 正常；部分信息 — 返回的信息只是一部分。 204 正常；无响应 — 已接收请求，但不存在要回送的信息。 3xx 重定向 301 已移动 — 请求的数据具有新的位置且更改是永久的。 302 已找到 — 请求的数据临时具有不同 URI。 303 请参阅其它 — 可在另一 URI 下找到对请求的响应，且应使用 GET 方法检索此响应。 304 未修改 — 未按预期修改文档。 305 使用代理 — 必须通过位置字段中提供的代理来访问请求的资源。 306 未使用 — 不再使用；保留此代码以便将来使用。 4xx 客户机中出现的错误 400 错误请求 — 请求中有语法问题，或不能满足请求。 401 未授权 — 未授权客户机访问数据。 402 需要付款 — 表示计费系统已有效。 403 禁止 — 即使有授权也不需要访问。 404 找不到 — 服务器找不到给定的资源；文档不存在。 407 代理认证请求 — 客户机首先必须使用代理认证自身。 415 介质类型不受支持 — 服务器拒绝服务请求，因为不支持请求实体的格式。 5xx 服务器中出现的错误 500 内部错误 — 因为意外情况，服务器不能完成请求。 501 未执行 — 服务器不支持请求的工具。 502 错误网关 — 服务器接收到来自上游服务器的无效响应。 503 无法获得服务 — 由于临时过载或维护，服务器无法处理请求。 Tomcat 简单概念网址：Tomcat Tomcat 简单的说是一个运行 Java 的网络服务器，底层是 Socket 的一个程序，它也是 JSP 和 Serlvet 的一个容器 axios axios 是一个基于 promise 的 HTTP库，简单的讲就是可以发送get、post请求，因为Vue等框架，不需要操作Dom了，所以不需要引入Jquery.js 了？所以一些轻量级库的就跟着出现了 mongo导出与备份 mongo4.4 版本之后，mongodb数据库工具与现在的mongodb服务分开发布，需要单独安装 快速导出接口文档 怎么用Java快速生成接口文档 方案： 使用 japidocs swagger + knife4j 开源接口文档生成工具 前言 常常在项目收尾阶段，客户需要项目的接口文档，或则是一个大的sass平台，各个产品之间互相调用的时候，需要对方提供接口文档。通常来说，接口文档属于产品的技术沉淀，是一个长期积累的过程，然后开发阶段并不会想这么多，结果到了需要接口文档的时候总是疲于应付，情急之下，往往采用最笨拙的方法，就是对照着项目代码一个一个拷贝 该文提供了几种方法的策略 JapiDocs 这是一种最简单也最高效的快速生成接口文档的方式，也是对既有项目改造代价最小的方式 可用于生成spring boot api文档 读取JAVA DOC注释，无需额外的代码改造 使用步骤原文已经很清楚了 添加依赖 添加一个类，并写一些代码，运行 swagger + knife4j swagger 很出名的一个插件，用以快速进行接口调试，但是单纯使用swagger的效果并不理想（如导出文档这一块），这时候都会配合 knife4j 使用 步骤： 导入依赖 添加 swagger 配置类 访问接口页面 开源方案 japi ApiPost 工具 "},"languages/JavaScript.html":{"url":"languages/JavaScript.html","title":"JavaScript","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 A re-introduction to JavaScript Numbers String Variables Operators Control structures Objects Array Functions Anonymous functions Recursive functions Custom objects Closures 课外 JS_轮询 Promise 简介：回调 什么是回调 回调中回调 处理Error 厄运金字塔 Promise 消费者：then，catch，finally Promise 链 返回Promise 更复杂的示例：fetch 使用 promise 进行错误处理 再次抛出（rethrowing） 未处理的 rejection Fetch 错误处理示例 Promise API Promise.all Promise.allSettled Promise.race Promise.resolve、Promise.reject Promisification await 处理 promise 返回 reject 报错的问题 ES5的异常捕获 ES6 promise 方式的错误捕获 ES6 通过 async， await优化promise时的异常捕获 解决async/await 的promise 返回错误 reject 的问题及错误捕获 正则表达式 为什么要学习字符串 处理 教程 模式（Paterns）和修饰符（flags） 字符类 Unicode：修饰符 'u' 和 class \\n{...} 锚点（anchors）： 字符串开始^和末尾$ 多行模式Flag \"m\" 词边界 \\b 转义，特殊字符 集合和范围 [...] 量词 +, *, ?, {n} 贪婪量词和惰性量词 捕获组 模式中的反向引用： \\N 和 \\k 选择 | 前瞻断言与后瞻断言 灾难性回溯 搭建一个图床 简介 AWS S3 防盗链 前端常用功能集合 http请求 基础知识 AJAX Fetch API JSDoc RESTful 理解 RESTful 架构 起源 资源（Resources) 表现层（Representation） 状态转化（State Transfer） 综述 深入理解浏览器 精读 分层结构 从渲染分层看性能优化 隐式合成层、层爆炸、层自动合并 深入理解浏览器一 CPU、GPU、操作系统、应用的关系 进程与线程 浏览器架构 Chrome 多进程架构的优势 浏览器的主从架构 深入理解浏览器二 概述 普通的跳转 跳转到别的网站 Service Worker 深入理解现代浏览器三 概述 解析阶段 样式计算 布局 绘图 合成 JavaScript_temp [toc] 如果在数学表达式中有一个NaN，那么它会一直传播下去 脚本永远不会因为一个致命错误就停止，大不了一个NaN alert prompt confirm 显示的转为字符串 String(value) 隐式的转为字符串 alert(value) 对undefined进行数字转换时候，结果为NaN，而不是0 比较的时候注意是否发生了类型转换 除了严格相等 === 外，其他但凡是有 undefined/null 参与的比较，我们都需要格外小心。 除非你非常清楚自己在做什么，否则永远不要使用 >= > 去比较一个可能为 null/undefined 的变量。对于取值可能是 null/undefined 的变量，请按需要分别检查它的取值情况。 '2' > '12' true js 的 || 能够返回第一个真值或者最后一个假值 两个非运算 !! 有时候用来将某个值转化为布尔类型 labelName 空值的 return 或没有 return 的函数返回值为 undefined 一个函数应该简短且只有一个功能 在其他编程语言中，只要提到函数的名称都会导致函数的调用执行，但 JavaScript 可不是这样。 回调其实就是传递了一个函数变量？ 一个函数是表示一个“行为”的值 一个函数代表一个行为，我们可以在变量之间传递它 函数声明是在js准备脚本阶段创建的，所以可以在任何位置使用它 箭头函数对于简单行为来说很方便 自动分号插入，有些时候它并不自动插入，代码块之后不需要分号 自描述型代码 $event 计算属性 方括号[] 属性名简写 对象能够访问任何属性，即使该属性不存在也不会报错 一般用in 来判断一个属性是否存在一个对象中，而不是undefined 赋值了对象的变量存储的不是对象本身，而是该对象'在内存中的地址'，换句话说就是对该对象的引用 仅当两个对象为同一对象的时候，它们才叫相等 Object.assign(dest, [src1, src2, src3...]) 深层克隆指的是对象里面的对象也拷贝过去 垃圾回收机制，可达性 对象属性的函数称为方法 在js中，this关键字和其它多数编程语言不同，js中的this可以用于任何函数，即使他不是对象的方法，this的值是在代码运行时计算出来的 this的并不取决于方法声明的位置，而是取决于点符号前的是什么对象（this的重要性就是c里面的指针 箭头函数没有自己的this，它取决于外部的正常函数 this通过函数调用才有意义 理解 this： this 永远指向一个对象 this的指向完全取决于函数调用的位置 js 中一切都是对象，运行环境也是一个对象，所以函数实在某个对象下运行，而this就是函数运行时的所在的对象（环境），但是js支持环境的动态切换，简单的说就是 this 的指向是动态的，很难事先确定到底指向哪里 事件绑定：行内绑定，动态绑定，事件监听 构造函数以大写字母开头，只能有'new' 操作符来执行 当一个函数使用new操作符执行时，它按照步骤为：一个新的对象被创建并分配给this；函数体执行，通常它会修改this，为其添加新的属性；返回this的值。隐式创建，隐式返回 可选链 ？. 使用在一些属性可以不存在的地方 symbol 类型 symbol不会被自动转为字符串 对象的属性键只能是字符串类型或则symbol类型，symbol类型可以防止被重写 symbol属性不参与for...in循环 除null 和 undefined 以外的原始类型都提供了许多有用的方法，从形式来说这些方法通过临时对象工作 Math.floor Math.ceil Math.round 编写一个随机整数的函数，容易边缘值的概率会低两倍 js中字符串不可更改 str.indexOf() 更现代的方法是 str.includes(substr, pos) str.startsWith(str) str.endsWith(str) str.slice(start [,end]) str.substr(start, [, length]) 对象能够存储键值集合，但是有些时候我们需要存储有序集合，这时候就到了数组了 数组可以存储任何类型的元素 pop push shift unshift 从本质上来说，数组仍然是一个对象 将数组视为有序数据的特殊结构 for... in 循环会遍历所有数组所有属性，不仅仅是这些数字属性 类数组对象 不应该用 for ... in 处理数组 我们修改数组的时候，length 属性会自动更新 数组通常都是使用方括号 数组有自己的 toString 实现，返回已逗号隔开的元素列表 不要使用 == 比较数组 仅当两个对象引用的是同一个对象的时候，它们才相等，如果==左右两个参数中有一个参数是对象，另一个参数是原始类型，那么该对象就会转换为原始类型 === 不会进行类型转换 如果我们使用 == 比较数组，除非它们两个引用了统一数组的变量，否则它们永远不相等，要用迭代的方法逐项的比较它们 遍历数组的元素： for( let i=0; i for ( let item of arr) 现代语法，只能访问items for (let i in arr) 永远不要用这个 传入call 和 apply 的第一个参数都会被看作函数上下文，不同之处在于后续的参数 箭头函数的this与声明所在的上下文相同 调用箭头函数时，不会隐式的传入this参数，而是从定义时的函数继承上下文 所有函数都可以访问bind方法， 可以创建并返回一个新函数，并绑定到传入的对象上，调用bind不会修改原函数，而是创建了一个全新的函数 this 表示函数上下文， 即与函数调用相关联的对象，函数的定义方式和调用方式决定了this的取值 函数的调用方式有四种： 作为函数调用 skulk() 作为方法调用 ele.skulk() 作为构造函数调用 new Skulk() 通过apply 和 call方法调用 skulk.apply(ele) skulk.call(ele) 函数调用方式影响this的取值： 如果作为函数调用，非严格模式下指向window对象， 严格模式下指向undefined 作为方法调用，this通常指向调用的对象 作为构造函数调用，this指向新创建的值 通过call 或 apply 调用，this 指向 call 或 apply 的第一个参数 箭头函数和bind某些时候都是绑定的感觉 闭包允许函数访问并操作函数外部的变量，只要函数或变量存在于声明函数时的作用域内，闭包即可使函数能够访问这些变量和函数 function getMaxSubSum(arr) { let maxSum = 0; let partialSum = 0; for (let item of arr) { partialSum += item maxSum = Math.max(maxSum, partialSum) if(partialSum arr.splice 方法可以说是处理数组的瑞士军刀 arr.slice 复制一部分值 arr.concat 连接多个数组 arr.forEach 方法允许为数组的每一个元素都运行一个函数 arr.indexOf、arr.lastIndexOf 和 arr.includes 方法与字符串操作具有相同的语法，并且作用基本上也与字符串的方法相同 如果是一个对象数组，可以用 arr.find() 方法找到具有特定条件的对象 同理有 arr.findIndex 和 arr.filter arr.map 方法对数组中的每个元素都调用函数，并返回结果数组，该方法和forEach 很像，但是forEach 并不返回结果数组，这两个应该是最常用的方法了 arr.sort() 方法对数组进行 原位(in-place) 排序，更改元素的顺序，但是默认情况下是按字符串进行排序了，所以一般要使用我们自己的函数进行排序 对于字符串比较算法，最好是使用 str.localeCompare 方法正确的对字母进行排序 arr.split 与 arr.join 恰好相反 arr.reduce 根据数组计算单个值 Array.isArray thisArg 也可以采用箭头函数 sort，reverse 和 splice 方法修改的是数组本身。 let prices = { banana: 1, orange: 2, meat: 4, }; let doublePrices = Object.fromEntries( // 转换为数组，之后使用 map 方法，然后通过 fromEntries 再转回到对象 Object.entries(prices).map(([key, value]) => [key, value * 2]) ); 可以通过这种方式建立强大的转换链, Object.keys, values, entries function count(obj) { return Object.keys(obj).length; } JS中最常用的两种数据结构是Object 和 Array， 对象能让我们创建键来存储数据项的单个实体， 数组则让我们能够将数据收集到一个有序的集合中，但是，当我们把它们传递给函数时， 函数可能只需要单个块 let [firstName, surname] = \"Ilya Kantor\".split(' '); 解构并不意味着破坏 let user = { name: \"John\", age: 30 }; // 循环遍历键—值对 for (let [key, value] of Object.entries(user)) { alert(`${key}:${value}`); // name:John, then age:30 } 内建对象： 日期（Date），该对象提供了日期/时间的管理方法 JS 提供了如下方法 JSON.stringify 将对象转换为JSON, JSON.parse 将 JSON 转换回对象 一些特定于 JS 的对象属性会被JSON.stringify 跳过，即：函数属性、 Symbol类型的属性、存储undefined的属性 JSON.stringify(user, null, 2) // 首行缩进 2 个字符 let str = '{\"title\":\"Conference\",\"date\":\"2017-11-30T12:00:00.000Z\"}'; let meetup = JSON.parse(str, function(key, value) { if (key == 'date') return new Date(value); return value; }); alert( meetup.date.getDate() ); // 现在正常运行了！ 函数进阶内容 所有函数的处理都是这样的： 当前上下文被记录在堆栈的顶部 为子调用创建一个新的上下文 当子调用结束后，前一个的上下文从堆栈中弹出，并继续执行 递归使用的时候要考虑堆栈的深度 Rest 参数必须放到参数列表的末尾 arguments是一个类数组 箭头函数是没有arguments的 spread语法可以传递多个可迭代对象，可以用来合并数组，和Array.from() 很像，但是后者还可以用来操作类数组 在 JS 中，每个运行的函数，代码块以及整个脚本都有一个成为词法环境(Lexical Environment) 的内部隐藏的关联对象 词法环境由两部分组成： 环境记录(Environment Record)：一个存储所有局部变量作为其属性的对象 对外部词法环境的引用，与外部代码相关联 变量是特殊内部对象的属性，与当前正在执行的块/函数/脚本有关，操作变量实际上是操作该对象的属性 当代码要访问一个变量是，首先回搜索内部词法环境，然后搜索外部环境，然后搜索更外部的环境，直到全局词法环境 在JS中，所有函数都是天生闭包的，闭包就是指内部函数总是可以访问所在的外部函数中声明的变量和参数 词法环境仅在可达时才会保留在内存中 debugger 理论上当函数可达时，它外部变量也都将存在，但在时间中，JS引擎会试图优化它，如果从代码中可以明显看出所有未使用的外部变量，那么就会将它删除，此类变量在调试中将不可用 从程序进入代码块的那一刻开始，变量就开始进入“未初始化”状态，它一直保持未初始化状态，直至程序执行到相应的let语句 var 没有块级作用域，用var声明的变量，不是函数作用域就是全局作用域，var 的变量可以重新声明，可以在声明前被使用，声明会提升，但是赋值不会 (function{...})，立即调用函数声明，但是如今没有理由这么来编写代码 全局对象，浏览器中是 'window' ， 对 Node.js 而言，它的名字是 'global' ，最近 globalThis 被作为全局对象的标准名称加入了JS 全局对象的所有属性都可以直接访问 在浏览器中，使用var 声明的全局函数和变量会变成全局对象的属性 把函数想成一个可被调用的行为对象，我们不仅可以调用它们，还能把它当作对象来处理，函数对象包含一些便于使用的属性 name length 函数也可以添加属性，然后用于闭包 给函数表达式添加名字，可以在局部词法环境中添加一个函数，这样可以以防外面的被更改掉，当我们需要一个可靠的内部名时，就可以吧函数声明写成函数表达式 函数名后面跟着多个括号，为了函数能够正常工作，需要是函数的结果也是一个函数 function makeCounter() { let count = 0; function counter() { return count++; } counter.set = value => count = value; counter.decrease = () => count--; return counter; } function sum(a) { let currentSum = a; function f(b) { currentSum += b; return f; } f.toString = function() { return currentSum; }; return f; } js的函数变量是真的好用啊 \"new Function\" 很少被使用，但是有些时候只能选择它，它允许我们将任意字符串变为函数，这样我们就可以从服务器接受一个新的函数并执行它，只有这种从服务器动态的创建函数的情况可能才会使用到这个语法 通常，闭包是指使用一个特殊的属性 [[Environment]] 来记录函数自身创建时的环境的函数，它具体指向了函数创建时的词法环境 setTimeout 允许我们将函数推迟到一段时间间隔之后再执行 setInterval 允许我们重复运行一个函数，从一段时间间隔之后开始运行，之后以一个时间间隔重复运行 clearTimeout clearInterval let delay = 5000 let timerId = setTimeout(function request(){ ... if(request failen due to server overload){ delay *= 2 } timerId = setTimeout(request, delay); // 感觉这就是递归了 }, delay) 嵌套的setTimeout 能够精确的设置两次执行之间的延时， 而 setInterval 却不能 function slow(x) { // 这里可能会有重负载的 CPU 密集型工作 alert(`Called with ${x}`); return x; } function cachingDecorator(func) { let cache = new Map(); return function(x) { if (cache.has(x)) { // 如果缓存中有对应的结果 return cache.get(x); // 从缓存中读取结果 } let result = func(x); // 否则就调用 func cache.set(x, result); // 然后将结果缓存（记住）下来 return result; }; } 一旦方法被传递到与对象分开的某个地方，this就丢失 setTimeout 方法的函数调用设定了 this = window 这个需求很典型：我们想将一个对象方法传递到别的地方，然后再该位置调用它，如何确保在正确的上下文中调用它 setTimeout(user.sayHi, 1000); // Hello, undefined! setTimeout(() => user.sayHi(), 1000); // Hello, John! 最简单的解决方案是使用一个包装函数，看起来不错，如果在setTimeout触发前一秒user的值有改变的话就错误了 第二种解决方案是内建方法 bind, 它可以绑定this let boundFunc = func.bind(context) func.bind(context) 的结果是一个特殊的类似于函数的\"外来对象\"，它可以像函数一样被调用，并且透明地将调用传递给func并将this=context 如果一个函数有多个方法，可以使用bindAll 我们不仅可以绑定this，还可以绑定参数（arguments），但是很少这么做 一个函数不能重绑定 bind之后，函数会丢失原来的函数属性 bind 和 包装都可以解决一样的问题，但是包装可能在一些复杂的场景下失效 function askPassword(ok, fail) { let password = prompt(\"Password?\", ''); if (password == \"rockstar\") ok(); else fail(); } let user = { name: 'John', login(result) { alert( this.name + (result ? ' logged in' : ' failed to log in') ); } }; askPassword(()=>user.login(true), ()=>user.login(false)) askPassword(user.login.bind(user, true), user.login.bind(user, false)) 箭头函数不仅是简洁代码，它还具有一些特性 JS 的精髓在于创建一个函数并将其传递到某个地方，在这样的函数中，我们通常不想离开当前上下文，这就是i箭头函数的主战场 .bind(this) 会创建一个该函数的\"绑定版本\"，箭头函数没有创建任何绑定，箭头函数只是没有this，this的查找与常规变量的搜索方式完全相同：在外部词法环境中查找 对象可以存储属性，但是目前的属性对我来说只是简单的\"键值对\"，但是实际上属性是更灵活和强大的东西 对象属性除了value，还有三个特殊的特性：writable、 enumerable、 configurable getOwnPropertyDescriptor defindeProperty defineProperties 除了数据属性，还有访问器属性，它们本质上是用于获取和设置值的函数 let user = { name: \"John\", surname: \"Smith\", get fullName() { return `${this.name} ${this.surname}`; } }; alert(user.fullName); // John Smith 从外表看，访问器属性看起来就是普通属性，这就是访问器属性的设计思想 let user = { name: \"John\", surname: \"Smith\", get fullName() { return `${this.name} ${this.surname}`; }, set fullName(value) { [this.name, this.surname] = value.split(\" \"); } }; // set fullName 将以给定值执行 user.fullName = \"Alice Cooper\"; alert(user.name); // Alice alert(user.surname); // Cooper 现在我们有了一个虚拟属性，而且他是可读可写的 访问器属性没有 value 和 writable， 但是有 get 和 set 函数 Getter/Setter 可以用作”真实“属性值的包装其，以便进行更多的控制，如我们可以设置命名的时候判断name是不是太短 function User(name, birthday) { this.name = name; this.birthday = birthday; // 年龄是根据当前日期和生日计算得出的 Object.defineProperty(this, \"age\", { get() { let todayYear = new Date().getFullYear(); return todayYear - this.birthday.getFullYear(); } }); } let john = new User(\"John\", new Date(1992, 6, 1)); alert( john.birthday ); // birthday 是可访问的 alert( john.age ); // ……age 也是可访问的 在编程中我们经常会像获取并扩展一些东西，原型继承(Prototypal inheritance) 这个语言特性能够帮助我们实现这一个需求 在 JS中，对象有一个特殊的隐藏属性 [[Prototype]] ，它要么为 null，要么就是对另一个对象的引用，该对象被称为原型 当我们从 object中读取一个缺失的属性时，JS会自动从原型中获取该属性，在编程中，这种行为被称为原型继承 rabbit.__proto__ = animal 这种感觉和闭包有点像啊，都是继承的关系 原型继承有两个限制 引用不能形成闭环 __proto__的值可以是对象，也可以是 null ，而其它类型会被忽略 __proto__ 是 [[Prototype]]不一样 写入不适用原型，原型仅用于读取属性，访问器属性是一个例外，因为分配操作是由setter函数处理的，因此，写入此类属性实际上与调用函数相同 无论在哪里找到方法，在一个对象还是在原型中，在一个方法调用中，this始终是 . 前面的对象 for ... in 循环也会迭代继承的属性 属性查找和执行是两回事，先从原型中找到属性，然后给当前的this 执行 所有描述特定对象状态的属性，都应该被写入改对象中，这样可以避免一些问题 Obejct.create(proto, [descriptors]) Object.getPrototypeOf(obj) Object.setPrototypeOf(obj, proto) 类的方法之间没有逗号，在JavaScript中，类也是一种函数，准确的说是构造方法 有些人说class是一种语法糖，但是仍有一些区别，首先通过从class创建的函数具有特殊的内部属性标记，类的方法不能枚举，类定义将“prototype”中的所有方法的enumerable标志设置为false，类里面总是使用 use strict 静态方法不是某个特定的方法，而是整个class的方法，可用于搜索/保存/删除，静态属性同理 静态属性和方法是可被继承的 在面向对象中，属性和方法分为两组： 内部接口：可以通过该类的其它方法访问，但不能从外部访问的方法和属性 外部接口：可以从类的外部访问的属性和方法 受保护的属性通常以下划线_作为前缀 内建的方法也是返回的扩展内建类 类检查 instanceof 操作符用于检查一个对象是否属于某个特定的class 要使 try ... catch 能工作，代码必须是可执行的 try ... catch 同步工作，如setTimeout 如果我们不需要 error 的详细信息， catch 可以忽略它 throw 操作符会生成一个 error 对象 try ... catch ... finally function loadScript(src, callback){ let script = document.createElement('script') script.src = src script.onload = () => callback(script) document.head.append(script) } loadScript('/my/test.js', function(){newFunction()}) 这被称为”基于回调“的异步编程风格，异步执行某项功能的函数应该提供一个callback 参数用于在相应事件完成是调用 let promise = new Promise(function(resolve, reject){ // executer }) promise 我感觉和 setTimeOut 的区别就是区分的了成功和失败，成功了就 resolve， 失败了就 reject let promise = new Promise(function(resolve, reject) { setTimeout(() => reject(new Error(\"Whoops!\")), 1000); }); // reject 运行 .then 中的第二个函数 promise.then( result => alert(result), // 不运行 error => alert(error) // 1 秒后显示 \"Error: Whoops!\" ); promise.then(alert); // 只对成功感兴趣 promise.catch(alert); // 只对失败感兴趣 promise 基于回调的模式的一些好处： promise 允许我们按照自然顺序进行编码，首先允许函数然后利用 .then 来处理结果，我们可以根据需要多次 .then ，称之为 Promise链 第二个对resolve的调用会被忽略，只有第一次对 reject/resolve 的调用才会被处理 cnew Promise(function(resolve, reject) { setTimeout(() => resolve(1), 1000); // (*) }).then(function(result) { // (**) alert(result); // 1 return result * 2; }).then(function(result) { // (***) alert(result); // 2 return result * 2; }).then(function(result) { alert(result); // 4 return result * 2; }); 从技术上我们可以将多个 .then 添加到一个promise上，但这并不是promise链 在前端编程中， promise通常被用于网络请求，也可使用 fetch 方法从远程服务器加载用户信息 Fetch JS 可以将网络请求发送到服务器，并在需要时加载新信息，对于来自 JS 的网络请求，有一个总称术语 AJAX（Asynchronous JavaScript and XML），但是我们一般不必使用XML，这个是一起的了 let promise = fetch(url, [options]) url 要访问的url options 可选参数：method，header 如果没有options，那就是一个简单的 get 请求，下载url 的内容，浏览器立即启动请求，并返回一个该调用代码用来获取结果的promise 获取响应通常需要经历两个阶段： 第一阶段，当服务器发送了响应头（response header），fetch 返回的 promise 就使用内建的 Response class 对象来对响应头进行解析 这个阶段，我们通过检查响应头来检查HTTP状态以确定请求是否成功，如果没有响应体（response body），那么promise就会reject，异常的HTTP状态，不会出现error，我们可以从response中看到http状态： status、ok let res = await fetch(url) if(res.ok){} 第二阶段，为了获取response body，我们需要使用一个其它方法调用 response提供了很多基于promise的方法，以不同的格式来访问body：response.text(), response.json(), response.formData(), response.blob(), 我们只能选择一种读取body的方法，因为第二次的是已经被处理过的 response header 位于 response.headers 中的一个类似于 Map 的header 对象 let user = { name: 'John', surname: 'Smith' } let res = await fetch('/article/fetch',{ method: 'POST', headers: { 'Content-Type': 'application/json;charset=utf-8' }, body: JSON.stringify(user) }) let result = await res.json() alert(res.message) 同样我们可以使用 Blob 或 BufferSource 对象通过 fetch 提交二进制数据，如图片 canvasElem.onmousemove = function(e){ let ctx = canvasElem.getContext('2d') ctx.lineTo(e.lientX, e.e.clientY) ctx.stroke() } async function submit(){ let blob = await new Promise(resolve=>canvasElem.toBlob(resolve, 'image/png')) let res = await fetch('/article/fetch/post/image',{ method:'POST', body: blog }) let result = await res.json() alert(result.message) } 典型的fetch 请求由两个 await 组成 let res = await fetch(url, [options]) let result = await res.json() // 或者是 fetch(url, options) .then(res => res.json()) .then(result => /* ... */) 下面这段代码有意思，promise和fetch一起联合写的： // 发送一个对 user.json 的请求 fetch('/article/promise-chaining/user.json') // 将其加载为 JSON .then(response => response.json()) // 发送一个到 GitHub 的请求 .then(user => fetch(`https://api.github.com/users/${user.name}`)) // 将响应加载为 JSON .then(response => response.json()) // 显示头像图片（githubUser.avatar_url）3 秒（也可以加上动画效果） .then(githubUser => { let img = document.createElement('img'); img.src = githubUser.avatar_url; img.className = \"promise-avatar-example\"; document.body.append(img); setTimeout(() => img.remove(), 3000); // (*) }); 这段代码可以工作，但是有个为题， * 行头像显示结束后如果我们还想显示一个编辑的表单是做不到的，为了使得链可以扩展，我们需要显示一个在头像结束时进行 resolve 的 promise 作为一个好的做法，异步行为应该始终返回一个promise promise 的 executor 周围存在隐式的 try...catch 自动获取了 error， 并将其变为 rejected promise promise.all 并行执行多个 promise let names = ['iliakan', 'remy', 'jeresig']; let requests = names.map(name => fetch(`https://api.github.com/users/${name}`)); Promise.all(requests) .then(responses => { // 所有响应都被成功 resolved for(let response of responses) { alert(`${response.url}: ${response.status}`); // 对应每个 url 都显示 200 } return responses; }) // 将响应数组映射（map）到 response.json() 数组中以读取它们的内容 .then(responses => Promise.all(responses.map(r => r.json()))) // 所有 JSON 结果都被解析：\"users\" 是它们的数组 .then(users => users.forEach(user => alert(user.name))); Async/await 是以更舒适的方式使用promise的一种特殊语法，同时它非常易于理解和使用 async 这个单词表达了一个简单的事情，即这个函数总是返回一个promise， 其它值将自动被包装在一个resolved的promise中 await 只在async 中工作，关键字await 让JS引擎等待直到 promise 完成（settle）并返回结果，await 实际上会暂停函数的执行，知道promise的状态变为settled，然后以promise的结果继续执行，这个行为不会耗费任何CPU资源，因为 JS引擎可以同时处理其它脚本 await 不能在顶层代码中运行，但我们可以将其包裹在一个匿名 async 函数中 (async()=>{ let res = await fetch(/*...*/) })() async/await 可以和 promise.all 一起使用 常规函数只会返回单一值或者直接不返回任何值，但generator 可以按需一个接一个的返回（“yeild”）多个值，他们可以与iterable完美配合使用，从而可以轻松的创建数据流 要创建一个generator，我们需要一个特殊的语法结构：function* 异步迭代允许我们对按需通过异步请求而得到的数据进行迭代，例如，我们通过网络分段（chunk-by-chunk）下载数据的时候，异步生成器（generator）是这一步骤更加方便 随着我们的应用越来越大，我们想要将其拆分成多个文件，即所谓的模板（module），一个模板可以用户包含用于特定目的的类和函数库 模块可以相互加载，并可以使用特殊的指令export和import来交换功能，从一个模块调用一个模块的函数 import 指令通过相当于当前文件的路径加载模块，并将导入的函数分配给相应的变量 模块始终默认使用 use strict 每个模块都有自己的顶级作用域，一个模块中的顶级作用域变量和函数在其它脚本中是不可见的 如果我们真的需要创建一个 window-level 的全局变量，我们可以明确的赋值给 window 如果同一个模块被导入到多个其它位置，那么它的代码仅会在第一次导入的时候执行， 在一个模块中，this 是 undefined 模块脚本总是延迟的，模块脚本回等到HTML文档完全准备就绪，然后才会运行，保持脚本的相对顺序，在文档中排在前面的脚本先执行 如果内联脚本具有 async 特种，它就不会等待任何东西 标签 --> import {counter} from './analytics.js'; counter.count(); import 必须给出相对或绝对的 url 路径，没有任何路径的模块被成为裸模块，在import中是不允许这种模块的 在实际开发中，浏览器模块很少被以”原始“形式进行使用，通常我们会使用一些特殊工具，如Webpack将它们打包在一起，然后部署到生产环境的服务器中，使用打包工具的一个好处是它们可以更好的控制模块的解析方式，允许我们使用裸模块和更多功能，例如css/html 模块等 构建工具做以下这些事： 从一个打算放在 HTML 中的 ` ”主“模块开始 分析它的依赖，它的导入，它的导入的导入等 使用所有模块构建一个文件或者多个文件，并用打包函数（bundler function）替代原生的import调用，以使其正常工作，还支持像 html/css 模块等特殊的模块类型 在处理过程中进行一些优化 我们可以通过在声明之前防止export来标记任意声明为导出，在类或者函数前的export不会让它们变成函数表达式，尽管被导出了，但它仍然是一个函数声明，不建议在函数和类声明后使用分号 通通导入一般不可取，如果明确列出我们需要的导入的内容，优化器（optimizer）就会检测到它，从而是构建更小，这就是所谓的”摇树（tree-shaking）“ import as 可以让导入具有不同的名字 eval 执行代码字符串，代码字符串可能会比较长，eval的结果是最后一条语句的结果 A re-introduction to JavaScript A re-introduction to JavaScript Numbers console.log(3/2) // 1.5, not 1​ an apparent integer is fact implicitly a float parseInt parseInt('123', 10); // 123 parseInt('010', 10); // 10 parseInt('11', 2); // 3 parseInt('0x10'); // 16 parseFloat() always uses base 10. You can also use the unary + operator to convert values to numbers: + '42'; // 42 + '010'; // 10 + '0x10'; // 16 A special value called NaN(not a number) is returned if the string is non-numeric: parseInt('hello') NaN is toxic: if you provide it as an operand to any mathematical operation, the result will also be NaN +'10.2abc' // NaN parseFloat('10.2abc') // 10.2 String Strings are sequences of Unicode characters. 'hello'.charAt(0); // \"h\" 'hello, world'.replace('world', 'mars'); // \"hello, mars\" 'hello'.toUpperCase(); // \"HELLO\" null: only accessible through the null keyword. undefined: a value hasn't even been assigned yet. undefined is actually a constant You can perform this conversion explicitly using the Boolean() function: Boolean(''); // false Boolean(234); // true false, 0, empty strings (\"\"), NaN, null, and undefined all become false. All other values become true. Variables let, const or var let allows you to declare block-level variables, the declared variable is available from the block it is enclosed in. // myLetVariable is *not* visible out here for (let myLetVariable = 0; myLetVariable const allows you to declare variables whose values are never intended to change. The variable is available from the blcok. var does not have the restrictions, a variable declared with the var keyword is available from the function it is declared in. // myVarVariable *is* visible out here for (var myVarVariable = 0; myVarVariable An important difference between JavaScript and other languages like Java is that in JavaScript, blocks do not have scope, only functions have a scope. Operators The + operator also does string concatenation: 'hello' + 'world' Adding an empty string to something is a useful way of converting it to a string itself: ' ' + 5 ==: the double-equals operator performs type coercion if you tive it different types. 123 == '123'; // true 1 == true; // true to avoid type coercion, user the triple-equals operator: === Control structures The && and || operators use short-circuit logic, which means whether they will execute their second operand is dependent on the first. Objects JavaScript objects can be thought of as simple collections of name-value pairs. The 'name' part is a JavaScript string, while the value can be any JavaScript value -- including more objects. Attribute access can be chained together: obj.details.color obj['details']['size'] The following example creates an object prototype and an instance of that prototype: function Person(name, age) { this.name = name; this.age = age; } // Define an object var you = new Person('You', 24); // We are creating a new person named \"You\" aged 24. obj.for = 'Simon'; // Syntax error, because 'for' is a reserved word obj['for'] = 'Simon'; // works fine Array Arrays in JavaScripts are actually a special type of object. The work very much like regular objects but they have one magic property called 'length'. Note that array.length isn't necessarily the number of items of the array.Consider the following: var a = ['dog'] a[100] = 'fox' a.length; // 101 Remember -- the length of the array is one more than the highest index If you query a non-existent array index, you'll get a value of undefined in return: typeof a[90]; // undefined ES2.15 introduced the more concise for...of loop for iterable objects such as array. for..in this does not iterate over the array elements, but the array indeces. Futhermore, if someone added new properties to Array.prototype, they would also be iterated overby such a loop. forEach(): ['dog', 'cat', 'hen'].forEach(function(currentValue, index, array)) { } Functions If no return statement is used(or an empty return with no value), JavaScript returns undefined. Functions have access to an additional variable inside their body called arguments. ...variable will include within that variable the entire list of uncaptured arguments that the function was called with. JavaScript let you call a function with an arbitrary of arguments, using the apply() method of any function object. Anonymous functions Anonymous functions are typically used as arguments to other functions or are made callable by immediately assigning them to a variable that can be used to invoke the function. (function() { // … })(); Recursive functions Custom objects JavaScript uses functions as classes function makePerson(first, last) { return { first: first, last: last }; } function personFullName(person) { return person.first + ' ' + person.last; } function personFullNameReversed(person) { return person.last + ', ' + person.first; } var s = makePerson('Simon', 'Willison'); personFullName(s); // \"Simon Willison\" personFullNameReversed(s); // \"Willison, Simon\" This works, but it's pretty ugly. What we really need is a way to attach a function to an object. Since functions are objects, this is easy: function makePerson(first, last) { return { first: first, last: last, fullName: function() { return this.first + ' ' + this.last; }, fullNameReversed: function() { return this.last + ', ' + this.first; } }; } var s = makePerson('Simon', 'Willison'); s.fullName(); // \"Simon Willison\" s.fullNameReversed(); // \"Willison, Simon\" We can take advantage of the this keyword to imporove our function: function Person(first, last) { this.first = first; this.last = last; this.fullName = function() { return this.first + ' ' + this.last; }; this.fullNameReversed = function() { return this.last + ', ' + this.first; }; } var s = new Person('Simon', 'Willison'); new is strongly related to this. It creates a brand new empty object, and then calls the function specified, with this set to that new object. Functions that are designed to be called by new are called constructor functions. function personFullName() { return this.first + ' ' + this.last; } function personFullNameReversed() { return this.last + ', ' + this.first; } function Person(first, last) { this.first = first; this.last = last; this.fullName = personFullName; this.fullNameReversed = personFullNameReversed; } That's better: we are creating the method functions only once, and assigning references to them inside the constructor. Can we do any better than that? The answer is yes: function Person(first, last) { this.first = first; this.last = last; } Person.prototype.fullName = function() { return this.first + ' ' + this.last; }; Person.prototype.fullNameReversed = function() { return this.last + ', ' + this.first; }; Person.prototype is an object shared by all instances of Person. The first argument to apply() is the object that should be treated as 'this'. apply() has a sister function named call, which again lets you set this but takes an expanded argument list as opposed to an array. An important detail of nested functions in JavaScript is that they can access variables in their parent function's scope. Closures function makeAdder(a) { return function(b) { return a + b; }; } var add5 = makeAdder(5); var add20 = makeAdder(20); add5(6); // ? add20(7); // ? This allow you to write many similar functions. 课外 JS_轮询 思否 轮询其实就是一个循环了 轮询的坑 function getData() { return new Promise((resolve,reject) => { setTimeout(() => { resolve({data:666}) },500) }) } // 轮询 async function start () { const { data } = await getData() // 模拟请求 console.log(data) timerId = setTimeout(start, 1000) } start () 想暂停，就是清除 timeId 了，继续就是重新轮询 轮询的坑 暂停 let timerId = null function getData() { return new Promise((resolve,reject) => { setTimeout(() => { resolve({data:666}) },500) }) } // 轮询 async function start () { const { data } = await getData() // 模拟请求 console.log(data) timerId = setTimeout(start, 1000) } // 暂停 function stop () { clearTimeout(timerId) } start () const botton = document.querySelector(\"#button\") let isPlay = true botton.addEventListener(\"click\", function(){ isPlay = !isPlay botton.innerHTML = isPlay ? '暂停' : '播放' isPlay ? start() : stop() }, false) 有bug，因为js是单线程，如果快速点击或则异步的运行很久的话，就会有几个轮询的情况出现，所以应该有个标记，但是一个变量的 true false 不满足快速点击的情况 轮询的坑 暂停 let timerId = 1 // 模拟计时器id，唯一性 let timerObj = {} // 计时器存储器 function getData() { return new Promise((resolve,reject) => { setTimeout(() => { resolve({data:666}) },500) }) } // 轮询 function start () { const id = timerId++ timerObj[id] = true async function timerFn () { if (!timerObj[id]) return const { data } = await getData() // 模拟请求 console.log(data) setTimeout(timerFn, 1000) } timerFn() } // 暂停 function stop () { timerObj = {} } start () const botton = document.querySelector(\"#button\") let isPlay = true botton.addEventListener(\"click\", function(){ isPlay = !isPlay botton.innerHTML = isPlay ? '暂停' : '播放' isPlay ? start() : stop() }, false) Promise 现代JavaScript教程 Promise 这部分知识挺有用的，仔细看一遍，当时是 Promise 链没有看熟悉，回头重新看看 简介：回调 什么是回调 JavaScript 主机（host）环境提供了许多函数，这些函数允许我们计划异步行为（action），现在看是执行的行为，但是在稍后才完成。eg：setTimeout 函数 例如加载脚本的一个函数： function loadScript(src) { let script = document.createElement('script') script.src = src document.head.append(script) } loadScript('/my/test1.js') console.log('test1') 在执行loadScript 的函数的时候是异步，函数会在异步执行这个函数的时候接着往下走，如果我们想用这个脚本中的函数，我们其实并不知道什么时候这个异步行为能结束，虽然我们不知道这个异步行为什么时候结束，但是我们可以传递一个函数作为参数，只要它一结束就可以执行这个传递的函数，这就是回调 function loadScript(src, callback) { let script = document.createElement('script') script.src = src document.head.append(script) script.onload = () => callback() // 脚本加载完之后执行 } loadScript('my/test1.js', () => {console.log('append test1.js')}) 回调中回调 如何在第一个回调后结束第二个回调，自然的想法就是第一个执行的回调中有第二个回调 loadScript('/my/test1.js', () => { console.log('append test1.js') loadScrit('my/test2.js', () => {console.log('append test2.js')}) }) 每一个新的行为（action）都在回调的内部，如果只是几个行为还好，如果行为多了，就会出现回调地狱 处理Error 在上述的例子当中，我们都没有考虑出现error的情况，如果脚本加载失败怎么办？回调需要能对此做出反应 function loadScript(src, callback) { script = document.createElement('script') script.src = src script.onload = () => callback(src) script.onerror = () => callback(new Error(`append error for ${src}`)) document.head.append(script) } loadScript('my/test1.js', (err, src) => { if(err) { console.error('error: ', err) return } console.log(`${src} append success.`) }) Error 优先回调（error-first callback）风格，约定是： callback的第一个参数是为 error 而保留的，一点出现 error，callback(err) 就会被调用 第二个参数及以后的参数用于成功的结果，此时 callback(null, result1, result2, ...) 就会被调用 厄运金字塔 看起来这是一种可行的异步编程方式，的确对于一个或两个嵌套的调用看起来还不错，但是对于一个接一个的多个异步行为，代码会变成这样： loadScript('1.js', function(error, script) { if (error) { handleError(error); } else { // ... loadScript('2.js', function(error, script) { if (error) { handleError(error); } else { // ... loadScript('3.js', function(error, script) { if (error) { handleError(error); } else { // ...加载完所有脚本后继续 (*) } }); } }); } }); 嵌套调用的“金字塔”随着每个异步行为会向右增长，很快它就失控了，解决方法是独立函数，但是这些函数都是一次性使用的，代码看起来就像是撕裂的表格，可读性很差，在阅读的时候需要在各个代码块之间跳转。解决方法最好的办法之一就是 “promise” Promise e.g: 想象一下，你是一个顶尖的歌手，粉丝没日没夜的问你什么时候发新歌，终于你忍受不了了，然后想了一个解决方案：你发了一个订阅列表，愿意的粉丝在上面填上自己的邮箱，你承诺一首歌出来（或者出了事故不能发歌）的时候立马向这个列表的邮箱发送消息。 Promise 与这个例子的类比： “生产者代码（producing code）”：做事情，但是需要一段时间 “消费者代码（consuming code）”：想要在“生产者代码（producing code）”出现的第一时间获得结果 Promise 是将“生产者代码”和“消费者代码”连接在一起的的一个特殊的 JavaScript 对象，就好比前面说的订阅列表 Promise 对象的构造器（constructor）语法如下： let promise = new Promise((resolve, reject) => { // executor 生产者代码 }) 传递给 new Promise 的代码被称为 executor，当 new Promise 被创建，executor 会自动运行，它包含最终应产出结果的生产者代码 当 executor 获得了结果，无论或早或晚都可以，它应该调用以下回调之一： resolve(value)：如果任务成功完成并带有结果 value reject(err)：如果出现了error Promise 对象具有以下内部属性： state：最初是 pending，然后再 resolve 被调用的时候变成 fulfilled，或者在 reject 被调用时变成 rejected result：最初是 undefined，然后在 resolve 被调用的时候变为 value，或者在 reject 被调用的时候变成 error promise 状态变化 小提示： 与最初的 \"pending\" promise 相反，一个 resolved 或 rejected 都会被称为 \"settled\"，任何状态的更改都是最终的，也就是只能调用一个 resolve 或者 一个 reject 如果什么出了问题，exector 应该调用 reject，这可以使用任何类型的参数来完成，但是建议使用 Error 对象 state 和 result 是内部的，Promise 对象的 state 和 result 属性都是内部的，我们无法直接访问它们，但我们可以对它们使用 .then / .catch / .finally 方法 消费者：then，catch，finally promise 对象充当的是 executor 和消费者代码之间的连接，后者将接收结果或者 error，通过使用 .then / .catch / .finally 来为消费者函数注册 踩了一个坑，如果executor中有异常，则promise 必须要有 catch 的错误回调函数，否则会报错，所以说写promise随手写 catch 是一个好习惯 最重要最基础的就是 then， then 的第二个参数可以是执行失败的回调函数： let promise = new Promise((resolve, reject) => { setTimeout(resolve('done'), 1000) }) promise.then( value => console.log('value: ', value), // 执行 err => console.error('error: ', err) // 不执行 ) let promise2 = new Promise((resolve, reject) => { setTimeout(() => reject(new Error('not'))) }) promise2.then( value => console.log('value: ', value), // 不执行 err => console.error('error: ', err) // 执行 ) 如果我们只对成功的完成感兴趣，那么可以只为 .then 提供一个函数参数： let promise = new Promise((resolve, reject) => { setTimeout(resolve('done'), 1000) }) promise.then(console.log) 如果我们只对 error 感兴趣，那么我们可以使用 null 作为 .then 的第一个参数或者使用 .catch，这两者是一样的： let promise = new Promise((resolve, reject) => { setTimeout(() => reject(new Error('not done')), 1000) }) promise.catch(console.log) .finally(f) 调用和 .then(f, f)，类似，在某种意义上，f 总是在 promise 被 settled 时执行，finally 是执行清理（cleanup）的很好的程序（handler），它们之间有一些细微的区别： finally 处理程序时没有参数，也不知道 promise 是否成功 finally 处理程序将结果和 error 传递给力下一个处理程序 JavaScript 不具有 sleep() 函数，但是可以尝试使用 setTImeout 和 promise 来共同实现它，也可以使用 Date.now 直接阻塞主线程（但是一般不考虑这个），一个同步一个异步 // 用 promise 模拟 sleep 函数 let delay = (time = 0) => {return new Promise((resolve, reject) => setTimeout(resolve, time))} console.log('delay time: ', new Date().toLocaleTimeString()) delay(3000).then(() => console.log('runs after 3 seconds first at ', new Date().toLocaleTimeString())) // 使用 Date.now() 阻塞主线程 let delay2 = (time = 0) => { let record = Date.now() while(Date.now() - record Promise 链 回调我们提过，有一系列的异步任务要一个接一个地执行，加载脚本，利用 Promise 链我们可以写出更好的代码，它看起来就像这样： new Promise((resolve, reject) => { setTimeout(() => resolve(1), 1000) }).then(value =>{ console.log('value: ', value) return 2 }).then(value => { console.log('value: ', value) return 3 }).then(value => { console.log('value: ', value) console.log('finished.') }) 它的理念是将 result 通过 .then 处理程序（handler）链进行传递 Promise 链 新手常犯的一个经典错误：将多个 .then 添加到一个 promise 上，但这并不是 promise 链（chaining）： let promise = new Promise(function(resolve, reject) { setTimeout(() => resolve(1), 1000); }); promise.then(function(result) { alert(result); // 1 return result * 2; }); promise.then(function(result) { alert(result); // 1 return result * 2; }); promise.then(function(result) { alert(result); // 1 return result * 2; }); Promise 多处理程序情况 同一个 promise 上的所有 .then 获得的结果都相同，实际上我们极少遇到一个 promise 需要多处理程序（handler）的情况 返回Promise .then（handler）中所使用的处理程序（handler）可以创建并返回一个 Promise，在这种情况下，其它的处理程序（handler）将等待它 settled 后再获得其结果（result） new Promise((resolve, reject) => { setTimeout(() => resolve(1), 1000) }).then(value => { console.log('value: ', value) return new Promise((resolve, reject) => { setTimeout(() => resolve(99), 1000) }) }).then(value => { console.log('value: ', value) return new Promise((resolve, reject) => { setTimeout(() => resolve(8), 1000) }) }).then(value => { console.log('value: ', value, '\\nfinished.') }) 返回 promise 让我们能够构建异步行为链 更复杂的示例：fetch 一个好的做法，异步行为应该始终返回一个 promise，这样就可以使得我们计划后续的行为成为可能，即使我们现在不打算对链进行扩展，但我们之后可能会需要 function loadJson(url) { return fetch(url) .then(response => response.json()) } function loadGithubUser(name) { return fetch(`https://api.github.com/users/${name}`) .then(response => response.json()) } function showAvatar(githubUser) { return new Promise((resolve, reject) => { let img = document.createElement('img') img.src = githubUser.avatar_url img.className = 'promise-avatar-examle' document.body.append(img) setTimeout(() => { img.remove() resolve(githubUser) }, 3000) }) } loadJson('/user.json') .then(user => loadGithubUser(user.name)) .then(showAvatar) .then(githubUser => alert(`Finished showing ${githubUer.name}`)) 如果 .then （或 catch/finally 都可以）处理程序（handler）返回一个promise，那么链的其余部分将会等待，知道它的状态变为 settled。当它被 settled 后，其 result（或 error）将被进一步传递下去 Promise chain flow chart 使用 promise 进行错误处理 Promise 链在错误（error）处理中十分强大。当一个 promise 被 reject 时，控制权将移交给最近的 rejection 处理程序。 fetch('/article/promise-chaining/user.json') .then(response => response.json()) .then(user => fetch(`https://api.github.com/users/${user.name}`)) .then(response => response.json()) .then(githubUser => new Promise((resolve, reject) => { let img = document.createElement('img'); img.src = githubUser.avatar_url; img.className = \"promise-avatar-example\"; document.body.append(img); setTimeout(() => { img.remove(); resolve(githubUser); }, 3000); })) .catch(error => alert(error.message)); .catch 不必是立即的，它可能在一个或多个 .then 之后出现，捕获所有 error 最简单的方法是，将 .catch 附加到链的末尾 Promise 的执行者（executor） 和 promise 的处理程序（handler）周围有一个“隐式”的 try...catch 。如果发生异常，它就会被捕获，并被视为 rejection 进行处理，一下这两段代码是等价的 new Promise((resolve, reject) => { throw new Error('error') }).catch(console.log) new Promise((resolve, reject) => { reject(new Error('error')) }).catch(console.log) 再次抛出（rethrowing） 正如我们所注意到的，链尾端的 .catch 的表现有点像 try...catch，我们可能由许多个 .then 处理程序（handler），然后在尾端使用一个 .catch 处理上面所有的 error 在常规的 try...catch 中，我们可以分析错误（error），如果我们无法处理它，可以将其再次抛出，对于promise来说，这样也是可以的 如果我们在 .catch 中 throw，那么控制权就会被移交到下一个最近的 error 处理程序，如果我们处理该 error 并正常完成，那么它将继续到最近的成功的 .then 处理程序 new Promise((resolve, reject) => { reject(new Error('err')) }) .catch(console.log) .then(() => console.log('finish')) catch 立马继续 throw，忽略 then 处理程序，传给下一个 catch 处理程序 new Promise((resolve, reject) => { reject(new Error('err')) }) .catch(err => { if(err instanceof URIError) { // handle it } else { throw err } }) .then(() => console.log('no handle')) .catch(err => console.log('unknown err: ', err)) 未处理的 rejection 当一个 error 没有被处理，未被 try...catch 捕获，那么脚本就死了，并在控制台留下来一个信息，同理在 promise 中未被处理的rejection 也会发生类似的事 JavaScript 引擎会跟踪此类 rejection，在这种情况下会生成一个全局的 error，在浏览器中我们可以使用 unhandledrejection 事件来捕获这类 error： window.addEventListener('unhandledrejection', (event) => { console.log(event.promise) console.log(event.reason) }) 通常此类 error 是无法恢复的，所以我们最好的解决方案是将问题告知用户，并且可以将事件报告给服务器，在 Node.js 等非浏览器环境中，有其他用于跟踪未处理的 error 的方法 Fetch 错误处理示例 当请求无法发出时，fetch reject 会返回 promise，但是如果远程服务器返回错误响应 404 或者是 500，这些都被认为是合法的响应，但是这应该当作错误来处理，并且无论是 404 或者 500 的响应，它的response都会被当成 json 处理，都会报 SyntaxError ，但是实际上并不是这个错误，错误只是落在了链上，并没有相关细节信息 fetch('test.json') .then(response => response.json()) .catch(console.log) // SyntaxError: Unexpected token 所以我们可以为 HTTP 错误 创建一个自定义类用来区分 HTTP 错误和其它类型错误，这个新类有一个 constructor，它接受response 对象，并将其保存到 error 中 然后我们将请求和错误处理代码包装进一个函数，它能 fetch url 并将所有状态码不是 200 的视为错误，我们通常需要这样的逻辑 // fetch 请求 github 用户 function printOneGithubUser() { let name = prompt('Enter your name', 'name') fetch(`https://api.github.com/users/${name}`) .then(response => { if(response.status == 200) { return response.json() } else { throw new HttpError(response) } }) .then(user => console.log('user: ', user)) .catch(err =>{ if(err instanceof HttpError && err.response.status != 200) { console.log('no such user') return printOneGithubUser() } else { console.log('other error: ', err) } }) } printOneGithubUser() 如果我们有加载指示（load-indication），finally 就是一个很好的处理程序，在 fetch 完成时停止。try...catch 结构只能抓捕同步的错误。 Promise API 在 Promise 类中，有 5 中静态方法 Promise.all 假设我们需要并行执行多个 promise，并等待所有 promise 都准备就绪，比如并行下载交给 URL，并等到所有内容都下载完毕后再对它们进行处理。 // promise.all 简单使用 Promise.all([ new Promise(resolve => setTimeout(() => resolve(1), 1000)), new Promise(resolve => setTimeout(() => resolve(2), 2000)), new Promise(resolve => setTimeout(() => resolve(3), 3000))]) .then(console.log) let urls = ['https://api.github.com/users/Ting-xin', 'https://api.github.com/users/Ting-xin'] Promise.all(urls.map(url => fetch(url))) .then(responses => responses.forEach(response => { console.log('response: ', response) })) 一个更加实际的例子是 response.json()，应该有一个 promise.all 专门来处理这个，踩了一个坑，第二个Promise.all 使用 {} 会有问题，暂时我也不知道为啥： let urls = ['https://api.github.com/users/Ting-xin', 'https://api.github.com/users/Ting-xin'] Promise.all(urls.map(url => fetch(url))) .then(responses => Promise.all(responses.map(response => response.json()))) .then(resultArr => resultArr.forEach(result => console.log('name: ', result.name))) 如果任意一个 promise 被 reject，由 Promise.all 返回的 promise 就会立即 reject，并且带有这个error，其它的 promise 将被忽略，其中一个失败，但是其余的 fetch 操作仍然会继续执行，但是结果还是会被忽略，promise 中没有取消的概念，只能通过 AbortController 来取消 Promise.all(iterable) 允许在 iterable 中使用 non-promise 的“常规”值 Promise.allSettled 在 Promise.all 中，如果任意的 promise reject，整个都会 reject，当我们需要所有的结果，无论结果是啥的时候，就可以用 Promise.allSettled 例如，我们想要获取多个用户的信息，即使其中一个请求失败，我们仍然对其它的感兴趣，就可以使用 Promise.allSettled let urls = [ 'https://api.github.com/users/iliakan', 'https://api.github.com/users/remy', 'https://no-such-url' ]; Promise.allSettled(urls.map(url => fetch(url))) .then(results => { // (*) results.forEach((result, num) => { if (result.status == \"fulfilled\") { alert(`${urls[num]}: ${result.value.status}`); } if (result.status == \"rejected\") { alert(`${urls[num]}: ${result.reason}`); } }); }); Promise.race 与 Promise.all 类似，但只等待一个 settled 的 promise 并获取其结果 Promise.race([ new Promise((resolve, reject) => setTimeout(() => resolve(1), 1000)), new Promise((resolve, reject) => setTimeout(() => reject(new Error(\"Whoops!\")), 2000)), new Promise((resolve, reject) => setTimeout(() => resolve(3), 3000)) ]).then(alert); // 1 Promise.resolve、Promise.reject 已经过时了，因为 async/await 语法 Promisification Promisification 是指将一个接收回调的函数转换为一个返回promise的函数。由于许多函数和库都是基于回调的，因此在实际开发中经常会需要进行这种转换，因为使用 promise 更加方便，所以将基于回调的函数和库 promisfy 是有意义的 function loadScript(src, callback) { let script = document.createElement('script') } await 处理 promise 返回 reject 报错的问题 blog promise 用 async，awati 优化，不仅是为了更优雅的书写和阅读，通过优化把异步代码写成同步，也是为了更加符合人正常的思维方式 ES5的异常捕获 try{ throw new Error(3) } catch(e) { console.log(e) } 这是ok的，但是如果try中出现了异步的代码呢 try{ setTimeout(() => { throw new Error(3) }, 1000) } catch(e) { console.log(e) } try-catch 是同步的，setTimeout 是在异步任务队列中的，同步任务执行完再从任务队列中的回调函数拿来执行就出错了 改正 setTimeout(() => { try{ throw new Error(3) } catch(e) { console.log(e) } }, 0) ES6 promise 方式的错误捕获 异步任务完成调用 resolve 的做法： function fn() { return new Promise((resolve, reject) => { setTimeout(() => { resolve('ok') }, 1000) }) } fn().then(res => { console.log(res) }) 异步任务失败的，调用reject的捕获异常方法： function fn() { return new Promise((resolve, reject) => { setTimeout(() => { reject(3) }, 1000) }) } fn().catch(err => console.log(err)) ES6 通过 async， await优化promise时的异常捕获 问题，通过 async，await的方式去优化promise，只能接收到成功 resolve() 的结果，对与 reject() 的记过是回报错的 // resolve情况，正常 function fn1() { return new Promise((resolve, reject) => { setTimeout(() => { resolve('ok') }, 0) }) } async function test1() { let res = await fn1() console.log(res) } test1() // reject情况，异常 function fn2() { return new Promise((resolve, reject) => { setTimeout(() => { reject('error') }, 0) }) } async function test2() { let res = await fn2() console.log(res) } test2() 解决async/await 的promise 返回错误 reject 的问题及错误捕获 方式一：async/await 已经把异步代码优化成了同步代码，同步代码可以通过 try, catch捕获异常 function fn() { return new Promise((resolve, reject) => { setTimeout(() => { reject('error') }, 0) }) } async function test() { try{ let test = await fn() } catch (e) { console.log(e) } } test() 方式2：通过返回一个pending 状态的结果，中断promise链的方式处理错误 function fn() { return new Promise((resolve, reject) => { setTimeout(() => { // reject('error') return new Promise(() => {}) // 中断 promise 链 }) }) } async function test() { let res = await fn() console.log(res) } test() 方法2不会出现多余且不好看的代码，但是根本不能拿到错误了呀 正则表达式 为什么要学习字符串 处理 为什么学习字符串处理 传统的统计学教育几乎没有告诉过我们如何进行文本的统计建模分析。然而我们日常生活中接触到的大部分数据都是以文本的形式存在，文本分析与挖掘在业界有着非常广泛的应用。 由于文本数据大多数属于非结构化数据，要想对文本数据进行传统的统计模型分析，必须要经过层层的数据清洗和整理，正则表达式就用来干这个的。 和建立酷炫的模型比起来，数据的清洗与整理似乎是一种低档次的工作。如果吧建模比作高级厨师的工作，那么数据清洗就类似于切菜洗碗打扫卫生的活儿。然而想要成为资深的“数据玩家”，这种看似低档次的工作是必不可少的，并且这种工作极有可能占据整个建模流程的 80% 的时间。如果我们能掌握高效的数据清洗工作，那么我们将拥有更多的时间来选择模型和参数选择。 教程 以前一直都是草草了事，这次一定要把这个好好看懂 教程 模式（Paterns）和修饰符（flags） 正则表达式是搜索和替换字符串的一种强大方式，在JavaScript中，正则表达式通过内置的“RegExp”类的对象实现，并与字符串集成 创建正则表达式有两种语法 // 较长的语法 regexp = new RegExp(\"pattern\", \"flags\") // 较短的语法 regexp = /pattern/; // 没有修饰符 regexp = /pattern/gmi; // 伴随修饰符 g m i 如果要在字符串种进行搜索，可以使用search 方法 let str = 'I love JavaScript' let regexp = /love/ alert(str.search(regexp)) // 2 // 上面这段代码等价于 let str = 'I love JavaScript' let substr = 'love' alert(str.search(substr)) // 2 str.search 方法会查找模式 /love/ ，然后返回匹配项在字符串中的位置 通常我们使用的都是简短语法 /../ 。但是它不接受任何变量的插入，new RegExp 允许从字符串中动态的构造模式 let search = prompt('What you want to search?', 'love') let regexp = new RegExp(search) alert('I love JavaScript'.search(regexp)) 正则表达式的修饰符可能会影响搜索结果，在JavaScript中有5个修饰符 i 不区分大小写 g 查找所有的匹配项，而不只是第一个 m 多行模式 u 开启完整的 unicode 支持，能修正对于代理对的处理 y 粘滞模式 alert('love'.search(/LOVE/)) // -1，没找到 alert('love'.search(/LOVE/i)) // 0 如果不使用我们后面将会学到的修饰符和特殊标志，正则表达式的搜索就等同于字符串查找了 字符类 字符类（character classes）是一个特殊的符号，匹配特定集合中的任何符号 str.match(regexp) 方法在字符串中 str 中找到匹配 regexp 的字符 // 考虑一个实际的例子，只保留字符中的所有数字 console.log('+1,3,5,,,,'.match(/\\d/g).join('')); // 135 常用的字符类有： \\d d 来自 digit，从 0 到 9 的字符 \\s s 来自 space，空格符号，包括空格，制表符\\t，换行符\\n，及其他稀有字符，如 \\v，\\f 和 \\r \\w w 来自 word，拉丁字符或数字或下划线 正则表达式可能同时包含常规符号和字符类，匹配项（每个正则表达式字符类都有对应的结果字符） 对于每个字符类，都有一个反向类，用相同的字符表示，但是要大写，反向代表它与所有其它字符匹配 \\D 非数字，匹配除 \\d 以外的所有字符 \\S 非空格字符，匹配除 \\s 以外的所有字符 \\W 非单字字符，匹配除 \\w 以外的所有字符 // 考虑一个实际的例子，只保留字符中的所有数字 console.log('+1,3,5,,,,'.match(/\\d/g).join('')); // 135 // 另一种快捷的方式是将所有的非数字字符找到，并直接删除 console.log('+1,3,5,,,'.replace(/\\D/g, '')); // 135 点（.）是一种特殊的字符类，匹配任何字符，点表示任何字符，而不是缺少字符，必须有一个与之匹配的字符 默认情况下，点与换行符 \\n 不匹配，但在很多情况下，当我们希望用点来表示任何字符（包括换行符\\n时），就要用到标识符 s console.log('a\\nb'.match(/a.b/)) // null console.log('a\\nb'.match(/a.b/s)) // a\\nb 的 object 但是 \\s 的方式不是所有的浏览器都适用，有一种替代方法在任何地方都适用，可以使用 [\\s\\S] 之类的正则表达式来匹配任何字符 alert(\"a\\nb\".match(/a[\\s\\S]b)/) // a\\nb 在正则表达式中，所有字符都很重要，空格也很重要 Unicode：修饰符 'u' 和 class \\n{...} 很久以前，当JavaScript被发明出来的时候，Unicode的编码要更加简单：当时并没有 4 个字节长的字符，所以一部分语言特性在现在仍旧无法队Unicode进行正确的处理 与字符串有所不同的是，正则表达式有一个修饰符 u 被用以解决这类问题，但一个正则表达式使用了这个修饰符后，4个字节长的字符将被正确的处理 我们可以查找具有某种属性的字符，写作 \\p{...} ，为了顺利使用 \\p{...}，一个正则表达式必须使用修饰符u \\p{Letter} 表示任何语言中的一个字母，可以使用 \\p{L} 代替 let str = \"A ბ ㄱ\" // 英语，格鲁吉亚语，韩语字母 console.log(str.match(/\\p{L}/gu)) // ['A', 'ბ', 'ㄱ'] console.log(str.match(/\\p{L}/g)) // null 一个 16 进制数字可以表示为 \\p{Hex_Digit}： let regexp = /x\\p{Hex_Digit}\\p{Hex_Digit}/u; alert(\"number: xAF\".match(regexp)); // xAF 有一个 unicode 属性 Script （一个书写系统），这个属性可以有一个值：Cyrillic，Greek，Arabic，Han （中文）等等 let regexp = /\\p{sc=Han}/gu; // 返回中文 console.log(`Hello Привет 你好 123_456`.match(regexp).join('')) // 你好 接着是一个数字”的价格文本： let regexp = /\\p{Sc}\\d/gu; let str = `Prices: $2, €1, ¥9`; alert( str.match(regexp) ); // $2,€1,¥9 修饰符 u 在正则表达式中提供对 Unicode 的支持。 这意味着两件事： 4 个字节长的字符被以正确的方式处理：被看成单个的字符，而不是 2 个 2 字节长的字符。 Unicode 属性可以被用于查找中 \\p{…}。 有了 unicode 属性我们可以查找给定语言中的词，特殊字符（引用，货币）等等。 锚点（anchors）： 字符串开始^和末尾$ 插入符号 ^匹配文本开头，而美元符号 $ 匹配文本末尾 测试完全匹配，这两个锚点放在一起常常被用于测试一个字符串是否完全匹配一个模式 // 测试字符是否属于 12:34 的格式 let goodInput = '12:34' let errInput = '12:345' let regexp = /^\\d\\d:\\d\\d$/ console.log(regexp.test(goodInput)) // true console.log(regexp.test(errInput)) // false 锚点 ^ 和 $ 属于测试。它们的宽度为零。 换句话来说，它们并不匹配一个具体的字符，而是让正则引擎测试所表示的条件（文本开头/文本末尾） 多行模式Flag \"m\" 通过flag /.../m 可以开启多行模式，这仅仅影响 ^ 和 $ 锚符的行为，在多行模式下，它们不仅仅匹配文本的开始和结束，还匹配每一行的开始和结束 let str = `1st place: Winnie 2nd place: Piglet 33rd place: Eeyore`; console.log(str.match(/^\\d+/gm)) // ['1', '2', '33'] 词边界 \\b 词边界 \\b 是一种检查，就像 ^ 和 $ 一样，match 返回的应该是一个类数组 console.log('hello, java'.match(/\\bjava\\b/)) // ['java'] console.log('hello, javascript'.match(/\\bjava\\b/)) // null \\b 既可以用于单词，也可以用于数字 例如，模式 \\b\\d\\d\\b 查找独立的两位数。换句话说，它查找的是两位数，其周围是与 \\w 不同的字符，例如空格或标点符号（或文本开头/结尾）。 转义，特殊字符 所有特殊字符的列表：[ \\ ^ $ . | ? * + ( ) 如果要把特殊字符作为常规字符来使用，只需要在它的前面加一个反斜杠 斜杠符号 / 并不是一个特殊符号，他被用于在 JavaScript 中开启和关闭正则匹配 console.log('/'.match(/\\//)) // '/' console.log('/'.match(new RegExp('/'))) // '/' 在字符串中的反斜杠表示转义或者类似 \\n 这种只能在字符串中使用的特殊字符。这个引用会“消费”并且解释这些字符，所以调用 new RegExp 会获得一个灭有反斜杠的字符串，如果要修复这个，需要双斜杠 要在字面（意义）上搜索特殊字符 [ \\ ^ $ . | ? * + ( )，我们需要在它们前面加上反斜杠 \\（“转义它们”）。 如果我们在 /.../ 内部（但不在 new RegExp 内部），还需要转义 /。 传递一个字符串（参数）给 new RegExp 时，我们需要双倍反斜杠 \\\\，因为字符串引号会消费其中的一个。 集合和范围 [...] 在方括号 [...] 中的几个字符或者字符类意味着”搜索给定的字符中的任意一个\" console.log('Mop top'.match(/[tm]op/gi)) // ['Mop', 'top'] 请注意尽管在集合中有多个字符，但它们只会对应其中一个 方括号可以包含字符范围，比如说 [a-z]， [0-5] [0-8A-F] 表示两个范围：它搜索一个字符，满足其中一个条件，如果我们还想查找小写字母，则可以添加范围 a-f：[0-9A-Fa-f]。或添加标志 i。 由于字符类 \\w 是简写的 [a-zA-Z0-9_]，因此无法找到中文象形文字 除了普通的范围匹配，还有类似 [^...] 的排除范围匹配 通过在匹配查询的开头添加插入符号 ^ 来表示，它会匹配所有除了给定的字符之外的任意字符 [^aeyo] 匹配任何除了 a, e, y, o 之外的字符 在 [...] 中不转义， [-().^+] 会查找 -().^+ 的其中任意一个字符： 范围和标志 'u' alert( '𝒳'.match(/[𝒳𝒴]/u) ); // 𝒳 量词 +, *, ?, {n} 数量 {n} \\d{5} 表示 5 位的数字 某个范围的位数： {3, 5} 大多数量词都可以有缩写 + 代表一个或者多个，相当于 {1,} ? 代表一个或者0个，相当于{0, 1} * 代表零个或者多个，相当于 {0,} 正则表达式越精确，它就越长且越复杂 贪婪量词和惰性量词 量词看上去很简单，但实际上它可能会很棘手，如果我们打算寻找比 /\\d+/ 更加复杂的工作，就需要理解搜索工作是如何进行的 eg：有一个文本，我们需要用书名号： 《...》 来代理所有的 引号 “...”，第一想法是不是采用 /\".+\"/g 的正则去寻找，但是实际情况并不是这样的 str = '\"str\" is \"test\" str' console.log(str.match(/\".+\"/g)) // ['\"str\" is \"test\"'], 返回了一整个，而不是两个 贪婪搜索 为了查找到一个匹配项，正则表达式采用了以下算法：对于字符串中的每一个字符，用这个模式来匹配此字符，若无匹配，则移至下一个字符（回溯），在贪婪模式下（默认情况），量词都会尽可能的重复多次 懒惰模式 懒惰模式中的量词与贪婪模式中的是相反的，我们通过在量词后添加一个问好 ？ 来启用它，？它本身就是一个量词（0 或 1） 上例子中，正则表达式 /\".+?\"/g 就会如预期工作了 str = '\"str\" is \"test\" str' console.log(str.match(/\".+\"/g)) // ['\"str\"', '\"test\"'], 返回了两个 懒惰模式只能通过带 ？ 的量词启用 alert( \"123 456\".match(/\\d+ \\d+?/g) ); // 123 4 总结：量词有两种工作模式，贪婪模式和懒惰模式 捕获组 模式的一部分可以用括号括起来，这称为捕获组，它有两个影响： 它允许将匹配的一部分作为结果数组中的单独项 如果我们将量词放在括号后，则它将括号视为一个整体 eg： gogogo 'Gogogo now'.match(/(go)+/i) // 'Gogogo' eg：域名 let regexp = /(\\w+\\.)+\\w+/g \"site.com my.site.com\".match(regexp) //site.com my.site.com eg: email 名称可以是任何单词，可以使用连字符和点，在正则表达式是 [-.\\w]+ let regexp = /[-.\\w]+@([\\w-]+\\.)+[\\w-]+/g \"my@mail.com @ his@site.com.uk\".match(regexp) // ['my@mail.com', 'his@site.com'] eg： 匹配括号中的内容 括号可以嵌套，在这种情况下，编号从左往右 let str = ''; let regexp = /]*))>/; let result = str.match(regexp); alert(result[0]); // alert(result[1]); // span class=\"my\" alert(result[2]); // span alert(result[3]); // class=\"my\" 可选组，即使组是可选的并且在匹配项中不存在，也存在相应的 result 数组项，并且等于 undefined let match = 'a'.match(/a(z)?(c)?/); alert( match.length ); // 3 alert( match[0] ); // a（完全匹配） alert( match[1] ); // undefined alert( match[2] ); // undefined 搜索所有具有组的匹配项：matchAll，由 matchAll 所返回的每个匹配，其格式与不带标志 g 的 match 所返回的格式相同：它是一个具有额外的 index（字符串中的匹配索引）属性和 input（源字符串）的数组 命名组：用数字记录组很困难。对于简单模式，它是可行的，但对于更复杂的模式，计算括号很不方便。我们有一个更好的选择：给括号起个名字。 let dateRegexp = /(?[0-9]{4})-(?[0-9]{2})-(?[0-9]{2})/; let str = \"2019-04-30\"; let groups = str.match(dateRegexp).groups; alert(groups.year); // 2019 alert(groups.month); // 04 alert(groups.day); // 30 替换捕获组：方法 str.replace(regexp, replacement) 用 replacement 替换 str 中匹配 regexp 的所有捕获组。这使用 $n 来完成，其中 n 是组号 模式中的反向引用： \\N 和 \\k 我们可以将两种引号放在方括号中：['\"](.*?)['\"]，但它会找到带有混合引号的字符串，例如 \"...' 和 '...\"。当一种引号出现在另一种引号内，比如在字符串 \"She's the one!\" 中时，便会导致不正确的匹配： let str = `He said: \"She's the one!\".`; let regexp = /['\"](.*?)['\"]/g; // 不是我们想要的结果 alert( str.match(regexp) ); // \"She' 如我们所见，该模式找到了一个开头的引号 \"，然后文本被匹配，直到另一个引号 '，该匹配结束。 为了确保模式查找的结束引号与开始的引号完全相同，我们可以将其包装到捕获组中并对其进行反向引用：(['\"])(.*?)\\1。 这是正确的代码： let str = `He said: \"She's the one!\".`; let regexp = /(['\"])(.*?)\\1/g; alert( str.match(regexp) ); // \"She's the one!\" 选择 | gr(a|e)y 严格等同 gr[ae]y。 gra|ey 匹配 “gra” or “ey”。 时间正则表达式 // 错误版本 let reg = /[01]\\d|2[0-3]:[0-5]\\d/g; alert(\"12\".match(reg)); // 12 (matched [01]\\d) // 正确版本 let reg = /([01]\\d|2[0-3]):[0-5]\\d/g; alert(\"00:00 10:10 23:59 25:99 1:2\".match(reg)); // 00:00,10:10,23:59 正则表达式引擎查找选择模式的时是挨个查找的。意思是：它先匹配是否存在 Java，否则 —— 接着匹配 JavaScript 及其后的字符串。 变更匹配顺序，长的字符串优先匹配：JavaScript|Java|C\\+\\+|C|PHP。 合并相同前缀：Java(Script)?|C(\\+\\+)?|PHP。 运行代码如下： let reg = /Java(Script)?|C(\\+\\+)?|PHP/g; let str = \"Java, JavaScript, PHP, C, C++\"; alert( str.match(reg) ); // Java,JavaScript,PHP,C,C++ 前瞻断言与后瞻断言 有时候我们需要匹配后面跟着特定模式的一段模式。比如，我们要从 1 turkey costs 30€ 这段字符中匹配价格数值。 我们需要获取 € 符号前面的数值（假设价格是整数）。 那就是前瞻断言要做的事情。 前瞻断言 语法为：x(?=y)，它表示 “匹配 x, 仅在后面是 y 的情况\"” 语法为：x(?!y)，意思是 “查找 x, 但是仅在不被 y 跟随的情况下匹配成功”。 后瞻断言 前瞻断言允许添加一个“后面要跟着什么”的条件判断。 后瞻断言也是类似的，只不过它是在相反的方向上进行条件判断。也就是说，它只允许匹配前面有特定字符串的模式。 语法为: 后瞻肯定断言：(?, 匹配 x, 仅在前面是 y 的情况。 后瞻否定断言：(?, 匹配 x, 仅在前面不是 y 的情况。 灾难性回溯 有些正则表达式看上去很简单，但是执行起来耗时非常非常非常长，甚至会导致 JavaScript 引擎「挂起」。 开发者们很容易一不小心就写出这类正则表达式，所以我们迟早会面对这种意外问题。 典型的症状就是 —— 一个正则表达式有时能正常工作，但对于某些特定的字符串就会消耗 100% 的 CPU 算力，出现“挂起”现象。 在这种情况下，Web 浏览器会建议杀死脚本并重新载入页面。这显然不是我们愿意看到的。 在服务器端 JavaScript 中，在使用这种正则表达式处理用户数据时可能会引发程序漏洞。 搭建一个图床 利用Minio搭建私有图床 简介 图片存储服务，也叫图床，是博客需要具备的基础服务。过往我们采用的是公共免费的图床，但是这些服务有一些缺点： 存储容量受限 稳定性，可能突然对方不提供服务了 安全性，没在自己这始终不放心 因此，大家开始自建私有图床，参考的博客的采用的存储服务是Minio AWS S3 一文读懂 AWS S3 S3 的全名是 simple storage service，简单的存储服务。它的作用有： 提供了同一的接口 REST/SOAP 来统一访问任何数据 对 S3 来说，存在里面的就是对象名和数据 不限量，单个文件最高可达 5 TB 高速，每个 bucket 下每秒可达 3500 put/copy/post/delete 或 5500 get/head 请求 具备版本、权限控制能力 具备数据生命周期管理能力 每个对象最多指定 10 个标签（其实数据标签真的很有用） 防盗链 传说中防盗链的爱恨情仇 盗链是指自己的页面上展示一些并不在自己服务器上的内容。通常的做法是通过技术手段获得它人服务器上的资源地址，绕过别人的资源展示页面，直接在自己的页面上向最终用户提供此内容，比较常见的是一些小站盗用大站的资源 防盗链的原理：在HTTP协议中，如果从一个页面调到另一个页面，header字段里面会带个Referer，图片服务器通过检测Referer是否来自规定的域名来进行防盗链 前端常用功能集合 掘金 这位大佬自己动手做了前端的一些无依赖，精简高效的东西，然后按需应用到实际项目中，小白也想要一个一个的试试，就当练手了 http请求 前端必备技能，也是使用最多的技能。 基础知识 XMLHttpRequest (XHR) 对象用于与服务器交互，通过 XMLHttpRequest 可以在不刷新页面的情况下请求特定 URL，获取数据。这允许页面在不影响用户操作的情况下更行页面的局部内容，XMLHttpRequest 在 AJAX 编程中被大量使用。 AJAX(Asynchronous JavaScript And XML) 是一种使用 XMLHttpRequest 技术构建更复杂，动态的网页的编程实践。AJAX 允许只更新一个 HTML 页面的部分 DOM，而无须重新加载整个页面。AJAX 还允许异步工作，这意味着当网页的一部分正试图重新加载时，代码可以继续运行 AJAX 发送请求 为了使用 JavaScript 向服务器发送一个 http 请求，所以需要一个包含必要函数功能的对象实例，这就是为什么会有 XMLHttpRequest 的原因 创建一个 XMLHttpRequest 实例： // Old compatibility code, no longer needed. if (window.XMLHttpRequest) { // Mozilla, Safari, IE7+... httpRequest = new XMLHttpRequest() } else { httpRequest = new ActiveXObject(\"Microsoft.XMLHTTP\") } 发送一个请求后会收到响应，在这个阶段，需要告诉 XMLHttp 请求对象应该由哪一个 JavaScript 函数处理响应 httpRequest.onreadystatechange = nameofTheFunction; // 这个只是应用赋值，为了真正的调用，应该用个匿名函数 httpRequest.onreadystatechange = () => { // process the server response here. } 接下来，通过调用 HTTP 请求对象的 open() 和 send() 方法： httpRequest.open('GET', 'http://www.example.org/some.file', true) httpRequest.send() open 的第一个参数是 HTTP 请求，由 GET, POST, HEAD 以及服务器支持的其它方法，这些方法都是大写 第二个参数是你要发送的URL。由于安全原因，默认不能调用第三方 URL 域名。确保使用正确的域名，否则调用时会有\"permission denied\" 错误提示 第三个参数是设置请求是否异步，如果是 true 即代表是异步 send() 方法的参数可以是任何你想发送给服务器的内容，如果是 POST 请求的话，发送表单数据应该用服务器可以解析的格式 处理服务器响应 在发送请求时，我们提供的JavaScript函数负责处理响应，这个函数首先检查请求的状态，如果状态值是 XMLHttpRequest.DONE(对应的值是4)，意味着服务器响应收到了并且是没有问题的，然后可以继续执行 httpRequest.onreadystatechange = () => { if(httpRequest.readyState = XMLHttpRequest.DONE) { // everythin is good, the response is received. } else { // not ready yet. } } 接下来通过检查 200 OK 判断AJAX有没有成功 if (httpRequest.status === 200) { // perfect! } else { } 一个简单的例子 make a request (function() { var httpRequest; document.getElementById('test').addEventListener('click', makeRequest) function makeRequest() { httpRequest = new XMLHttpRequest() if(!httpRequest) { alert('Browser don\\'t support XMLHttpRequest.') return } httpRequest.onreadystatechange = handleRequest httpRequest.open('GET', 'www.test.com/test.html') httpRequest.send() } function handleRequest() { if(httpRequest.readystate = XMLHttpRequest.DONE) { if(httpRequest.status = 200) { alert(httpRequest.responseText) } else { alert('Something wrong.') } } } }) 在这个例子中： 用户点击“make a request” 按钮 事件处理调用 makeRequest() 函数 请求通过 onreadystatechange 传给 handleRequest 函数 handleRequest 函数首先进行判断，然后处理 提示： 如果你向一个代码片段发送请求，将返回 XML，而不是静态 XML 文件，在 IE 浏览器上则必须要设置响应头才能正常工作。如果不设置响应头 Content-Type: application/xml，IE 浏览器会在访问你的 XML 元素的时候抛出 “Object Expected” 错误 如果不设置响应头 Cache-Control: no-cache，那么浏览器会把响应缓存下来而且再也无法重新提交请求。还有一种做法是添加一个总是不同的 GET 参数，比如时间戳或者随机数 如果变量 httpRequest 在全局范围内使用，那么它会在 makeRequest() 函数中被相互覆盖，从而导致资源竞争，为了避免这个情况，请求包含 AJAX 函数的闭包中声明 httpRequest 变量 在通信错误的事件中（例如服务器宕机），在访问响应状态 onreadystatechange 方法中会掏出一个例外 exception，为了缓和这种情况，则可以使用 try...catch... function handleRequest() { try{ if(httpRequest.onreadystate === XMLHttpRequest.DONE) { if(httpRequest.status === 200) { // do something with httpRequest.responseText } else { alert('something wrong') } } } catch(e) { alert('Caught Exception: ' + e.description) } } XMLHttpRequest.readyState: 0 未初始化 或 请求还未初始化 1 正在加载 或 已建立服务器链接 2 加载成功 或 请求已接收 3 交互 或 正在处理请求 4 完成 或 请求已完成并且响应已准备好 XMLHttpRequest.status: 100-199 信息响应 200-299 成功响应 300-399 重定向消息 400-499 客户端错误响应 500-599 服务端错误响应 处理 XML 响应 在上一个例子中，在收到 HTTP 请求的响应后我们会使用对象的 responseText 属性，包含 test.html 文件的内容。现在我们试试 responseXML 属性 有效的 xml 文档： test 将 test.html 改为 test.xml ，然后再把 httpRequest.responseText 改为： let xmlDoc = httpRequest.responseXML; let rootNode = xmlDoc.getElementByTagName('root').item(0) alert(rootNode.firstChild.data) Fetch API Fetch API 提供了一个获取资源的接口（包括跨域请求）。任何使用过 XMLHttpRequest 的人都能轻松上手，新的 API 提供了更强大和灵活的功能集。Fetch 提供了对 Request 和 Response （以及其他与网络请求有关的）对象的通用定义。使之今后可以被使用到更多的应用场景中：无论是service worker、cache api、又或者是其它处理请求和响应的方式、甚至是任何一种需要再自己程序中生成响应的方式 fetch() 必须接受一个参数：资源的路径。无论请求成功与否，它都返回一个 Promise 对象，resolve 对应请求的 Response 简单使用： fetch('http://example.com/movies.json').then(response => response.json()).then(data => console.log(data)) fetch() 接收第二个可选参数，一个可以控制不同配置的 init 对象： // example of post method implementation by fetch api async function postData(url = '', data = {}) { const response = await fetch(url, { // default option are marked with * method: 'POST', // *GET, POST, PUT, DELETE, etc. mode: 'cors', // no-cors, *cors, same-origin cache： 'no-cache', // *default, no-cache, reload, force-cache, only-if-cached credentials: 'same-origin', // include, *same-cache, omit headers: { 'Content-Type': 'application/json' //'Content-Type': 'application/x-www-form-urlencoded' }, redirect: 'follow', //manual, *follow, error referrerPolicy: 'no-referrer', // no-referrer, *no-refer-when-downgrade, etc. body: JSON.stringfy(data) // body data type must match \"Content-Type\" header }) return response.json() // parses JSON response into native JavaScript objects } 使用 fetch() 发送 json 数据： // Post json data by fetch api fetch(url, { method: 'Post', headers: { 'Content-Type': 'application/json' }, body: JSON.stringfy(data) }) .then(res => res.json()) .then(data => console.log('success: ',data)) .catch((e) => { console.error('error: ', e) }) 通过 HTML 元素，FormData() 和 fetch() 上传文件： // Put file by fetch api const formData = new FormData() const fileField = document.querySelector('input[type=\"file\"]') formData.append('name', 'test') formData.append('file', fileField.files[0]) fetch(url, { method: 'PUT', body: formData }) .then(res => res.json()) .then(data => console.log('success: ', data)) .catch((e) => { console.error('error: ', e) }) 通过 HTML 元素，FormData() 和 fetch() 上传文件： // Post files by fetch api const filesField = document.querySelector('input[type=\"file\"][multiple]') const formData2 = new FormData() formData2.append('name', 'multiple files') for(let i = 0; i response.json()) .then(data => console.log('success: ', data)) .catch(e => console.error('error: ', e)) 从响应中读取的分块并不是按行分割的，并且是 Uint8Array 数组类型（不是字符串类型）。如果通过 fetch() 获取一个文本文件并逐行处理它，那需要自行处理这些复杂的情况： // Processing text files line by line async function* makeTextFileLineIterator(fileURL) { const utf8Decoder = new TextDecoder('utf-8') const response = new fetch(fileURL) const reader = response.body.getReader() let { value: chunk, done: readerDone} = await reader.read() chunk = chunk ? utf8Decoder.decode(chunk): '' const re = /\\n|\\r|\\r\\n/gm; let startIndex = 0 let result for(;;) { let result = re.exec(chunk) if(!result) { if(readerDone) { break } let remainder = chunk.substr(startIndex) ({ vlaue: chunk, done: readerDone} = await reader.read()); chunk = remainder + (chunk ? utf8Decoder.decode(chunk): '') startIndex = re.lastIndex = 0 continue } yield chunk.substring(startIndex, result.index) startIndex = re.lastIndex } if(startIndex 如果遇到网络故障或者服务端的 CORS 配置错误时， fetch() promise 将会 reject，带上一个 TypeError 对象 // Detecting the success of a request fetch('test.jpg') .then(response => { if(!response.ok) { throw new Error(\"Network response was not ok\") } return response.blob() }) .then(myBlob => { myImage.src = URL.createObjectURL(myBlob) }) .catch(err => console.error('error: ', error)) 除了传给 fetch() 一个资源的地址，还可以通过 Request() 构造函数来创建一个 request 对象，然后在作为参数传给 fetch()： // Customizing the request object const myHeader = new Headers() const request = new Request('test.jpg', { method: 'GET', headers: myHeader, mode: 'cors', cache: 'default' }) fetch(request) .then(response => response.blob()) .then(myBlob => myImage.src = URL.createObjectURL(myBlob)) 提示： 当请求使用 credentials: 'include' 时，响应的 Access-Control-Allow-Origin 不能使用通配符 *，在这种情况下， Access-Control-Allow-Origin 必须是当前请求的源 function 是定义一个生成器函数（generator function），它返回一个 generator 对象，generator 函数在执行时能暂停，后面又能从暂停出继续执行。调用一个 generator 函数并不会马上执行它里面的语句，而是返回一个这个生成器的迭代器（iterator）对象。当这个迭代器的 next() 方法被首次（后续）调用时，其内的语句会执行到一个出现 yield 的位置为止，yield 后紧跟迭代器要返回的值，如果使用的是 yield 则表示执行权移交给另一个生成器函数（当前生成器暂停执行）。当在生成器函数中显示 return 时，会导致生成器立即变成完成状态 Request() 构造器创建一个新的 Request 对象，语法： let myRequest = new Request(input[, init]) 不管是请求还是响应都能够包含 body 对象，body 也可以是以下任意类型的实例： ArrayBuffer ArrayBufferView(Uint8Array 等) Blob/File string URLSearchParams FormData Body 类定义了以下方法以获取 body 内容，这些方法都会返回一个别解析后的 Promise 对象和数据，相比于 XHR，这些方法让非文本化数据的使用更加简单： Request.arrayBuffer() Request.blob() Request.formData() Request.json() Request.text() JSDoc 使用JSDoc提高代码的可读性 讲的很好，脑容量要用到改用的地方，写出别人看不懂的代码不是什么能力，写出所有人能看懂的代码才是真的厉害 RESTful 理解 RESTful 架构 理解RESTful架构 越来越多的人意识到，网络即软件，而且是一种新型的软件，这种“互联网软件”采用客户端/服务端模式，建立在分布式体系上，通过互联网通信，具有高延时（hige latency），高并发等特点。网站开发，完全可以采用软件开发的模式，但是传统上，软件和网络是两个不同的领域，软件开发主要针对单机环境，网络则主要研究系统之间的通信。互联网的兴起，这两个领域开始融合，现在我们必须考虑，如何开发在互联网环境中使用的软件。 RESTful 架构是目前流行的一种互联网软件架构，它结构清晰、符合标准、易于理解、扩展方便，被多个网站所采用 起源 Fielding 在 2000 年的博士论文中提出，作者目的是在符合架构原理的前提下，理解和评估以网络为基础的应用软件的架构设计，得到一个功能强，性能好，适宜通信的架构。Fielding 将他对互联网软件的架构原则，定名为 REST，即 Representational State Transfer 的缩写，即 表现层状态变化。要理解 RESTful 架构，最好的方法就是去理解 Representational State Transfer 这个词组的意思。 资源（Resources) REST 的名称“表现层状态转化”中，省略了主语，表现层其实指的是资源（Resorces）的表现层 所谓资源，就是网络上的一个实体，或者说是网络上的一个具体的信息，可以用一个URI（统一资源定位符）指向它，每种资源对应一个特定的 URI，要获取这个资源，访问相应的 URI 即可。上网其实就是与互联网上的一系列资源的互动，调用它的URI 表现层（Representation） 资源是一种信息实体，它可以有很多种外在表现形式。我们把资源具体呈现出来的形式，叫做它的表现层（Representation）。比如，文本可以用txt格式表现，也可以用 HTML 格式、 XML 格式、 JSON 格式呈现；图片可以用 JPG 格式表现，PNG 格式表现。URI 只代表资源的实体，不代表它的具体形式，它的具体表现形式应该在 HTTP 请求的头信息中用 Accept 和 Content-Type 字段指定。 状态转化（State Transfer） 访问一个网站，就代表了客户端和服务端的一个互动过程，在这个过程中，势必涉及到数据和状态的变化。互联网通信协议 HTTP 协议是一个无状态协议，这意味着所有的状态都保存在服务器端，如果客户端想要操作服务器，必须通过某种手段让服务器端发生“状态转化”（State Transfer），而这种状态变化是建立在表现层之上的，所以就是“表现层状态转化” 客户端用到的手段只能是 HTTP 协议，具体来说就是 HTTP 协议中四个表示操作方式的动词：GET、POST、POST、PUT、 DELETE。它们分别对应四种基本操作：GET 用来获取资源，POST 用来新建资源（也可以用来更新资源），PUT 用来更新资源，DELETE 用来删除资源。 综述 综上，我们总结一下什么是RESTful 架构： 资源（Resource）：每一种 URI 表示一种资源 表现层（Representation）：客户端与服务器端传递这种资源的某种表现层 状态转化（State Transfer）：客户端通过 HTTP 四个动词对服务端资源进行操作，实现“表现层状态转化” RESTful 架构中不应该有动词 深入理解浏览器 原文：Inside look at modern web browse 翻译：深入了解现代浏览器 精读 分层结构 模块之间需要合理分工，一般称之为 renderer process 而不是 renderer thread，因为 process（进程）相比 thread（线程），之间的数据是被操作系统隔离的，为了网页间无法相互读取数据，浏览器必须为每个 tab 创建一个独立的进程，甚至每个 iframe 都必须是独立进程（但是我查询的 vue 中 tab 和 iframe 存在数据交互） UI thread 处理浏览器 UI 的展现与用户交互，比如当前加载的状态变化，历史前进后退，浏览器地址的输入、校验与监听按下 Enter 等事件，但不会涉及诸如发送请求、解析网页内容、渲染等内容 network thread 仅处理网络相关的事情，它主要关心通信协议、安全协议，目标就是快速准确的找到网站服务器，并读取其内容。network thread 会读取内容头做一些前置判断，读取内容和 renderer process 做的事情是有一定重合，但是 network thread 读取内容头仅为了判断内容类型，以便交给渲染引擎或者下载管理器（content-type 等设置），所以为了不让渲染引擎知道下载管理器的存在，读取内容头必须交给 network thread 来做 browser process 做与 renderer process 的通信， 也就是 UI thread、network thread 一旦要创建或与 renderer process 通信，都会交由它们所在的 browser process 处理 renderer process 仅处理渲染逻辑，它不关心从哪来的，比如是网络请求来的，还是 service worker 拦截后修改的，也不关心当前浏览器的状态是什么，它只管按照约定的接口规范，在指定的节点抛出回调，而修改应用状态由其它关心的模块复杂，比如 onload 回调触发后，browser process 处理浏览器的状态就是一个例子 假如 renderer process 里点击了一个新的跳转链接，这个事情是发生在 renderer process，但会交给 browser process 处理，因为每个模块解耦的非常彻底，所以任何复杂工作都能找到一个能响应它的模块，而这个模块也只要处理这个复杂工作的一部分，其余部分交给其它模块就好了，这就是大型应用维护的秘诀（类比 GFS 中的一个 master 节点，这些不就是设计的一些思想吗，说起来设计模式也只是看了一个开头） 提到加速优化，Chrome 惯用技巧就是用资源换时间（其实硬盘现在都不值钱，都是资源换时间，分布式也是想要通过空间换取其它东西）。即宁可浪费潜在资源，也要让事物尽可能的并发，这些从提前创建 renderer process、提前发起 network proces 都能看出来 从渲染分层看性能优化 渲染有 5 个重要环节：解析、样式、布局、绘图、合成，这是前端开发者日常工作中对浏览器体感最深的部分，也是优化最常发生的部分 从性能优化角度来看，解析环节可以被替代为 JS 环节，因为现代 JS 框架往往没有什么 HTML 模板内容要解析，几乎全是 JS 操作 DOM，所以可以看作 5 个新的环节：JS、样式、布局、绘图、合成 几乎每层的计算都依赖上层的结果，但并不是每层都一定会重复计算，尤其是以下几点： 修改元素的几何属性（位置、宽高等）会触发所有层的重新计算，因为这是一个非常重量级的修改 修改某个元素绘图属性（颜色、背景色），并不影响位置，则会跳过布局层 修改比如 transform 属性会跳过布局与绘图层，transform 的内容会提升到合成层并交由 GPU 渲染 隐式合成层、层爆炸、层自动合并 除了 transform、will-change 属性外，还有很多种情况元素会提升到合成层，比如 video、canvas、iframe、fixed 元素，这些都有明确的规则，所以属于显式合成 而隐式合成是指元素没有被特别标记，但也被提升到合成层的情况，这种情况常见发生在 z-index 元素产生重叠时，下方的元素显式申明提升到合成层，则浏览器为了保证 z-index 覆盖关系，就要隐式把上方的元素提升到合成层 层爆炸是指隐式合成的原因，当 css 出现一些复杂行为时（比如轨迹动画），浏览器无法实时捕捉到哪些元素位于当前元素上方，所以只好把所有元素都提升到合成层，当合成层数量过多，主线程与 GPU 的通信可能会成为瓶颈，反而影响性能 浏览器也会支持层自动合并，比如隐式提升到合成层时，多个元素会自动合并到一个合成层里。但这种方式不总是靠谱的，自动处理毕竟猜不到开发者的意图，所以最好的优化方式就是开发自己主动干预 浏览器规范由于是逐步迭代的，因此看似都在描述位置的 css 属性其实背后实现原理都是不同的，虽然这个规则体现在 W3C 规范上，但如果仅从属性名是很难看出端倪的，因此想要做极致性能优化就必须了解浏览器实现原理 深入理解浏览器一 CPU、GPU、操作系统、应用的关系 cpu：可以处理几乎所有计算，现在的cpu是多核的 gpu：开始专门为图像处理设计，现在拥有大量并行处理简单事物的能力，非常适合矩阵运算，矩阵运算又是图形学的基础，所以大量用在可视化领域 这些硬件各自都提供了一些接口供汇编语言使用，而操作系统基于它们之上用 c 语言（如Linux）将硬件管理了起来，包括进程调度、内存分配、用户内核态切换等 运行在操作系统之上的就是应用程序了，应用程序不直接和硬件打交道，而是通过操作系统间接操作硬件 为什么应用程序不能直接操作硬件呢？这样做有巨大的安全隐患，因为硬件是没有任何抽象与安全措施的，这意味着理论上一个网页可以通过 js 程序，在你打开网页时直接访问你的任意内存地址，读取你的聊天记录，甚至读取历史输入的银行卡密码进行转账操作。 进程与线程 为了让程序运行的更安全，操作系统创造了进程与线程的概念（Linux对进程与线程的实现是同一套），进程可以分配独立的内存空间，进程内可以创建多个线程进行工作，这些线程共享内存空间 因为线程间共享内存空间，因此不需通信就能交流，但内存地址相互隔离的进程间也有通信需求，需通过IPC（inter process communication）进行通信 进程之间相互独立，即一个进程挂了不会影响到其它进程，而在一个进程中可以创建一个新进程，并与之通信，所以浏览器就采用了这种策略，将UI、网络、渲染、插件、存储等模块进程独立，并且任意挂掉之后都可以被重新唤起 浏览器架构 浏览器可以拆分为许多独立的模块，比如 浏览器模块（Browser）：负责整个浏览器内行为协调，调用各个模块 网络模块（Network）：负责网络 I/O 存储模块（Storage）：负责本地 I/O 用户界面模块（UI）：负责浏览器提供给用户的界面模块 GPU模块：负责绘图 渲染模块（Rencderer）：负责渲染网页 设备模块（Device）：负责与各种本地设备交互 插件模块（Plugin）：负责处理各类浏览器插件 基于这些模块，浏览器有两种可用的架构设计：一种是少进程，一种是多进程 Chrome 多进程架构的优势 Chrome 尽量为每个 tab 单独创建一个进程，所以我们才能在某个tab未响应时，从容的关闭它，而其它tab不会受影响。不仅是tab间，一个tab内的iframe也会创建一个单独的进程 Chrome 并不满足于采用一种架构，而是在不同环境下切换不同的架构。Chrome 将各功能模块化后，就可以自由决定当前将哪些模块放在一个进程中，将哪些模块启动独立的进程，即可以在运行时决定采用哪套进程架构 浏览器的主从架构 类似应用模式的主从模式，浏览器的 Browser 模块可以看作是主模块，它本身用于协调其它模块的运行，并维持其它各模块的正常工作，在其它模块失去响应时等待或重新唤起，在模块销毁时进行内存回收 各从模块也分工明确，比如在浏览器敲击URL地址时，会先通过 UI 模块响应用户的输入，并判断输入是否是 URL 地址，若校验通过之后，会通知 Network 网络模块发送请求，UI 模块就不再关心请求是如何处理了。Network模块也是相对独立的，仅处理请求的发送与接收，如果接收到的是 HTML 网页，则交给 Render 模块进行渲染 有了这些相对独立且分工明确的模块划分后，将这些模块作为线程或进程管理就都不会影响他们的业务逻辑了，唯一影响的就是内存是否共享，以及某个模块 crash 后是否会影响其它模块了。 深入理解浏览器二 概述 重点介绍了浏览器路由跳转后发生了什么，上一篇介绍了，browser process 包含了 UI thread，network thread 和 storage thread，当我们在浏览器菜单栏输入网址并敲击回车时，这套动作均由 browser process 的 UI thread 响应 普通的跳转 UI thread 响应输入，并判断是否是合法的网址，如果是搜索协议，导致分发到另外的服务处理 如果第一步输入的是合法地址，则 UI thread 会通知 network thread 获取网页内容，network thread 会寻找合适的协议处理网络请求，一般会通过 DNS协议 寻址，通过 TLS 协议 建立安全链接。如果服务器返回了比如 301 重定向信息，network thread 会通知 UI thread 这个信息，再启动一遍第二步 读取响应内容，在这一步 network thread 会首先读取首部一些字节，即我们常说的响应头，其中包含 Content-Type 告知返回内容是什么，如果返回内容是 HTML，则 network thread 会将数据传送给 renderer process。这一步还会校验安全性，比如 CORB 或 cross-site 问题 寻找 renderer process，一旦所有检查都完成，network thread 会通知 UI thread 已经准备好跳转了（注意此时并没有加载完所有数据，第三步只是检查了首字节），UI thread 会通知 renderer process 进行渲染。为了提升性能， UI thread 在通知 network thread 的同时会实例化一个 renderer process 等着，一旦 network thread 完毕后就可以立即进入渲染阶段 确认导航。第四步后，browser process 通过 IPC 向 renderer process 传送 stream 数据，此时导航会被确认，浏览器的各个状态将会被修改，同时为了方便 tab 关闭后快速恢复，会话记录会被存储在硬盘 跳转到别的网站 如果是跳转到别的网站，在执行普通跳转流程前，还会响应 beforeunload 事件，这个事件注册在 renderer process，所以 browser process 需要检查 renderer process 是否注册了这个响应，如无必要，请勿注册。 如果跳转是 js 发出的，那么执行跳转就由 renderer process 触发，browser process 来执行，后续流程就是普通的跳转流程。需要注意的是，执行跳转时，会触发原网站 upload 等事件，这个由旧的 renderer process 响应，而新网站会创建一个新的 render process 处理，当旧网页全部关闭时，才会销毁旧的 renderer process Service Worker Service Worker 可以在页面加载前执行一些逻辑，甚至改变网页的内容，但是浏览器仍然把 Service Worker 实现在了 renderer process 中 深入理解现代浏览器三 概述 宏观介绍 renderer process 做了哪些事情。浏览器 tab 内 html、css、JavaScript 内容基本上都由 renderer process 的主线程处理，除了一些 js 代码会放在 web worker 或 service worker 内，所以浏览器主线程的核心工作就是解析 web 三件套并生成可交互的用户界面 解析阶段 首先 renderer process 主线程会解析 HTML 文本为 DOM（Document Object Model，文档对象模型），要把文本结构化才能继续处理。 对于 HTML 的 link、script、img 需要加载远程资源的，浏览器会调用 network thread 优先并行处理，但遇到 script 标签就必须停下来优先执行，因为 js 代码可能会改变任意 DOM 对象，这可能导致浏览器重新解析。如果 js 代码中没有修改 DOM 的副作用，可以添加 async， defer 标签，或则弄成 js 模块的方式，这样浏览器不必等待 js 的执行 样式计算 只有 DOM 是不够的，style 标签申明的样式需要作用在 DOM 上，所以基于 DOM，浏览器要生成 CSSOM，这个 CSSOM 主要基于 css 选择器（selector）确定作用节点的 布局 有了 DOM、CSSOM 仍然不足以绘制网页，因为仅知道结构和样式，但不知道元素的位置，这就需要生成 LayoutTree 以描述布局的结构。LayoutTree 和 DOM 结构很像，但比如 display:none 的元素不会出现在 LayoutTree 上，所以 LayoutTree 仅考虑渲染结构，而 DOM 是一个综合性描述结构，它不适合用来渲染 原文特别提到，Layout Tree 有个很大的技术难点：排版，Chrome 专门有一整个团队在攻克这个技术难题。为什么排版难：盒模型之间的碰撞、字体撑开内容导致换行，引发更大区域的的重新排版、一个盒模型撑开挤压另外一个盒模型... 布局最难的地方在于，需要对所有奇奇怪怪的布局做一个尽量合理的处理，而很多时候布局定式间的规则是相互冲突的。而且这还不考虑布局引擎的修改在数亿网页上引发 bug 的风险 绘图 最后一环 PaintRecord，绘图记录。它会记录元素的层级关系，以决定元素绘制的顺序。因为 LayoutTree 仅决定了物理结构，但不决定元素的上下空间结构 有了 DOM、CSSOM、LayoutTree、PaintRecord 之后，终于可以绘图了。然后当 HTML 变化时，重绘的代价是巨大的，因为上面的任何一步的计算结果都依赖前面一步，HTML 改变时，需要对 DOM、CSSOM、LayoutTree、PaintRecord 重新计算。 大部分时候浏览器都可以在 16 ms 内完成，使 FPS 保持在 60 左右，但当页面结构过于复杂，这些计算本身超过了 16 ms，或其中遇到了 js 代码的阻塞，都会导致用户感到卡顿。对于 js 卡顿可以通过 requestAnimationFrame 把逻辑运算分散在各帧空闲时进行，也可以独立到 web worker 里。 合成 绘图的步骤称为 rasterizing（光栅化）。在 Chrome 最早发布时，采用了一种较为简单的光栅化方案，即仅渲染可视区域内的像素点，当滚动后，再补充渲染当前滚动位置的像素点。这样做会导致渲染永远滞后于滚动 现在一般采用较为成熟的合成技术（compositing），即将渲染内容分层绘制与渲染，这可以大大提升性能，并可通过 CSS 属性 will-change 手动申明一个新层（不要滥用） 浏览器会根据 LayoutTree 分析后得到 LayerTree（层树），并根据它逐层渲染，合成层会将绘图内容切分为多个栅格并交由 GPU 渲染，因此性能会非常好 "},"languages/Node.html":{"url":"languages/Node.html","title":"Node","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 知识点讲解 example myblog 组件的概念 Node入门 绪论 JavaScript 与 node.js 简单应用 构建应用的模块 second time fs (文件系统) 回调 MongoDB 操作 spawn 的坑 child_process 介绍 exec与spawn的区别与陷阱 Node.js [toc] 作为一个异步事件驱动的 js 运行时，node.js 被设计用来构建可扩建的可扩展的网络应用 现在看的是 一起学node.js 知识点讲解 require require 可以用来加载一个文件的代码，可加载 js、json、 和 .node 后缀的文件，require的过程是i同步的 require 的目录机制是：如果目录下有 package.json 并指定了main字段，则用它，如果不存在，则一次加载 index.js 和 index.node 判断是否是程序的入口文件： require.main === module 不在最外层 require，在用到的时候 require exports 和 module.exports require 用来加载代码，而 exports 和 module.exports 用来导出代码，exports 是指向 module.exports 的引用 express express 路由 和 模板引擎 ejs，express的精髓在于中间件（middleware）的设计理念 express 中的中间件（middleware）就是用来处理请求的，当一个中间件处理完，可以通过调用 next() 传递给下一个中间件，如果没有调用 next()，则请求不会往下传递，如内置的 res.render 其实就是渲染完 html 直接返回给客户端，没有调用 next()，从而没有传递给下一个中间件。看个小例子，修改 index.js 如下： 从 GitHub 安装 express-formidable 最新版，v1.0.0 有 bug example myblog restful 是一种 api 设计风格，提出了一组api 的设计原则和约束条件 如上面删除文章的路由设计： GET /posts/:postId/remove Restful 风格的设计： DELETE /posts/:postId cookie 和 session 由于http 协议是一种无状态协议，所以服务端需要记录用户状态时，就需要session 他俩的区别： cookie是浏览器的，有大小限制，session是服务端的，没有大小限制 通常 session 的实现是基于 cookie 的， session的 id 存储于 cookie 中 session更安全，cookie 可以直接在浏览器中查看并编辑 组件的概念 上面的 ejs 模板中我们用到了 blog、user、success、error 变量，我们将 blog 变量挂载到 app.locals 下，将 user、success、error 挂载到 res.locals 下。为什么要这么做呢？app.locals 和 res.locals 是什么？它们有什么区别？ express 中有两个对象可用于模板的渲染，app.locals 和 res.locals 可以看出：在调用 res.render 的时候，express 合并（merge）了 3 处的结果后传入要渲染的模板，优先级：res.render 传入的对象> res.locals 对象 > app.locals 对象，所以 app.locals 和 res.locals 几乎没有区别，都用来渲染模板，使用上的区别在于：app.locals 上通常挂载常量信息（如博客名、描述、作者这种不会变的信息），res.locals 上通常挂载变量信息，即每次请求可能的值都不一样（如请求者信息，res.locals.user = req.session.user）。 node-mongodb-native 与 mongoose，前者是官方库，但是不支持文档校验，mongoose 通过 schema 支持文档校验 mongolass 保持了与 mongodb 一样的api，又借鉴了许多 mongoose 的优点，同时又保持了精简 Node入门 绪论 应用本身并没有什么了不起的，相比为了实现该功能书写的代码本身，我们更关注的事如何创建一个框架类对我们应用的不同模块进行干净的剥离 本书三部分结构： node.js 中进行JavaScript 开发和在浏览器中进行 js 开发的差异 node.js 应用 如何设计一个完整的应用，剖析不同的模块 JavaScript 与 node.js 现在还是一个 JavaScript 用户，而非 JavaScript 开发者，写Node.js应用是一件事情；理解为什么它们要以它们书写的这种方式来书写则意味着——你要懂JavaScript。这次是玩真的了。 要实现在后台运行 JavaScript 代码，代码需要先被解释然后正确的执行，node.js 的原理正是如此，它使用了 Google 的 V8虚拟机来解释和执行 JavaScript 代码，此外 node.js 还有许多有用的模块，node.js 事实上既是一个运行时环境，也是一个库 简单应用 目标： 用户可以通过浏览器使用我们的应用。 当用户请求http://domain/start时，可以看到一个欢迎页面，页面上有一个文件上传的表单。 用户可以选择一个图片并提交表单，随后文件将被上传到http://domain/upload，该页面完成上传后会把图片显示在页面上。 分析： 我们需要提供Web页面，因此需要一个HTTP服务器 对于不同的请求，根据请求的URL，我们的服务器需要给予不同的响应，因此我们需要一个路由，用于把请求对应到请求处理程序（request handler） 当请求被服务器接收并通过路由传递之后，需要可以对其进行处理，因此我们需要最终的请求处理程序 路由还应该能处理POST数据，并且把数据封装成更友好的格式传递给请求处理入程序，因此需要请求数据处理功能 我们不仅仅要处理URL对应的请求，还要把内容显示出来，这意味着我们需要一些视图逻辑供请求处理程序使用，以便将内容发送给用户的浏览器 最后，用户需要上传图片，所以我们需要上传处理功能来处理这方面的细节 对于node.js来说，使用 node.js，我们不仅仅事在实现一个应用，同时还实现了整个 http 服务器 构建应用的模块 server.js let http = require('http') http.createServer(function(req,res) { res.writeHeader(200, {'Content-Type': 'text/plain'}) res.write('hello, world') res.end() }).listen(8888) 我们请求了 node.js 自带的http模块，调用http模块的 createServer函数，该函数会返回一个对象，这个对象有个listen的方法，该方法有个一个数值的参数，用来指定这个http服务器监听的端口号 在 JavaScript 中，函数和其他变量一样都是可以被传递的 为什么要用函数传递的方式呢？ node.js 是基于事件驱动的回调，当我们使用 http.createServer 方法的时候，我们当然不只是想要一个侦听某个端口的服务器，我们还想它在服务器收到一个 http 请求的时候做点什么，问题是，这是异步的：请求任何时候都可能到达，但是我们的服务器却跑在一个单进程里面 写 php 应用的时候，任何时候有请求进入的时候，网页服务器（apache）就为这个请求新建一个进程，并开始执行脚本 那么在node.js 程序中，当一个新的请求到达时，我们怎么控制流程呢？ 我们创建了服务器，并且向创建它的方法传递了一个函数，无论何时我们的服务器收到一个请求，该函数就会被调用，这个就是回调，我们给某个地方传递了一个函数，这个方法在有相应事件发生的时候调用这个函数来进行回调 大部分浏览器都会在你访问 http://localhost:8888/ 时尝试读取 http://localhost:8888/favicon.ico 服务器是如何处理请求的 在函数中有两个参数：request 和 response，它们是对象，你可以使用它们的方法来处理HTTP请求的细节，并且响应请求 当收到请求时，使用 res.writeHead() 函数发送一个 http 状态 200 和 http头的内容类型，使用res.write() 函数在HTTP相应主体中发送文本，最后调用 res.end() 完成响应 把某段代码变成模块意味着我们希望提供其功能的部分，并导出到请求这个模块的脚本 我们现在可以把我们应用的不同部分放入不同的文件里，并且通过模块的方式把它们连接在一起 url 和 querystring 我们的服务器应当知道路由的存在并加以有效利用。我们当然可以通过硬编码的方式将这一依赖项绑定到服务器上，但是其它语言的编程经验告诉我们这会是一件非常痛苦的事，因此我们将使用依赖注入的方式较松散地添加路由模块（你可以读读Martin Fowlers关于依赖注入的大作来作为背景知识）。 依赖注入不应该仅仅为使用而使用，使用依赖注入可以让路由和请求处理程序之间的耦合更加松散，重用性更高 在C++或C#中，当我们谈到对象，指的是类或者结构体的实例。对象根据他们实例化的模板（就是所谓的类），会拥有不同的属性和方法。但在JavaScript里对象不是这个概念。在JavaScript中，对象就是一个键/值对的集合 -- 你可以把JavaScript的对象想象成一个键为字符串类型的字典。 此就有了简洁流畅的形如handlepathname;的表达式 server，route，requestHandlers 三个模块都有了，浏览器传给了server，再传给了route，再传给了 requestHanlders，现在需要requestHandlers做出回应了 如果回应是直接 return，当未来有请求处理程序是进行非阻塞的操作的时候，我们的应用就挂了 阻塞操作：一个工作阻塞了所有其它的处理工作 node.js 可以再不新增额外线程的情况下，依然对任务进行并行处理 child_process 可以用来执行 shell命令 然而，要用非阻塞操作，我们需要使用回调，通过将函数作为参数传递给其他需要花时间做处理的函数（比方说，休眠10秒，或者查询数据库，又或者是进行大量的计算）。 对于Node.js来说，它是这样处理的：“嘿，probablyExpensiveFunction()（译者注：这里指的就是需要花时间处理的函数），你继续处理你的事情，我（Node.js线程）先不等你了，我继续去处理你后面的代码，请你提供一个callbackFunction()，等你处理完之后我会去调用该回调函数的，谢谢！” 现在我们能够异步的运行一些命令了，模块也分开了，但是我们的应用并没有实际的用途 添加一个交互：用户选择一个文件，上传该文件，然后再浏览器中看到上传的文件 用node.js 来处理文件上传（multipart post 请求） 是比较复杂的 post请求一般都比较重，用户可能输入大量内容，用阻塞的方式处理大数据量的请求必然会导致用户操作的阻塞，为了使整个过程非阻塞，node.js会将post数据拆分成很多个小的数据块，然后通过促发特定的事件，将这些小数据块传递给回调函数，这里的特定事件就是有data事件（表示新的小数据块到达了）以及end事件（表示所有的数据都已经接收完毕） 我们需要告诉 node.js 当这些事件触发的时候，回调哪些函数，怎么告诉呢，我们通过在 request 对象上注册监听器（listener）。这里的request对象是每次接收到 http请求时候，都会把该对象传递给 onRequest 回调函数 request.addListener(\"data\", function(chunk) { // called when a new chunk of data was received }); request.addListener(\"end\", function() { // called when all chunks of data have been received }); 问题来了，这部分逻辑写在哪里呢？我们现在只是在服务器中获取到了request对象，我们并没有像之前 response 对象那样，把 request对象传递给请求路由和请求处理程序 在我看来，获取所有来自请求的数据，然后将这些数据交给应用层处理应该是http服务器要做的事，因此我们直接在服务器中处理 post 数据，然后将最终的数据传递给请求路由和请求处理器 上述代码做了三件事：首先设置了接收数据的编码格式为 utf-8 ， 然后注册了'data' 事件的监听器，用于收集每次接收到的新数据块，最后将路由的调用放到了end事件处理程序中 当前我们是把请求的整个消息体都传递给了请求路由和请求处理程序，我们应该只把 post数据中我们感兴趣的部分传递给请求路由和请求处理程序 formidable模块对解析上传的文件数据做了很好的抽象，其实说白了，处理文件上传就是处理post数据，但是，麻烦的就是在具体的处理细节 我们需要将文件读取到我们的服务器中，使用一个叫fs的模块 supervisor express 使用了 path-to-regexp 模块实现的路由匹配 const app = express() app.get('/users/:name', function(req, res) { res.send('hello, ' + req.params.name) }) 模板引擎有很多种， ejs 是其中一种 app.set('views', path.join(__dirname, 'views')) app.set('view engine', 'ejs') express 理论上基于 connect 实现的中间件 second time 我们将 / 和 /user/:name 的路由分别放到了 routes/index.js 和 routes/users.js 中，每个路由文件通过生成一个 express.Router 实例并导出，通过 app.use 挂载到不同的路径，在实际开发中推荐使用 express.Router 将不同的路由分离到不同的路由文件中 通过 app.use 加载中间件，在中间件中通过next 将请求传递到下一个中间件， next 可接受一个参数接收错误信息 fs (文件系统) fs 模块可用于与文件系统进行交互，所有的文件系统操作都具有同步的、回调的、以及基于 promise 的形式 const fs = require('fs') // 同步的示例 try { fs.unlinkSync('文件') console.log('已成功删除文件') } catch (err) { } // 回调的示例 fs.unlink('文件'， (err) => { if (err) throw err; console.log('已成功删除文件') }) // promise 的示例 (async function(path) { try { await fs.unlink(path); console.log('已成功删除文件') } catch { } })('文件') err 感觉都在第一个参数 err 优先回调风格 readFile open writeFile access stat mkdir readdir rmdir unlink 回调与基于 promise 的操作的顺序，当使用异步的方法，无法发保证顺序 fs.rename('旧文件'， '新文件'， (err) => { if(err) throw err; console.log('重命名完成') }) fs.stat('新文件', (err, stats) => { if (err) throw err: console.log(`文件属性： ${JSON.stringify(stats)}`) }) 若要正确的排序这些操作，则移动 fs.stat() 调用到 fs.rename() 操作的回调中： fs.rename('旧文件', '新文件'， (err) => { if(err) throw err; fs.stat('新文件'， (err, stats) => { if(err) throw err; console.log(`文件属性： ${JSON.stringify(stats)}`) }) }) // 或者使用 promise (async function(from, to) { try { await fs.rename(from, to); const stats = await fs.stat(to); console.log(`文件属性： $({JSON.stringigy(stats)}`) } catch (err) { console.log('出错： '， err.message) } })('旧文件'， '新文件') 回调 因为函数能够作为变量，所以可以有回调这种写法？，函数不作为变量也可以有回调这种写法吧，但是函数作为变量的话看着要清楚一点 回调应该要考虑如果出现错误的情况，error优先回调风格，约定是： callback 的第一个参数是为了 error 而保留的，一旦出现 error， callback(err) 就会被调用 第二个参数及以后的参数用于成功的结果，此时是 callback(null, res1, res2) 就会被调用 promise 对象的构造器（constructor）语法如下： let promise = new Promise(function(resolve, reject) { // executor }) 当 executor 获得了结果，无论是早还是晚都没关系，它应该调用以下回调之一： resolve(value) — 如果任务成功完成并带有结果 value。 reject(error) — 如果出现了 error，error 即为 error 对象。 由 new Promise 构造器返回的 promise 对象具有以下内部属性： state — 最初是 \"pending\"，然后在 resolve 被调用时变为 \"fulfilled\"，或者在 reject 被调用时变为 \"rejected\"。 result — 最初是 undefined，然后在 resolve(value) 被调用时变为 value，或者在 reject(error) 被调用时变为 error。 promise 只能有一个结果或者一个error promise 做出承诺之后，后者通过 then, catch, finally 接收结果或者 error pormise.then(function(result) {},function(err) {}) .then 的第一个参数是一个函数，该函数在 promise resolved 后运行并接收结果，第二个参数也是一个函数，该函数在promise rejected后运行并接收结果 let promise = new Promise(function(resolve, reject) { setTimeout(() => resolve('done!'), 1000); }) promise.then(res=>{alert(res)}, err=>{alert(err)}) let promise = new Promise(function(resolve, reject) { setTimeout(() => reject(new Error('err')), 1000) }) promise.then(res =>{alert(res)}, err => {alert(err)}) 如果我们只对成功完成的情况感兴趣，则可以只为 .then 提供一个函数，如果我们只对失败的情况感兴趣，则可以 .then(null, err) 或者 使用 catch promise 中的 .finally(f) 并不意味着要处理 promise 的结构，所以它将结果传递了下去 // 基于回调的函数 function loadScript(src, callback) { let script = document. } nodejs: 浅析高并发和分布式集群 nodejs的几个特性 单线程 异步I/O 事务驱动 分布式Node架构 event loop normal stack $\\Rightarrow$ setTimeout({}, 0) (process.nextTick、 setImmediate) $\\Rightarrow$ message Queue $\\Rightarrow$ job queue error-first callbacks promise: a proxy for a value that will eventually become available $\\Rightarrow$ async await promise: remain in a pending state \\ promisifying \\ util.promisify chaining promises: return Promise.resolve(), Promise.reject() response: status, statusText, json()(return a promise) promise.all() promise.race() prepending the async keyword to any function means that the function will return a promise const getFirstUserData = () => { return fetch('/usres.json') // get users list .then(response => respongse.json()) // parse json .then(usres => users[0]) // pick first user .then(user => fetch(`/user/${user.name}`)) // get user data .then(userResponse => userResponse.json()) // parse json } getFirstUserData() const getFirstUserData = async () => { const response = await fetch('/user.json') // get users list const users = await response.json() // parse json const user = users[0] // pick first user const userResponse = await fetch(`/users/${user.name}`) // get user data const userData = await userResponse.json // parse json return userData } getFirstUserData() Debugging promises is hard because debugger will not stop over asynchronous code. Async/await makes this very easy because to the compiler it's just like synchronous code. EventEmitter const EventEmitter = require('event') const eventEmitter = new EventEmitter() const http = require('http') const port = process.env.PORT const server = http.createServer((req, res) => { res.statusCode = 200 res.setHeader('Content-Type', 'text/html') res.end('Hello, world!') }) server.listen(port, () => { console.log(`Server running at port ${port}`) }) request http.IncomingMessage request headers and request data response http.ServerResponse perform a get request const https = request('https') const options = { hostname: 'example.com', port: 443, path: '/todos', method: 'GET' } const req = https.request(options, res => { res.on('data', d => { process.stdout.write(d) }) req.on('error', error => { console.log(error) }) }) req.end() perform a post request const https = require('https') const data = new TextEncoder().encode( JSON.stringify({ todo: 'Buy thie milk 🍼' }) ) const optoins = { hostname: 'whatever.com', por: 443, path: '/todos', method: 'POST', headers: { 'Content-Type': 'application/json', 'Content-Length': data.length } } const req = http.request(options, res => { res.on('data', d => { process.stdout.write(d) }) }) req.on('error', err => console.log(err)) req.write(data) req.end() const axios = require('axios') axios.post('https://watever.com/todos', { todo: 'but the milk' }) .then(res => { console.log(`statusCode: ${res.status}`) console.log(res) }) .catch(error => { console.log(error) }) path dirname basename extname path.basename(notes, path.extname(notes)) join resolve normalize fs.writeFile('/test.txt', content, {flag: 'a+'}, err => {}) const isFile = fileName => { return fs.lstatSync(fileName).isFile() } fs.readdirSync(folderPath).map(fileName => { return path.join(folderPath, fileName) }).filter(isFile) fs.rmdir(dir, {recursive: true}, (err) => { if(err) { throw err } console.log(`${dir} is deleted.`) }) fs-extra buffer deal with binary data why streams: 1. memory efficiency 2. time efficiency const http require('http') const fs = require('fs') const server = http.createServer((req, res) => { fs.readFile(__dirname + '/data.txt', (err, data) => { res.end(data) }) }) server.listen(3000) const http = require('http') const fs = require('fs') const server = http.createServer((req, res) => { const stream = fs.createReadStream(__dirname + '/data.txt') stream.pipe(res) }) server.listen(3000) src.pipe(dest1).pipe(dest2) MongoDB 操作 blog {$lt: } {$lte: } {$gte: } {$ne: } {$in: []} ··· mongoose spawn 的坑 使用node子进程 spawn, exec 踩过的坑 使用 spawn 的时候，子进程有太多的日志输出，导致该子进程卡在那里，没有正常或者异常的退出，文件也被占用着，最坑的是一点提示都没有 child_process 介绍 nodejs 是单线程单进程的，但是有了 child_process 模块，可以在程序中直接创建子进程，并在主进程和子进程之间实现通信 exec与spawn的区别与陷阱 exec与spawn方法的区别与陷阱 2011年的文章了，，，好老 exec 和 spawn 都是通过生成一个子进程，去执行指定的命令，但是在命令的指定上，exec 更加灵活，等于一个 shell 的命令行，他俩都有参数的 spawn 的 options 默认为： { cwd: undefined, env: process.env, setsid: false } exec 的 option 默认为： { encoding: 'utf8', timeout: 0, /*子进程最长执行时间 */ maxBuffer: 200*1024, /*stdout和stderr的最大长度*/ killSignal: 'SIGTERM', cwd: null, env: null } 注意 maxBuffer 这个参数，如果 stdout 的值超过 200 k 的时候就会杀死进程，其实spawn 表现的更差，当 spawn 的子进程的 stdout 更多的时候会出现我前文说过的问题，文章中说 spawn 没有 maxBuffer 限制，但是我个人感觉还是有 maxBuffer 的类似限制。exec 在使用便捷上要超过 spawn，且执行速度上也相差无几，但是这种便携性要付出一定的代价。在exec的options中，有一项是 maxBuffer，如果执行的 command 输出超出了这个长度，不管是采用回调函数的方式，还是emit data 事件方式传递结果，都会抛出 maxBuffer exceeded异常，并且杀死子进程 "},"languages/Python.html":{"url":"languages/Python.html","title":"Python","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 python-offer python 利用python进行数据分析第二版 python-offer python解决剑指offer和一些算法 "},"languages/TypeScript.html":{"url":"languages/TypeScript.html","title":"TypeScript","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 TypeScript 教程 简介 基础 原始数据类型 boolean 数值 字符串 空值 Null 和 Undefined 任意值 什么是任意类型 任意值的属性和方法 未声明类型的变量 类型推论 什么是类型推论 联合类型 简单例子 访问联合类型的属性或方法 对象的类型——接口 什么是接口 可选属性 任意属性 只读属性 数组的类型 [类型+方括号]表示法 数组泛型 用接口表示数组 类数组 any 在数组中的应用 函数类型 函数声明 用接口定义函数的形状 可选参数 参数默认值 剩余参数 重载 类型断言 语法 将一个联合类型断言为其中一个类型 将一个父类断言为具体的子类 将任何一个类型断言成any 将any断言成一个具体的类型 类型断言的限制 双重断言 类型断言 vs 类型转换 vs 类型声明 声明文件 进阶 类型别名 字符串字面量类型 元组 简单例子 枚举 简单的例子 手动赋值 类 类的概念 es6 中类的用法 属性和方法 类的继承 存取器 静态方法 es7 中类的用法 typescript 中类的用法 public private 和 protected 参数属性 抽象类 类的类型 类与接口 类实现接口 接口继承接口 接口继承类 泛型 简单的例子 多个类型参数 泛型约束 泛型接口 泛型类 泛型参数的默认类型 声明合并 工程 代码检查 编译选项 TypeScript 接口是一系列抽象方法的声明，是一些方法特征的集合，这些方法应该都是抽象的，需要由具体的类去实现，然后第三方就可以通过这组抽象方法调用 interface IPerson{ firstName: string, lastName: string, sayHi: () => string } let customer: IPerson = { firstName: 'Tian', lastName: 'Wu', sayHi: ():string => {return 'hello, world'} } console.log('customer: ', customer) let test: IPerson = { firstName: 'testFirst', lastName: 'testLast', sayHi: ():string => {return 'hey, I\\'m testing'} } console.log('test: ', test) interface Person { age: number } interface Musician extends Person { instrument: string } let drummer = {} drummer.age = 27 drummer.instrument = 'Drums' console.log('drummer: ', drummer) TypeScript 是面向对象的 JavaScript。 类描述了所创建的对象共同的属性和方法。 TypeScript 支持面向对象的所有特性，比如 类、接口等。 定义类的关键字为 class，后面紧跟类名，类可以包含以下几个模块（类的数据成员）： 字段 − 字段是类里面声明的变量。字段表示对象的有关数据。 构造函数 − 类实例化时调用，可以为类的对象分配内存。 方法 − 方法为对象要执行的操作。 TypeScript 支持继承类，即我们可以在创建类的时候继承一个已存在的类，这个已存在的类称为父类，继承它的类称为子类。 类继承使用关键字 extends，子类除了不能继承父类的私有成员(方法和属性)和构造函数，其他的都可以继承。 TypeScript 一次只能继承一个类，不支持继承多个类，但 TypeScript 支持多重继承（A 继承 B，B 继承 C）。 子类只能继承一个父类，typescript 不支持继承多个类，但支持多重继承 类继承后，子类可以对父类的方法重新定义，这个过程称之为方法的重写 其中super关键字是对父类的直接引用，该关键字可以直接引用父类的属性和方法 instanceof 运算符用于判断对象是否是指定的类型，如果是返回true， 否则返回false，父类包括了子类 static 关键字用于定义类的数据成员（属性和方法）为静态的，静态成员可以直接通过类名调用。（没有初始化就可以调用） 访问控制修饰符 public: 公有，可以在任何地方被访问 protected: 保护，可以被其自身及其子类和父类访问 private： 私有，只能在被其定义所在的类访问 类和接口 类可以实现接口，是有关键字implements(interface)，并将interest作为类的属性使用 鸭子类型（duck typing） （还不懂） 鸭子类型（英语：duck typing）是动态类型的一种风格，是多态(polymorphism)的一种形式。 在这种风格中，一个对象有效的语义，不是由继承自特定的类或实现特定的接口，而是由\"当前方法和属性的集合\"决定。 可以这样表述： \"当看到一只鸟走起来像鸭子、游泳起来像鸭子、叫起来也像鸭子，那么这只鸟就可以被称为鸭子。\" 在鸭子类型中，关注点在于对象的行为，能作什么；而不是关注对象所属的类型。例如，在不使用鸭子类型的语言中，我们可以编写一个函数，它接受一个类型为\"鸭子\"的对象，并调用它的\"走\"和\"叫\"方法。在使用鸭子类型的语言中，这样的一个函数可以接受一个任意类型的对象，并调用它的\"走\"和\"叫\"方法。如果这些需要被调用的方法不存在，那么将引发一个运行时错误 typescript命名空间 命名空间一个最明确的目的就是解决重名问题 如果一个命名空间在一个单独的typeScript文件忠，则应该使用三斜杠 /// 引用它 我可以认为模块就是一个文件级别的命名空间吗，这种不需要写namespace了（但是实际上不是这样的，编译的结果不一样） typescript 声明文件 TypeScript 作为 JavaScript 的超集，在开发过程忠不可避免要引用第三方的JavaScript的库，虽然可以直接通过调用库的类和方法，但是却无法使用 typeScript 诸如类型检查等特性功能。为了解决这个问题，需要将这些库里的函数和方法体去掉后只保留导出类型声明，而产生了一个描述JavaScript库和模块信息的声明文件，通过引用这个声明文件，就可以借用 typescript 的各种特性来使用库文件了 声明文件以 .d.ts 为后缀 Jest 作为 typescript 的单元测试 /** * 判断一个value是不是 NaN、null、undefined * @param value */ export function isNull(value): boolean { return String(value) ==== 'NaN' || value === null || value === void 0 } 正则表达式 （元字符感觉还行，但是简写字符集、断言自己有i点会懵） 元字符 . 匹配除换行符以外的任意字符。 [ ] 字符类，匹配方括号中包含的任意字符。 否定字符类。匹配方括号中不包含的任意字符 * 匹配前面的子表达式零次或多次 + 匹配前面的子表达式一次或多次 ? 匹配前面的子表达式零次或一次，或指明一个非贪婪限定符。 {n,m} 花括号，匹配前面字符至少 n 次，但是不超过 m 次。 (xyz) 字符组，按照确切的顺序匹配字符 xyz。 \\ 分支结构，匹配符号之前的字符或后面的字符。 \\ 转义符，它可以还原元字符原来的含义，允许你匹配保留字符 `[ ] ( ) { } . * + ? ^ $ \\ ` ^ 匹配行的开始 $ 匹配行的结束 简写字符集 . 匹配除换行符以外的任意字符 \\w 匹配所有字母和数字的字符：[a-zA-Z0-9_] \\W 匹配非字母和数字的字符：[^\\w] \\d 匹配数字：[0-9] \\D 匹配非数字：[^\\d] \\s 匹配空格符：[\\t\\n\\f\\r\\p{Z}] \\S 匹配非空格符：[^\\s] 断言 ?= 正向先行断言 ?! 负向先行断言 ? 正向后行断言 ? 负向后行断言 标记 i 不区分大小写：将匹配设置为不区分大小写。 g 全局搜索：搜索整个输入字符串中的所有匹配。 m 多行匹配：会匹配输入字符串每一行。 TypeScript 教程 入门教程 [toc] 简介 大部分JavaScript代码都只需要少量的修改就变成typescript，这得益于typescript强大的[类型推论] []，即使不去手动声明变量的类型，typescript也可以自动推论出它的类型 console.log(1 + '1'); // 打印字符串 print(1 + '1'); // python代码，报错 typescript是完全兼容JavaScript的，它不会修改JavaScript运行时的特性，所以它们完全是弱类型的，作为对比，python是强类型的 基础 原始数据类型 JavaScript的类型分为两种：原始数据类型和对象类型 原始数据类型：布尔值、数值、字符串、null、undefined、ES6中的新类型symbol，ES10中的bigint boolean 使用构造函数Boolean 创造的对象不是布尔值，布尔值boolean和布尔对象Boolean不是一个东西 let isDone:boolean = false let createByNewBoolean:Boolean = new Boolean(1) 数值 0b1010 和 0o744 是 ES6 中的二进制和八进制表示法，它们会被编译为十进制数字。 字符串 其中`用来定义定义ES6中的模板字符串，${expr}用来在模板字符串中嵌入表达式 let myName:string = 'Tom' let myAge:number = 25 //模板字符串 let sentence:string = `Hello, ${myName} will be ${myAge + 1} nest year.` 空值 JavaScript中没有空值（void）的概念，在typescript中，可以用void表示没有任何返回值的函数： function alertName(myName:string):void { alert(`my name is ${myName}.`) } 声明一个void类型的变量没有什么用，因为你只能将它复制为undefined和null let unusable:void = undefined Null 和 Undefined 在typescript中，可以用null和undefined来定义这两个原始数据类型： let u:undefined = undefined let n:null = null 于void 的区别是，undefined和null是所有类型的子类型，也就是说undefined类型的变量可以赋值给number类型的变量： let num:number = undefined // 不会报错 let u:undefined let num:number = u // 这样也不会报错 void类型不能赋值给number类型的变量 任意值 任意值（Any）用来表示允许赋值为任意类型 什么是任意类型 如果是一个普通类型，在赋值过程中改变类型是不允许的，但是如果是any类型的，则允许被赋值为任意类型 let myFavoriteNumber:string = 'seven' myFavoriteNumber = 7 // error let myFavoriteNumber:any = 'seven' myFavoriteNumber = 7 //正常 任意值的属性和方法 在任意值上访问任何属性都是允许的，也允许调用任何方法，可以认为声明一个变量是任意值之后，对它的任何操作，返回的类型都是任意值 let anyThing:any = 'hello' console.log(anyThing.myName) console.log(anThing.myName.firstName) anyThing.setName('Jerry') anyThing.setName('Jerry').sayHello() 未声明类型的变量 变量如果在声明的时候，为指定其类型，那么它会被识别为任意值类型： let something somthing = 'seven' somthing = 7 something.setName('Tom') 等价于 let something:Any somthing = 'seven' somthing = 7 something.setName('Tom') 类型推论 如果没有明确的指定类型，那么typescript会按照类型推论（Type Inference）的规则推断出一个类型 什么是类型推论 一下代码虽然没有指定类型，但是会在编译的时候报错 let myFavoriteNumber = 'seven' myFavoriteNumber = 7 // error 事实上，它等价于 let myFavoriteNumber:string = 'seven' myFavoriteNumber = 7 // error typescript会在没有明确的指定类型的时候推测出一个类型，这就是类型推论 let myFavoriteNumber myFavoriteNumber = 'seven' myFavoriteNumber = 7 如果定义的时候没有赋值，不管之后有没有赋值，都会被推断成any类型而完全不被类型检查 联合类型 联合类型（union types）表示取值可以为多种类型的一种 简单例子 let myFavoriteNumber:string|number myFavoriteNumber = 'seven' myFavoriteNumber = 7 myFavoriteNumber = true // error 联合类型使用 | 分隔每一个类型 这里 let myFavoriteNumber:string|number 的含义是 myFavorite 的类型可以是 string 或者 number， 但是不可以是其它类型 访问联合类型的属性或方法 当typescript不确定一个联合类型的变量到底是哪个类型的时候，我们只能访问此两盒类型的所有类型里共有的属性或方法 function getLength(something:string|number):number{ return something.length } // error, something 不确定类型，length只是string的属性 function getString(something:string|number):string{ return something.toString() // 正确，这是共有属性 } 联合类型的变量在赋值的时候，会根据类型推论的规则推断出一个类型： let myFavoriteNumber:string|number myFavoriteNumber = 'seven' console.log(myFavoriteNumber.length) // 正确 myFavoriteNumber = 7 console.log(myFavoriteNumber.length) // 编译时报错 对象的类型——接口 在typescript中，我们使用接口（interfaces）来定义对象的类型 什么是接口 在面向对象语言中，接口是一个很重要的概念，它是对行为的抽象，而具体如何行动需要类去实现 typescript中的接口是要给非常灵活的概念，处理可用于类的一部分行为进行抽象意外，也常对对象的形状（形状）进行描述 interface Person{ name: string; age: number; } let tom: Person = { name: 'Tom', age: 25 } 在这个例子中，我们定义了一个接口 Person，接着定义了一个变量 tom，它的类型是Person，这样我们就约束了tom的形状必须和接口Person一致 接口一般首字母大写，有些编程语言会建议接口的名称前加一个 I 定义的变量比接口少了一些属性是不允许的 interface Person { name: string; age: number; } let tom: Person = { name: 'tom' } // Propertyp 'age' is missing in type '{name: string}' 多一些属性也是不允许的： let tom: Person = { name: 'tom', age: 25, gender: 'male' } // 'gender' does not exist in type 'Person' 可见，赋值的时候，变量的形状必须和接口的形状保持一致 可选属性 有时我们希望不要完全匹配一个形状，那么可以用可选属性： interface Person { name: string; age?: number } let tom: Person = { name: 'Tom' } 但是仍然不允许添加未定义的属性 let tom: Person = { name: 'tom', age: 25, gender: 'male' } // 'gender' does not exist in type 'Person' 任意属性 有时候我们希望一个接口允许有任意的属性，可以使用如下方式： interface Person { name: string; age?: number; [propName: string]: any; } let tom: Person = { name: 'tom', gender: 'male' } 使用 [propName: string] 定义了任意属性取string类型的值 需要注意的是，一旦定义了任意属性，那么确定属性和可选属性的类型必须都是它的类型的子集 interface Person { name: string; age?: number; [propName: string]: strnig; } let tom: Person = { name: 'tom', age: 25, gender: 'male' } // error, type 'number' is not assignable to type 'string' 上例中，任意属性的值允许是 string，但是可选属性age的值确实number，number不是string的子属性，所以报错了 一个接口中只能定义一个任意属性，如果接口中有多个类型的属性，则可以在任意属性中使用联合类型 只读属性 有时候我们希望对象中的一些字段只能在创建的时候赋值，那么可以使用readonly定义只读属性： interface Person { readonly id: number; name: string; age?: number; [propName: string]: any; } let tom: Person = { id: 1, name: 'tom', gender: 'male' } tom.id = 2 // error, id is read-only 注意，只读的约束存在于第一次给对象赋值的时候，而不是第一次给只读属性赋值的时候 let tom: Person = { name: 'tom' } tom.id = 1 // error 两个错误，第一次初始化没有给id赋值，重新给id赋值的时候已经晚了 数组的类型 在typescript中，数组类型有多种定义方式，比较灵活 [类型+方括号]表示法 最简单的方法是使用[类型+方括号]来表示数组： let fibonacci: number[] = [1, 1, 2, 3] 数组的项中不允许出现其它的类型，数组的一些方法的参数也会根据数组在定义时按约定的类型进行限制 let fabonacci: number[] = [1, '1', 2, 3] // error, 类型不对 let fibonacci.push('5') // error, 方法也被类型限制了 上例中，push 方法只允许传入number类型的参数 数组泛型 我们也可以使用数组泛型（array generic）Array 来表示数组： let fibonacci: Array = [1, 1, 2, 3, 5] 用接口表示数组 interface NumberArray { [index: number]: number; } NumberArray 表示： 只要索引的类型是数字时，那么值的类型必须是数字 虽然接口也可以用来描述数组，但是我们一般不会这么做，因为这种方式比前两种复杂多了 有一种情况例外： 类数组 类数组 类数组（Array-like Object）不是数组类型，比如arguments： function sum() { let args: number [] = arguments } // error, 类数组不能用普通的数组的方式描述，而应该用接口 function sum() { let args: { [index: number]: number; length: number; callee: Function; } = arguments } 事实上常用的类数组都有自己的接口定义，如 IArguments， NodeList， HTMLCollectoin等： function sum() { let args: IArguments = arguments } any 在数组中的应用 一个比较常见的做法是，用 any 表示数组中允许出现任意类型： let list: any[] = ['xcatliu', 25, { website: 'http://xcatliu.com' }]; 函数类型 函数是JavaScript中的一等公民 函数声明 在JavaScript中，有两种常见的定义函数的方式：函数声明和函数表达式 // 函数声明（Function Declaration） function sum(x, y) { return x + y } // 函数表达式（Function Expression) let mySum = function(x, y) { return x + y } 一个函数有输入输出，要在typescript中对其进行约束，需要把输入和输出都考虑到，其中函数声明的类型定义较为简单： function sum(x: number, y: number): number { return x + y } 输入多余的（或者少于要求的）参数，都是不允许的 函数表达式在typescript中的定义： let mySum = function(x: number, y: number): number { return x + y } 事实上，我们只对右侧的匿名函数进行了类型定义，而等号左边的可以通过赋值操作进行类型推论而推断出来，如果我们需要手动给mySum添加对象，则应该是这样： let mySum:(x: number, y: number) => number = function(x: number, y: number): number { return x + y } 注意不要混淆了typescript中的 => 和ES6 中的 => 在typescript中，=> 用来表示函数的定义，左边是输入类型，需要用括号，右边是输出类型，es6 中这个是箭头函数 用接口定义函数的形状 我们也可以使用接口的方式来定义一个函数需要符合的形状： interface SearchFunc { {source: string, subString: string}: boolean } let mySearch: SearchFunc mySearch = function(source: string, subString: string) { return source.search(sbString) != -1 } 采用函数表达式|接口定义函数的方式时，对等号左侧进行类型限制，可以在以后对函数名赋值时保证参数个数、参数类型、函数值返回不变 可选参数 前面提到，输入多余的（或者少于要求的）参数，是不被允许的，那么如何定义可选参数呢，与接口类似，我们用 ？ 表示可选的参数 function buildName(firstName: string, lastName?: string) { if(lastName) { return firstName + ' ' + lastName } else { return firstName } } 可选参数后面不允许再出现必需参数了 参数默认值 在 ES6 中，我们允许给函数的参数添加默认值，typescript会将添加量默认值的参数识别为可选参数，这时候就可以不受顺序影响 剩余参数 ES6中，可以使用 ...rest 的方式获取函数中的剩余参数 function push(array, ..items) { items.forEach(function(item) { array.push(item) }) } 事实上items是一个数组，我们可以用数组的类型来定义它 function push(array: any[], ...items: any[]) { items.forEach(function(item) { array.push(item) }) } rest参数只能是最后一个参数 重载 重载允许一个函数接受不同数量或类型的参数时，做出不同的处理 function reverse(x: number | string): number | string | void { if(typeof x === 'number') { return Number(x.toString().split('').reverse().join('')) } else if(typeof x === 'string') { return x.split('').reverse().join('') } } 然而这样有一个缺点，就是不够精确的表达，输入数字的时候，输出也应该是数字，输入是字符串的时候，输出也应该是字符串 function reverse(x: number): number; function reverse(x: string): string; function reverse(x: number | string): number | string | void { if(typeof x === 'number') { return Number(x.tostring().split('').reverse().join('')) } else if(typeof x === 'string') { return x.split('').reverse().join('') } } typescript会优先从最前面的函数定义开始匹配，所以多个函数定义如果有包含关系，需要优先把精确的定义写在前面 类型断言 类型断言（type assertion）可以用来手动指定一个值的类型 语法 值 as 类型 或者 值 tsx语法必须使用前者，建议在使用类型断言时，统一使用 值 as 类型 这样的语法 将一个联合类型断言为其中一个类型 interface Cat { name: string; run(): void; } interface Fish { name: string; run(): void; } function isFish(animal: Cat | Fish) { if(typeof animal.swim === 'function') { return true } return false } // Error, Property 'swim' does not exit on type 'Cat' function isFish(animal: Cat | Fish) { if (typeof (animal as Fish).swim === 'function') return true return false } 这样就可以解决访问 animal.swim 报错的问题，但是类型断言只能够欺骗typescript编译器，无法避免运行时的错误，滥用类型断言可能会导致运行时错误 将一个父类断言为具体的子类 当类之间有继承关系时，类型断言也很常见 class ApiError extends Error { code: number = 0 } class HttpError extends Error { statusCode: number = 200 } function isApiError(error: Error) { if(typeof (error as ApiError).code === 'number') { // instanceof 也是一个办法，如果判断的是类的话 return true } return false } 将任何一个类型断言成any 在any类型的变量上，访问任何属性都是允许的，但是将一个变量断言成any可以说是解决typescript中类型问题的最后一个手段 它极有可能掩盖了真正的类型错误，所以如果不是非常确定，不要使用 as any (window as any).foo = 1 上面例子中最好的解决办法是扩展window 的类型，但是使用 as any 更加方便 我们需要在类型的严格性和开发的便利性之间掌握平衡 将any断言成一个具体的类型 遇到 any 类型的变量时，我们可以选择无视它，任由它滋生更多的 any。 我们也可以选择改进它，通过类型断言及时的把 any 断言为精确的类型，亡羊补牢，使我们的代码向着高可维护性的目标发展。 类型断言的限制 联合类型可以被断言为其中一个类型 父类可以被断言为子类 任何类型都可以被断言为 any any 可以被断言为任何类型 要使得 A 能够被断言为 B，只需要 A 兼容 B 或 B 兼容 A 即可 前四种情况都是最后一个的特例 双重断言 既然任何类型都可以被断言成any，any可以被断言成任何类型，双重断言基本就可以断言成想要的类型，但是这样做的大部分都是错误的 类型断言 vs 类型转换 vs 类型声明 类型断言只会影响 typescript编译时的类型，类型断言语句会在编译结果中被删除 function toBoolean(something: any): boolean { return something as boolean } toBoolean(1) // 返回值 1 // 编译结果 function toBoolean(something: any): boolean { return something } toBoolean(1) 类型转换就是一句允许的语句了 animal 断言为 Cat，只需要满足 Animal 兼容 Cat 或 Cat 兼容 Animal 即可 animal 赋值给 tom，需要满足 Cat 兼容 Animal 才行 我们还有第三种方式可以解决这个问题，那就是泛型 声明文件 当使用第三方库时，我们需要引用它的声明文件，才能获得对应的代码补全、接口提示等功能。 declare var 声明全局变量 declare function 声明全局方法 declare class 声明全局类 declare enum 声明全局枚举类型 declare namespace 声明（含有子属性的）全局对象 interface 和 type 声明全局类型 export 导出变量 export namespace 导出（含有子属性的）对象 export default ES6 默认导出 export = commonjs 导出模块 export as namespace UMD 库声明全局变量 declare global 扩展全局变量 declare module 扩展模块 /// 三斜线指令 暴露在最外层的interface 或 type 会作为全局类型作用于整个项目中，我们应该尽可能的减少全局变量或全局类型的变量，故最好将它们放到namespace下 注意只有function、class和interface可以直接默认导出，其它的变量需要先定义出来，在默认导出 进阶 类型别名 类型别用来给一个类型起一个新的名字 type Name = string type NameResolver = () => string type NameOrResolver = Name | NameResolver function getName(n: NameOrResolver) : Name { if(typeof n === 'string') return n return n() } 字符串字面量类型 字符串字面量类型用来约束取值只能是某几个字符串中的一个(枚举？) type EventNames = 'click' | 'scroll' | 'mousemove' function handleEvent(ele: Element, event: EventNames) { } handleEvent(document.getElementById('hello'), 'scroll') // 没问题 handleEvent(document.getElementById('hello'), 'dbclick') // error 没有这个类型 我们使用type定义了一个字符串字面量类型，它只能取这几个字符串中的一个 类型别名与字符串字面量类型都使用 type 进行定义 元组 数组合并了相同类型的对象，而元组（tuple）合并了不同类型的对象 简单例子 let tom: [string, number] = ['Tom', 25] tom[0] = 'Tom' // 可以只赋值其中一项 tom = ['Tom', 25] // 直接对元组类型的变量进行初始化，需要提供所有元组类型中指定的项 枚举 枚举（Enum）类型用于取值被限定在一定范围内的场景，比如一周内只有七天 简单的例子 枚举成员会被赋值为从0开始递增的数字，同时也会对枚举值到枚举名进行反向映射 enum Days {Sun, Mon, Tue, Wed,Thu, Fri, Sat} console.log(Days[\"Sun\"] === 0); // true console.log(Days[\"Mon\"] === 1); // true console.log(Days[\"Tue\"] === 2); // true console.log(Days[\"Sat\"] === 6); // true console.log(Days[0] === \"Sun\"); // true console.log(Days[1] === \"Mon\"); // true console.log(Days[2] === \"Tue\"); // true console.log(Days[6] === \"Sat\"); // true // 事实上，上面会被编译成 var Days; (function (Days) { Days[Days[\"Sun\"] = 0] = \"Sun\"; Days[Days[\"Mon\"] = 1] = \"Mon\"; Days[Days[\"Tue\"] = 2] = \"Tue\"; Days[Days[\"Wed\"] = 3] = \"Wed\"; Days[Days[\"Thu\"] = 4] = \"Thu\"; Days[Days[\"Fri\"] = 5] = \"Fri\"; Days[Days[\"Sat\"] = 6] = \"Sat\"; })(Days || (Days = {})); 手动赋值 enum Days {Sun = 7, Mon = 1, Tue, Wed, Thu, Fri, Sat}; console.log(Days[\"Sun\"] === 7); // true console.log(Days[\"Mon\"] === 1); // true console.log(Days[\"Tue\"] === 2); // true console.log(Days[\"Sat\"] === 6); // true 未手动赋值的枚举项会接着上一个枚举项递增。 类 在传统方法中，JavaScript通过构造函数实现类的概念，通过原型链实现继承，而在es6中，我们终于迎来的class 类的概念 类（Class）：定义了一件事物的抽象特点，包含它的属性和方法 对象（Object）：类的实例，通过 new 生成 面向对象（OOP）的三大特性：封装、继承、多态 封装（Encapsulation）：将对数据的操作细节隐藏起来，只暴露对外的接口。外界调用端不需要（也不可能）知道细节，就能通过对外提供的接口来访问该对象，同时也保证了外界无法任意更改对象内部的数据 继承（Inheritance）：子类继承父类，子类除了拥有父类的所有特性外，还有一些更具体的特性 多态（Polymorphism）：由继承而产生了相关的不同的类，对同一个方法可以有不同的响应。比如 Cat 和 Dog 都继承自 Animal，但是分别实现了自己的 eat 方法。此时针对某一个实例，我们无需了解它是 Cat 还是 Dog，就可以直接调用 eat 方法，程序会自动判断出来应该如何执行 eat 存取器（getter & setter）：用以改变属性的读取和赋值行为 修饰符（Modifiers）：修饰符是一些关键字，用于限定成员或类型的性质。比如 public 表示公有属性或方法 抽象类（Abstract Class）：抽象类是供其他类继承的基类，抽象类不允许被实例化。抽象类中的抽象方法必须在子类中被实现 接口（Interfaces）：不同类之间公有的属性或方法，可以抽象成一个接口。接口可以被类实现（implements）。一个类只能继承自另一个类，但是可以实现多个接口 es6 中类的用法 属性和方法 使用class定义类，使用constructor定义构造函数 通过new生成新实例的时候，会自动调用构造函数 class Animal { public name; constructor(name) { this.name = name } sayHi() { return `my name is ${this.name}` } } let tian = new Animal('Tian') console.log(tian.sayHi()) // my name Tian 类的继承 使用extends关键字实现继承，子类中使用super关键字来调用分类的构造函数和方法 class Cat extends Animal { constructor(name) { super(name); // 调用父类的构造方法 console.log(this.name) } sayHi() { return 'Meow,' + super.sayHi() } } let mango = new Cat('Mongo') console.log(mongo.sayHi()) // Meow, my name is Mongo 存取器 使用getter和setter可以改变属性的赋值和读取行为 class Animal { constructor(name) { this.name = name } get name() { return 'Jack' } set name(value) { console.log('setter: ' + value) } } let test = new Animal('Kitty') test.name = 'Tom' // setter： Tom console.log(test.name) // Jack 静态方法 使用 static 修饰符修饰的方法称为静态方法，他们不需要实例化，而是直接通过类来调用 class Animal { static isAnimal(a) { return a instanceof Animal } } lat a = new Animal('Jack') Animal.isAnimal(a) // true a.isAnimal(a) // error, a.isAnimal is not a function es7 中类的用法 ES6 中实例的属性只能通过构造函数中的 this.xxx 来定义，ES7 提案中可以直接在类里面定义 ES7 提案中，可以使用 static 定义一个静态属性 typescript 中类的用法 public private 和 protected TypeScript 可以使用三种访问修饰符（Access Modifiers），分别是 public、private 和 protected。 public 修饰的属性或方法是公有的，可以在任何地方被访问到，默认所有的属性和方法都是 public 的 private 修饰的属性或方法是私有的，不能在声明它的类的外部访问 protected 修饰的属性或方法是受保护的，它和 private 类似，区别是它在子类中也是允许被访问的 当构造函数修饰为private，该类不允许被继承或者实例化，当构造函数修饰为protected时，该类只允许被继承，不能用super来调用 参数属性 修饰符和readonly还可以使用在构造函数参数中，等同于类中定义该属性同时给该属性赋值，使代码更简洁。 只读属性关键字 readonly，只允许出现在属性声明或索引签名或构造函数中。 抽象类 abstract 用于定义抽象类和其中的抽象方法 抽象类是不允许被实例化的 abstract class Animal { public name; public constructor(name) { this.name = name } public abstract sayHi() } let a = new Animal('Jack') // error， cannot create an instance of the abstract class 其次，抽象类中的抽象方法必须被子类实现： abstract class Animal { public name; public constructor(name) { this.name = name } public abstract sayHi() } // 子类实现 class Cat extends Animal { public sayHi() { console.log(`Meow, My name is ${this.name}`); } } 类的类型 给类加上typescript中的类型很简单，与接口类似： class Animal { name: string; constructor(name: string) { this.name = name } sayHi(): string { return `my name is ${this.name}` } } let a:Animal = new Animal('Jack') console.log(a.sayHi()) 类与接口 接口可以用于对对象的形状进行描述，也可以对类的一部分行为进行抽象 类实现接口 实现（implements）是面向对象中的一个重要概念，一般来说，一个类只能继承自另一个类，有时候不同了类之间可以有一些共有的特性，这时候就可以把特性提取成接口（interfaces），用 implements 关键字来实现，这个特性大大提高了面向对象的灵活性 举例来说，门是一个类，防盗门是门的子类。如果防盗门有一个报警器的功能，我们可以简单的给防盗门添加一个报警方法。这时候如果有另一个类，车，也有报警器的功能，就可以考虑把报警器提取出来，作为一个接口，防盗门和车都去实现它 interface Alarm { alert(): void } class Door {} class SecurityDoor extends Door implements Alarm { alert() { console.log('SecurityDoor alert') } } class Car implements Alarm { alert() { console.log('Car alert') } } 一个类可以实现多个接口 interface Alarm { alert(): void } interface Light { lightOn(): void; lightOff(): void; } class Car implements Alarm, Light { alert() { console.log('Car alert') } lightOn() { console.log('Car light on') } lightOff() { console.log('Car light off') } } 接口继承接口 接口与接口之间可以是继承关系： interface Alarm { alert(): void; } interface LightableAlarm extends Alarm { lightOn(): void; lightOff(): void; } 接口继承类 常见的面向对象语言中，接口是不能继承类的，但是在 TypeScript 中却是可以的： class Point { x: number; y: number; constructor(x: number, y: number) { this.x = x; this.y = y; } } interface Point3d extends Point { z: number; } let point3d: Point3d = {x: 1, y: 2, z: 3}; 当我们在声明 class Point 时，除了会创建一个名为 Point 的类之外，同时也创建了一个名为 Point 的类型 「接口继承类」和「接口继承接口」没有什么本质的区别 泛型 泛型（Generics）是指在定义函数、接口或类的时候，不预先指定具体的类型，而在使用的时候再指定类型的一种特性 简单的例子 首先，我们来实现一个函数 createArray，它可以创建一个指定长度的数组，同时将每一项都填充一个默认值： function createArray(length: number, value: any): Array { let result = []; for (let i = 0; i 这个函数使用了数组泛型来定义返回值的类型，这段代码有一个缺陷，它并没有准确的定义返回值的类型： Array允许数组的每一项都是任意类型，但是实际上我们希望每一项都是 value 的类型 function createArray(length: number, value: T): Array { let result: T[] = []; for(let i = 0; i (3, 'x') // ['x', 'x', 'x'] 调用的时候可以不指定 T 的具体类型，而让类型推论自动推论出来 多个类型参数 定义泛型的时候，可以一次定义多个类型参数： function swap(tuple: [T, U]): [U, T] { return [tuple[1], tuple[0]] } swap([7, 'seven']) // ['seven', 7] 泛型约束 再函数内部使用泛型变量的时候，由于事先不指定它是那种类型，所以不能随意的操作它的属性 function loggingIdentity(arg: T): T{ console.log(arg.length) return arg } // error, Property 'length' does not exist on type 'T' 泛型 T 不一定包含属性 length，所以编译的时候报错了，这时候我们可以对泛型进行约束，只允许这个函数传入那些包含length属性的变量，这就是泛型约束： interface Lengthwise { length: number } function loggingIdentity(arg: T): T{ console.log(arg.length) return arg } 我们使用了 extends 约束了泛型 T 必须符合接口 Lengthwise 的形状，也就是必须包含 length 属性 此时如果调用 loggingIdentity 的时候，传入的 arg 不包含 length，那么在编译阶段就会报错了 多个类型参数之间也可以互相约束： function copyFields(target: T, source: U): T { for (let id in source) { target[id] = (source)[id]; } return target; } let x = { a: 1, b: 2, c: 3, d: 4 }; copyFields(x, { b: 10, d: 20 }); 上例中，我们使用了两个类型参数，其中要求 T 继承 U，这样就保证了 U 上不会出现 T 中不存在的字段。 泛型接口 可以使用接口的方式来定义一个函数需要符合的形状： interface SearchFunc { (source: string, subString: string): boolean; } let mySearch: SearchFunc; mySearch = function(source: string, subString: string) { return source.search(subString) !== -1; } 当然也可以使用含有泛型的接口来定义函数的形状： interface CreateArrayFunc { (length: number, value: T):Array } 泛型类 与泛型接口类似，泛型也可以用于类的类型定义汇总： class GenericNumber { zeorValue: T; add: (x: T, y:T) => T } let myGenericNumber = new GentericNumber(); myGenericNumber.zeroValue = 0 myGenericNumber.add = function(x, y) {return x + y}; 泛型参数的默认类型 在 TypeScript 2.3 以后，我们可以为泛型中的类型参数指定默认类型。当使用泛型时没有在代码中直接指定类型参数，从实际值参数中也无法推测出时，这个默认类型就会起作用。 function createArray(length: number, value: T): Array { let result: T[] = []; for (let i = 0; i 声明合并 如果定义了两个相同名字的函数、接口或类，它们会合并成一个类型 合并的属性的类型必须是唯一的 工程 掌握了typescript的语法就像是学会了砌墙的工艺 代码检查 代码检查主要是用来发现代码错误，同意代码风格，eslint 用的比较多 编译选项 TypeScript 提供了非常多的编译选项，但是官方文档对每一项的解释很抽象，这一章会详细介绍每一个选项的作用，并给出对应的示例。 "},"skills/Docker.html":{"url":"skills/Docker.html","title":"Docker","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 前言 Docker 简介 基本概念 镜像 容器 仓库 安装Docker Docker gitbook [toc] 前言 Docker是个划时代的开源项目，它彻底释放了计算虚拟化的威力，极大的提高了应用的维护效率，降低了云计算应用开发的成本，使用Docker，可以让应用的部署、测试和分发都变得前所未有的高效和轻松 Docker 简介 Docker 在容器的基础上，进行了进一步的封装，从文件系统、网络互联到进程隔离等等，极大的简化了容器的创建和维护，使得Docker技术比虚拟机技术更为轻便、快捷 更高效的利用系统资源 快速的启动时间 一直的运行环境 持续交付和部署 更轻松的迁移 更轻松的维护和扩展 基本概念 Docker 包括三个基本概念：镜像（Image）、容器（Container）、仓库（Repository） 镜像 们都知道，操作系统分为 内核 和 用户空间。对于 Linux 而言，内核启动后，会挂载 root 文件系统为其提供用户空间支持。而 Docker 镜像（Image），就相当于是一个 root 文件系统。 Docker 镜像 是一个特殊的文件系统，除了提供容器运行时所需的程序、库、资源、配置等文件外，还包含了一些为运行时准备的一些配置参数（如匿名卷、环境变量、用户等）。镜像 不包含 任何动态数据，其内容在构建之后也不会被改变。 容器 镜像（Image）和容器（Container）的关系就像是面向对象程序设计中的类和实例一眼，镜像是静态的定义，容器是镜像运行时的实体，容器可以被创建、启动、停止、删除、暂停等 容器的实质是进程，但与直接在宿主执行的进行不同，容器进程运行于属于自己的独立的命名空间，因此容器可以拥有自己的root文件系统，自己的网络配置、自己的进程空间，容器的进程是运行在一个隔离的环境里。容器不应该向其存储层中写入任何数据、容器存储层要保持无状态化。所有的文件写入操作，都应该使用数据卷（Volume）或者绑定宿主目录 仓库 镜像构建完成后，可以很容易在当前宿主机上运行，但是，如果需要在其它服务器上使用这个镜像，我们就需要一个几种的存储、分发镜像的服务，Docker Registry 就是这样的服务 一个 Docker Registry 中可以包含多个仓库（Repository），每个仓库可以包含多个标签，每个标签对应一个镜像 安装Docker Docker分为 stable test 和 nightly 三个更新频道 "},"skills/Git.html":{"url":"skills/Git.html","title":"Git","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 起步 本地版本控制系统 Git Introduction to Git Commits(branching, merging, rebasing, etc) Git Remotes Git ProGit 起步 版本控制是一种记录一个或若干文件内容变化，以便将来查阅特定版本修订情况的系统（可以对任何文件进行版本控制） 本地版本控制系统 许多人习惯用复制整个项目目录的方式来保存不同的版本，或许还会改名加上备份时间以示区别。 这么做唯一的好处就是简单，但是特别容易犯错。 有时候会混淆所在的工作目录，一不小心会写错文件或者覆盖意想外的文件。 为了解决这个问题，人们很久以前就开发了许多种本地版本控制系统，大多都是采用某种简单的数据库来记录文件的历次更新差异。 Git learn Git Branching Introduction to Git Commits(branching, merging, rebasing, etc) commit: records a snapshot of all files(even better) branch early, and branch often(branches are pointers to a specific commit) Git rebase: second way of combining work hash $\\Rightarrow$ relative refs git branch -f main HEAD~1 git reset / git revert I want this work here and that work there git cherry-pick git rebase -i juggling commits Git Remotes You can typically talk to this other computer through the Internet, which allows you to transfer commits back and forth. git pull $\\rightleftarrows$ git fetch; git merge o/main The difficulty comes in when the history of the repository diverges. git fetch $\\Rightarrow$ git rebase o/main $\\Rightarrow$ git push $\\rightleftarrows$ git pull git fetch $\\Rightarrow$ git merge o/main $\\Rightarrow$ git push $\\rightleftarrows$ git pull --rebase "},"skills/Linux.html":{"url":"skills/Linux.html","title":"Linux","keywords":"","body":"Linux "},"skills/画图.html":{"url":"skills/画图.html","title":"画图","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 架构图 前言 架构分类 技术文章配图指南 概述 画图 样式 [toc] 架构图 思否 思否 前言 程序代码本身就是一种数学逻辑的具体体现，如果没有一些图表配合文字的阐述，很难让所有人都能在共同的共识下进行交流。 而我们画的架构图、流程图、结构图、功能图、逻辑图等，都需要好看、好懂、好用、好搞，因为： 好看是为了提升沟通效率， 好懂是为了提升交流共识， 好用是为了提升交付质量， 好搞是为了提升实施速度。 架构分类 业务架构：需求初期业务的结果和过程描述一般比较模糊，可能来自于某个老板、运营或用户的反馈。客户说海尔洗衣机洗土豆会堵，海尔立马设计专门的土豆洗衣机 业务方向往往是定方向和结果的叫战略，主要包括业务规划、业务模块和流程以及问题域的列表等。 应用架构：服务复用、跨组协同，简单、灵活、整合是应用架构必须考虑的点，就像你要上线一个聊天功能，那么聊天内容的输入法、文字识别、舆情监控以及视频服务、支付服务等，它们都是在应用架构分层下沉淀到平台的产物，在供各个方使用。 产品架构：业务提需求，产品定方案，相对于业务的粗放流程，产品架构会更加细腻以及考虑各个模块的分层和边界。 数据架构：数据的获取、数据的存放和数据的使用是数据架构要解决的三个问题，数据库存放、大数据汇总、数据分析等。 技术架构：是离程序员最近的架构设计，它不仅是系统搭建的架构图设计，还包括了结构、功能、流程、逻辑等内容。它的具体描述就是整个系统如何落地的具体实现方案。 业务架构 应用架构 产品架构 数据架构 技术架构 技术文章配图指南 draveness 无论是使用Photoshop还是 OmniGraffle 甚至是其它工作都能达到完全相同的效果，更加重要的是我们对于制图规则的思考并形成一套自洽的体系。 概述 作者的画图准则： 图片必须足够美观并且清晰地传达想要表现的内容； 是技术博客中出现图片的意义； 图片必须能够在短时间内实现量产，不影响写作的效率； 博客中的全部图片都是在写作的过程中一一绘制的，而不是最后统一完成的，所以会希望画图的时间可以尽量短，一旦画图的时间超过过长，那么整个思路就会被打断； 博客的内容和逻辑相比于图片更加重要，作者不希望在上面花费过长的时间； 图片需要保证风格上的一致性，不会显得非常突兀； 图片的风格和配色对于作者来说就是签名，形成统一的风格之后会给读者留下比较深的印象； 作者推荐： Sketch（明年筹钱买一个mac） 画图 为技术文章绘制图片和使用PS修改图片或者为App绘制UI设计图是完全不同的，技术文章的配图主要作用还是为了辅助说明内容，相比于图片的样式，我们应该更加关注图片的内容是否清晰和简单。 图片的内容是配图时至关重要的，作者在一个问题太过复杂或者连续文字太多时，就会选择为文章插入适合的图片。作者将博客中的图片简单分成了一下三类： 用于展示多个平等的概念时 用于描述模块以及概念之间的关系时 用于描述特定场景下概念的特性 在需要展示某个问题的多个方面、多个原因或者阶段等处于相同层次的概念时就会使用如下所示的图片： 这张图片介绍了选择版本控制系统时应该关注的三个特性：分布式、性能和可靠性，使用列表的方式也是没有问题的，这只是作者的配图习惯，而你在这篇文章稍微靠前的部分中也会看到用于展示绘图工具的插图，这些图片的内容类型都是相似的。 除了展示概念的配图之外，作者还会使用如下所示的图片来展示不同概念或者模块之间的关系，流程图、架构图等类型的图片都会被作者归到这一类中： 上述图片展示了在分布式的版本控制系统中，各个仓库之间的树形结构，图中使用不同的颜色将不同仓库在树中的高度做出了区分，这种图片能够很好地帮助读者理解各个模块之间的关系，我们在 LucidChart 一节中分享的图片其实也属于这种类型的图片，只是使用的工具不同： 除了这两种比较常见的插图类型之外，作者在遇到一些特殊问题时也会选择通过图片帮助读者理解问题，例如 为什么 DNS 使用 UDP 协议 中就使用了如下所示的图片： 这张巨型图片的主要作用就是帮助读者理解 DNS 协议使用 TCP 或者 UDP 获取域名解析时所需要传输数据的大小，通过这张图片我们能够比较直观的了解不同协议在处理 DNS 协议时在数据方面的差别。 样式 图片的内容是它的核心价值所在，而图片的样式是决定图片是否『优雅』的关键，内容和样式之间的关系，就是 Web 前端中 HTML 和 CSS 的关系一样，我们在这一节中就详细介绍作者对于博客中图片样式的一些约定。 调色： Coolors 长宽： 宽度 1200px，长度不宜太长 字号：标题 30px，非标题字号：20 px 圆角：能用圆角就用圆角，显得柔和 "},"temp/TestForS.html":{"url":"temp/TestForS.html","title":"TestForS","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 中途隔了几天了，review一下： 简介 安装Vue Cli 后端项目创建 前端使用element 前端路由 后面的地址成为hash，有#号成为hash模式，另一种常用的前端模式是history模式，模式的原理是先把页面的状态保存到一个对象（state）里，当页面的 URL 变化时找到对应的对象，从而还原这个页面 后端拦截器 数据库 review到此结束 写了加深记忆的 前后端分离的意思是通过RESTful API 传递JSON数据进行交流，后端不交涉页面内容。 前端用前端的服务器(Nginx)，后端用后端的服务器（Tomcat），通过前端的服务器将前端的请求发送给后端的服务器，这就成为反向代理，反向代理可以不暴露服务器的真实地址 真实的项目中，直接将账号密码写上去太危险了了，一般的做法是存储密码等信息的hash值 使用数据库验证的逻辑和前面类似，大致如下： 获得前端发送过来的用户名和密码信息 查询数据库中是否存在相同的一对用户名和密码 如果存在返回200，否则返回失败代码400 对UserDAO进行了二次封装，我们再DAO中定义了基础的增删改查操作，而具体的操作应该是再Service里面进行完成 这个项目将会很长的时间都会采用这种简单的三层架构：DAO + Servic + Controller DAO用于与数据库交互，定义增删改查操作 Service负责业务逻辑，跟功能有关的代码一般都写在这里，编写、调用各种方法对DAO取得的数据进行操作 Controller 负责数据交互，即接受前端发送的数据，通过调用Service获得处理后的数据并返回 在实践中我们一般倾向于让Controller清凉一些，以方便代码的阅读者快速找到分析功能的入口 在这个看脸的时代，代码写的烂，界面写的也不好，就真的没救了，所以所我们需要element等组件，为什么我的element总是没有引用进去啊 登录的页面似乎较为完善了，但是我们这个登录页面其实没有用，因为别人直接输入首页的网址就可以进去了，为了防止别人绕过登录页面，我们需要做一个拦截器。 登录界面做完，我们差不多就理解了项目的构成，之后的开发就可以直接集中在业务功能的实现上面了，之后的基本模式就是前端开发组件，后端开发控制器，调试功能 URL中的#号是什么意思呢？#号可以认为是一个锚点，里哦那个AJAX，我们就可以不重载页面就刷新数据，如果我们加上#号的特性（即改变URL但是不请求后端），我们就可以在前端实现页面的整体变化而不用每次都去请求后端。为了实现前端路由，我们就可以监听#号后面内容的变化（hashchange），从而动态的改变页面的内容，URL的#号后面的地址成为hash，这种实现模式我们称之为hash模式，是非常典型的前端路由方式。 另一种常用的模式叫history模式，这种方式使用了History API，该API是针对历史记录的API，这种模式的原理是把原来页面的状态保存到一个对象（state）里面，当页面的URL变化时找到对应的对象，从而还原了这个页面。 Vue已经实现了这两种前端路由 回顾一下单页面应用的概念，在项目中其实只有index.html这一个页面，所有其他的内容都是在这一个页面中渲染的，当我们直接在后端方位/login路径的时候，后端中并未有该内容，为了获取到我们需要的页面，我们需要想办法触发前端路由，即在后端添加处理内容，把通过这个URL渲染出的index.html返回到浏览器中。 后端访问登录页面还是没跳转过去啊 后端拦截器的开发： 用户访问URL，检测是否为登录页面 如果用户访问的不是登录页面，检测用户是否已经登录，否则转到登录界面 为了保存登录的状态，我们需要把用户信息保存在Session中（当用户在web页面之间进行跳转的时候，存储在Session中的对象的变量不会丢失） 我们在拦截器 LoginInterceptor 中配置的路径，即index，触发的时机在拦截器生效以后。我们访问一个URL，先通过Configurer判断是否需要拦截，如果需要，才会触发拦截器，根据我们的自定义的规则再次判断。拦截器这里没咋看懂 前端拦截器需要一个全局属性，不应该写在单一的组件里面，所以引入了一个新的工具Vuex（专门为vue开发的状态管理方案），该工具可以把需要在各个组件中传递使用的变量、方法定义在这里。 项目虽然本质上是一个单页面应用，但是表面上有多个功能页面 在一个组件中通过导入引用了其它组件，可以称之为父子组件，如果想要通过控制子组件的显示，则需要相关的路由的配置 Books.Vue的修改：添加搜索框，添加增加，删除按钮，完善分页功能，构造增、删、改、查功能 pojo包中读数据库中的表 dao包中提供接口 service包中根据接口写服务 controller中继续写需要的API 项目中需要查询的地方主要有三处： 打开页面，默认查询出所有图书并显示(页面初始化) 点击左侧分类栏，按照分类显示图书 在搜索栏中输入作者或者书名，可以模糊的查询出相关书籍 页面初始化：使用了Vue的钩子函数-mounted，钩子函数就是在某个特定条件下被触发的函数，钩子函数一般与生命周期对应，mounted翻译为已挂载，所谓挂载，就是我们写的Vue代码被转换为HTML并替换为相应的DOM这个过程，这个过程完事的时候，就会执行mounted里面的代码。 中途隔了几天了，review一下： 简介 安装Vue Cli npm 安装 ， npm install -g vue-cli 安装脚手架，vue init webpack [name] 构建前端项目 components中创建组件，然后设置反向代理（就是再src/main.js)里面配置axios，eg： // 设置反向代理，前端请求默认发送到 http://localhost:8443/api var axios = require('axios') //我个人写的是 import axios from 'axios' axios.defaults.baseURL = 'http://localhost:8443/api' // 全局注册，之后可在其他组件中通过 this.$axios 发送数据 Vue.prototype.$axios = axios Vue.config.productionTip = false 配置页面路由： //格式如下 routes: [ // 下面都是固定的写法 { path: '/login', name: 'Login', component: Login }, { path: '/index', name: 'AppIndex', component: AppIndex } ] 在 config\\index.js 中配置跨域支持： proxyTable: { '/api': { //我也不知道为啥要api，可能是配置反向代理的时候用了api吧 target: 'http://localhost:8443', changeOrigin: true, pathRewrite: { '^/api': '' } } } 运行项目 npm run dev 后端项目创建 spring initializer，输入项目元数据，选择web，finish pojo包中创建自己要使用的类 result包中创建Result类，构造response，主要是响应码： package com.evan.wj.result; public class Result { //响应码 private int code; //这里code应该使用枚举，响应码是确定的 public Result(int code) { this.code = code; } public int getCode() { return code; } public void setCode(int code) { this.code = code; } } controller包中新建一个类，用来对响应进行处理，eg：LoginController package com.evan.wj.controller; import com.evan.wj.result.Result; //引进了响应码 import org.springframework.stereotype.Controller; import org.springframework.web.bind.annotation.*; import org.springframework.web.util.HtmlUtils; import com.evan.wj.pojo.User; //引进了类 import java.util.Objects; @Controller public class LoginController { @CrossOrigin @PostMapping(value = \"api/login\") //我写的是 @RequestMapping(value = \"api/login\") @ResponseBody public Result login(@RequestBody User requestUser) { //RequestBody就是前端传来的数据 // 对 html 标签进行转义，防止 XSS 攻击 String username = requestUser.getUsername(); username = HtmlUtils.htmlEscape(username); if (!Objects.equals(\"admin\", username) || !Objects.equals(\"123456\", requestUser.getPassword())) { String message = \"账号密码错误\"; System.out.println(\"test\"); return new Result(400); } else { return new Result(200); } } } 引入数据库：MySQL，工具Navicat，创建数据库，表，导入数据 项目相关配置：修改 pom.xml(配置完之后要在maven中重新导入一遍) 把pojo包中的类重新改一遍，因为数据是从数据库里面拿了，要建立对数据库的映射 eg： package com.evan.wj.pojo; import com.fasterxml.jackson.annotation.JsonIgnoreProperties; import javax.persistence.*; @Entity //表示一个实体 @Table(name = \"user\") //表名 @JsonIgnoreProperties({\"handler\",\"hibernateLazyInitializer\"}) public class User { @Id @GeneratedValue(strategy = GenerationType.IDENTITY) @Column(name = \"id\") int id; String username; String password; public int getId() { return id; } public void setId(int id) { this.id = id; } public String getUsername() { return username; } public void setUsername(String username) { this.username = username; } public String getPassword() { return password; } public void setPassword(String password) { this.password = password; } } 在dao包中创建一个类来操作数据库对象，但是这里是创建一个接口，eg： package com.evan.wj.dao; import com.evan.wj.pojo.User; import org.springframework.data.jpa.repository.JpaRepository; public interface UserDAO extends JpaRepository { User findByUsername(String username); User getByUsernameAndPassword(String username,String password); } 这里关键的地方在于方法的名字。由于使用了 JPA，无需手动构建 SQL 语句，而只需要按照规范提供方法的名字即可实现对数据库的增删改查。 在service包中创建一个类，提供相关服务，这里实际上是对 UserDAO 进行了二次封装，一般来讲，我们在 DAO 中只定义基础的增删改查操作，而具体的操作，需要由 Service 来完成。eg： package com.evan.wj.service; import com.evan.wj.dao.UserDAO; import com.evan.wj.pojo.User; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.stereotype.Service; @Service public class UserService { @Autowired UserDAO userDAO; public boolean isExist(String username) { User user = getByName(username); return null!=user; } public User getByName(String username) { return userDAO.findByUsername(username); } public User get(String username, String password){ return userDAO.getByUsernameAndPassword(username, password); } public void add(User user) { userDAO.save(user); } } controller包里面写一个类，引入pojo，result，service，dao，处理前端发回来的数据和后端的数据，完成业务逻辑 package com.evan.wj.controller; import com.evan.wj.pojo.User; import com.evan.wj.result.Result; import com.evan.wj.service.UserService; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.stereotype.Controller; import org.springframework.web.bind.annotation.*; import org.springframework.web.util.HtmlUtils; @Controller public class LoginController { @Autowired UserService userService; @CrossOrigin @PostMapping(value = \"/api/login\") @ResponseBody public Result login(@RequestBody User requestUser) { String username = requestUser.getUsername(); username = HtmlUtils.htmlEscape(username); User user = userService.get(username, requestUser.getPassword()); if (null == user) { return new Result(400); } else { return new Result(200); } } } 简单的三层架构（DAO + Service + Controller） DAO 用于与数据库的直接交互，定义增删改查等操作 Service 负责业务逻辑，跟功能相关的代码一般写在这里，编写、调用各种方法对 DAO 取得的数据进行操作 Controller 负责数据交互，即接收前端发送的数据，通过调用 Service 获得处理后的数据并返回 前端使用element 安装：npm i element-ui -S ，引入import Element-UI from 'element-ui' , import 'element-ui/lib/theme-chalk/index.css' , 接下来就是根据例子改自己组件的部分了 前端路由 前端路由：作用改变前端的URL却不用的请求后端，在前端实现页面的整体变化 后面的地址成为hash，有#号成为hash模式，另一种常用的前端模式是history模式，模式的原理是先把页面的状态保存到一个对象（state）里，当页面的 URL 变化时找到对应的对象，从而还原这个页面 使用history模式：修改 router\\index.js，加入 mode: 'history 前端打包部署到后端（不推荐的做法）：先npm run build，这时在项目的 dist 文件夹下生成了 static 文件夹和 index.html 文件，把这两个文件，拷贝到我们后端项目的 wj\\src\\main\\resources\\static 文件夹下 为什么要这里做呢，因为我们实际上只有index.html，后端想要方位其它路径是没有的，所以使用这种build之后copy的方式 后端拦截器 使用session来判断用户是否已经登录，加一条语句 session.setAttribute(\"user\", user); 新建一个拦截器的包 interceptor,然后新建类，在 Springboot 我们可以直接继承拦截器的接口，然后实现 preHandle 方法。preHandle 方法里的代码会在访问需要拦截的页面时执行。eg： package com.evan.wj.interceptor; import com.evan.wj.pojo.User; import org.apache.commons.lang.StringUtils; import org.springframework.web.servlet.HandlerInterceptor; import javax.servlet.http.HttpServletRequest; import javax.servlet.http.HttpServletResponse; import javax.servlet.http.HttpSession; public class LoginInterceptor implements HandlerInterceptor{ @Override public boolean preHandle (HttpServletRequest httpServletRequest, HttpServletResponse httpServletResponse, Object o) throws Exception { HttpSession session = httpServletRequest.getSession(); String contextPath=session.getServletContext().getContextPath(); String[] requireAuthPages = new String[]{ \"index\", }; String uri = httpServletRequest.getRequestURI(); uri = StringUtils.remove(uri, contextPath+\"/\"); String page = uri; if(begingWith(page, requireAuthPages)){ User user = (User) session.getAttribute(\"user\"); if(user==null) { httpServletResponse.sendRedirect(\"login\"); return false; } } return true; } private boolean begingWith(String page, String[] requiredAuthPages) { boolean result = false; for (String requiredAuthPage : requiredAuthPages) { if(StringUtils.startsWith(page, requiredAuthPage)) { result = true; break; } } return result; } } 写完拦截器之后要将它配置到项目中： 新建config包，再新建类： package com.evan.wj.config; import com.evan.wj.interceptor.LoginInterceptor; import org.springframework.boot.SpringBootConfiguration; import org.springframework.context.annotation.Bean; import org.springframework.web.servlet.config.annotation.*; @SpringBootConfiguration public class MyWebConfigurer implements WebMvcConfigurer { @Bean public LoginInterceptor getLoginIntercepter() { return new LoginInterceptor(); } @Override public void addInterceptors(InterceptorRegistry registry){ // 这条语句是关键 registry.addInterceptor(getLoginIntercepter()).addPathPatterns(\"/**\").excludePathPatterns(\"/index.html\"); } } 前端还要进行相应的设置，感觉我现在用不上，就不看了 数据库 review到此结束 上传文件的逻辑很简单：前端向后端发送post请求，后端对接受到的数据进行处理（压缩、格式转换、重命名等），并保存再服务器中的指定位置，再把该位置对应的url返回给前端即可 "},"temp/文件系统的设计原理.html":{"url":"temp/文件系统的设计原理.html","title":"文件系统的设计原理","keywords":"","body":"TreeviewCopyright © aleen42 all right reserved, powered by aleen42 摘要 硬盘 文件系统 Inode inode 的内容、大小和号码 目录文件 硬、软链接 RAID 分布式文件系统 小结 文件系统的设计原理 [toc] 摘要 这次又是要写文件的上传下载，又是需要对文件进行管理，文件的元数据信息，目录结构，文件夹和文件的管理，我感觉这是一个很重要的东西，想要把文件系统搞懂一点。参考文章：文件系统的设计原理，这篇写的很好，绝大部分都copy的，但是我还想要了解具体设计的方面的东西，比如有哪些元数据信息，Inode 或则 NameNode 怎么抽象的，目录是啥样的，然后怎么管理的 文件及硬盘管理是计算机操作系统的重要组成部分。让微软走上成功之路的正是微软最早推出的个人电脑 PC 操作系统，这个操作系统叫做 DOS，即 Disk Operating System，硬盘操作系统。我们每天使用电脑都离不开硬盘，硬盘既有大小的限制，通常大一点的硬盘也只是几T，又有速度的限制，快一点的硬盘也不过每秒几百M（现在局域网下的带宽都可以达到几千M，分布式文件系统的重要原因） 文件是存储在硬盘上的，文件的读写速度必然受到硬盘的物理限制，那么如何才能 1 分钟内完成一个 100 T 大文件的遍历呢？ 想要知道这个问题的答案，我们就必须知道文件系统的原理。做软件开发的时候，我们经常要和文件系统打交道，而文件系统也是一个软件，了解文件系统的设计原理，可以帮助我们更好的使用文件系统，另外设计文件系统的各种考量，也对我们自己软件设计有诸多简介意义 硬盘 硬盘是一种可持久保存、多次读写数据的存储介质。硬盘的形式主要有两种：机械式硬盘、固态硬盘 机械式硬盘的结构，主要包含盘片、主轴、次投币，主轴带动盘片高速旋转，当需要读写盘上的数据的时候，磁头臂会移动磁头到盘片所在的磁道上，磁头读取磁道上的数据。读写数据需要移动磁头，这样一个机械的动作，至少需要花费数毫秒的时间，这是机械式硬盘访问延迟的主要原因。 固态硬盘的读写速度快得多，但是成本也要高得多，因此在生产环境中，最主要的存储介质依然是机械式硬盘。如果一个场景对数据访问速度、存储容量、成本都有较高的要求，那么可以采用固态硬盘和机械式硬盘混合部署的方式 文件系统 我们一般不需要直接操作硬盘，而是通过操作系统，以文件的方式对硬盘上的数据进行读写。文件系统将硬盘空间以块为单位进行划分，每个文件占据若干个块，然后通过文件控制块 FCB 记录每个文件占据的硬盘数据块 文件系统分块 文件控制块在 Linux 中的角色是 inode，要想访问文件，就必须获得文件的 inode 信息，在 inode 中查找文件数据块索引表，根据索引表中记录的硬盘地址信息访问硬盘，读写数据 inode 中记录着文件权限、所有者、修改时间和文件大小等文件属性信息，以及文件数据块硬盘地址索引。inode 是固定结构的，能够记录的硬盘地址索引数也是固定的，只有 15 个索引。其中前 12 个索引直接记录数据块地址，第 13 个索引记录索引地址，也就是说，索引块指向的硬盘数据块并不直接记录文件数据，而是记录文件数据块的索引表，每个索引表可以记录 256 个索引；第 14 个索引记录二级索引地址，第 15 个索引记录三级索引地址，如下图： Inode 文件控制块 每个 inode 最多可以存储 12+256+256256+256256*256 个数据块，如果每个数据块的大小为 4k，也就是单个文件最大不超过 70G，而且即使可以扩大数据块大小，文件大小也要受单个硬盘容量的限制。这样的话，对于我们开头提出的一分钟完成 100T 大文件的遍历，Linux 文件系统是无法完成的。 Inode 理解Inode inode 的内容、大小和号码 文件存储在硬盘上，硬盘的最小存储单位是扇区（Sector），每个扇区存储 512 字节，但是操作系统读取硬盘的时候，不会一个一个扇区的读取，这样效率太低了，而是一次性读取多个扇区，我们将这多个扇区称为一个块（Block）， 常见大小是 4 kb，也就是 8 个扇区 文件数据都存储在块中了，但是我们必须找到一个地方存储文件的元信息，比如文件的创建者、创建日期、文件的大小等等，这种存储文件元信息的区域就叫做 inode（索引节点） inode 包含的信息： 文件的字节数 文件的拥有者 User ID 文件的 Group ID 文件的读、写、执行权限 文件的时间戳：ctime， inode 上一次变动的事件；mtime，文件内容上一次变动的事件；atime，文件上一次打开的时间 链接数，既有多少文件名指向这个 inode 文件数据 block 的位置 inode 也会消耗硬盘空间，所以硬盘格式化的时候，操作系统自动将硬盘分为两个区域，一个是数据区，存放文件数据；另一个是 inode 区，存放 inode 包含的信息。每个inode节点的大小，一般是128字节或256字节。inode节点的总数，在格式化时就给定，一般是每1KB或每2KB就设置一个inode。假定在一块1GB的硬盘中，每个inode节点的大小为128字节，每1KB就设置一个inode，那么inode table的大小就会达到128MB，占整块硬盘的12.8%。由于每个文件都必须有一个inode，因此有可能发生inode已经用光，但是硬盘还未存满的情况。这时，就无法在硬盘上创建新文件。 每个 inode 都有一个号码，操作系统用 inode 号码来识别不同的文件。Linux 系统内部不适用文件名，而使用 inode 号码来识别文件。对于系统来说，文件名只是 inode 号码便于识别的别称或者绰号。表面上，用户通过文件名打开文件，实际上，系统内部这个过程分为三步：首先，系统找到这个文件名对应的 inode 号码；其次，通过 inode 号码获取 inode 信息；最后，根据 inode 信息，找到文件数据所在的 block，读取数据 由于inode号码与文件名分离，这种机制导致了一些Unix/Linux系统特有的现象。 　　1. 有时，文件名包含特殊字符，无法正常删除。这时，直接删除inode节点，就能起到删除文件的作用。 　　2. 移动文件或重命名文件，只是改变文件名，不影响inode号码。 　　3. 打开一个文件以后，系统就以inode号码来识别这个文件，不再考虑文件名。因此，通常来说，系统无法从inode号码得知文件名。 第3点使得软件更新变得简单，可以在不关闭软件的情况下进行更新，不需要重启。因为系统通过inode号码，识别运行中的文件，不通过文件名。更新的时候，新版文件以同样的文件名，生成一个新的inode，不会影响到运行中的文件。等到下一次运行这个软件的时候，文件名就自动指向新版文件，旧版文件的inode则被回收。 目录文件 在 Unix/Linux 系统中，目录（directory）也是一种文件。打开目录，实际上就是打开目录文件。目录文件的结构非常简单，就是一系列目录项（dirent）的列表。每个目录项，有两部分组成：所包含文件的文件名，文件名对应的 inode 号码。ls命令只列出目录文件中的所有文件，ls -i命令列出整个目录文件，即文件名和inode号码。如果要查看文件的详细信息，就必须根据 inode 号码，访问 inode 节点，读取信息。ls -l命令列出文件的详细信息。 理解了上面这些知识，就能理解目录的权限。目录文件的读权限（r）和写权限（w），都是针对目录文件本身。由于目录文件内只有文件名和inode号码，所以如果只有读权限，只能获取文件名，无法获取其他信息，因为其他信息都储存在inode节点中，而读取inode节点内的信息需要目录文件的执行权限（x）。 stat 查看详细信息 df -i 查看inode总数和使用数量 ls命令只列出目录文件中的所有文件名，ls -i命令列出整个目录文件，即文件名和inode号码，ls -i命令列出整个目录文件，即文件名和inode号码（需要目录文件有 x 执行权限） 硬、软链接 一般情况下，文件名和 inode 号码是一一对应的关系，但是 Linux 系统允许多个文件名指向同一个 inode。这意味着，可以用不同的文件名访问同样的内容；对文件内容进行修改，回影响到所有文件名；但是删除一个文件名，不影响另一个文件名的访问。这种情况称为硬链接（hard link），ln命令可以创建硬链接 ln 创建硬链接 运行上面这条命令以后，源文件与目标文件的inode号码相同，都指向同一个inode。inode信息中有一项叫做\"链接数\"，记录指向该inode的文件名总数，这时就会增加1。反过来，删除一个文件名，就会使得inode节点中的\"链接数\"减1。当这个值减到0，表明没有文件名指向这个inode，系统就会回收这个inode号码，以及其所对应block区域。 目录文件的链接数：创建目录时，默认回生成两个目录项：'.' 和 '..'，前者的 inode 号码就是当前目录的 inode 号码，等同于当前目录的硬链接，后者的 inode 号码就是当前目录的父目录的 inode 号码，等同于父目录的硬链接。 除了硬链接之外，还有一种特殊情况。文件 A 和 文件 B 的 inode 号码虽然不一样，但是文件 A 的内容是文件 B 的路径，读取文件 A 时，系统会自动将访问者导向文件 B（好比是window 中的快捷方式）。因此，无论打开哪一个文件，最终读取的都是文件 B。这时，文件 A 就称为文件 B 的软连接 这意味着，文件A依赖于文件B而存在，如果删除了文件B，打开文件A就会报错：\"No such file or directory\"。这是软链接与硬链接最大的不同：文件A指向文件B的文件名，而不是文件B的inode号码，文件B的inode\"链接数\"不会因此发生变化。 ln -s 创建软链接 RAID RAID(Redundant Array of Independent Disks, 独立硬盘冗余阵列)：利用虚拟化存储技术把多个硬盘组合起来，称为一个或多个硬盘阵列组，目的是提升性能或减少冗余，或者是两者同时提升。 RAID 的核心思路其实是利用文件系统将数据写入硬盘中不同数据块的特性，将多块硬盘上的空闲空间看作一个整体，进行数据写入，也就是说，一个文件的多个数据块可能写入多个硬盘。根据硬盘组织和使用方式不同，常用 RAID 有五种，分别是 RAID 0、RAID 1、RAID 10、RAID 5 和 RAID 6。we RAID 0 将一个文件的数据分成 N 片，同时向 N 个硬盘写入，这样单个文件可以存储在 N 个硬盘上，文件容量可以扩大 N 倍，（理论上）读写速度也可以扩大 N 倍。但是使用 RAID 0 的最大问题是文件数据分散在 N 块硬盘上，任何一块硬盘损坏，就会导致数据不完整，整个文件系统全部损坏，文件的可用性极大地降低了。 RAID 1 则是利用两块硬盘进行数据备份，文件同时向两块硬盘写入，这样任何一块硬盘损坏都不会出现文件数据丢失的情况，文件的可用性得到提升。 RAID 10 结合 RAID 0 和 RAID 1，将多块硬盘进行两两分组，文件数据分成 N 片，每个分组写入一片，每个分组内的两块硬盘再进行数据备份。这样既扩大了文件的容量，又提高了文件的可用性。但是这种方式硬盘的利用率只有 50%，有一半的硬盘被用来做数据备份。 RAID 5 针对 RAID 10 硬盘浪费的情况，将数据分成 N-1 片，再利用这 N-1 片数据进行位运算，计算一片校验数据，然后将这 N 片数据写入 N 个硬盘。这样任何一块硬盘损坏，都可以利用校验片的数据和其他数据进行计算得到这片丢失的数据，而硬盘的利用率也提高到 N-1/N。 校验数据这一块建议去了解汉明码，然后 3Blue1Brown 的两个视频讲的特别好，地址：B站 RAID 5 可以解决一块硬盘损坏后文件不可用的问题，那么如果两块文件损坏？RAID 6 的解决方案是，用两种位运算校验算法计算两片校验数据，这样两块硬盘损坏还是可以计算得到丢失的数据片。 实践中，使用最多的是 RAID 5，数据被分成 N-1 片并发写入 N-1 块硬盘，这样既可以得到较好的硬盘利用率，也能得到很好的读写速度，同时还能保证较好的数据可用性。使用 RAID 5 的文件系统比简单的文件系统文件容量和读写速度都提高了 N-1 倍，但是一台服务器上能插入的硬盘数量是有限的，通常是 8 块，也就是文件读写速度和存储容量提高了 7 倍，这远远达不到 1 分钟完成 100T 文件的遍历要求。 分布式文件系统 我们再回过头看下 Linux 的文件系统：文件的基本信息，也就是文件元信息记录在文件控制块 inode 中，文件的数据记录在硬盘的数据块中，inode 通过索引记录数据块的地址，读写文件的时候，查询 inode 中的索引记录得到数据块的硬盘地址，然后访问数据。 如果将数据块的地址改成分布式服务器的地址？也就是查询得到的数据块地址不只是本机的硬盘容量，还可以是其他服务器的地址，那么文件的存储容量就将是整个分布式服务器集群的硬盘容量，这样还可以在不同的服务器上同时并行读取文件的数据块，文件访问速度也将极大的加快。 这样的文件系统就是分布式文件系统，分布式文件系统的思路其实和 RAID 是一脉相承的，就是将数据分成很多片，同时向 N 台服务器上进行数据写入。针对一片数据丢失就导致整个文件损坏的情况，分布式文件系统也是采取数据备份的方式，将多个备份数据片写入多个服务器，以保证文件的可用性。当然，也可以采用 RAID 5 的方式通过计算校验数据片的方式提高文件可用性。 我们以 Hadoop 分布式文件系统 HDFS 为例，看下分布式文件系统的具体架构设计。 HDFS 的关键组件有两个，一个是 DataNode，一个是 NameNode。 DataNode 负责文件数据的存储和读写操作，HDFS 将文件数据分隔成若干数据块（Block），每个 DataNode 存储一部分数据块，这样文件就分部存储在整个 HDFS 服务器集群中。应用程序客户端（Client）可以并行对这些数据块进行访问，从而使得 HDFS 可以在服务器集群规模上实现数据并行访问，极大地提高了访问速度。在实践中，HDFS 集群的 DataNode 服务器会有很多台，一般在几百台到几千台这样的规模，每台服务器配有数块硬盘，整个集群的存储容量大概在几 PB 到数百 PB。 NameNode 负责整个分布式文件系统的元数据（MetaData）管理，也就是文件路径名、访问权限、数据块的 ID 以及存储位置等信息，相当于 Linux 系统中 inode 的角色。HDFS 为了保证数据的高可用，会将一个数据块复制为多分（缺省情况下为 3 份），并将多份相同的数据块存储在不同的服务器上，甚至不同的机架上。这样当有硬盘损坏，或者某个 DataNode 服务器宕机，甚至某个交换机宕机，导致其存储的数据块不能访问的时候，客户端会查找其备份的数据块进行访问。 有了 HDFS，可以实现单一文件存储几百 T 的数据，再配合大数据计算框架 MapReduce 或者 Spark，可以对这个文件的数据块进行并发计算。也可以使用 Impala 这样的 SQL 引擎对这个文件进行结构化查询，在数千台服务器上并发遍历 100T 的数据，1 分钟都是绰绰有余的。 小结 文件系统从简单操作系统文件，到 RAID 再到分布式文件系统，其设计思路其实是具有统一性的。这种统一性方面体现在文件数据如何管理，也就是如何通过文件控制块管理文件的数据，这个文件控制块在 Linux 系统中就是 inode，在 HDFS 中就是 NameNode。 另一方面体现在如何利用更多的硬盘实现越来越大的文件存储需求和越来越快的读写速度需求，也就是将数据分片后同时写入多块硬盘。单服务器我们可以通过 RAID 来实现，多服务器则可以将这些服务器组成一个文件系统集群，共同对外提供文件服务，这时候，数千台服务器的数万块硬盘以单一存储资源的方式对文件使用提供服务，也就是一个文件可以存储数百 T 的数据，并在一分钟完成这样一个大文件的遍历。 "}}