{"./":{"url":"./","title":"Introduction","keywords":"","body":"吴天 网名吴天，专业是 GIS（很小众的一个专业），很菜很菜的一个人，现在还没有什么产出。笔记大部分都是看书，看教程或者优秀博主学习的，一般都写了原创链接，也可能没注意少写了。自己会把很多相关的知识都写在一个文档里面，这样我也好看 ​ 由于上传图床的时候有些图片落下了，有些笔记弄丢了，有些笔记 GitBook 没有正确转出来，所以笔记是有问题的 制作这样一个笔记本的形式是为了方便自己看，也可以当作博客写一些想法，希望自己能坚持吧！ 编译命令：gitbook serve . ./docs，需要放到 docs 文件夹，GitHub 才能自动部署 在线地址：https://ting-xin.github.io/notebook/ "},"bigData/BigData-Notes.html":{"url":"bigData/BigData-Notes.html","title":"BigData-Notes","keywords":"","body":"BigData-Notes github [toc] 前言 块存储、文件存储、对象存储这三者的本质区别 知乎 这三者的本质差别是使用数据的\"用户\"不同：块存储的用户是可以读写块设备的软件系统，例如传统的文件系统、数据库；文件存储的用户是自然人；对象存储的用户则是其它计算机软件 1 大数据处理流程 1.1处理流程 中大型项目通常采用微服务架构进行分布式部署，采集过程不能影响正常业务的开展。多种日志收集工具：Flume， Logstash， Kibana，都能通过简单的配置完成复杂的数据收集和数据聚合 1.2 数据存储 结构化数据（表）、半结构化数据（日志数据、视频、音频），为了解决海量半结构化和非结构化数据的存储，衍生了Hadoop HDFS，KFS，GFS等分布式文件系统，它们能支持结构化、半结构和非结构化数据的存储，并可以通过增加机器进行横向扩展 分布式文件系统完美地解决了海量数据存储的问题，但是一个优秀的数据存储系统需要同时考虑数据存储和访问两方面的问题，比如你希望能够对数据进行随机访问，这是传统的关系型数据库所擅长的，但却不是分布式文件系统所擅长的，那么有没有一种存储方案能够同时兼具分布式文件系统和关系型数据库的优点，基于这种需求，就产生了 HBase、MongoDB。 1.3 数据分析 数据分析：批处理和流处理 批处理：对一段时间内海量的离线数据进行统一的处理，对应的处理框架有 Hadoop MapReduce、Spark、Flink 等； 流处理：对运动中的数据进行处理，即在接收数据的同时就对其进行处理，对应的处理框架有 Storm、Spark Streaming、Flink Streaming 等。 批处理和流处理各有其适用的场景，时间不敏感或者硬件资源有限，可以采用批处理；时间敏感和及时性要求高就可以采用流处理。随着服务器硬件的价格越来越低和大家对及时性的要求越来越高，流处理越来越普遍，如股票价格预测和电商运营数据分析等。 上面的框架都是需要通过编程来进行数据分析，那么如果你不是一个后台工程师，是不是就不能进行数据的分析了？当然不是，大数据是一个非常完善的生态圈，有需求就有解决方案。为了能够让熟悉 SQL 的人员也能够进行数据的分析，查询分析框架应运而生，常用的有 Hive 、Spark SQL 、Flink SQL、 Pig、Phoenix 等。这些框架都能够使用标准的 SQL 或者 类 SQL 语法灵活地进行数据的查询分析。这些 SQL 经过解析优化后转换为对应的作业程序来运行，如 Hive 本质上就是将 SQL 转换为 MapReduce 作业，Spark SQL 将 SQL 转换为一系列的 RDDs 和转换关系（transformations），Phoenix 将 SQL 查询转换为一个或多个 HBase Scan。 1.4 数据应用 数据分析完成后，接下来就是数据应用的范畴，这取决于你实际的业务需求。比如你可以将数据进行可视化展现，或者将数据用于优化你的推荐算法，这种运用现在很普遍，比如短视频个性化推荐、电商商品推荐、头条新闻推荐等。当然你也可以将数据用于训练你的机器学习模型，这些都属于其他领域的范畴，都有着对应的框架和技术栈进行处理，这里就不一一赘述。 1.5 其他框架 上面是一个标准的大数据处理流程所用到的技术框架。但是实际的大数据处理流程比上面复杂很多，针对大数据处理中的各种复杂问题分别衍生了各类框架： 单机的处理能力都是存在瓶颈的，所以大数据框架都是采用集群模式进行部署，为了更方便的进行集群的部署、监控和管理，衍生了 Ambari、Cloudera Manager 等集群管理工具； 想要保证集群高可用，需要用到 ZooKeeper ，ZooKeeper 是最常用的分布式协调服务，它能够解决大多数集群问题，包括首领选举、失败恢复、元数据存储及其一致性保证。同时针对集群资源管理的需求，又衍生了 Hadoop YARN ; 复杂大数据处理的另外一个显著的问题是，如何调度多个复杂的并且彼此之间存在依赖关系的作业？基于这种需求，产生了 Azkaban 和 Oozie 等工作流调度框架； 大数据流处理中使用的比较多的另外一个框架是 Kafka，它可以用于消峰，避免在秒杀等场景下并发数据对流处理程序造成冲击； 另一个常用的框架是 Sqoop ，主要是解决了数据迁移的问题，它能够通过简单的命令将关系型数据库中的数据导入到 HDFS 、Hive 或 HBase 中，或者从 HDFS 、Hive 导出到关系型数据库上。 分类总结： 日志收集框架：Flume、Logstash、Filebeat 分布式文件存储系统：Hadoop HDFS 数据库系统：Mongodb、HBase 分布式计算框架： 批处理框架：Hadoop MapReduce 流处理框架：Storm 混合处理框架：Spark、Flink 查询分析框架：Hive 、Spark SQL 、Flink SQL、 Pig、Phoenix 集群资源管理器：Hadoop YARN 分布式协调服务：Zookeeper 数据迁移工具：Sqoop 任务调度框架：Azkaban、Oozie 集群部署和监控：Ambari、Cloudera Manager Hadoop 分布式文件存储系统 HDFS HDFS 写数据原理 HDFS 读数据原理 HDFS 故障类型和检测方法 读写故障处理 DataNode 故障处理 副本布局策略 分布式计算框架MapReduce map reduce 编程模型 剩下的看不懂，前面的勉强还能当课外了解了 集群资源管理器YARN yarn工作原理 Hadoop 单机版环境搭建 Hadoop 的运行依赖 JDK，需要预先安装 配置SSH免密登录 Hadoop(HDFS)环境搭建 Hadoop(YARN)环境搭建 Hadoop集群环境搭建 集群规划 前置条件 配置免密登录 集群搭建 提交服务到集群 HDFS常用shell命令 HDFS Java API 的使用 基于Zookeeper搭建Hadoop高可用集群 minIO minIO是高性能对象存储 什么是大数据的技术生态 大数据本身是个很宽泛的概念，Hadoop生态圈（或者泛生态圈）基本上都是为了处理超过单机尺度的数据处理而诞生的。你可以把它比作一个厨房所以需要的各种工具。锅碗瓢盆，各有各的用处，互相之间又有重合。你可以用汤锅直接当碗吃饭喝汤，你可以用小刀或者刨子去皮。但是每个工具有自己的特性，虽然奇怪的组合也能工作，但是未必是最佳选择。 Minio 是一种高性能的分布式对象存储服务器，用于大型数据基础设施，是机器学习和其它大数据工作负载下 Hadoop HDFS的理想 s3 兼容替代品 npm install --save-dev @types/minio "},"bigData/Flink.html":{"url":"bigData/Flink.html","title":"Flink.md","keywords":"","body":"Flink [toc] 摘要 Apache Flink 是一个用于分布式流和批数据处理的开源平台。Flink 的核心是流数据流引擎，为数据流上的分布式计算提供数据分发，通信和容错。Flink 在流引擎之上构建批处理，覆盖本机迭代支持，托管内存和程序优化。 概念：从Flink的数据流编程模型和分布式运行时环境的基本概念开始。这将有助于您了解文档的其他部分，包括设置和编程指南。我们建议您先阅读这些部分。 教程： 实现并运行DataStream应用程序 设置本地Flink群集 编程指南：您可以阅读我们关于基本API概念和DataStream API或DataSet API的指南，以了解如何编写您的第一个Flink程序。 概念 数据流编程模型 抽象层次 Flink 提供不同级别的抽象来开发流/批处理应用程序： Flink 抽象级别 状态流：它通过Process Function嵌入到DataStream API中。它允许用户自由处理来自一个或多个流的事件，并使用一致的容错状态。此外，用户可以注册事件时间和处理时间回调，允许程序实现复杂的计算。 Core API：大多数应用程序不需要上述低级抽象，而是针对Core API编程， 如DataStream API（有界/无界流）和DataSet API （有界数据集）。这些流畅的API提供了用于数据处理的通用构建块，例如各种形式的用户指定的转换，连接，聚合，窗口，状态等。在这些API中处理的数据类型在相应的编程语言中表示为类。 Table API：Table API是为中心的声明性DSL 表，其可被动态地改变的表（表示流时）。 Table API遵循（扩展）关系模型：表有一个模式连接（类似于在关系数据库中的表）和API提供可比的 算子操作，如选择，项目，连接，分组依据，聚合等 Table API程序以声明方式定义应该执行的逻辑 算子操作，而不是准确指定 算子操作代码的外观。虽然 Table API可以通过各种类型的用户定义函数进行扩展，但它的表现力不如Core API，但使用更简洁（编写的代码更少）。此外， Table API程序还会通过优化程序，在执行之前应用优化规则。 SQL：Flink 提供的最高级别抽象是 SQL，在语义和表达方面类似于 __Table API_，在SQL抽象与 Table API紧密地相互作用，和SQL查询可以通过定义表来执行 Table API。 程序和数据流 Flink 程序的基础构建块是流和转换。从概念上讲，流是（可能永无止境的）数据记录流，而转换是将一个或多个流作为一个或多个流的算子操作。 Flink 数据流 执行时，Flink 程序映射到流数据流，由流和转换算子组成。每个数据流都以一个或多个源开头，并以一个或多个接收器结束。数据流类似于任意有向无环图。通常程序中的转换与数据流中的算子之间存在一对一的对应关系，但是有时一个转换可能包含多个转换算子。 源流和接收器记录在流连接器和批处理连接器文档中。DataStream 算子和DataSet转换中记录了转换。 并行数据流 Flink 中的本质上是并行和分布式的。在执行期间，_流_具有一个或多个流分区，并且每个 _算子_ 具有一个或多个算子子任务。算子子任务彼此独立，并且可以在不同的线程中执行，可能在不同的机器或容器上执行 算子子任务的数量是该特定算子的并行度。流的并行性始终是其生成算子的并行性。同一程序的不同算子可能具有不同的并行级别。 并行计算 流可以以 一对一流 模式或 重新分配流 模式在两个算子之间传输数据： 一对一流：（例如，在上图中的Source_和_map（） 算子之间）保存数据元的分区和排序。这意味着map（） 算子的subtask [1] 将以与Source 算子的subtask [1]生成的顺序相同的顺序看到相同的数据元 重新分配流： （在上面的map（）和_keyBy / window之间，以及 keyBy / window和Sink之间）重新分配流。每个 算子子任务将数据发送到不同的目标子任务，具体取决于所选的转换。实例是 _keyBy（） （其通过散列Keys重新分区），广播（） ，或Rebalance （） （其重新分区随机地）。在重新分配交换中，数据元之间的排序仅保存在每对发送和接收子任务中（例如，map（）的子任务[1] 和子任务[2]keyBy / window）。因此，在此示例中，保存了每个Keys内的排序，但并行性确实引入了关于不同Keys的聚合结果到达接收器的顺序的非确定性。 窗口 聚合事件（计算，总和）在流上的工作方式和批处理方式不同。例如，不可能计算流中的所有数据元，因为流通常是无限的。相反，流上的聚合（计算，总和）等由窗口限定，例如“在最后5分钟内计数”或“最后100个数据元的总和”。 window 可以是时间驱动的（例如：每30秒）或数据驱动的（每100个数据元）。 窗口 时间 当在流程序中引用时间时，可以参考不同的时间概念： 事件时间：创建事件的时间。它通常是由事件中的时间戳描述，例如由生产传感器或生产服务附加。Flink通过时间戳分配器访问事件事件戳 摄取时间：事件在源算子处输入 Flink 数据流的时间 处理时间：执行基于时间的算子操作的每个算子的本地时间 有状态的算子操作 虽然数据流中的许多算子操作只是一次查看一个单独的事件（例如事件解析器），但某些算子操作会记住多个事件（例如窗口算子）的信息，这些算子操作称为有状态 状态算子操作的状态保持在可以被认为是嵌入式键/值存储的状态中。状态被分区并严格地与有状态算子读取的流一起分发 容错检查点 Flink 使用 流重放 和 检查点 的组合实现容错，检查点与每个输入流中的特定点以及每个算子的对应状态相关。通过恢复 算子的状态并从检查点重放事件，可以从检查点恢复流数据流，同时保持一致性（恰好一次处理语义）。 检查点间隔是在执行期间用恢复时间（需要重放的事件的数量）来折衷容错开销的手段。 容错内部的描述提供了有关Flink如何管理检查点和相关主题的更多信息。有关启用和配置检查点的详细信息 流处理批处理 Flink执行批处理程序作为流程序的特殊情况，其中流是有界的（有限数量的数据元）。一个数据集在内部视为数据流。因此，上述概念以相同的方式应用于批处理程序，并且它们适用于流程序，除了少数例外： 批处理程序的容错不使用检查点。通过完全重放流来恢复。这是可能的，因为输入有限。这会使成本更多地用于恢复，但使常规处理更便宜，因为它避免了检查点。 DataSet API中的有状态 算子操作使用简化的内存/核外数据结构，而不是键/值索引。 DataSet API引入了特殊的同步（超级步骤）迭代，这些迭代只能在有界流上进行。有关详细信息，请查看迭代文档。 分布式运行环境 任务和算子链 对于分布式执行，Flink 链 算子子任务一起放入 任务，每个任务由一个线程执行。将算子链接到任务中是一项有用的优化：他可以 Reduce 线程到线程切换和缓冲的开销，并在降低延迟的同时提高整体吞吐量。 并行线程 TaskManager, JobManager, 客户端 Flink 运行时包含两种类型的进程： JobManagers（也称为Masters）：协调分布式执行，它们安排任务，协调检查点，协调故障恢复等 TaskManagers（也叫 Workers）：执行 任务(或者更具体的说：子任务)的数据流，以及缓冲器和交换数据流 JobManagers 和 TaskManagers 可以通过多种方式启动：作为独立集群直接在计算机上，在容器中，由 Yarn 或 Mesos 等资源框架管理。TaskManagers 连接到 JobManagers，宣布自己可用，并被分配工作 任务槽和资源 每个 worker（TaskManager）都是一个 JVM 进程，可以在不同的线程中执行一个或多个子任务。为了控制worker接受的任务数量，worker也有一个任务槽（至少一个） 每个任务槽代表 TaskManager 的固定资源子集。例如，具有三个插槽的 TaskManager 将其 1/3 的托管内存专用于每个插槽。切换资源意味着子任务不会与其它作业的子任务竞争托管内存，而是具有一定数量的保存托管内存。这里不会发生 CPU 隔离，当前插槽只分离任务的托管内存。 通过调整任务槽的数量，用户可以定义子任务如何相互隔离。每个TaskManager 有一个插槽意味着每个任务组在一个单独的JVM中运行（例如，可以在一个单独的容器中启动）。拥有多个插槽意味着更多子任务共享同一个 JVM。同一 JVM 的任务共享TCP连接（通过多路复用）和心跳信息。它们还可以共享数据集和数据结构，从而Reduce 任务开销 默认情况下，Flink 允许子任务共享插槽，即使它们是不同任务的子任务，只要它们来自同一个作业。结果是一个槽可以保存作业的整个管道。允许插槽共享有两个主要好处： Flink 集群需要与作业中使用的最高并行度一样多的插槽。无需计算程序总共包含多少任务（具有不同的并行性） 更容易获得更好的资源利用率。通过插槽共享，将示例中的基本并行性从2增加到6可以充分利用时隙资源，同时确保繁重的子任务在TaskManagers之间公平分配。 根据经验，一个很好的默认任务槽数是 CPU 核心数。使用超线程，每个插槽需要 2 个或更多硬件线程上下文 状态后台 存储键/值索引的确切数据结构取决于所选的状态后台。一个状态后台将数据存储在内存中的哈希映射中，另一个状态后台使用RocksDB作为键/值存储。除了定义保存状态的数据结构之外，状态后台还实现逻辑以获取键/值状态的时间点SNAPSHOT，并将该SNAPSHOT存储为检查点的一部分。 保存点 用Data Stream API编写的程序可以从保存点恢复执行。保存点允许更新程序和Flink群集，而不会丢失任何状态。 保存点是手动触发的检查点，它会获取程序的SNAPSHOT并将其写入状态后台。他们依靠常规的检查点机制。在执行期间，程序会定期在工作节点上创建SNAPSHOT并生成检查点。对于恢复，仅需要最后完成的检查点，并且一旦新的检查点完成，就可以安全地丢弃旧的检查点。 保存点与这些定期检查点类似，不同之处在于它们由用户触发，并且在较新的检查点完成时不会自动过期。可以从命令行或通过REST API取消作业时创建保存点 "},"bigData/Google 三大核心技术及其衍生.html":{"url":"bigData/Google 三大核心技术及其衍生.html","title":"Google 三大核心技术及其衍生.md","keywords":"","body":"[toc] Google 三大核心技术及其衍生 简介 参考自谷歌三篇论文（GFS,MapReduce,BigTable） Google于2003、2004、2006年分别发表了GFS、 MapReduce 和 BigTable 相关的 3 篇论文，其中MapReduce 和 BigTable都是以GFS为基础，这三大基础核心技术构建出了完整的分布式运算架构，也奠定了大数据和云计算的基础。 Google File System(GFS)：可扩展的分布式文件系统，用于大型的、分布式的、对大量数据进行访问的应用。它运行于廉价的普通硬件上，提供容错功能。从根本上说：文件被分割成很多块，使用冗余的方式储存于商用机器集群上。 MapReduce：描述了大数据的分布式计算方式，主要思想是将任务分解然后在多台处理能力较弱的计算节点中同时处理（Map），然后将结果合并从而完成大数据处理（Reduce）。 BigTable：BigTable 是建立在 GFS 和 MapReduce 之上的。每个Table都是一个多维的稀疏图 -------------- 参考自Google大数据三大论文读后感 三篇论文之后，Google继续公布的了一下技术： 2012 Spanner 开源实现（Hadoop）及Google自身的发展，参考自技术硬核】从Google F1 看HTAP数据库的诞生 GFS （HDFS） ---> Colossus MapReduce （MapReduc ---> Spark） ---> Percolator/Dremel BigTable （HBase） ---> F1/Spanner 参考自一文系统梳理Google三驾马车，有机会把这个课程学习了 大数据技术脉络 .jpg) 大数据技术脉络 Google File System（GFS） Google File System（GFS、GoogleFS），一种专有的分布式文件系统，由Google公司开发，运行于Linux平台上，尽管Google在2003年公布了该系统的一些技术细节，但Google并没有将该系统的软件部分开源，2013年，Google公布了Colossus项目，作为下一代的Google文件系统 why hard 为什么分布式存储困难 个人理解：分布式的初衷是利用数百台计算机的资源来同时完成大量工作，获取巨大的性能加成（high performance），所以数据需要分片（sharding）存储在这些机器上。然后服务器会宕机，通信也会出现故障，不可能通过人工来修复错误，我们需要一个自动化的容错系统（fault tolerance）。实现容错的最有用的方法就是复制（replication），其中一个出错了，我们就立刻替上它的副本。但是数据在动态的变化，副本之间的复制不能同步的进行更新，一不小心两个数据的副本会不一致（inconsistency），这时候用户请求的数据取决于用户向哪个副本请求数据。显然我们要避免不一致的问题，为了达到一致性，不同的服务器之间需要通过网络进行额外的交互（Network interaction），这种交互会降低性能（low performance）。 分布式难点 所以说，分布式系统的最大难点就在于各个节点的状态如何同步，也就是 CAP（consistency，availability，partition tolerance）定理 1998年，加州大学的计算机科学家 Eric Brewer 提出，分布式系统有三个指标: Consistency Availability Partition tolerance Eric Brewer 说，这三个指标不可能同时做到。这个结论就叫做 CAP 定理。 前文已经说到，故障总是存在，也即分区容错（Partition tolerance）是无法避免的，剩下的 C、A就只能选择一个。 为什么只能选择一个，举例： 如果保证 G2 的一致性，那么 G1 必须在写操作时，锁定 G2 的读操作和写操作。只有数据同步后，才能重新开放读写。锁定期间，G2 不能读写，可用性不成立。 如果保证 G2 的可用性，那么势必不能锁定 G2，所以一致性不成立。 综上所述，G2 无法同时做到一致性和可用性。系统设计时只能选择一个目标。如果追求一致性，那么无法保证所有节点的可用性；如果追求所有节点的可用性，那就没法做到一致性。 总结来说，我们以为分布式能给我们带来绝大的性能提升，但是因为种种原因（最大的原因就是各个节点的状态如何同步），最终实际上的效果差强人意。 The Google File System 《The Google File System》是 GFS 最经典的论文，没有之一（2003年就有了:cow:)。 原文 翻译1 翻译2 原文简要目录结构： Introduction 简介 Design Overview 设计概述 2.3 Architecture 架构 2.6 Metadata 元数据 2.7 Consistency Model 一致性模型 System Interactions 系统交互 master Operation Master 节点操作 High Availability 容错和判断 简要理解： 1. 简介 参考自翻译2和理解 The Google File System 设计一个通用的分布式文件系统是不现实的，它不仅在实现上异常困难（因为不得不考虑所有应用场景），而且实际使用也难以满足要求（往往存在显而易见的性能或容错瓶颈）。GFS 设计初衷是利用数以千计的廉价机器为MapReduce提供底层可靠且高性能的分布式数据存储，以应对海量离线数据存储与处理的应用场景，比如存储应用程序持续产生的日志流以提供离线日志分析。由此，其设计目标为容错可靠(fault tolerance)、高性能读写(high-performance read&write)以及节约网络带宽(save bandwidth)。 组件故障是常态（the norm rather than the exception）。该文件系统由数百甚至数千台存由廉价普通（commodity）硬件组装的存储机器，并且被大量的客户机器访问。组件的数量和质量几乎保证了任何时间都有一些组件失效甚至有些无法从当前错误中恢复。我们见过由应用bugs，操作系统bugs和人为错误，还有硬盘错误，内存，连接器，网络和电源供应引起的问题。因此，持续监控，错误探测，容错和自动恢复必须集成到系统中。 传统标准下文件都很大。GB级的文件很常见。每个文件通常包含许多应用对象，比如Web文档。当我们通常要处理快速增长数据集组成的数十亿的对象时，不适合用数十亿大约KB大小的文件去管理。因此，设计假设和参数，例如I/O操作，块大小（blocksize）必须被重新审视（revisited）。 大部分文件是因追加数据被突变（mutated）而不是覆盖已有数据。某个文件里的随机写实践上不存在。一旦写入这些文件只会被读取而且经常是顺序读。多种数据都共有（share）这些特征。一些可能组成数据仓库（constitute large repositories）被数据分析程序扫描。一些可能是运行应用持续生成的数据流。一些可能是归档的数据。一些可能是一台机器产出在另一台机器同时或者后面适时（whether simultaneously or later in time）被处理的中间数据， 基于这种大文件访问模式，追加成为性能优化和原子性保证的关注点，与此同时客户端缓存数据块失去了吸引力。 ，综合设计应用和文件系统API，通过增加灵活性，对整个系统有好处。例如，我们放松了（relaxed）GFS的一致性模型来极大的简化了该文件系统且没有对应用施加繁重的负担。我们还引入了一种原子追加操作，这样多个客户端可以对同一文件并发追加，而它们之间不需要额外的同步。本文后面会详细讨论这些。 2. 设计概述 2.3. 架构 参考自理解 Google File System 以往的分布式系统，是没有中心节点的，但是在 GFS 中，我们将 Metadata（元数据，可以理解为控制信息）保存在 Master节点中，将用户需要的数据保存在 Chuck Sever 中， 这样我们可以方便的从 Master 中得知各个 Chuck Sever 的运行情况，同时 Master 不会成为制约这个系统的瓶颈，而且我们可以使用廉价的普通硬件作为 Chuck Sever 一举多得。 系统架构 GFS将整个系统节点分为三类角色: client（客户端） GFS提供给应用程序的访问接口 Master（主服务器） GFS的管理节点，也就是主节点，负责管理整个文件系统 Chuck Sever（数据块服务器） 负责具体的数据存储工作 GFS实现机制： client 首先访问 Master节点，从 Master 那里知道，自己应该去那些 Chuck Sever 那里去读取、写入数据，然后 client 再访问这个 Chuck Sever 去完成数据读写的工作。这样的设计方法实现了控制流和数据流的分离 clinet 和 Master 之间只有控制流，没有数据流，这样就极大的减轻了 Master 的负担。 client 和 Chuck Sever 之间直接传输数据流，同时由于文件被分成多个 Chuck 进行分布式存储， client 可以同时访问多个 Chuck Sever 从而使得整个系统的 I/O 高度并行，系统整体性能得到提升。 GFS特点： 采用中心服务器模型 可以方便地增加 Chuck Sever Master 可以掌握系统内所有 Chuck Sever 的情况，方便进行负载均衡。 不存在元数据的一致性问题 （解释一下，元数据就是存储在 Master 中的信息，一个系统内部会有多个 Master，这些 Master 可以看作彼此的备份。） 不缓存数据 文件操作大部分是流式读写，不存在大量重复读写，使用 Cache 对性能提高不大。 Chuck Sever 上数据存取使用本地文件系统，不用Cache 就不需要考虑缓存一致性的问题。 但是 Master 中的 metadata（元数据） 会缓存。 在用户态下实现 利用 POSIX 编程接口，提高了通用性。 Master 和 Chuck Sever 都以进程的方式运行，单个进行不影响整个操作系统。 GFS和操作系统运行在不同的空间，两者耦合性降低。 2.6. 元数据 Master存储了3种主要类型的元数据：文件和块命名空间（namespace），文件到块的映射和每个块副本的位置。所有元数据保存在master的内存中。前两种类型（namespaces和file-to-块 mapping）也会被通过记录突变（mutations）操作日志（by logging mutations to an operation log）存储在master本地磁盘和复制到远端机器。使用日志使得我们可以简单，可靠地更新master状态和在master崩溃时保持一致性。Master不持久化块位置信息。相反，它在启动时向每个块服务器询问块位置信息，和某个块服务器加入集群时询问。 2.7 一致性模型 参考自翻译2 和 理解 The Google File System GFS的宽松一致性模型支持我们的高度分布式的应用，GFS并没有采用复杂的一致性协议来保证副本数据的一致性，而是通过定义了三种不同的文件状态，并保证在这三种文件状态下，能够使得客户端看到一致的副本。三种状态描述如下： Consitent状态：当chunk被并发执行了操作后，不同的客户端看到的并发执行后的副本内容是一致的 defined状态：在文件处于consistent状态的基础上，还要保证所有客户端能够看到在此期间对文件执行的所有并发操作。即当文件操作并发执行时，如果它们是全局有序执行的（执行过程中没有被打断），则由此产生的文件状态为defined（当然也是consistent）。 undefined状态：如果并发操作文件失败，此时各客户端看到的文件内容不一致，则称文件处于undefined状态，当然也处于inconsistent状态。 文件命名空间突变（比如，文件创建）是原子的。它们只被master处理：命名空间锁保证原子性和正确性（4.1节）；master的操作日志定义全局操作顺序。 突变后文件区域状态 3. 系统交互 写入控制与数据流 我们通过跟随一次写的控制流的步骤解释这个过程: 客户端向master询问哪个块服务器握有这个块的租约和其它副本的位置。如果没有任何块有租约，master选择其中一个副本授予（未显示）。 Master回复首要副本的标识（identity）和其它副本的位置。客户端缓存这个数据用于未来的突变（mutations）。它只有当首要副本变得不可达或者回复说不再握有租约才需要再次联系master。 客户端把数据推到（push）所有的副本。这个操作客户端可以任意顺序。每个块服务器会将数据存储在内部的LRU缓冲缓存直到数据被使用或者老化。通过数据流与控制流解耦，我们可以通过基于网络拓扑调度繁重的数据流而不管哪个块服务器是首要的来改善性能。3.2节会进一步讨论这些。 一旦所有的副本确认收到数据，客户端发送写请求给primary。这个请求标识（identifies）了之前推送到所有副本的数据。Primary给所有收到的突变赋予连贯有序的序号，提供了必要的序列化。它序号应用突变到本地状态。 Primary转发了写请求给所有的二级副本（secondary replicas）。每个副本按照Primary分配的相同序号实施突变。 所有副本回复Primary操作已经完成。 Primary回复客户端。任何副本上的任何错误都会报告给客户端。如果出现错误，primary和任意二级副本子集可能已经被成功写入。（如果写操作在primary上就已经失败了，它就不会被分配序列号和转发。）客户端请求被认为失败了，修改的区域处于不一致状态。我们的客户端代码通过重试失败的突变来处理这样的错误。在重试整个写之前，它会重试步骤(3)到步骤(7)。 如果应用的写很大或者跨块边界，GFS客户端会将其分解成多个写操作。它们都遵循上面所述控制流，但是可能被其它客户端的并发操作交错（interleaved）或者重写（overwritten）。因此，共享文件区域最终可能包含来自不同客户端的片段，虽然这些副本将会是一致的，因为各个操作是完全成功的且在所有副本上是相同顺序的。这使得文件区域处于2.7节所定义的一致但是未定义的状态（consistent but undefined）。 值得注意的技术：记录追加（record append），快照 4. master 节点操作 Master执行所有命名空间操作。 此外，它还管理整个系统中的块复制：它进行放置决策，创建新块及其副本，并协调各种系统范围的活动以保持块完全复制，平衡所有块服务器的负载，并回收未使用的存储。 我们现在讨论这些主题。 命名空间管理和锁：许多Master操作可能需要很长时间：例如，快照操作必须撤消快照覆盖的所有块上的块服务器租约。 我们不希望在运行时推迟其它Master操作。 因此，我们允许多个操作处于活动状态，并在命名空间的区域上使用锁定以确保正确的序列化。 副本放置：最大限度地提高数据的可靠性和可用性，并最大化网络带宽利用率。 垃圾回收：文件被删除后，GFS不会立即回收可用的物理存储。它只惰性地在文件和块级别的常规垃圾收集期间这样做。我们发现这个方法让系统更简单，更可靠。 5. 容错和判断 参考自理解 Google File System Master 容错 Master维护文件系统所有的元数据（metadata），包括名字空间、访问控制信息、从文件到块的映射以及块的当前位置。 另外，每个 Chuck Sever 上都会保存 Chuck 副本的信息，每个 Chuck 默认有三个副本，这样当某个 Chuck 坏了之后，不会影响 Chuck 数据的读取。 当 Master 发生故障时，在磁盘数据保存完好的情况下，可以快速的恢复所有的 metadata。并且为了防止 Master 彻底死机的情况， GFS 还提供了 Master 的远程备份。 Chuck Sever 容错 GFS采用副本的方式实现Chunk Server的容错 每一个Chunk有多个存储副本（默认为三个） 对于每一个Chunk，必须将所有的副本全部写入成功，才视为成功写入 相关的副本出现丢失或不可恢复等情况，Master自动将该副本复制到其他 Chunk Server GFS中的每一个文件被划分成多个Chunk，Chunk的默认大小是64MB 每一个Chunk以Block为单位进行划分，大小为64KB，每一个Block对应一个 32bit 的校验和 开源技术 HDFS Colossus 背景 Colossus 的一些背景知识： 它是下一代 GFS。 其设计增强了存储可扩展性并提高了可用性，以应对数量不断增长的应用程序的大量数据需求。 Colossus 引入了分布式元数据模型，该模型提供了更具可扩展性和高可用性的元数据子系统。 Colossus 架构图 Client Library：客户端库是应用程序或服务与 Colossus 交互的方式，也是整个文件系统中最复杂的部分。 Colossus Control Plane：可扩展的元数据服务，它由许多 Curator 组成。客户直接与策展人交谈以进行控制操作，例如文件创建，并且可以水平扩展。 Metadata database：Curators 将文件系统元数据存储在 Google 的高性能 NoSQL 数据库BigTable 中。构建 Colossus 的最初动机是为了解决我们在尝试适应与搜索相关的元数据时使用 Google 文件系统 (GFS) 遇到的扩展限制。 D File Servers：Colossus 还最大限度地减少了网络上数据的跃点数。 Custodians：在维护数据的持久性和可用性以及整体效率、处理磁盘空间平衡和 RAID 重建等任务方面发挥着关键作用。 简单理解 参考自Google Spanner原理：地球上最大的单一数据库 2013年Google提出的下一代文件系统，而关于Colossus目前为止还没有相关的论文，网上只有一些零散介绍：Colossus。 Colossus也是一个不得不提起的技术。他是第二代GFS，对应开源世界的新HDFS。GFS是著名的分布式文件系统。初代GFS是为批处理设计的。对于大文件很友好，吞吐量很大，但是延迟较高。所以使用他的系统不得不对GFS做各种优化，才能获得良好的性能。那为什么Google没有考虑到这些问题，设计出更完美的GFS ?因为那个时候是2001年，Hadoop出生是在2007年。如果Hadoop是世界领先水平的话，GFS比世界领先水平还领先了6年。 Colossus是第二代GFS。Colossus是Google重要的基础设施，因为他可以满足主流应用对FS的要求。Colossus的重要改进有： 优雅Master容错处理 (不再有2s的停止服务时间) Chunk大小只有1MB (对小文件很友好) Master可以存储更多的Metadata(当Chunk从64MB变为1MB后，Metadata会扩大64倍，但是Google也解决了) Colossus可以自动分区Metadata。使用Reed-Solomon算法来复制，可以将原先的3份减小到1.5份，提高写的性能，降低延迟。客户端来复制数据。具体细节未开源。 MapReduce MapReduce是一个编程模型，也是一个处理和生成超大数据集的算法模型的相关实现。用户首先创建一个Map函数处理一个基于 key/value pair的数据集合，输出中间的基于key/value pair的数据集合；然后再创建一个Reduce函数用来合并所有的具有相同中间key值的中间value值。 MapReduce架构的程序能够在大量的普通配置的计算机上实现并行化处理。这个系统在运行时只关心：如何分割输入数据，在大量计算机组成的 集群上的调度，集群中计算机的错误处理，管理集群中计算机之间必要的通信。采用MapReduce架构可以使那些没有并行计算和分布式处理系统开发经验的 程序员有效利用分布式系统的丰富资源。 MapReduce: Simplified Data Processing on Large Clusters 原文 翻译 原文简要目录结构： 介绍 编程模型 实现 简要理解 介绍 大数据的数据处理一般在概念上容易理解，然后由于输入的数据量巨大，因此想要在可接受的时间内完成运算，只有将这些计算分布在成百上千的主机上。如何处理并行计算、如何分发数据、如何处理错误？所有这些问题综合在一起，需要大量的代码处理，因此也使得原本简单的运算变得难以处理 为了解决上述复杂的问题，我们设计一个新的抽象的问题，使用这个抽象模型，我们摘要表述我们想要执行的简单运算即可，而不必关心并行计算、容错、数据分布、负载均衡等复杂的细节，这些问题都被封装在一个库里面。 大多数运算都包含这样的操作：在输入数据的“逻辑”记录上应用 Map 操作得到一个中间 key/value pair 集合，然后在所有具有相同 key 值的 value 值上应用 Reduce 操作，从而达到合并中间的数据，得到一个想要的结果的目的。使用 MapReduce 模型，再结合用户实现的 Map 和 Reduce 函数，我们就可以非常容易的实现大规模并行化计算，通过 MapReduce 模型自带的 re-execution 功能，也提供了初级的容灾实现方案 MapReduce 的主要贡献是通过简单的接口来实现自动的并行化和大规模的分布式计算，通过使用 MapReduce 模型接口实现在大量普通的 PC 机上高性能计算 编程模型 MapReduce 编程模型的原理是：利用一个 key/value pair 集合来产生一个输出的 key/value pair 集合。 MapReduce 库的用户两个函数表达这个计算：Map 和 Reduce，用户自定义的 Map 函数接受一个输入的 key/value pair 值，然后产生一个中间 key/value pair 值的集合。 MapReduce 库把所有具有相同中间 key 值的中间 value值集合在一起后传递给 Reduce 函数 eg: map(String key, String value): // key: document name // value: document contents for each word w in value: EmitIntermediate(w, “1″); reduce(String key, Iterator values): // key: a word // values: a list of counts int result = 0; for each v in values: result += ParseInt(v); Emit(AsString(result)); 实现 MapReduce 模型有多种实现方式，如何正确选择取决于具体的环境： 小型的共享内存式的机器 大型 NUMA 架构的多处理器的主机 大型的网络连接集群 执行概况 操作流程： 用户程序首先调用 MapReduce 库将输入文件分成 M 个数据片度，每个数据片段的大小一般从 16 MB 到 64 MB，然后用户程序在集群中创建大量的程序副本 这些程序副本中的有一个特殊的程序——master。副本中其它程序都是 worker 程序，由 master 分配任务，有 M 个 Map 任务和 R 个 Reduce 任务被分配， master 将一个 Map 任务或 Reduce 任务分配一个空闲的 worker 被分配了 map 任务的 worker 程序读取相关的输入数据片段，从输入的数据片段中解析出 key/value pair，然后把 key/value pair 传递给用户自定义的 Map 函数，由 Map 函数生成并输出中间 key/value pair，并缓存在内存中 缓存中的 key/value pair 通过分区函数分成 R 个区域，之后中周期性的写入到本地磁盘上。缓存的 key/value pair 在本地磁盘上的存储位置将被回传给 master，由 master 负责把这些存储位置再传送给 Reduce worker 当 Reduce worker 程序接收到master程序发来的数据存储位置信息后，适用 RPC 从 Map worker 所在的主机的磁盘上读取这些缓存数据。当 Reduce worker 读取了所有的中间数据，通过对 key 进行排序后使得具有相同 key 值的数据聚合在一起。 Reduce worker 程序遍历排序后的中间数据，对于每一个唯一的中间 key 值，Reduce worker 程序将这个 key 值和它相关的种中间 value 值的集合传递给用户定义的 Reduce 函数。Reduce 函数的输出被追加到所属分区的输出文件 当所有的 Map 和 Reduce 任务都完成之后，master 唤醒用户程序 Master 数据结构：Master持有一些数据结构，它存储每一个 Map 和 Reduce 任务的状态（空闲、工作中或完成），以及 Worker 机器（非空闲任务的机器）的标识。Master 就像一个数据管道，中间文件存储区域的位置信息通过这个管道从 Map 传递给 Reduce，因此对于每个已经完成 Map 任务，Master存储了 Map 任务产生的 R 个中间文件存储区域的大小和位置。当 Map 任务完成时，Master 接收到位置和大小爱的更新信息，这些信息被逐步递增的推送给那些正在工作的 Reduce 工作 存储位置 在我们的计算运行环境中，网络带宽是一个相当匮乏的资源。我们通过尽量把输入数据(由GFS管理)存储在集群中机器的本地磁盘上来节省网络带 宽。GFS把每个文件按64MB一个Block分隔，每个Block保存在多台机器上，环境中就存放了多份拷贝(一般是3个拷贝)。MapReduce的 master在调度Map任务时会考虑输入文件的位置信息，尽量将一个Map任务调度在包含相关输入数据拷贝的机器上执行；如果上述努力失败 了，master将尝试在保存有输入数据拷贝的机器附近的机器上执行Map任务(例如，分配到一个和包含输入数据的机器在一个switch里的 worker机器上执行)。当在一个足够大的cluster集群上运行大型MapReduce操作的时候，大部分的输入数据都能从本地机器读取，因此消耗 非常少的网络带宽。 结束语 MapReduce编程模型在Google内部成功应用于多个领域。我们把这种成功归结为几个方面：首先，由于MapReduce封装了并行处 理、容错处理、数据本地化优化、负载均衡等等技术难点的细节，这使得MapReduce库易于使用。即便对于完全没有并行或者分布式系统开发经验的程序员 而言；其次，大量不同类型的问题都可以通过MapReduce简单的解决。比如，MapReduce用于生成Google的网络搜索服务所需要的数据、用 来排序、用来数据挖掘、用于机器学习，以及很多其它的系统；第三，我们实现了一个在数千台计算机组成的大型集群上灵活部署运行的MapReduce。这个 实现使得有效利用这些丰富的计算资源变得非常简单，因此也适合用来解决Google遇到的其他很多需要大量计算的问题。 我们也从MapReduce开发过程中学到了不少东西。首先，约束编程模式使得并行和分布式计算非常容易，也易于构造容错的计算环境；其次，网络带 宽是稀有资源。大量的系统优化是针对减少网络传输量为目的的：本地优化策略使大量的数据从本地磁盘读取，中间文件写入本地磁盘、并且只写一份中间文件也节 约了网络带宽；第三，多次执行相同的任务可以减少性能缓慢的机器带来的负面影响（alex注：即硬件配置的不平衡），同时解决了由于机器失效导致的数据丢失问题。 开源技术 Hadoop Mapreduce Spark Percolator/Dremel BigTable Bigtable是一个分布式的结构化数据存储系统，它被设计用来处理海量数据：通常是分布在数千台普通服务器上的PB级的数据。Google的很 多项目使用Bigtable存储数据，包括Web索引、Google Earth、Google Finance。这些应用对Bigtable提出的要求差异非常大，无论是在数据量上（从URL到网页到卫星图像）还是在响应速度上（从后端的批量处理到 实时数据服务）。尽管应用需求差异很大，但是，针对Google的这些产品，Bigtable还是成功的提供了一个灵活的、高性能的解决方案。利用这个模型，用户可以动态的控制数据的分布和格式。 通常GFS用于存储海量数据，文件系统将数据在各个节点冗余复制。在某种程度上MapReduce可以对GFS进行补充，以便充分利用GFS中廉价的服务器所提供的CPU。和GFS一起构成了处理海量数据的核心力量，构建类似于Google的搜索索引也是一样的。但是这两个系统都缺乏实时随机存取数据的能力，在web应用处理方面还有所欠缺。 Bigtable: A Distributed Storage System for Structured Data 原文 翻译 原文简要目录结构： 介绍 数据模型 BigTable 构件 实施 5.1 Tablet的位置 5.2 Tablet 分配 5.3 Tablet 服务 结果感言 1. 介绍 Bigtable已经在超过60个Google的产品和项目上得到了应用，包括 Google Analytics、Google Finance、Orkut、PersonalizedSearch、Writely和Google Earth。这些产品对Bigtable提出了迥异的需求，有的需要高吞吐量的批处理，有的则需要及时响应，快速返回数据给最终用户。它们使用的Bigtable集群的配置也有很大的差异，有的集群只有几台服务器，而有的则需要上千台服务器、存储几百TB的数据。 在很多方面，Bigtable 和数据库很类似，它使用了很多数据库的实现策略。并行数据库和内存数据库，已经具备高可扩展性和高性能，但是 Bigtable 不支持完整的关系型数据模型，与之相反，Bigtable 为客户提供了简单的数据模型，利用这个模型，客户可以动态控制数据的分布和格式。数据的下标是行和列的名字，名字可以是任意的字符串。Bigtable将存储的数据都视为字符串，但是Bigtable本身不去解析这些字符串，通常客户程序会把各种结构化或者半结构化的数据串行化到这些字符串里。通过仔细选择数据的模式，客户可以控制数据的位置相关性。最后，可以通过BigTable的模式参数来控制数据是存放在内存中还是硬盘上 2. 数据模型 Bigtable 是一个稀疏的、分布式的、持久化存储的多维度排序Map，索引key 是行关键字、列关键字和时间戳，值value是一个未经解析的byte数组 (row:string,column:string,time:int64)->string 这里最重要的就是 row 的值，它的长度最大可以为 64KB，对于同一 row 下数据的读写都可以看做是原子的；因为 Bigtable 是按照 row 的值使用字典顺序进行排序的，每一段 row 的范围都会被 Bigtable 进行分区，并交给一个 tablet 进行处理。 Rows 可以是任意的字符串（最大支持 64 kb，但是对大多数用户，10-100个字节就足够了）。对同一个行关键字的读或者写操作都是原子的，这个设计决策能够使用户很容易的理解程序在对同一个行进行并发更新操作的行为 Bigtable 通过行关键字的字典顺序来组织数据。表中的每个行都可以动态分区，每个分区叫做一个\"Tablet\"，Tablet 是数据分布和负载均衡的最小单位 Cols 列是访问控制的基本单位。存放在同一列簇下的所有数据通常都属于同一类型（我们可以把同一列簇下的数据压缩在一起）。列簇在使用之前必须先创建，然后才能在列簇中任何的列关键字下存放数据。列簇创建后，其中的任何一个列关键字下都可以存放数据 Timestamps 在Bigtable 中，表中的每一个数据项都可以包含同一份数据的不同版本，不同版本的数据通过时间戳来索引。Bigtable时间戳的类型是64位整型， 4. 基础组成 BIgtable 是建立在其它的几个 Google 基础构件之上的。BigTable 使用 Google 的分布式文件系统（GFS）存储日志文件和数据文件。BigTable 集群通常运行在一个共享的机器池中，池中的机器还会运行其它的各种各样的分布式应用程序，BigTable的进程通常要和其它应用的进程共享机器。BigTable 依赖集群管理系统来调度任务、管理共享机器上的资源，处理机器的故障以及监视机器的状态 BigTable内部存储数据的文件是GoogleSSTable格式的。SSTable是一个持久化的、排序的、不可更改的Map结构，而Map是一个key-value 映射的数据结构，key和value的值都是任意的Byte串。可以对SSTable进行如下的操作：查询与一个key值相关的value，或者遍历某个 key值范围内的所有的key-value对。从内部看，SSTable是一系列的数据块（通常每个块的大小是64KB，这个大小是可以配置的）。 SSTable使用块索引（通常存储在SSTable的最后）来定位数据块；在打开SSTable的时候，索引被加载到内存。每次查找都可以通过一次磁盘 搜索完成：首先使用二分查找法在内存中的索引里找到数据块的位置，然后再从硬盘读取相应的数据块。也可以选择把整个SSTable都放在内存中，这样就不 必访问硬盘了。 BigTable还依赖一个高可用的、序列化的分布式锁服务组件，叫做Chubby【8】。一个Chubby服务包括了5个活动的副本，其中的一个副本被选为Master，并且处理请求。只有在大多数副本都是正常运行的，并且彼此之间能够互相通信的情况下，Chubby服 务才是可用的。当有副本失效的时候，Chubby使用Paxos算法【9,23】来保证副本的一致性。Chubby提供了一个名字空间，里面包括了目录和 小文件。每个目录或者文件可以当成一个锁，读写文件的操作都是原子的。Chubby客户程序库提供对Chubby文件的一致性缓存。每个Chubby客户 程序都维护一个与Chubby服务的会话。如果客户程序不能在租约到期的时间内重新签订会话的租约，这个会话就过期失效了(alex注：又用到了lease。原文是：Aclient’s session expires if it is unable to renew its session lease within the leaseexpiration time.)。当一个会话失效时，它拥有的锁和打开的文件句柄都失效了。Chubby客户程序可以在文件和目录上注册回调函数，当文件或目录改变、或者会 话过期时，回调函数会通知客户程序。 5. Tablet Location BigTable 包括了三个主要的组件：链接到客户程序中的库、一个Master 服务器和多个 Tablet 服务器。针对系统工作负载的情况，BigTable 可以动态的向集群中添加（或者删除）Tablet 服务器 Master服务器主要负责以下工作：为Tablet服务器分配Tablets、检测新加入的或者过期失效的Table服务器、对Tablet服务器进行负载均衡、以及对保存在GFS上的文件进行垃圾收集。除此之外，它还处理对模式的相关修改操作，例如建立表和列族。 每个Tablet服务器都管理一个Tablet的集合（通常每个服务器有大约数十个至上千个Tablet）。每个Tablet服务器负责处理它所加载的Tablet的读写操作，以及在Tablets过大时，对其进行分割。 一个BigTable集群存储了很多表，每个表包含了一个Tablet的集合，而每个Tablet包含了某个范围内的行的所有相关数据。初始状态 下，一个表只有一个Tablet。随着表中数据的增长，它被自动分割成多个Tablet，缺省情况下，每个Tablet的尺寸大约是100MB到 200MB。 Tablet 的位置信息 Tablet 的层次结构 第一层是一个存储在Chubby中的文件，它包含了Root Tablet的位置信息。Root Tablet包含了一个特殊的METADATA表里所有的Tablet的位置信息。METADATA表的每个Tablet包含了一个用户Tablet的集合。RootTablet实际上是METADATA表的第一个Tablet，只不过对它的处理比较特殊 — Root Tablet永远不会被分割 — 这就保证了Tablet的位置信息存储结构不会超过三层。 在METADATA表里面，每个Tablet的位置信息都存放在一个行关键字下面，而这个行关键字是由Tablet所在的表的标识符和Tablet 的最后一行编码而成的。METADATA的每一行都存储了大约1KB的内存数据。在一个大小适中的、容量限制为128MB的METADATA Tablet中，采用这种三层结构的存储模式，可以标识2^34个Tablet的地址 Tablet 管理 既然在整个 Bigtable 中有着海量的 tablet 服务器以及数据的分片 tablet，那么 Bigtable 是如何管理海量的数据呢？Bigtable 与很多的分布式系统一样，使用一个主服务器将 tablet 分派给不同的服务器节点。 为了减轻主服务器的负载，所有的客户端仅仅通过 Master 获取 tablet 服务器的位置信息，它并不会在每次读写时都请求 Master 节点，而是直接与 tablet 服务器相连，同时客户端本身也会保存一份 tablet 服务器位置的缓存以减少与 Master 通信的次数和频率。 读和写请求 从读写请求的处理，我们其实可以看出整个 Bigtable 中的各个部分是如何协作的，包括日志、memtable 以及 SSTable 文件。 当有客户端向 tablet 服务器发送写操作时，它会先向 tablet 服务器中的日志追加一条记录，在日志成功追加之后再向 memtable 中插入该条记录；这与现在大多的数据库的实现完全相同，通过顺序写向日志追加记录，然后再向数据库随机写，因为随机写的耗时远远大于追加内容，如果直接进行随机写，由于随机写执行时间较长，在写操作执行期间发生设备故障造成数据丢失的可能性相对比较高。 当 tablet 服务器接收到读操作时，它会在 memtable 和 SSTable 上进行合并查找，因为 memtable 和 SSTable 中对于键值的存储都是字典顺序的，所以整个读操作的执行会非常快。 表的压缩 随着写操作的进行，memtable 会随着事件的推移逐渐增大，当 memtable 的大小超过一定的阈值时，就会将当前的 memtable 冻结，并且创建一个新的 memtable，被冻结的 memtable 会被转换为一个 SSTable 并且写入到 GFS 系统中，这种压缩方式也被称作 Minor Compaction。 每一个 Minor Compaction 都能够创建一个新的 SSTable，它能够有效地降低内存的占用并且降低服务进程异常退出后，过大的日志导致的过长的恢复时间。既然有用于压缩 memtable 中数据的 Minor Compaction，那么就一定有一个对应的 Major Compaction 操作。 Bigtable 会在后台周期性地进行 Major Compaction，将 memtable 中的数据和一部分的 SSTable 作为输入，将其中的键值进行归并排序，生成新的 SSTable 并移除原有的 memtable 和 SSTable，新生成的 SSTable 中包含前两者的全部数据和信息，并且将其中一部分标记为删除的信息彻底清除。 Google Earth Google通过一组服务为用户提供了高分辨率的地球表面卫星图像，访问的方式可以使通过基于Web的Google Maps访问接口（maps.google.com），也可以通过Google Earth定制的客户端软件访问。这些软件产品允许用户浏览地球表面的图像：用户可以在不同的分辨率下平移、查看和注释这些卫星图像。这个系统使用一个表 存储预处理数据，使用另外一组表存储用户数据。 数据预处理流水线使用一个表存储原始图像。在预处理过程中，图像被清除，图像数据合并到最终的服务数据中。这个表包含了大约70TB的数据，所以需要从磁盘读取数据。图像已经被高效压缩过了，因此存储在Bigtable后不需要再压缩了。 Imagery表的每一行都代表了一个单独的地理区域。行都有名称，以确保毗邻的区域存储在了一起。Imagery表中有一个列族用来记录每个区域 的数据源。这个列族包含了大量的列：基本上市每个列对应一个原始图片的数据。由于每个地理区域都是由很少的几张图片构成的，因此这个列族是非常稀疏的。 数据预处理流水线高度依赖运行在Bigtable上的MapReduce任务传输数据。在运行某些MapReduce任务的时候，整个系统中每台Tablet服务器的数据处理速度是1MB/s。 这个服务系统使用一个表来索引GFS中的数据。这个表相对较小（大约是500GB），但是这个表必须在保证较低的响应延时的前提下，针对每个数据中心，每秒处理几万个查询请求。因此，这个表必须在上百个Tablet服务器上存储数据，并且使用in-memory的列族。 开源技术 LevelDB LevelDB 是对 Bigtable 论文中描述的键值存储系统的单机版的实现，它提供了一个极其高速的键值存储系统，并且由 Bigtable 的作者 Jeff Dean 和 Sanjay Ghemawat 共同完成，可以说高度复刻了 Bigtable 论文中对于其实现的描述。 Hbase F1 Spanner Spanner 参考自Google Spanner原理：地球上最大的单一数据库 Spanner 是Google的全球级的分布式数据库 (Globally-Distributed Database) 。Spanner的扩展性达到了令人咋舌的全球级，可以扩展到数百万的机器，数已百计的数据中心，上万亿的行。更给力的是，除了夸张的扩展性之外，他还能同时通过同步复制和多版本来满足外部一致性，可用性也是很好的。冲破CAP的枷锁，在三者之间完美平衡。 Spanner是个可扩展，多版本，全球分布式还支持同步复制的数据库。他是Google的第一个可以全球扩展并且支持外部一致的事务。Spanner能做到这些，离不开一个用GPS和原子钟实现的时间API。这个API能将数据中心之间的时间同步精确到10ms以内。因此Spanner是个可扩展，多版本，全球分布式还支持同步复制的数据库。他是Google的第一个可以全球扩展并且支持外部一致的事务。Spanner能做到这些，离不开一个用GPS和原子钟实现的时间API。这个API能将数据中心之间的时间同步精确到10ms以内。因此有几个给力的功能：无锁读事务，原子schema修改，读历史数据无block。有几个给力的功能：无锁读事务，原子schSpanner是个可扩展，多版本，全球分布式还支持同步复制的数据库。他是Google的第一个可以全球扩展并且支持外部一致的事务。Spanner能做到这些，离不开一个用GPS和原子钟实现的时间API。这个API能将数据中心之间的时间同步精确到10ms以内。因此有几个给力的功能：无锁读事务，原子schema修改，读历史数据无block。Spanner是个可扩展，多版本，全球分布式还支持同步复制的数据库。他是Google的第一个可以全球扩展并且支持外部一致的事务。Spanner能做到这些，离不开一个用GPS和原子钟实现的时间API。这个API能将数据中心之间的时间同步精确到10ms以内。因此有几个给力的功能：无锁读事务，原子schema修改，读历史数据无block。Spanner是个可扩展，多版本，全球分布式还支持同步复制的数据库。他是Google的第一个可以全球扩展并且支持外部一致的事务。Spanner能做到这些，离不开一个用GPS和原子钟实现的时间API。这个API能将数据中心之间的时间同步精确到10ms以内。因此有几个给力的功能：无锁读事务，原子schema修改，读历史数据无block。ema修改，读历史数据无block。 Spanner: Google’s Globally-Distributed Database 原文 翻译 Spanner是一个可伸缩、全球化分布的数据库，其由Google设计、构建、并部署。在抽象的最高层，Spanner是一个将数据分片（shard）到分布在全世界的多个数据中心中的跨多个Paxos[21]状态机集合上的数据库。Spanner采用多副本以提供全球化的可用性和地理位置优化；客户端自动地在副本间进行故障转移。在数据总量或服务器的数量变化时，Spanner自动地在机器间重分片数据，并自动地在机器间（甚至在数据中心间）迁移数据来平衡负载和应对故障。按照设计，Spanner扩展到跨数百个数据中心的数百万台机器与数万亿个数据库行。 Borg Kubernetes Flume 开源技术 大数据中台 发展阶段 1、单一系统 2、分布式系统 3、平台化（服务业务，支撑作用） 4、中台化（驱动业务，中枢作用） 单一系统 数据仓库，数据库 分布式系统 上述三篇论文提出一种面向海量数据分析、面向海量异构数据的统御i计算和存储方法，奠定了现代大数据、大规模并行计算的基础。Yahoo对此做了开源实现，就是现在的 Hadoop 演变关系： GFS—->HDFS(2004) Google MapReduce—->Hadoop MapReduce (2004)--> Spark (2014) BigTable—->HBase(2008) 随着Hadoop技术日趋成熟，2010年提出一个新的概念：数据湖（Data Lake）是一个以原始格式存储数据的存储库或系统 2018年提出数据河的概念，避免“数据湖”成为“数据沼泽”，流动的“数据河”是关键。因为大部分使用数据湖的企业在数据真的需要使用的时候，往往因为数据湖中的数据质量太差而无法最终使用。数据只有流动起来，才可以不成为数据沼泽，湖泊只是暂存数据河流的基地。数据流动就意味着所有的数据产生，最终要有它的耕种者和使用者。要让数据有效流动起来，就要建立有效的“数据河”（Data River）。数据河（Data River）就是在由源头产生清晰干净的有效数据（去ETL化，数据源头业务就像生态水源一样，不让污水流下去），通过各个河流网，流向各个数据消费端的架构。 数据工厂时代：大数据平台 大数据平台是面向数据研发场景的，覆盖数据研发的完整链路的数据工作台。就是为了提高数据研发的效率，降低数据研发的门槛，让数据能够在一个设备流水线上快速地完成加工。 大数据平台按照使用场景，分为数据集成、数据开发、数据测试……任务运维，大数据平台的使用对象是数据开发。大数据平台的底层是以 Hadoop 为代表的基础设施，分为计算、资源调度和存储等。 数据存储：HDFS，HBase，Kudu等 数据计算：MapReduce, Spark, Flink 交互式查询：Impala, Presto 在线实时分析：ClickHouse，Kylin，Doris，Druid，Kudu等 资源调度：YARN，Mesos，Kubernetes 任务调度：Oozie，Azakaban，AirFlow等 .... 数据收集，数据迁移，服务协调，安装部署，数据治理等 大数据平台像一条设备流水线，经过大数据平台的加工，原始数据变成了指标，出现在各个报表或者数据产品中。 数据价值时代：数据中台 在应用大数据平台架构的时候，你可能遇到这么个问题：因为烟囱式的开发，不同数据应用可能存在相同应用指标，但是运营可能发现这些数据指标的结果不一致，因为不知道该用谁信任谁而导致运营对数据的信任下降。 数据割裂的另外一个问题，就是大量的重复计算、开发，导致的研发效率的浪费，计算、存储资源的浪费，大数据的应用成本越来越高。 如果你是运营，当你想要一个数据的时候，开发告诉你至少需要一周，你肯定想是不是太慢了，能不能再快一点儿？ 如果你是数据开发，当面对大量的需求的时候，你肯定是在抱怨，需求太多，人太少，活干不完。 如果你是一个企业的老板，当你看到每个月的账单成指数级增长的时候，你肯定觉得这也太贵了，能不能再省一点，要不吃不消了。 这些问题的根源在于，数据无法共享。 2016 年，阿里巴巴率先提出了“大中台，小前台”战略，推出了数据中台。数据中台的核心，是避免数据的重复计算，通过数据服务化，提高数据的共享能力，赋能数据应用。之前，数据是要啥没啥，中间数据难于共享，无法积累。现在建设数据中台之后，要啥有啥，数据应用的研发速度不再受限于数据开发的速度，然后我们就可以根据需求场景，快速孵化出很多数据应用，这些应用让数据产生价值。 总的来说，数据中台吸收了传统数据仓库、数据湖、大数据平台的优势，同时又解决了数据共享的难题，通过数据应用，实现数据价值的落地。 2016 年，阿里巴巴就提出了数据中台建设的核心方法论：OneData 和 OneService，OneData 就是所有数据只加工一次OneService，数据即服务，强调数据中台中的数据应该是通过 API 接口的方式被访问。 现阶段企业数据应用现状： 数据量小的使用 MySQL：Hive数仓，Spark计算引擎的计算结果导出到MySQL 数据量大的使用HBase + ElasticSearch：解决海量数据中的低延迟高效查询 需要多维分析的可能需要 ClickHouse，Kylin，Greenplum：提供现在分析能力 实时性要求高的需要用到 Redis 网易数据中台 发展 谷歌新一代搜索引擎平台和大数据分析核心技术 Google是GFS MapReduce BigTable的缔造者，但Google 新一代搜索引擎平台正逐步用更强计算能力的系统来替换原有系统，新一代搜索引擎平台有几个核心技术系统： 于Percolator的增量处理索引系统来取代MapReduce批处理索引系统，这个索引系统被称作Caffeine，它比MapReduce批处理索引系统搜索更快。 是专为BigTable设计的分布式存储Colossus，也被称为GFS2（二代Google文件系统），它专为建立Caffeine搜索索引系统而用。 是列存储数据库BigTable，但为了更好地支持大数据集的互动分析，Google推出了Dremel和PowerDrill。Dremel被设计用来管理非常大量的大数据集（指数据集的数量和每数据集的规模都大），而PowerDrill则设计用来分析少量的大数据集（指数据集的规模大，但数据集的数量不多）时提供更强大的分析性能。 Google Instant提供服务的实时搜索引擎存储和分析架构 是Pregel，这是谷歌更快捷的网络和图算法。 　　在谷歌新一代搜索引擎平台上，每月40亿小时的视频，4.25亿Gmail用户，150,000,000 GB Web索引，却能实现0.25秒搜索出结果 Google基础云服务 基于Colossus，谷歌为用户提供计算、存储和应用的云服务。计算服务包括计算的引擎（ComputeEngine）和应用APP的引擎(AppEngine)；存储服务包括云存储（CloudStorge）、云SQL(CLoudSQL)、云数据存储（Cloud DataStore）、永久磁盘等服务；云应用服务包括BigQuery、云终端（Cloud Endpoints）、缓冲、队列等 "},"bigData/Hadoop.html":{"url":"bigData/Hadoop.html","title":"Hadoop","keywords":"","body":"Hadoop [toc] 初学者指南 地址是 hadoop 初学者指南 0. 前言 以前大型数据集应用复杂分析的能力曾经是大公司和政府机构的专利，但是现在可以通过免费的开源软件（OSS）实现。但由于这一领域似乎很复杂，变化速度也很快，掌握基础知识可能会有点令人望而生畏。这就是这本书的用武之地，它会告诉你 Hadoop 是什么，它是如何工作的，以及你如何使用它从数据中提取价值。 除了对核心 Hadoop 的解释之外，我们还花了几章来探索使用 Hadoop 或与之集成的其它技术。我们的目标不仅是让你了解 Hadoop 是什么，还希望你了解更广泛的技术基础设施的一部分来使用。一种补充技术是使用云计算，特别是亚马逊 Web 服务。在整本书中，将会展示如何使用这些服务来托管你的 Hadoop 工作负载，从而说明你不仅可以处理大量数据，而且实际上不需要购买任何物理硬件就可以实现这一点。 1. 说明这一切是怎么回事 Hadoop 不是在真空中创建的；相反，它的存在是因为创建和使用的数据量呈爆炸式增长，而且这种数据洪流不仅出现在大型跨国公司身上，还出现在小型初创公司身上。 与此同时，其他趋势也改变了软件和系统的部署方式，与更传统的基础设施一起使用云资源，甚至优先使用云资源。 大数据处理 环顾一下我们今天拥有的技术，很容易得出这样一个结论：一切都是数据的。不仅生成的数据量在增加，而且增长速度也在加快。从电子邮件到 Facebook 帖子，从购买历史到网络连接，到处都有不断增长的大型数据集。挑战在于如何从这些数据中提取最有价值的方面，有时这意味着寻找数据集里面特定的数据元素，而在其它时候，重点是识别数据片段之间的趋势和关系。 在幕后发生了一种微妙的变化，这一切都是关于以越来越有意义的方式使用数据。 数据的价值 如果大规模的数据处理不能带来可观的回报，为什么要对它进行处理呢，大数据的价值可能会在以下几个方面体现： 有些问题只有在足够大的数据集才会给出价值。在没有任何其它因素的情况下，根据一个人的喜好推荐一部电影不太可能非常准确，将人数增加到100人，机会略有增加，如果是1000万人其它人的观看历史记录，发现有用的建议的机会会大大提高 与以前的解决方案相比，现在的大数据工具能以更低的成本执行以前昂贵得让人望而却步的数据处理任务 大规模数据处理的成本不仅仅是财务费用，延迟也是一个关键因素。一个系统可能能够处理非常多的数据，但是平均处理时间是以周为单位来衡量，那么它可能就没有什么用处了。大数据工具允许在控制处理时间的同时增加数据量，通常是通过将增加的数据量与额外的硬件相匹配来实现（横向扩展） 以前关于数据库是什么样子或则它的数据应该怎么设计可能需要重新考虑了，以满足最大的数据问题的需要 足够大的数据集和灵活的工具可能可以回答以前想象不到的问题 经典数据处理系统 大数据挖掘系统稀少且昂贵的根本原因是，扩展一个系统以处理大数据集事非常困难；正如我们将看到的，它传统上受限于一台计算机的处理能力。但是随着数据大小的增加，有两种扩展系统的主要方法，通常称为向上扩展和向外扩展 向上扩展：在大多数企业中，数据处理通常是在价格高得惊人的大型计算机上执行的。随着数据大小的增长，方法是移动到更大的服务器或存储阵列。简单向上扩展的优势在于架构不会因为增长而发生重大变化。虽然用来较大的组件，但基本关系（例如，数据库服务器和存储阵列）保持不变。对于商业数据库引擎等应用，软件处理利用可用硬件的复杂性，但从理论上讲，通过将相同的软件迁移到越来越大的服务器上可以实现更大的规模。（但是实际上这个难度也不低） 向外扩展：单个主机大小也有实际限制，在某些情况下，向上扩展不能在进一步扩展。横向扩展方法将处理分散到越来越多的机器上，而不是将系统扩展到越来越大的硬件上。如果数据集翻了一番，只需要使用两台服务器，而不是一台双倍大小的服务器。这种方法的明显好处事，购买成本低得多。假设一台主机的价格是 5000 美元，但一台处理能力是其十倍的主机的价格可能是其一百倍。缺点是，我们需要制定策略将我们的数据处理分散到一组服务器上，而历史上证明这个策略也是复杂的 因此部署横向扩展解决方案需要大量的工程工作，系统开发人员需要手工制作用于数据分区和数据重组的机制，更不用说跨集群安排工作和处理单个机器故障的逻辑了 向上扩展的成本很高，向外扩展开发和管理系统的努力也是如此。限制因素主要有： 随着横向扩展系统变得越来越大，或者随着纵向扩展系统处理多个 CPU，系统中并发的复杂性带来的困难变得非常严重。有效利用多个主机或 CPU 是一项非常难的任务，实施必要的策略以在所需工作负载的整个执行过程中保持效率可能需要付出巨大的努力 系统能力的差异开始凸显。CPU 能力的增长速度远远快于网络或磁盘速度，CPU 周期曾经是系统中最有价值的资源，但是在今天这种情况已不再存在。与 20 年前相比，现代 CPU 能执行数百万倍的操作，但是内存和硬盘速度只增加了数千或数百倍。构建一个 CPU 强大的现代系统比较容易，以至于存储系统根本不能以足够快的速度向其提供数据，从而使 CPU 忙碌 从前面的场景来看，许多技术已经被成功用于减轻将数据处理系统扩展到大数据所需的痛苦，一些经验之谈如下： 1. 不共享任何内容 共享的原则不适用于数据处理系统，而且这一思想既适用于数据，也适用于硬件。例如横向扩展体系结构中每个主机处理整个数据集的一个子集，以产生其最终结果的一部分。然后显示很少如此，主机之间可能需要相互通信，或者多个主机可能都需要某些数据。这些额外的依赖关系会给系统带来两方面的负面影响：瓶颈和故障。 瓶颈：如果系统中的每个计算都需要一条数据或单个服务器，则在相互竞争的客户端访问公共数据的主机时，存在争用和延迟的可能性。例如，如果在具有 25 台主机的系统中，只有一台主机必须由其它主机访问，则系统的整体性能将受该关键主机的功能限制 故障：如果保持关键数据的这个“热”服务器或存储系统出现故障，整个工作负载将崩溃。早期的集群解决方案经常显示出这种风险 系统的各个组件应该尽可能独立，而不是共享资源，无论其它组件是否被复杂的工作所束缚或者已经故障了，每个组件都可以继续工作 2. 预计失败 我们可能会听到一种术语 “99.999% 的正常运行时间或可用性）”，虽然这绝对是同类中最好的可用性，但更重要的是认识到由此类设备组成的系统的总体可靠性可能由很大的差异，这取决于系统是否能够容忍单个组件故障 不能容忍单个组件故障：假设一台服务器具有 99% 的可靠性，系统需要 5 台这样的主机才能运行，则系统的可用性就是 0.99 的 5 次方，相当于 95% 的可用性。如果单个服务器的可靠性只有 95%，系统可靠性就会下降到只有 76% 能容忍单个组件故障：相反，如果构建的系统在任何给定时间只需要五台主机中的一台正常工作，则系统可用性将达到五个九的范围。 考虑与每个组件的关键程度相关的系统正常运行时间有助于将重点放在系统可用性可能达到的水平上。 99% 到底是什么程度的概念呢？ 例如，99%的可用性相当于每年的停机时间略高于 3.5 天或每月停机 7 小时。这样听起来好像 99% 也不是那么可靠了。预计失败，拥抱失败，解决失败。 3. 智能软件，哑巴硬件 如果我们希望看到硬件集群以尽可能灵活的方式使用，为多个并行工作流提供托管，答案是将智能推向软件，而不是硬件。 在此模型中，硬件被视为一组资源，将硬件分配给特定工作负载的责任交给软件层。 这允许硬件是通用的，因此获得起来既容易又便宜，并且有效使用硬件的功能转移到软件上，而软件是关于有效执行该任务的知识所在。 4. 移动处理，而不是数据 假设您有一个非常大的数据集，比如说 1000TB(即 1PB)，并且您需要对数据集中的每个数据执行一组四个操作。 让我们看看实现系统来解决这个问题的不同方式。 传统的大型纵向扩展解决方案将看到一台巨型服务器连接到同样令人印象深刻的存储系统，几乎可以肯定地使用光纤通道等技术来最大化存储带宽。 系统将执行该任务，但会受到 I/O 限制；即使是高端存储交换机也会限制将数据传送到主机的速度。 或者，以前集群技术的处理方法可能会看到一个由 1,000 台机器组成的集群，每台机器都有 1TB 的数据，分为四个象限，每个象限负责执行其中一个操作。 然后，集群管理软件将协调数据在集群中的移动，以确保每一块都接受所有四个处理步骤。 由于每条数据可以在其所在的主机上执行一个步骤，因此它将需要将数据流式传输到其他三个象限，因此我们实际上消耗了 3 PB 的网络带宽来执行处理。 请记住，处理能力的增长速度快于网络或磁盘技术，那么这些真的是解决问题的最佳方法吗？ 最近的经验表明答案是否定的，另一种方法是避免移动数据，而是移动处理。 使用刚才提到的集群，但不要将其划分为象限；相反，让 1000 个节点中的每个节点对本地保存的数据执行所有四个处理阶段。 如果幸运的话，您只需从磁盘流式传输数据一次，而通过网络传输的只有程序二进制文件和状态报告，这两者与实际数据集相比都相形见绌。 如果 1,000 个节点的群集听起来大得离谱，请考虑一下大数据解决方案所使用的一些现代服务器外形规格。 它们看到的是单个主机，每个主机中有多达 12 个 1 TB 或 2 TB 的磁盘。 因为现代处理器有多个核心，所以可以构建一个具有 1 PB 存储空间的 50 节点集群，同时仍然有一个 CPU 核心专门处理来自每个单独磁盘的数据流。 5. 构建应用，而不是基础设施 在考虑上一节中的场景时，很多人都会关注数据移动和处理的问题。 但是，任何曾经构建过这样的系统的人都会知道，作业调度、错误处理和协调等不太明显的元素才是真正的魔力（难度）所在。 如果我们必须实现用于确定在哪里执行处理、执行处理并将所有子结果合并到整体结果中的机制，我们就不会从旧模型中获得太多好处。 在那里，我们需要显式地管理数据分区；我们只是在交换一个难题和另一个难题。 这涉及到最新的趋势，我们将在这里重点介绍：一个透明地处理大部分集群机制并允许开发人员从业务问题的角度进行思考的系统。 框架提供了定义良好的接口，这些接口抽象了所有这些复杂性-智能软件-在此基础上可以构建特定于业务领域的应用，从而提供了开发人员和系统效率的最佳组合。 Hadoop 的由来 前面都是在说一些集群的关键，但是还没回答 Hadoop 到底是什么 这一切都始于谷歌，它在 2003 年和 2004 年发布了两篇描述谷歌技术的学术论文：Google 文件系统(gfs)(http://research.google.com/archive/gfs.html)和 MapReduce(http://research.google.com/archive/mapreduce.html)。 这两者共同提供了一个以高效方式大规模处理数据的平台。 与此同时，Doug Cutting 正在开发 Nutch 开源网络搜索引擎。 他一直在研究系统中的元素，这些元素在 Google GFS 和 MapReduce 论文发表后引起了强烈共鸣。 Doug 开始了这些 Google 系统的实现工作，Hadoop 很快就诞生了，最初是 Lucene 的一个子项目，很快就成为了 Apache 开源基金会中自己的顶级项目。 因此，Hadoop 的核心是一个开源平台，它同时提供 MapReduce 和 GFS 技术的实现，并允许跨低成本商用硬件集群处理非常大的数据集。 雅虎在 2006 年聘请了 Doug Cutting，并很快成为 Hadoop 项目最著名的支持者之一。 除了经常宣传一些世界上最大的 Hadoop 部署外，雅虎还允许 Doug 和其他工程师在受雇期间为 Hadoop 做出贡献；雅虎还贡献了一些内部开发的 Hadoop 改进和扩展。 虽然道格现在已经转向 Cloudera(另一家支持 Hadoop 社区的知名初创公司)，雅虎 Hadoop 团队的大部分成员也被剥离出来，成立了一家名为 Hortonworks 的初创公司，但雅虎仍然是 Hadoop 的主要贡献者。 顶层 Hadoop 项目有许多组件子项目，我们将在本书中讨论其中几个，但主要的两个是Hadoop 分布式文件系统(HDFS)和 MapReduce。 这些都是 Google 自己的 GFS 和 MapReduce 的直接实现。 我们将对两者进行更详细的讨论，但目前，最好将 HDFS 和 MapReduce 视为一对互补但截然不同的技术。 HDFS是一个文件系统，它可以通过跨主机群集向外扩展来存储非常大的数据集。 它具有特定的设计和性能特征；尤其是，它针对吞吐量而不是延迟进行了优化，并且通过复制而不是冗余来实现高可用性。 MapReduce是一种数据处理范例，它指定数据将如何从其两个阶段(称为映射和还原)输入和输出，然后将其应用于任意大的数据集。 MapReduce 与 HDFS 紧密集成，确保 MapReduce 任务尽可能直接在保存所需数据的 HDFS 节点上运行。 Hadoop 生态圈 HDFS 的体系结构图 2. 启动和运行 Hadoop 安装 Hadoop 配置 Ubuntu 20, hadoop 3.3.1，模式选择的 伪分布式模式 ，参考教程: Hadoop 3.3伪分布式环境搭建, hadoop3.3.1单机与伪分布安装，启动和运行hadoop，最后个是个老版本的教程，但是好多命令行都是相似的，操作跟着教程走下来就行，踩到坑了就看日志，坑实在解决不了就换主机 记录下自己踩的坑 第一次下了一个hadoop 的源代码，里面并没有 bin 文件夹，然后 java 的版本没搞懂，jdk1.8 约等于 jdk8，有个 hadoop-env.sh 里面需要加入 JAVA_HOME 的路径 刚开始只有一个 jps 进程，需要先 stop-all.sh ，然后删除 tmp、logs 文件，将namenode文件夹格式化：hdfs namenode -format，最后重新启动 我重新启动之后查看进程，并没有 namenode，提示ip连接的问题，死活没解决，最后换了一个虚拟机和第一个教程 Hadoop 3.3伪分布式环境搭建 成功了，管理界面不是 9000 端口，是 8088 了（第一台虚拟机的配置文件几乎一样，不知道为啥第一台机器还是不可以，来回安装了十几次吧，一晚上就这么没有了，猜测原因是第一个虚拟机的配置太差了 ) Hadoop 的三种模式 本地独立模式：在这种模式下，Hadoop 的所有组件(如 NameNode、DataNode、JobTracker 和 TaskTracker)都在单个 Java 进程中运行。 伪分布式模式：在此模式下，将为每个 Hadoop 组件生成一个单独的 JVM，它们通过网络套接字进行通信，从而有效地在单个主机上提供一个功能齐全的微集群。 完全分布式模式：在这种模式下，Hadoop 分布在台机器上，其中一些机器是通用工作者，另一些机器则是组件的专用主机，比如 NameNode 和 JobTracker。 每种模式都有其优点和缺点。 完全分布式模式显然是唯一可以跨机器集群扩展 Hadoop 的模式，但它需要更多的配置工作，更不用说机器集群了。 本地或独立模式最容易设置，但您与其交互的方式与完全分布式模式不同。 在本书中，我们通常更喜欢伪分布式模式，即使在单个主机上使用示例时也是如此，因为伪分布式模式中完成的所有操作几乎与它在更大的集群上的工作方式相同。 配置伪分布式模式 在 安装 Hadoop 里使用的就是伪分布式模式，其中主要文件的配置如下： core-site.xml 配置： hadoop.tmp.dir file:/usr/local/hadoop/tmp Abase for other temporary directories. fs.defaultFS hdfs://localhost:9000 NameNode URI hdfs-site.xml 配置： dfs.replication 1 dfs.namenode.name.dir file:/usr/local/hadoop/tmp/dfs/name dfs.datanode.data.dir file:/usr/local/hadoop/tmp/dfs/data yarn-site.xml 配置如下： mapreduce.framework.name yarn mapred-site.xml 配置如下： mapreduce.framework.name yarn 配置完成之后输入jps，应该有6个Java进程： 8002 NameNode 15624 Jps 7449 ResourceManager 7546 NodeManager 7306 SecondaryNameNode 8415 DataNode 如果选择伪分布式或完全分布式模式，则在启动第一个 Hadoop 集群之前，需要执行两个步骤： 设置存储 Hadoop 文件的基本目录（mkdir & chmod） 格式化 HDFS 文件系统（hdfs namenode -format) 运行单词示例 如果是单机环境，直接一行命令就可以了 hadoop jar /usr/local/hadoop-3.3.0/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.0.jar wordcount /home/hadoop/input/data.input /home/hadoop/output 如果是伪分布式或分布式环境，需要创建文件夹，然后上传文件，最终运行，中途可能会有些问题，我是通过更改 yarn-site.xml 文件解决的，我碰到的问题是 找不到主类 和 mapreduce_shuffle 问题。伪分布式的文件目录和本地目录并不一样 hadoop fs -mkdir /user/hadoop/input hadoop fs -put /home/hadoop/input/data.input /user/hadoop/input hadoop jar /usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.1.jar wordcount /user/hadoop/input/data.input /user/hadoop/output4 3. 了解 MapReduce 为什么要选择键/值数据 使用键/值数据作为 MapReduce 操作的基础，可以实现一个功能强大的编程模型，该模型具有惊人的广泛适用性。许多数据本质上要么是键/值，要么可以用这种方式表示，他是一个简单的模型，具有广泛的适用性和足够直接的予以，根据它定义的程序可以应用到 Hadoop 框架 当然，数据模型本身并不是使 Hadoop 变得有用的唯一因素，它的真正威力在于它如何适用并行执行技术。我们可以拥有大量的主机，在这些主机上我们可以存储和执行数据，甚至可以实用一个框架来将大的任务划分为较小的块，然后将部分答案组合成整体答案。我们需要这个框架来为我们提供一种表达问题的方式，而不需要我们成为执行机制方面的专家，我们需要表达数据所需的转换，然后让框架来完成其余的工作。 MapReduce 及其键/值接口提供了这样一个抽象级别，程序员只需指定这些转换，Hadoop 就可以处理将其应用于任意大型数据集的复杂过程 {K1, V1} -> {K2, List} -> {K3, V3} MapReduce 作业的 map 方法的输入是一系列键/值对，称之为 K1 和 V1，输出是一系列键和相关的值列表，称为 K2 和 V2。每个映射器只输出一系列单独的键/值输出，在 shuffle 方法中，这些输出组合为键和值列表。MapReduce 作业的最终输出是另一系列键/值对，称为 K3 和 V3 Hadoop Java API for MapReduce 这本书还是使用的 Hadoop 1.0 版本的，大概看看就好了 Mapper 类 Mapper 类的简化视图如下： class Mapper { void map(K1 key, V1 value, Mapper.Contex) throws IOException, InterruptedException { } } 这个类使用了泛型，该类是根据键/值输入和输出类型定义的，然后 map 方法在其参数中接受输入键/值对，另一个参数是 Context 类的实例，它提供了与 Hadoop 框架通信的各种机制，其中之一是输出 map 或 reduce 方法的结果。map 方法仅引用 K1 和 V1 键/值对的单个实例，这是 MapReduce 范例的一个关键方面。在 MapReduce 范例中，需要编写处理单个记录的类，框架负责将大量数据集转换为键/值对流所需的所有工作。我们不需要编写 map 或 reduce 类来尝试处理完整的数据集。Hadoop 还通过 InputFormat 和 OutputFormat 类提供了一些机制，这些机制提供了通用文件格式的实现，消除了为常用文件类型编写文件解析器的必要 有时可能需要重写三个附加方法： protected void setup(Mapper.Context context) throws IOException, Interrupted Exception {...} protected void cleanup(Mapper.Context context) throws IOException, Interrupted Exception {...} protected void run(Mapper.Context context) throws IOException, Interrupted Exception {...} setup 方法在将任何键/值对呈现给 map 方法前先被调用一次，默认实现不执行任何操作 cleanup 方法在所有键/值对都已呈现给 map 方法后被调用一次，默认实现不执行任何操作 run 方法控制 JVM 中任务处理的整体流程。默认实现是在拆分中的每个键/值对重复调用 map 方法之前调用 setup 方法一次，然后最后调用 cleanup 方法 Reducer 类 Reducer 基类的工作方式与 Mapper 类非常相似，通常只需要子类覆盖单个 reduce 方法，精简类定义如下： public class Reduce { void reduce(K1 key, Iterable values, Reducer.Context context) throws IOException, InterruptedException {...} } reduce 方法接受 K2/V2 作为输入，并提供 K3/V3 作为输出，而实际的 Reduce 方法只接受单个键及其关联的值列表，Context 对象也是输出方法结果的机制，Reducer 类同样也有 setup、run 和 cleanup 方法，它们默认实现与 Mapper 类相似，可以选择性覆盖 驱动程序类 尽管 Mapper 和 Reducer 实现是我们执行 MapReduce 作业所需的全部，但是还需要另外一段代码：与 Hadoop 框架通信并指定运行 MapReduce 作业所需的配置元素的驱动程序。这涉及到一些方面，比如告诉 Hadoop 使用哪个 Mapper 和 Reducer 类、在哪里查找输入数据以及以什么格式查找输入数据、在哪里放置输出数据以及如何格式化输出数据，还可以设置多种其它配置选项 驱动程序逻辑通常存在于为封装 MapReduce 作业而编写的类的 Main 方法中： public class ExampleDriver { public static void main(String[] args) throws Exception { Configuration conf = new Configuration(); Job job = new Job(conf, \"ExampleJob\"); job.setJarByClass(ExampleDriver.class); job.setMapperClass(ExampleDriver.class); job.setReducerClass(ExampleDriver.class); job.setOutputKeyClass(Text.class); job.setOutputValueClass(IntWritable.class); FileInputFormat.addInputPath(job, new Path(args[0])); FileOutputFormat.addOutputpath(job, new Path(args[1])); System.exit(job.waitForCompletion(true) ? 0 : 1); } } 编写 MapReduce 程序 我们使用和谈论单词计数了，但是还没有实际编写过一个程序，现在上手写一个吧。教程里面的例子太老了，参考了网上的一个例子：wordcount wordcount 的具体过程 现在用步骤来描述一下 Hadoop 是怎么做单词统计的，假设我们有一个文件如下： hello world hello java hello hadoop 首先读取这个文件，按行来将这个文件每一行的单词拆分出来，形成很多 key/value 的结果： 排序，排完序的结果： 合并，合并后的结果如下： 汇聚结果： 这就是 mapreduce 的处理过程，第 2 和 3 步是 Hadoop 框架帮助我们完成的，我们实际上需要写代码的地方是第 1 和 4步，第 1 步对应 Map 的过程，第 4 步对应的是 Reduce 过程 编写MapReduce 代码 这个代码和教程里面的代码差不多，主要代码如下，分成三部分：WordCountMapper、WordCountReducer、main： import org.apache.hadoop.conf.Configuration; import org.apache.hadoop.fs.Path; import org.apache.hadoop.io.IntWritable; import org.apache.hadoop.io.Text; import org.apache.hadoop.mapreduce.Job; import org.apache.hadoop.mapreduce.Mapper; import org.apache.hadoop.mapreduce.Reducer; import org.apache.hadoop.mapreduce.lib.input.FileInputFormat; import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat; import java.io.IOException; import java.util.StringTokenizer; /** * @description: MapReduce 简单程序，模仿的网上写的：[wordCount](https://segmentfault.com/a/1190000020388581) * @author: Tian * @date: 2022/1/11 10:35 */ public class WordCount { /* * Object 输入的文件内容 * Text 输入的每一行的数据 * Text 输出的 key * IntWritable 输出的 value */ private static class WordCountMapper extends Mapper { @Override protected void map(Object key, Text value, Context context) throws IOException, InterruptedException { StringTokenizer itr = new StringTokenizer(value.toString()); while(itr.hasMoreTokens()) { context.write(new Text(itr.nextToken()), new IntWritable(1)); } } } /* * Text Mapper 输出的 key * IntWritable Mapper 输出的value * Text Reducer 输出的 key * IntWritable Reducer 输出的 value */ private static class WordCountReducer extends Reducer { @Override protected void reduce(Text key, Iterable values, Context context) throws IOException, InterruptedException { int count = 0; for(IntWritable item : values) { count += item.get(); } context.write(key, new IntWritable(count)); } } public static void main(String[] args) throws IOException, ClassNotFoundException, InterruptedException { // 创建配置 Configuration configuration = new Configuration(); // 设置 hadoop 作业 Job job = Job.getInstance(configuration, \"WordCount\"); // 设置 jar job.setJarByClass(WordCount.class); job.setMapperClass(WordCountMapper.class); job.setReducerClass(WordCountReducer.class); job.setOutputKeyClass(Text.class); job.setOutputValueClass(IntWritable.class); // 设置输入输出路径 FileInputFormat.addInputPath(job, new Path(args[0])); FileOutputFormat.setOutputPath(job, new Path(args[1])); // 等待 job 执行完，程序退出 System.exit(job.waitForCompletion(true) ? 0 : 1); } } 程序创建后需要引入相关的包，这里主要是 hadoop 的 common 和 mapreduce 的包 打包成 jar 包的时候需要依赖一起打包，利用 build 工具，和 maven 的打包还不太一样 Hadoop 中 String 是 Text， Integer 是 IntWritable 编写的时候我们应该了解 MapReduce 的运行步骤，我们只需要写 map 和 reduce 的过程，其它步骤由 Hadoop 框架做了处理 可以说 Mapper 类的输入是最难理解的，因为实际上并没有使用键。job 将 TextInputFormat 指定为输入数据的格式，默认情况下，这将向映射器传递数据，其中键是文件中的行号，值是该行的文本，实际上我们可能都没有真正看到过 具体执行过程 JobTracker和TaskTracker 驱动程序中 job.waitForCompletion() 是所有操作的开始。该调用启动了与 JobTracker 的通信，JobTracker 负责作业调度和执行的所有方面，因此在执行任何与作业管理相关的任务时，它成为了主要的界面。JobTracker 代表与 NameNode 的通信，并管理与存储在 HDFS 上的数据相关的所有交互 拆分模型 交互首先发生在 JobTracker 查看输入数据并确定如何将其分配给映射任务。HDFS 文件通常被分割成至少 64 MB 的块，JobTracker 会将每个块分配一个映射任务。当然我们的字数统计示例使用了很少的数据量，这些数据完全在单个块内。假设一个更大的输入文件（以 TB 为单位），那么拆分模型就更有意义了。文件的每个段（在 MapReduce 中称为 Split）由一个映射任务唯一地处理。一旦计算拆分，JobTracker 就会将拆分和包含 Mapper 和 Reducer 类的 JAR 文件放入 HDFS 上特定与作业的目录中，该目录的路径将在任务启动时传递给每个任务 任务分配 一旦 JobTracker 确定需要多少映射任务，它就会查看集群中的主机数量，有多少 TaskTracker 在工作，以及每个任务可以同时执行多少映射任务（用户配置的变量）。JobTracker 还会查看各个输入数据块在集群中的位置，并尝试定义一个执行计划，以最大限度地减少 TaskTracker 处理位于同一物理主机上的拆分数据块的情况。如果失败，它将处理同一硬件机架的至少一个数据块。 这种数据局部性优化是 Hadoop 能够高效处理大型数据集的一个重要原因。默认情况下，每个数据块跨三个不同的主机进行复制，因此生成任务/主机计划已查看大多数数据块在本地处理的可能性要更高一点 任务启动 然后每个 TaskTracker 启动一个单独的 Java 虚拟机来执行任务。这确实增加了启动时间的损失，但它将 TaskTracker 与映射或减少任务行为不当导致的问题隔离开来，并且可以将其配置为在后续执行的任务之间共享 如果集群有足够的容量一次执行所有映射任务，那么它们都将被启动，并被赋予要处理的拆分和作业 JAR 文件的引用。然后每个 TaskTracker 将拆分复制到本地文件系统 如果任务数量超过集群容量，JobTracker 将保留挂起任务队列，并在节点完成初始分配的 Map 任务时将其分配给节点 然后就可以查看 Map 任务的执行数据了，这些是大量的工作，在运行任何 MapReduce 作业时，系统启动并执行所有这些步骤时总是要花费大量的时间 4. 开发 MapReduce 程序 我们已经探索了 MapReduce 技术，现在我们研究如何更好的使用它，如何利用 MapReduce 提供的工具来分析一个更丰富的数据集。现在从查看如何使用脚本编程语言来帮助 MapReduce 进行原型开发和初始分析开始。 在 Hadoop 中使用 Java 以外的语言 MapReduce 程序不必用 Java 编写。大多数程序都是用 Java 编写的，但是可以使用另外一种语言编写 Map 和减少 任务，因为你可能有现有的代码可以使用，或者需要使用第三方的二进制文件。Hadoop 通过 Hadoop pipe 提供了本机 C++ 接口以及 Hadoop Streaming，它允许任何使用标准输入和输出的程序用于映射和缩减任务，使用 Hadoop Streaming 的最大优势是它可以让你更快的尝试想法并进行迭代，你只需编写脚本并将它们作为参数传递到流 JAR 文件，而不是编译/JAR/提交，可以显著加快开发速度。 Hadoop Streaming 工作原理 Hadoop Streaming 使用总结，这篇文章介绍的很好 Hadoop Streaming 是 Hadoop 提供的一个工具，用户可以使用它来创建和运行一类特殊的 MapReduce 任务，这些 MR 任务可以使用任何可执行文件或脚本 作为 mapper 和 reducer。Hadoop Streaming 会创建一个 MR 任务，然后将任务提交到集群上执行，同时监控这个任务的整个执行过程。如果 mapper 和 reducer 都是可执行文件，streaming 程序会使用 PipeMapper 和 PipeReducer 来做一个类似代理的 Mapper 和 Reducer，它们负责启动实际的 mapper 和 reducer 可执行文件，然后从 HDFS 读取输入数据，再一行一行写入到可执行文件进程的标准输入，同时读取可执行文件进程处理完数据后输出到标准输出的数据，将其写出到 Mapper 和 Reducer 真正的输出中 以一个没有 reduce 阶段的 Streaming 程序为例，其 Mapper 简要运行流程可见下图： Hadoop Streaming Mapper 运行流程 PipeMapper 在启动 mapper.sh 后， 不断重复 2-7 （一次 map ）过程，直到所有数据处理完成。 与 PipeMapper 类似，PipeReducer 会将从 map 端 shuffle 过来数据，一行行的写到 reducer.sh 进程的标准输入，然后收集 reducer.sh 进程的标准输出，最终写出到 hdfs output。 使用 Hadoop Streaming 实现 wordcount wcmapper.rb: #/bin/env ruby while line = gets words = line.split(\"\\t\") words.each{ |word| puts word.strip+\"\\t1\"}} end wcreducer.rb: #!/usr/bin/env ruby current = nil count = 0 while line = gets word, counter = line.split(\"\\t\") if word == current count = count+1 else puts current+\"\\t\"+count.to_s if current current = word count = 1 end end puts current+\"\\t\"+count.to_s 流作业执行： hadoop jar hadoop/contrib/streaming/hadoop-streaming-1.0.3.jar -file wcmapper.rb -mapper wcmapper.rb -file wcreducer.rb -reducer wcreducer.rb -input test.txt -output output 使用流式处理看起来要比 Java 版本简单多了，但是里面其实有了更多的逻辑 5. 高级 MapReduce 技术 大概浏览过去吧，，， 对数据执行 join 很少有问题使用单一数据集，一般数据会被分割成多个表，然后使用将表连接在一起的 SQL 语句从多个源头检索数据。但是 MapReduce 连接通常很难编写，而且容易使效率低下。如果非常频繁的需要执行 MapReduce 连接，那么得看下是不是数据结构涉及的有问题了，通过一些方法可以消除在 MapReduce 框架尝试和处理大量离散但相关的数据集的需要。在 Hadoop 中有两种连接数据的基本方法：Map Side Join 和 Reduce Side Join，它们的名称取决于作业执行时连接发生的位置。在两种情况下，我们都需要将多个数据流放在一起，并通过某些逻辑执行连接。(更适合的解决方法是 pig 和 hive 的环境)。 hadoop join之map side join Map side join是针对以下场景进行的优化：两个待连接表中，有一个表非常大，而另一个表非常小，以至于小表可以直接存放到内存中。这样，我们可以将小表复制多份，让每个map task内存中存在一份（比如存放到hash table中），然后只扫描大表：对于大表中的每一条记录key/value，在hash table中查找是否有相同的key的记录，如果有，则连接后输出即可。为了支持文件的复制，Hadoop提供了一个类DistributedCache。 hadoop join之reduce side join reduce side join是一种最简单的join方式，其主要思想如下： 在map阶段，map函数同时读取两个文件File1和File2，为了区分两种来源的key/value数据对，对每条数据打一个标签（tag）,比如：tag=0表示来自文件File1，tag=2表示来自文件File2。即：map阶段的主要任务是对不同文件中的数据打标签。 在reduce阶段，reduce函数获取key相同的来自File1和File2文件的value list， 然后对于同一个key，对File1和File2中的数据进行join（笛卡尔乘积）。即：reduce阶段进行实际的连接操作。 "},"bigData/MinIO.html":{"url":"bigData/MinIO.html","title":"MinIO","keywords":"","body":"MinIO MinIO MinIO 是兼容 AWS S3 云存储服务的高性能对象存储，为机器学习、分析和应用程序的数据共奏负载构建高性能基础架构 服务器 部署 MinIO 是一个云原生的应用程序，旨在 多租户 环境中以可持续的方式进行扩展。编排（orchestration）平台为 MinIO 的扩展提供了非常好的支撑，MinIO 支持的 orchestration 平台： Docker Swarm Docker Compose Kubernetes DC/OS 为什么说 MinIO 是云原生（cloud-native）的 云原生这个词代表的是一些思想的集合，比如微服务部署，可伸缩，而不是说把一个单体应用改造成容器部署。一个云原生的应用在设计时就考虑了移植性和可伸缩性，而且可以通过简单的复制即可实现水平扩展，现在兴起的编排平台，如 Swarm， Kubernetes 以及 DC/OS，让大规模集群的复制和管理变得前所未有的简单。 容器提供了隔离的应用执行环境，编排平台通过容器管理以及复制功能提供了无缝扩展，MinIO 继承了这些，针对每个租户提供了存储环境的隔离。 MinIO 是建立在云原生的基础上，有纠删码、分布式和共享存储这些特性。MinIO专注于并且只专注于存储，而且做的还不错，它通过编排平台复制一个 MinIO 实例就实现了水平扩展 部署的时候碰到的坑 9000 和 9001 没有区分开，腾讯云开放了9000的端口，但是我们实际上访问的端口是 9001 启动的时候必须指定端口，否则会是一个动态的端口 docker 和 普通的部署并没有什么大的不同（可能是我是单机的情况） 服务器扩容真恶心，碰到了一个问题 lgdisplay 等命令没有响应，reboot 重启并没有什么不同，这个服务器不咋用其实也没啥 客户端 MinIO Client (mc)为ls，cat，cp，mirror，diff，find等UNIX命令提供了一种替代方案。它支持文件系统和兼容Amazon S3的云存储服务（AWS Signature v2和v4）。 Copyls 列出文件和文件夹。 mb 创建一个存储桶或一个文件夹。 cat 显示文件和对象内容。 pipe 将一个STDIN重定向到一个对象或者文件或者STDOUT。 share 生成用于共享的URL。 cp 拷贝文件和对象。 mirror 给存储桶和文件夹做镜像。 find 基于参数查找文件。 diff 对两个文件夹或者存储桶比较差异。 rm 删除文件和对象。 events 管理对象通知。 watch 监听文件和对象的事件。 policy 管理访问策略。 session 为cp命令管理保存的会话。 config 管理mc配置文件。 update 检查软件更新。 version 输出版本信息 SDKS 搭建图床 搭建图床成功 利用Minio搭建私有图床 ，博主写的很好，但是没有用 nginx，好多工具感觉有坑，得慢慢踩，但是现在自己得好好学一些东西了 部署完 minIO 之后需要创建一个自己的桶（bulket），然后设置为 public 下面的代码选择一个放到 typora 即可，建议 python 代码，这个好配置一点 js 代码 /* * typora插入图片调用此脚本，上传图片到图床 */ const path = require('path') // minio for node.js const Minio = require('minio') const { promises } = require('fs') // 解析参数， 获取图片的路径，有可能是多张图片 const parseArgv = () => { const imageList = process.argv.slice(2).map(u => path.resolve(u)) return imageList } // 入口 const uploadImageFile = async (bulkName = 'test', imageList = []) => { // 创建连接 const minioClient = new Minio.Client({ // 这里填写你的minio后台域名 endPoint: '111.229.14.128', port: 9001, useSSL: false, // 下面填写你的accessKey和secretKey accessKey: 'opengms', secretKey: 'opengms517' }) // 开始上传图片 const metaData = {} const tasks = imageList.map(image => { return new Promise(async (resolve, reject) => { try { // 图片重命名，这里采用最简单的，可以根据自己需求重新实现 const name = `${Date.now()}_${path.basename(image)}` // 具体请看Minio的API文档，这里是将图片上传到blog这个bucket上 const res = await minioClient.fPutObject(bulkName, name, image, metaData) resolve(name) } catch (err) { reject(err) } }) }) const result = await Promise.all(tasks) // 返回图片的访问链接 result.forEach(name => { const url = `http://111.229.14.128:9001//test/${name}` // Typora会提取脚本的输出作为地址，将markdown上图片链接替换掉 console.log(url) }) } // 执行脚本 uploadImageFile('test', parseArgv()) python 代码： from minio import Minio import os import time import sys minio_conf = { 'endpoint': '111.229.14.128:9001', 'access_key': 'opengms', 'secret_key': 'opengms517', 'secure': False } def update(bulkName = 'test', fileList = []): minioClient = Minio(**minio_conf) for filePath in fileList: with open(filePath, 'rb') as file: name = str(int(time.time())) + '_' + os.path.basename(filePath) file_stat = os.stat(filePath) minioClient.put_object(bucket_name=bulkName, object_name=name, data=file, length=file_stat.st_size) print('http://111.229.14.128:9001/{0}/{1}'.format(bulkName, name)) if __name__ == '__main__': print(sys.argv[1:]) update('test', sys.argv[1:]) 腾讯云的minIO 提示安全漏洞 漏洞是 minIO 官方提出来的，大概是有人能创建 minIO 的用户，升级到最新的版本即可，但是自己不想升级了，而且近期图床也用不上了（博客发布在github上，访问不了国内的ip），这个腾讯云的服务器2022年底也到期了，总之感觉还是没必要自己搭一个图床。最后，将minIO关掉了。 "},"bigData/MongoDB.html":{"url":"bigData/MongoDB.html","title":"MongoDB","keywords":"","body":"MongoDB [toc] temp 简介 关系数据库十分流行，遵循ACID特性。 分布式系统由多台计算机和通信的软件组件通过计算机网络连接组成。 NoSQL 用于超大规模数据的存储，数据存储不需要固定的模式，无需多余操作就可以横向扩展 RDBMS vs NoSQL RDBMS - 高度组织化结构化数据 - 结构化查询语言（SQL） (SQL) - 数据和关系都存储在单独的表中。 - 数据操纵语言，数据定义语言 - 严格的一致性 - 基础事务 NoSQL - 代表着不仅仅是SQL - 没有声明性查询语言 - 没有预定义的模式 -键 - 值对存储，列存储，文档存储，图形数据库 - 最终一致性，而非ACID属性 - 非结构化和不可预知的数据 - CAP定理 - 高性能，高可用性和可伸缩性 在计算机科学中, CAP定理（CAP theorem）, 又被称作 布鲁尔定理（Brewer's theorem）, 它指出对于一个分布式计算系统来说，不可能同时满足以下三点: 一致性(Consistency) (所有节点在同一时间具有相同的数据) 可用性(Availability) (保证每个请求不管成功或者失败都有响应) 分隔容忍(Partition tolerance) (系统中任意信息的丢失或失败不会影响系统的继续运作) 概念解析 数据库 数据库名可以是满足以下条件的任意UTF-8字符串。 不能是空字符串（\"\")。 不得含有' '（空格)、.、$、/、\\和\\0 (空字符)。 应全部小写。 最多64字节。 有一些数据库名是保留的，可以直接访问这些有特殊作用的数据库。 admin： 从权限的角度来看，这是\"root\"数据库。要是将一个用户添加到这个数据库，这个用户自动继承所有数据库的权限。一些特定的服务器端命令也只能从这个数据库运行，比如列出所有的数据库或者关闭服务器。 local: 这个数据永远不会被复制，可以用来存储限于本地单台服务器的任意集合 config: 当Mongo用于分片设置时，config数据库在内部使用，用于保存分片的相关信息。 document 文档是一组键值，文档不需要设置相同的字段，相同的字段不需要有相同的数据类型 需要注意的是： 文档中的键/值对是有序的。 文档中的值不仅可以是在双引号里面的字符串，还可以是其他几种数据类型（甚至可以是整个嵌入的文档)。 MongoDB区分类型和大小写。 MongoDB的文档不能有重复的键。 文档的键是字符串。除了少数例外情况，键可以使用任意UTF-8字符。 文档键命名规范： 键不能含有\\0 (空字符)。这个字符用来表示键的结尾。 .和$有特别的意义，只有在特定环境下才能使用。 以下划线\"_\"开头的键是保留的(不是严格要求的)。 collection 文档组 当第一个文档插入的时候，集合就会被创建 db.col.findOne() Capped collections 就是固定大小的collection，具有很高的性能， db.createCollection(\"mycoll\", {capped:true, size:100000}) 基础操作 use [name], db, show dbs, db.dropDatabase(), db.collection.drop(), db.createCollection(name, options) system.indexes, db.mycol2.drop(), MongoDB 官方文档 MongoDB introduction MongoDB 中的一条记录就是一个Documents，它是由字段和值对组成的数据结构。文档类似于 JSON 对象，字段的值包括其它document，array 用文档的优势是： Documents 对应许多编程语言中的原生数据类型 嵌入的 document 和 array 减少了 join 操作的需要 动态的数据结构支持多态性 MongoDB 将 document 存储在 collections，collections 类似于关系数据库中的表，除了 collections，MongoDB 还存储：只读 Views，On-Demand Materialized Views MongoDB 的主要特点是 MongoDB 提供高性能的数据持久化，特别是 对嵌入式数据的模型的支持减少了数据库系统上的 I/O 活动 索引支持更快的查询，并且可以包含来自嵌入式文档和数组的键 丰富的查询语言来支持 CRUD： 数据聚合 文本搜索和地理空间查询 高可用性，MongoDB 的复制工具，称为副本集，提供： 自动的故障转移 数据冗余 可扩展性，MongoDB 提供水平可扩展性作为其核心功能的一部分： 分片在一组计算机集群分布数据 MongoDB 支持基于 shard key 创建数据区域，在平衡集群中，MongoDB 将区域覆盖的读取和写入仅定向到区域内的那些分片 支持多个存储引擎 WiredTiger 存储引擎（包括对静态加密的支持） 内存存储引擎 入门 MongoDB 的云托管服务 Atlas，mongosh 一个更好用的 mongo 的命令行工具？ 基本操作 db 返回当前数据库 show collections 返回当前数据库下所有的 collection use [dbname] 切换数据库，或者创建并切换 插入 db.[collection].insertMany([...]) collection（集合）类似于关系数据库中的表，如果第一次插入没有这个集合，则会创建该集合 查找所有 db.[collection].find({}) 过滤数据，可以使用比较运算符来执行更高级的查询 db.movies.find({ \"awards.wins\" } : {$gt: 100}) db. movies.find({ \"languages\" }: {in: [\"Chiness\"]}) MongoDB 将数据记录存储为文档（特别是 BSON 文档），这些文档收集在集合中，一个数据库存储在一个文件名或更多的集合 MongoDB 视图是一个可查询的对象，其内容由其他集合或视图上的聚合管道定义。MongoDB 不会将视图内容持久化到磁盘，当客户端查询视图时，视图的内容是按需计算的。MongoDB 可以要求客户端具有查询视图的权限，MongoDB 不支持针对视图的写操作 "},"bigData/Nginx.html":{"url":"bigData/Nginx.html","title":"Nginx","keywords":"","body":"Nginx github [toc] Nginx简介 Nginx（engine x）是一款轻量级的web服务器、反向代理服务器及电子邮件（IMAP/POP3）代理服务器 反向代理 反向代理（Reverse Proxy）方式是指以代理服务器来接受Internet上的连接请求，然后将请求转发给内部网络上的服务器，并将从服务器上得到的结果返回internet上请求连接的额客户端，此时代理服务器对外就表现为一个反向代理服务器 Nginx入门 nginx -s stop 快速关闭Nginx，可能不保存相关信息，并迅速终止web服务。 nginx -s quit 平稳关闭Nginx，保存相关信息，有安排的结束web服务。 nginx -s reload 因改变了Nginx相关配置，需要重新加载配置而重载。 nginx -s reopen 重新打开日志文件。 nginx -c filename 为 Nginx 指定一个配置文件，来代替缺省的。 nginx -t 不运行，仅仅测试配置文件。nginx 将检查配置文件的语法的正确性，并尝试打开配置文件 nginx -v 显示 nginx 的版本。 nginx -V 显示 nginx 的版本，编译器版本和配置参数。 如果不想每次都敲命令，可以在 nginx 安装目录下新添一个启动批处理文件startup.bat，双击即可运行。内容如下： @echo off rem 如果启动前已经启动nginx并记录下pid文件，会kill指定进程 nginx.exe -s stop rem 测试配置文件语法正确性 nginx.exe -t -c conf/nginx.conf rem 显示版本信息 nginx.exe -v rem 按照指定配置去启动nginx nginx.exe -c conf/nginx.conf Nginx 实战 Http 反向代理 不考虑复杂的配置，仅仅是完成一个http反向代理 nginx.conf(nginx 的默认配置文件) 配置文件： #运行用户 #user somebody; #启动进程,通常设置成和cpu的数量相等 worker_processes 1; #全局错误日志 error_log D:/Tools/nginx-1.10.1/logs/error.log; error_log D:/Tools/nginx-1.10.1/logs/notice.log notice; error_log D:/Tools/nginx-1.10.1/logs/info.log info; #PID文件，记录当前启动的nginx的进程ID pid D:/Tools/nginx-1.10.1/logs/nginx.pid; #工作模式及连接数上限 events { worker_connections 1024; #单个后台worker process进程的最大并发链接数 } #设定http服务器，利用它的反向代理功能提供负载均衡支持 http { #设定mime类型(邮件支持类型),类型由mime.types文件定义 include D:/Tools/nginx-1.10.1/conf/mime.types; default_type application/octet-stream; #设定日志 log_format main '[$remote_addr] - [$remote_user] [$time_local] \"$request\" ' '$status $body_bytes_sent \"$http_referer\" ' '\"$http_user_agent\" \"$http_x_forwarded_for\"'; access_log D:/Tools/nginx-1.10.1/logs/access.log main; rewrite_log on; #sendfile 指令指定 nginx 是否调用 sendfile 函数（zero copy 方式）来输出文件，对于普通应用， #必须设为 on,如果用来进行下载等应用磁盘IO重负载应用，可设置为 off，以平衡磁盘与网络I/O处理速度，降低系统的uptime. sendfile on; #tcp_nopush on; #连接超时时间 keepalive_timeout 120; tcp_nodelay on; #gzip压缩开关 #gzip on; #设定实际的服务器列表 upstream zp_server1{ server 127.0.0.1:8089; } #HTTP服务器 server { #监听80端口，80端口是知名端口号，用于HTTP协议 listen 80; #定义使用www.xx.com访问 server_name www.helloworld.com; #首页 index index.html #指向webapp的目录 root D:\\01_Workspace\\Project\\github\\zp\\SpringNotes\\spring-security\\spring-shiro\\src\\main\\webapp; #编码格式 charset utf-8; #代理配置参数 proxy_connect_timeout 180; proxy_send_timeout 180; proxy_read_timeout 180; proxy_set_header Host $host; proxy_set_header X-Forwarder-For $remote_addr; #反向代理的路径（和upstream绑定），location 后面设置映射的路径 location / { proxy_pass http://zp_server1; } #静态文件，nginx自己处理 location ~ ^/(images|javascript|js|css|flash|media|static)/ { root D:\\01_Workspace\\Project\\github\\zp\\SpringNotes\\spring-security\\spring-shiro\\src\\main\\webapp\\views; #过期30天，静态文件不怎么更新，过期可以设大一点，如果频繁更新，则可以设置得小一点。 expires 30d; } #设定查看Nginx状态的地址 location /NginxStatus { stub_status on; access_log on; auth_basic \"NginxStatus\"; auth_basic_user_file conf/htpasswd; } #禁止访问 .htxxx 文件 location ~ /\\.ht { deny all; } #错误处理页面（可选择性配置） #error_page 404 /404.html; #error_page 500 502 503 504 /50x.html; #location = /50x.html { # root html; #} } } 启动webapp，注意启动绑定的端口要和nginx中的upstream设置的端口保持一致 更改host，在host文件中添加一条DNS记录 127.0.0.1 www.helloworld.com 启动前文中 startup.bat 的命令 Https反向代理 一些对安全性要求比较高的站点可能会使用HTTPS（一种使用ssl通信标准的安全 HTTP协议） HTTPS的固定端口是443，不同于HTTP的80端口 SSL标准需要引入安全证书，所以在nginx.conf 中你需要指定证书和它对应的key 其它和http反向代理基本一样，只是在 Server 部分配置有些不同 #HTTP服务器 server { #监听443端口。443为知名端口号，主要用于HTTPS协议 listen 443 ssl; #定义使用www.xx.com访问 server_name www.helloworld.com; #ssl证书文件位置(常见证书文件格式为：crt/pem) ssl_certificate cert.pem; #ssl证书key位置 ssl_certificate_key cert.key; #ssl配置参数（选择性配置） ssl_session_cache shared:SSL:1m; ssl_session_timeout 5m; #数字签名，此处使用MD5 ssl_ciphers HIGH:!aNULL:!MD5; ssl_prefer_server_ciphers on; location / { root /root; index index.html index.htm; } } 负载均衡 前面的例子中，代理仅仅指向一个服务器，但是网站在实际运营中，大部分是以集群的方式运行，这时需要使用负载均衡来分流，nginx也可以实现简单的负载均衡能力 假设这样一个应用场景：将应用部署在 192.168.1.11:80、192.168.1.12:80、192.168.1.13:80 三台 linux 环境的服务器上。网站域名叫 www.helloworld.com，公网 IP 为 192.168.1.11。在公网 IP 所在的服务器上部署 nginx，对所有请求做负载均衡处理（下面例子中使用的是加权轮询策略）。 nginx.conf 配置如下： http { #设定mime类型,类型由mime.type文件定义 include /etc/nginx/mime.types; default_type application/octet-stream; #设定日志格式 access_log /var/log/nginx/access.log; #设定负载均衡的服务器列表 upstream load_balance_server { #weigth参数表示权值，权值越高被分配到的几率越大 server 192.168.1.11:80 weight=5; server 192.168.1.12:80 weight=1; server 192.168.1.13:80 weight=6; } #HTTP服务器 server { #侦听80端口 listen 80; #定义使用www.xx.com访问 server_name www.helloworld.com; #对所有请求进行负载均衡请求 location / { root /root; #定义服务器的默认网站根目录位置 index index.html index.htm; #定义首页索引文件的名称 proxy_pass http://load_balance_server ;#请求转向load_balance_server 定义的服务器列表 #以下是一些反向代理的配置(可选择性配置) #proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; #后端的Web服务器可以通过X-Forwarded-For获取用户真实IP proxy_set_header X-Forwarded-For $remote_addr; proxy_connect_timeout 90; #nginx跟后端服务器连接超时时间(代理连接超时) proxy_send_timeout 90; #后端服务器数据回传时间(代理发送超时) proxy_read_timeout 90; #连接成功后，后端服务器响应时间(代理接收超时) proxy_buffer_size 4k; #设置代理服务器（nginx）保存用户头信息的缓冲区大小 proxy_buffers 4 32k; #proxy_buffers缓冲区，网页平均在32k以下的话，这样设置 proxy_busy_buffers_size 64k; #高负荷下缓冲大小（proxy_buffers*2） proxy_temp_file_write_size 64k; #设定缓存文件夹大小，大于这个值，将从upstream服务器传 client_max_body_size 10m; #允许客户端请求的最大单文件字节数 client_body_buffer_size 128k; #缓冲区代理缓冲用户端请求的最大字节数 } } } 负载均衡策略 轮询 加权轮询 最少连接 加权最少连接 IP Hash 普通Hash 网站有多个webapp的配置 当一个网站越来越丰富时，往往需要将一些功能相对独立的模块剥离出来，独立维护，这样的话，通常会有多个webapp 配置多个端口的文件： http { #此处省略一些基本配置 upstream product_server{ server www.helloworld.com:8081; } upstream admin_server{ server www.helloworld.com:8082; } upstream finance_server{ server www.helloworld.com:8083; } server { #此处省略一些基本配置 #默认指向product的server location / { proxy_pass http://product_server; } location /product/{ proxy_pass http://product_server; } location /admin/ { proxy_pass http://admin_server; } location /finance/ { proxy_pass http://finance_server; } } } 静态站点 有时候我们需要配置静态站点（html文件和一堆静态资源） 如果所有的静态资源都放在了 /app/dist 目录下，我们只需要在 nginx.conf 中指定首页以及这个站点的host即可 配置如下： worker_processes 1; events { worker_connections 1024; } http { include mime.types; default_type application/octet-stream; sendfile on; keepalive_timeout 65; gzip on; gzip_types text/plain application/x-javascript text/css application/xml text/javascript application/javascript image/jpeg image/gif image/png; gzip_vary on; server { listen 80; server_name static.zp.cn; location / { root /app/dist; index index.html; #转发任何请求到 index.html } } } 然后，添加 HOST： 127.0.0.1 static.zp.cn 此时，在本地浏览器访问 static.zp.cn ，就可以访问静态站点了。 搭建文件服务器 使用nginx可以快速便捷的搭建一个简易的文件服务器 Nginx中的配置要点： 将 autoindex 开启可以显示目录，默认不开启。 将 autoindex_exact_size 开启可以显示文件的大小。 将 autoindex_localtime 开启可以显示文件的修改时间。 root 用来设置开放为文件服务的根路径。 charset 设置为 charset utf-8,gbk;，可以避免中文乱码问题（windows 服务器下设置后，依然乱码，本人暂时没有找到解决方法）。 一个简化的配置如下： autoindex on;# 显示目录 autoindex_exact_size on;# 显示文件大小 autoindex_localtime on;# 显示文件时间 server { charset utf-8,gbk; # windows 服务器下设置后，依然乱码，暂时无解 listen 9050 default_server; listen [::]:9050 default_server; server_name _; root /share/fs; } 解决跨域 web领域开发中，经常采用前后端分离模式，这种模式下，前端和后端分别是独立的web应用程序，例如后端是Java程序，前端是React或Vue应用，各自独立的webapp在互相访问的时候，势必存在跨域问题，解决跨域问题一般有两种思路： CORS 在后端服务器设置HTTP响应头，把你允许访问的域名中加入 Access-Control-Allow-Origin 中 jsonp 把后端根据请求，构造json数据并返回，前端用jsonp跨域 nginx 根据第一种思路，也提供了一种解决跨域的解决方案： # allow origin list set $ACAO '*'; # set single origin if ($http_origin ~* (www.helloworld.com)$) { set $ACAO $http_origin; } if ($cors = \"trueget\") { add_header 'Access-Control-Allow-Origin' \"$http_origin\"; add_header 'Access-Control-Allow-Credentials' 'true'; add_header 'Access-Control-Allow-Methods' 'GET, POST, OPTIONS'; add_header 'Access-Control-Allow-Headers' 'DNT,X-Mx-ReqToken,Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type'; } if ($request_method = 'OPTIONS') { set $cors \"${cors}options\"; } if ($request_method = 'GET') { set $cors \"${cors}get\"; } if ($request_method = 'POST') { set $cors \"${cors}post\"; } 资源 Nginx 的中文维基 Nginx 开发从入门到精通 nginx-admins-handbook nginxconfig.io - 一款 Nginx 配置生成器 Nginx 运维 window 安装 Linux安装（推荐rpm包方式） Linux开机自启动 Nginx配置 Nginx 的默认配置文件是 nginx.conf nginx -c xx.conf - 以指定文件作为配置文件，启动nginx 配置文件实例 "},"bigData/Spark.html":{"url":"bigData/Spark.html","title":"Spark","keywords":"","body":"Spark [toc] 摘要 apachen yyds! 学习地址：Spark 2.2.0 中文文档，大概看来一下 Flink，这些都是面向大数据计算的，我也不知道用啥，还不知道怎么用，感觉自己一个人有点摸着石头过河的感觉 Spark 概述 Apache Spark 是一个快速的，通用的集群计算机系统。它对 Java，Scala，Python 和 R 提供了高层 API，并有一个经优化的支持通用执行图计算的引擎。它还支持一组丰富的高级工具，包括用于 SQL 和结构化数据处理的 Spark SQL，用于机器学习的 MLlib，用于图计算的 GraphX 和 Spark Streaming。 安全 默认情况下，Spark中的安全性处于关闭状态。这意味着您默认情况下容易受到攻击。在下载和运行Spark之前，请参阅Spark Security。 "},"bigData/大数据.html":{"url":"bigData/大数据.html","title":"大数据","keywords":"","body":"大数据 [toc] 摘要 开始系统的学习大数据，希望能学快一点，也能早点做出东西来，参考教程：Data Flair 概述 为什么要学习大数据？ 缺口大，很多行业很多领头羊都很重视它，大数据分析为领导者提供了一条获取想法的途径，成为一个数据科学家 什么是大数据分析？ 大数据以数 TB 的数量产生，它变化迅速、形式多样，难以使用 RDBMS 或其它传统技术方法进行处理和管理，大数据解决方案提供了用于在几秒钟内捕获、存储、搜索和分析数据的工具、方法和技术，以找到以前无法获得的创新和竞争收益的关系 "},"course/Hands-On Data Visualization.html":{"url":"course/Hands-On Data Visualization.html","title":"Hands-On Data Visualization","keywords":"","body":"Hands-On Data Visualization [toc] 前言 在了解 mapshaper.org 和 geojson.io 的过程中看到的一本书，该书探索数据可视化（可能是毕业方向之一），感觉讲的非常好。书籍地址 Introduction: Why Data Visualization 在本书中，我们将通过融合设计原则和一步一步的章节来学习如何创建真实且有意义的数据可视化，以使你的基于分析和论点更具有洞察力和吸引力。正如句子通过来源注释变得更有说服力一样，当与适当的表格、图表或地图配对时，数据驱动会变得更加强大。文字告诉我们故事，但可视化通过将定量、关系或空间模式转化为图像来向我们展示数据故事。当可视化设计得很好时，它们会将我们的注意力吸引到数据中最重要的部分。 如何设计交互式表格、图表和地图，并将它们嵌入到网络中。交互式可视化通过邀请用户与数据交互、探索用户感兴趣的模式、根据需要下载文件并分享结果，来扩大更广泛的受众。数据可视化在互联网上广泛传播，但是快速增长也带来了严重的问题。“信息时代”现在与“虚假信息时代”重叠，几乎人人都可以在网上发布信息，你如何做出明智的决定？当看到关于社会不平等或气候变化等分裂性政策问题的相互矛盾的数据故事时候，你选择相信哪一个？数据可视化照亮了我们追求真理的道路，但它也使我们能够欺骗和撒谎。 What Can You Believe? Point 1：自 1970 年代以来，美国的经济不平等急剧上升。 Point 2：1970 年，按今天的美元计算，美国前 10% 的成年人平均收入约为 135,000 美元，而后 50% 的人平均收入约为 16,500 美元。根据世界不平等数据库的数据，这种不平等差距在接下来的 50 年里急剧扩大，最高阶层的收入攀升至约 350,000 美元，而底部的一半收入几乎没有上升到约 19,000 美元。5 Point 3： 美国收入等级 1970年 2019年 前 10% 136,308 美元 352,815 美元 中间 40% 44,353 美元 76,462 美元 底部 50% 16,515 美元 19,177 美元 注：以 2019 年不变美元表示。20 岁及以上个人的国民收入，在税收和转移之前，但包括养老金缴款和分配。资料来源：世界不平等数据库，2020 年访问 What can you believe? Some Pictures Are More Persuasive Figure 0.1: Figure 0.1: Explore the interactive line chart of US adult income inequality over time. Figure 0.2: Figure 0.2: Explore the alternative version of the interactive line chart of US adult income inequality over time, using the same data as the first version. 图 0.1 和图 0.2 包含了相同的数据，为什么它们看起来如此的不同？不平等差距的显著增长发生了什么，现在似乎已经被消除了，危机消除了吗？还是说这是一个骗局？ 尽管这是同一份数据，但是图 0.2 y 轴上的金额是用对数刻度构建的，这最适合显示指数增长。在 Covid 病毒大流行期间也是使用的对数刻度，它们适当地说明了病例非常高的增长率，当时传统的线性刻度已经很难显示病例的增长了。可是图2使用对数刻度是具有误导性的，因为并没有充分的理由要使用对数刻度来解释这个收入数据，除非制度者是故意想要隐瞒事实。人们可以用图表来阐明真相，也可以用图表来掩盖真相 Different Shades of the Truth Point 4: 美国的收入不平等更为严重，目前最富有的 1% 的人口获得了国民收入的 20%。相比之下，在大多数欧洲国家，最富有的 1% 的人获得的份额较小，在国民收入的 6% 到 15% 之间 Figure 0.3 Figure 0.3: Explore the interactive map of world income inequality, measured by the share of national income held by the top 1 percent of the population, based on the most recent data available. Source: World Inequality Database 2020. Figure 0.4: Figure 0.4: Explore an alternative version of the interactive map of world income inequality, using the same data as the map above. 为什么要用地图而不是表格或者图表了？ 虽然我们可以创建观点 4 的表格或图表，但是这并不是集中快速显示 120 多个国家信息的最有效方法。同时这是空间数据，我们可以将其转换为交互式地图，以帮助用户探索全球的收入水平 图 0.3 是不是比观点 4 更有说服力？ 虽然地图和文本提供了关于美国和欧洲收入不平等的相同数据，按理说并没有区别。但是交互式地图将用户带入了一个强有力的数据故事，它生动地说明了贫富差距，地图上的颜色预示着危机，美国（以及俄罗斯和巴西）的收入不平等在最高水平上以深红色突出显示——前 1% 的人占据了国民收入的 19% 或更多，相比之下，当我们的目光飘向大西洋的时，几乎所有的欧洲国家都是呈现出较浅的米色或橙色，这表明它们的富人在国民收入的占比较小 图 0.3 和 图 0.4 你更相信哪张地图？ 图 0.4 看起来和 图 0.3 是不是有些不同？美国现在不是深红色，而是中蓝色，在光谱上更加接近加拿大和大多数欧洲国家。收入不平等的危机是不是从美国消失了？哪张地图是真的？ 两张地图都没有误导，且都已合理的设计对数据做出真实的解释，尽管它们在我们的眼中产生了截然不同的印象。请仔细看地图的图例。第一张地图将国家分为了三类：小于 13%， 13-19%， 19及以上，而第二张地图以绿蓝色渐变显示整个范围。由于美国的份额为 20.5%，因此在第一张图中，它以最深的红色显示，但在第二张图中，它以中蓝色更接近中间的某个位置。然后，这两张地图同样有效，因为既没有违反地图设计中的明确规则，也没有故意延时数据，人们可能因地图而产生误导，但也有可能对真相进行多幅描绘 数据可视化的解释性是一项严峻的挑战。创建真实而有意义的图表和地图，培养良好设计的原则和深思熟虑的思维习惯，并尝试以身作则。数据可视化相比科学来说，有时更像是一门艺术，我们知道图表和地图可以被操纵，就像是文字一样被用来误导你的观众，我们应该知道常见的欺骗技巧，防止被欺骗的同时避免自己的作品中出现欺骗。我们可能会因为同时存在多个看似正确的答案而沮丧，但是我们需要做的只是不断的寻找更好的答案，而不必期望找到一个正确的答案，尤其是随着可视化和工具的不断发展，新的方式会展示新的答案 Origanization of the Book 该书分为四个部分： 培养关于设想数据故事的基础技能，以及讲述它所需的工具和数据。1-5 章：选择一个工具来讲述你的数据故事；加强你的电子表格技能；查找和质疑你的数据；清理凌乱的数据；进行有意义的比较 使用易于学习的拖放工具构建大量可视化，并找出哪种类型最适合什么样的数据故事。6-9 章：绘制你的数据；映射你的数据；列出你数据的开始与强调的解释；嵌入Web以交互式可视化 使用更加强大的工具，特别是代码模板，这些工具是你可以更好的自定义可视化的外观以及在线托管它们的位置。10-13 章：使用GitHub编辑和托管代码；Chart.js 和 Highchart 模板；Leaflet 地图模板；转换地图数据中的更高级的空间工具 回归到本书的中心主题：用数据讲述真实而有意义的故事，总结你培养的所有可视化技能。14-15 章：学习如何使用图表和地图撒谎，从而更好地讲真话；最后，讲述和展示你的数据故事，数据可视化的目标不仅仅是制作关于数字的图片，而是制作一个真实的叙述，让读者相信你的解释并重视你的解释 该书的目标是让读者学习融合通过交互式数据可视化讲述真实而有意义的故事，同时注意人们可以利用它们来误导的方式。 Chapter 1 Choose Tools to Tell Your Story 如果你对当今可用的大量数字工具感到不知所措，那么你并不孤单。但是当你只是尝试做你的日常工作时，那么跟上最新的技术开发可能会让你感觉干了一份没有报酬的兼职。如果你喜欢尝试不同的选择，那么这将是一个好消息 "},"course/深入理解计算机系统.html":{"url":"course/深入理解计算机系统.html","title":"深入理解计算机系统","keywords":"","body":"深入理解计算机系统 中文电子版 [toc] 计算机系统漫游 从程序员的角度学习计算机系统是如何工作的。 源程序 hello 程序的源程序是一个比特序列 图1-1 hello 源程序 像 hello.c 这样只由 ASCII 字符构成的文件称为**文本文件**，所有其他文件都称为**二进制文件**。 hello.c 的表示方法说明了一个基本思想∶系统中所有的信息——包括磁盘文件、内存中的程序、内存中存放的用户数据以及网络上传送的数据，都是由一串比特表示的。区分不同数据对象的唯一方法是我们读到这些数据对象时的上下文。比如，在不同的上下文中，一个同样的字节序列可能表示一个整数、浮点数、字符串或者机器指令。 计算机的数字是对真值的有限近似值 - #### 编译过程 ![image-20220106153157053](../image/image-20220106153157053.png) 图1-2 编译过程 系统组成 图1-3 一个典型系统的硬件组成 CPU：中央处理单元；ALU：算术/逻辑单元；PC：程序计数器；USB：通用串行总线 高速缓存 图1-4 高速缓存存储器 利用高速缓存将程序的性能提高一个数量级 - #### 存储器层次 ![image-20220106153127142](../image/image-20220106153127142.png) 图1-5 存储器层次结构 操作系统的抽象表示 操作系统有两个基本功能∶（1）防止硬件被失控的应用程序滥用；（2）向应用程序提供简单一致的机制来控制复杂而又通常大不相同的低级硬件设备。操作系统通过几个基本的抽象概念（进程、虚拟内存和文件）来实现这两个功能。如图 1-11 所示，文件是对 I/O 设备的抽象表示，虚拟内存是对主存和磁盘 I/O 设备的抽象表示，进程则是对处理器、主存和 I/O 设备的抽象表示。我们将依次讨论每种抽象表示。 图1-6 操作系统提供的抽象表示 进程 进程是操作系统对一个正在运行程序的一种抽象。 进程是操作系统对一个正在运行的程序的一种抽象。在一个系统上可以同时运行多个进程，而每个进程都好像在独占地使用硬件。而并发运行，则是说一个进程的指令和另一个进程的指令是交错执行的。在大多数系统中，需要运行的进程数是多于可以运行它们的 CPU 个数的。传统系统在一个时刻只能执行一个程序，而先进的多核处理器同时能够执行多个程序。无论是在单核还是多核系统中，一个 CPU 看上去都像是在并发地执行多个进程，这是通过处理器在进程间切换来实现的。操作系统实现这种交错执行的机制称为上下文切换。 从一个进程到另一个进程的转换是由操作系统内核（kernel）管理的。内核是操作系统代码常驻主存的部分。当应用程序需要操作系统的某些操作时，比如读写文件，它就执行一条特殊的系统调用（system call）指令，将控制权传递给内核。然后内核执行被请求的操作并返回应用程序。注意，内核不是一个独立的进程。相反，它是系统管理全部进程所用代码和数据结构的集合。 图1-7 进程的上下文切换 线程 尽管通常我们认为一个进程只有单一的控制流，但是在现代系统中，一个进程实际上可以由多个称为线程的执行单元组成，每个线程都运行在进程的上下文中，并共享同样的代码和全局数据。由于网络服务器中对并行处理的需求，线程成为越来越重要的编程模型，因为多线程之间比多进程之间更容易共享数据，也因为线程一般来说都比进程更高效。 虚拟内存 虚拟内存是一个抽象概念，它为每个进程提供了一个假象，即每个进程都在独占地使用主存。每个进程看到的内存都是一致的，称为虚拟地址空间。图 1-13 所示的是 Linux 进程的虚拟地址空间（其他 Unix 系统的设计也与此类似）。在 Linux 中，地址空间最上面的区域是保留给操作系统中的代码和数据的，这对所有进程来说都是一样。地址空间的底部区域存放用户进程定义的代码和数据。请注意，图中的地址是从下往上增大的。 图1-8 进程的虚拟地址空间 文件 文件就是文字序列，仅此而已，每个I/O设备都可以看成是一个文件。系统中的所有输入输出都是通过一组称为 Unix I/O 的系统调用读写文件来实现的。 网络通信 系统漫游至此，我们一直是把系统视为一个孤立的硬件和软件的集合体。实际上，现代系统经常通过网络和其他系统连接到一起。从一个单独的系统来看，网络可视为一个 I/O 设备，如图 1-14 所示。当系统从主存复制一串字节到网络适配器时，数据流经过网络到达另一台机器，而不是比如说到达本地磁盘驱动器。相似地，系统可以读取从其他机器发送来的数据，并把数据复制到自己的主存。 图1-9 网络也是一种I/O设备 图1-10 利用 telnet 通过网络远程运行 hello Amdahl 定律 相对性能 图1-11 Amdahl定律 并发和并行 并发（concurrency）是一个通用的概念，指一个同时具有多个活动的系统；而术语并行（parallelism）指的是用并发来使一个系统运行得更快。并行可以在计算机系统的多个抽象层次上运用。在此，我们按照系统层次结构中由高到低的顺序重点强调三个层次。 计算机抽象 图1-12 计算机系统提供的一些抽象 计算机系统中的一个重大主题就是提供不同层次的抽象表示，来隐藏实际实现的复杂性 在学习操作系统时，我们介绍了三个抽象：文件是对 I/O 设备的抽象，虚拟内存是对程序存储器的抽象，而进程是对一个正在运行的程序的抽象。我们再增加一个新的抽象∶ 虚拟机，它提供对整个计算机的抽象，包括操作系统、处理器和程序。 小结 计算机系统是由硬件和系统软件组成的，它们共同协作以运行应用程序。计算机内部的信息被表示为一组组的位，它们依据上下文有不同的解释方式。程序被其他程序翻译成不同的形式，开始时是 ASCII 文本，然后被编译器和链接器翻译成二进制可执行文件。 处理器读取并解释存放在主存里的二进制指令。因为计算机花费了大量的时间在内存、I/O 设备和 CPU 寄存器之间复制数据，所以将系统中的存储设备划分成层次结构——CPU 寄存器在顶部，接着是多层的硬件高速缓存存储器、DRAM 主存和磁盘存储器。在层次模型中，位于更高层的存储设备比低层的存储设备要更快，单位比特造价也更高。层次结构中较高层次的存储设备可以作为较低层次设备的高速缓存。通过理解和运用这种存储层次结构的知识，程序员可以优化C程序的性能。 操作系统内核是应用程序和硬件之间的媒介。它提供三个基本的抽象∶1）文件是对 I/O 设备的抽象；2）虚拟内存是对主存和磁盘的抽象；3）进程是处理器、主存和 I/O 设备的抽象。 最后，网络提供了计算机系统之间通信的手段。从特殊系统的角度来看，网络就是一种 I/O 设备。 信息的表示和处理 1. 信息存储 bit 孤立地讲，单个的位不是非常有用。然而，当把位组合在一起，再加上某种解释 （interpretation），即赋予不同的可能位模式以含意，我们就能够表示任何有限集合的元素。比如，使用一个二进制数字系统，我们能够用位组来编码非负数。通过使用标准的字符码，我们能够对文档中的字母和符号进行编码。在本章中，我们将讨论这两种编码，以及负数表示和实数近似值的编码。 虚拟地址空间 大多数计算机使用 8 位的块，或者字节（byte），作为最小的可寻址的内存单位，而不是访问内存中单独的位。机器级程序将内存视为一个非常大的字节数组，称为虚拟内存（virtual memory）。内存的每个字节都由一个唯一的数字来标识，称为它的地址（address），所有可能地址的集合就称为虚拟地址空间（virtual address space）。顾名思义，这个虚拟地址空间只是一个展现给机器级程序的概念性映像。实际的实现（见第 9 章）是将动态随机访问存储器（DRAM）、闪存、磁盘存储器、特殊硬件和操作系统软件结合起来，为程序提供一个看上去统一的字节数组。 指针 真正理解指针需要查看它们在机器级上的表示以及实现。 "},"course/图说设计模式.html":{"url":"course/图说设计模式.html","title":"图说设计模式","keywords":"","body":"图说设计模式 github [toc] 目标 看懂UML类图和时序图 $\\rightarrow$ 创建型模式 $\\rightarrow$ 结构性模式 $\\rightarrow$ 行为型模式 看懂UML类图和时序图 车的类图结果是 $>$ ，表示车是一个抽象类 车有两个继承类：小汽车和自行车，它们之间的关系是实现关系，关系用一个带虚线的空心箭头表示 suv继承小汽车，它们之间的关系是泛化关系，关系用一个带实线的空心箭头表示 轮胎和发动机组成小汽车，是一种组成关系，用带实线的实心箭头表示 学生上学要用到自行车，是一种依赖关系，用带虚线的箭头表示 学生聚合成一个班级，是一种聚合关系，用带实心的空心箭头表示 学生有身份证，是一种关联关系，用实线表示 泛化关系（generalization） 类的集成结构表现在 UML 中： 泛化（generalize）和实现（realize） 集成关系是 $is-a$ 的关系，如果两个对象之间可以用 $is-a$来表示，就是继承关系：自行车是车 泛化关系用一条带实线的空心箭头实线 关系用一个带虚线的空心箭头表示 最终代码中，泛化关系表现为继承非抽象类 实现关系（realize） 实现关系用一个带空心箭头的虚线表示 eg：”车”为一个抽象概念，在现实中并无法直接用来定义对象；只有指明具体的子类(汽车还是自行车)，才 可以用来定义对象（”车”这个类在C++中用抽象类表示，在JAVA中有接口这个概念，更容易理解） 最终代码中，实现关系表现为继承抽象类 聚合关系（aggregation） 聚合关系用一条带空心菱形箭头的直线表示，如下图表示 A 聚合到 B 上，或者说 B 由 A 组成： 聚合关系用于表示实体对象之间的关系，表示整体由部分构成的语义，eg：一个部门由多个员工组成 与组合关系不同的是，整体和部分不是强依赖，即使整体不存在了，部分依然是存在的，eg：部门撤销了，人员不会消失，他们依然存在 组合关系（composition） 组合关系用一条带实现菱形箭头表示，如下图表示 A 组成 B： 与聚合关系一样，组合关系同样表示整体由部分存在的语义：公司由很多个部门存在 但是组合关系hi是一种强依赖关系，如果整体不存在了，则部分也不存在了：公司破产了，部门也无了 关联关系（association） 关联关系用一条直线表示，它表示不同类的对象之间的结构关系，它是一种静态关系，通常与运行状态无关，一般由常识等因素决定的，它一般用来定义对象之间静态的，天然的结构，所以，关联关系是一种“强关联”的关系：乘车人和车票 关联关系默认不强调方向，表示对象之间都相互知道，如果特别强调方向，如下图，表示 A 知道 B， B 不知道 A 在最终代码中，关联对象通常是以成员变量的形式实现的 依赖关系（dependency） 依赖关系用一个带箭头的虚线表示，如下图表示 A 依赖于 B；他描述一个对象在运行期间会用到另一个对象的关系 与关联关系不同的是，它是一种临时的关系，通常在运行期间产生，并且随着运行时的变化，依赖关系也可能发生变化 显然，依赖有方向，双向依赖是一种非常糟糕的结构，我们总是应该保持单向依赖，杜绝双向依赖的产生 在最终代码中，依赖关系体现为为类的构造方法及类方法的传入参数，箭头的指向表示调用关系，依赖关系处理临时知道对方外，还是使用对方的方法和属性 时序图（sequence diagram） 为了展示对象之间的交互细节，都会用到时序图 时序图（sequence diagram）是显示对象之间交互的图，如果这些对象是按时间顺序排列的，时序图显示的是参与交互的对象及其对象之间消息交互的顺序 时序图包括的建模元素有：对象（Actor）、生命线（Lifeline）、控制焦点（Focus of control）、消息（Message）等 创建型模式（creational pattern） 创建型模式对类的实例化过程进行了抽象，能够将软件模块中对象的创建和对象的使用分离。为了使软件的结构更加清晰，外界对于这些对象只需要知道它们共同的接口，而不清楚其具体的实现细节，使整个系统的设计更加符合单一职责原则。 包含模式：简单工程模式、工厂方法模式、抽象工厂模式、建造者模式、原型模式、单例模式 简单工厂模式（simple factory pattern） 模式定义：属于类创建型模式，在简单工厂模式中，可以根据参数的不同返回不同类的实例。简单工厂模式专门定义一个类来负责创建其它类的实例，被创建的实例通常都是具有共同的父类 模式结构： 工厂角色（factory）： 工厂角色负责实现创建所有实例的内部逻辑 抽象产品角色（product）：抽象产品角色是创建所有对象的父类，负责描述所有实例所共有的公共接口 具体产品角色（concreteProduct）：具体产品角色是创建目标，所有创建的对象都充当这个角色的某个具体类的实例 #include \"Factory.h\" #include \"ConcreteProductA.h\" #include \"ConcreteProductB.h\" Product* Factory:createProduct(string proname) { if(\"A\" === proname){ return new ConcreteProductA(); } else if(\"B\" === proname) { return new ConcreteProductB(); } return NULL; } 模式分析 将对象的创建和对象本身业务处理分离可以降低系统的耦合度，使得两者修改起来都相对容易 在调用工厂类的工厂方法时，由于工厂方法是静态方法，使用起来很方便，可以通过类名直接调用，而且只需要传入一个简单的参数即可，在实例开发中，还可以在调用时将所传入的参数保存在XML等格式的配置文件中，修改参数时无须修改任何源码 简单工厂问题的最大问题在于工厂类的职责相对过重，增加新的产品需要修改工厂类的判断逻辑，这一点与开闭原则是相违背的 简单工厂模式的要点在于：当你需要什么，只需要传入一个正确的参数，就可以获取你需要的对象，而无需知道其创建细节 优点 工厂类含有必要的判断逻辑，可以决定在什么时候创建哪一个产品类的实例，客户端可以免除直接创建产品对象的责任，而仅仅“消费”产品；简单工厂模式通过这种做法实现了对责任的分割，它提供专门的工厂类用于创建对象 客户端无须知道所创建的具体产品类的类名，只需要知道具体产品类所对应的参数即可，对于一些复杂的类名，通过简单工厂模式可以减少使用者的记忆量 通过引入配置文件，可以在不修改任何客户端代码的情况下更换和增加新的具体产品类，在一点程度上提高了系统的灵活性 缺点 由于工厂类集中了所产品创建逻辑，一点不能正常工作，整个系统都要受到影响 使用简单工厂模式将会增加系统中类的个数，在一定程度上增加了系统的复杂度和理解难度 系统扩展困难，一旦添加新产品就不得不修改工厂逻辑，在产品类型较多时，有可能造成工厂逻辑过于复杂，不利于系统的扩展和维护 总结 创建型模式对类的实例化过程进行了抽象，能够将对象的创建与对象的使用过程分离。 简单工厂模式又称为静态工厂方法模式，它属于类创建型模式。在简单工厂模式中，可以根据参数的不同返回不同类的实例。简单工厂模式专门定义一个类来负责创建其他类的实例，被创建的实例通常都具有共同的父类。 简单工厂模式包含三个角色：工厂角色负责实现创建所有实例的内部逻辑；抽象产品角色是所创建的所有对象的父类，负责描述所有实例所共有的公共接口；具体产品角色是创建目标，所有创建的对象都充当这个角色的某个具体类的实例。 简单工厂模式的要点在于：当你需要什么，只需要传入一个正确的参数，就可以获取你所需要的对象，而无须知道其创建细节。 简单工厂模式最大的优点在于实现对象的创建和对象的使用分离，将对象的创建交给专门的工厂类负责，但是其最大的缺点在于工厂类不够灵活，增加新的具体产品需要修改工厂类的判断逻辑代码，而且产品较多时，工厂方法代码将会非常复杂。 简单工厂模式适用情况包括：工厂类负责创建的对象比较少；客户端只知道传入工厂类的参数，对于如何创建对象不关心。 "},"dataStructure/leetcode算法教程.html":{"url":"dataStructure/leetcode算法教程.html","title":"leetcode算法基础","keywords":"","body":"LeetCode 算法教程 1 算法入门 20 天算法刷题计划 1.1 二分查找 例题 简单的二分查找 考虑数组的奇偶数，应该向下取整，平时用 c 做应该就是向下取整了，使用 JavaScript 的时候没有类型，应该使用 Math.floor 或者 Math.ceil 向下或者向上取整 left 和 right 怎么取，如果是数组，left 是 0， right 是数组长度减一，其它的又是另外的情况了 循环的判断条件是 left 判断完之后 mid 是否要加一还是减一呢 代码： var search = function(nums, target) { let left = 0, right = nums.length - 1 while(left > 1) + left if(target == nums[mid]) { return mid } else if(target 官方代码： var search = function(nums, target) { let low = 0, high = nums.length - 1; while (low target) { high = mid - 1; } else { low = mid + 1; } } return -1; }; 递归的写法和循环的写法用时差不多，但是循环的内存好像要少一点。比较两者而言，我还是喜欢递归的写法 第一个错误的版本 顺序的版本，找到第一个错误的版本，最直观的就是循环，算法就是二分 代码： /** * @param {function} isBadVersion() * @return {function} */ var solution = function(isBadVersion) { /** * @param {integer} n Total versions * @return {integer} The first bad version */ return function(n) { let left = 1, right = n while(left > 1) + left if(isBadVersion(mid)) { right = mid } else { left = mid + 1 } } return left }; }; 官方代码： var solution = function(isBadVersion) { return function(n) { let left = 1, right = n; while (left 用时都差不多，但是看到题解里面有说用移位 >>1 代替除以 2 的，>>1 相当于除以2并向下取整了，减了再加就是防止溢出了 搜索插入位置 这个题的判断条件有出入，可能是最后一个位置加一，所以多用了一个变量 ans = nums.length 代码： /** * @param {number[]} nums * @param {number} target * @return {number} */ var searchInsert = function(nums, target) { let left = 0, right = nums.length - 1, ans = nums.length while(left > 1) + left if(target 官方代码： var searchInsert = function(nums, target) { const n = nums.length; let left = 0, right = n - 1, ans = n; while (left > 1) + left; if (target 二分查找 简单题 x的平方根 非负整数 x 的算术平方根也是二分查找吗？是的，范围是从 1 到 x，找到哪个判断条件 /** * @param {number} x * @return {number} */ var mySqrt = function(x) { let left = 1, right = x while(left >1) if(mid*mid x) { return mid } left = mid + 1 } else { right = mid -1 } } return 0 }; 有效的完全平方数 同上 /** * @param {number} num * @return {boolean} */ var isPerfectSquare = function(num) { let left = 1, right = num while(left > 1) let value = mid * mid if(value == num) { return true } else if (value 猜数字的大小 题目描述的真是太 giao 了 /** * @param {number} n * @return {number} */ var guessNumber = function(n) { let left = 1, right = n while(left > 1) let res = guess(mid) if(res == 0) { return mid } else if(res == -1) { right = mid - 1 } else { left = mid + 1 } } }; 排列硬币 /** * @param {number} n * @return {number} */ var arrangeCoins = function(n) { let sum = 0, i = 0 while(sum 为什么这个可以用二分法呢？肯定是 1 到 n 的其中一个数满足等差数列的公式 /** * @param {number} n * @return {number} */ var arrangeCoins = function(n) { let left = 1, right = n while(left > 1) if (mid * (mid + 1) 寻找比目标字母大的最小字母 /** * @param {character[]} letters * @param {character} target * @return {character} */ var nextGreatestLetter = function(letters, target) { let left = 0, right = letters.length while(left > 1) if(target >= letters[mid]) { left = mid + 1 } else { right = mid } } return letters[left] > target ? letters[left] : letters[0] }; 山脉数组的峰顶索引 /** * @param {number[]} arr * @return {number} */ var peakIndexInMountainArray = function(arr) { let left = 0, right = arr.length - 1 while(left > 1) if(arr[mid] 公平的糖果交换 这个题感觉是哈希了，不是二分法了 /** * @param {number[]} aliceSizes * @param {number[]} bobSizes * @return {number[]} */ var fairCandySwap = function(aliceSizes, bobSizes) { const sumA = _.sum(aliceSizes), sumB = _.sum(bobSizes) const delta = (sumA - sumB) >> 1 const setA = new Set(aliceSizes) for(let y of bobSizes) { let x = y + delta if(setA.has(x)) { return [x, y] } } }; 矩阵中战斗力最弱的 K 行 /** * @param {number[][]} mat * @param {number} k * @return {number[]} */ var kWeakestRows = function(mat, k) { let list = [] for(let i = 0; i a.vlaue - b.vlaue) return list.map((item) => item.index).splice(0, k) }; var firstZero = function(arr) { let left = 0, right = arr.length - 1 if(arr[right]) return right + 1 while(left > 1) if(arr[mid]) { left = mid + 1 } else { right = mid } } return left } 检查整数及其两倍数是否存在 是哈希表了，简单易用的就解决了 /** * @param {number[]} arr * @return {boolean} */ var checkIfExist = function(arr) { let map = new Map() for(let i of arr) { if(map.has(i)) return true map.set(i*2, i) if(!(i%2)) map.set(i/2, i) } return false }; 统计有序矩阵中的负数 /** * @param {number[][]} grid * @return {number} */ var countNegatives = function(grid) { let row = grid.length, col = grid[0].length if(grid[row - 1][col - 1] >= 0) return 0 let sum = 0 for(let i = 0; i { let left = 0, right = arr.length - 0 if(arr[right] >= 0 ) return arr.length while(left > 1) if(arr[mid] >= 0) { left = mid + 1 } else { right = mid } } return left } 两个数组间的距离值 /** * @param {number[]} arr1 * @param {number[]} arr2 * @param {number} d * @return {number} */ var findTheDistanceValue = function(arr1, arr2, d) { arr2.sort((a, b) => a - b) console.log(arr2) let sum = 0 for(let i of arr1) { let left = 0, right = arr2.length - 1, flag = true while(left > 1) let distance = Math.abs(arr2[mid] - i) if(distance arr2[mid]) left = mid + 1 else right = mid -1 } if(flag){ sum = sum + 1 } } return sum }; 第 k 个缺失的正整数 /** * @param {number[]} arr * @param {number} k * @return {number} */ var findKthPositive = function(arr, k) { // 找规律，先找范围，范围是 x_n - n, n 是下标值，结果是 k + n let left = 0, right = arr.length - 1 while(left > 1) let temp = arr[mid] - mid - 1 if(temp > k) { right = mid - 1 } else if(temp 特殊数组的特征值 这题的规律不好找啊，溜了溜了，就做了前三页的简单题 1.2 双指针 例题 有序数组的平方 为什么没有用 JavaScript 内置的方法，反而时间和空间的消耗更大了呢 /** * @param {number[]} nums * @return {number[]} */ var sortedSquares = function(nums) { // 1. 先用暴力法 // nums.forEach((value, index) => nums[index] = value * value) // return nums.sort((a, b) => a - b) // 2. 应该用一种简单的方法，平方之后前面是降序，后面是升序，归并一下即可 nums.forEach((value, index) => nums[index] = value * value) let res = [] for(let i = 0, j = nums.length - 1; i 轮转数组 三种方法，感觉还不如用 JavaScript 自带的内置函数，这样速度还要快一点 /** * @param {number[]} nums * @param {number} k * @return {void} Do not return anything, modify nums in-place instead. */ var reverse = function(arr, i, j) { for(;i 移动零 /** * @param {number[]} nums * @return {void} Do not return anything, modify nums in-place instead. */ var moveZeroes = function(nums) { // 两个指针，一个 firstZero，一个指针用来遍历数组 let firstZero = -1, temp for(let i = 0; i 两数之和 /** * @param {number[]} numbers * @param {number} target * @return {number[]} */ var twoSum = function(numbers, target) { // 双指针了 let i = 0, j = numbers.length - 1 while(i target) { --j } else { ++i } } return [i + 1, j + 1] }; 反转字符串 /** * @param {character[]} s * @return {void} Do not return anything, modify s in-place instead. */ var reverseString = function(s) { // 1. 直接使用内置的方法 // s.reverse() // 2. 使用双指针 let temp for(let i = 0, j = s.length - 1; i 反转字符串中的单词 /** * @param {string} s * @return {string} */ var reverseWords = function(s) { // 双指针 let firstSpace = 0, secondSpace = 0, temp s = s.split('') while(s[secondSpace] != ' ' && secondSpace 链表的中间结点 /** * Definition for singly-linked list. * function ListNode(val, next) { * this.val = (val===undefined ? 0 : val) * this.next = (next===undefined ? null : next) * } */ /** * @param {ListNode} head * @return {ListNode} */ var middleNode = function(head) { let firstNode = head, secondNode = head while(secondNode && secondNode.next) { if(secondNode.next) secondNode = secondNode.next.next firstNode = firstNode.next } return firstNode }; 删除链表的倒数第 N 个结点 /** * Definition for singly-linked list. * function ListNode(val, next) { * this.val = (val===undefined ? 0 : val) * this.next = (next===undefined ? null : next) * } */ /** * @param {ListNode} head * @param {number} n * @return {ListNode} */ var removeNthFromEnd = function(head, n) { let first = head, second = head for(let i = 0; i 双指针 简单题 验证回文串 /** * @param {string} s * @return {boolean} */ var isPalindrome = function(s) { const str = s.toLocaleLowerCase().replace(/[\\W_]/ig, '') for(let i = 0, j = str.length - 1; i 快乐数 /** * @param {number} n * @return {boolean} */ var isHappy = function(n) { let slow = n, fast = sumSquare(n) while(fast!=1 && fast!=slow) { fast = sumSquare(sumSquare(fast)) slow = sumSquare(slow) } return fast === 1 }; var sumSquare = (num) => { return num.toString().split('').map(i => i ** 2).reduce((a, b) => a + b) } 反转字符串中的元音字母 /** * @param {string} s * @return {string} */ var reverseVowels = function(s) { let temp = ['a', 'e', 'i', 'o', 'u', 'A', 'E', 'I', 'O', 'U'] const str = s.split('') for(let i = 0, j = str.length - 1; i i) --j; if(i 反转字符串 II 快慢指针是两倍的情况，可以思考是否还需要两个指针 /** * @param {string} s * @param {number} k * @return {string} */ var reverseStr = function(s, k) { const str = s.split('') for(let i = 0; i { while(i 1.3 滑动窗口 无重复字符的最长子串 "},"dataStructure/simple/文件操作.html":{"url":"dataStructure/simple/文件操作.html","title":"文件操作","keywords":"","body":"文件操作 概念知识 文件是操作系统管理数据的基本单位，文件一般包括三要素：文件路径、文件名、后缀。 D:\\\\C_WorkSpace\\\\Chapter_10\\\\file_1.txt D:/C_WorkSpace/Chapter_10/file_1.txt 以上两个是文件的两种不同写法 根据文件中数据的组织形式的不同，可以把文件分为：文本文件和二进制文件（考试只考文本文件） 文本文件：把要存储的数据当成一系列字符组成，把每个字符的 ASCII 码值存入文件中。每个 ASCII 码值占一个字节，每个字节表示一个字符。故文本文件也称作字符文件或 ASCII 文件，是字符序列文件。 进制文件：把数据对应的二进制形式存储到文件中，是字节序列文件。 C语言文件操作 函数介绍 fopen() fopen:文件打开操作 函数原型：FILE fopen(char pname, char * mode) mode：r read，w write（如果文件不存在，则建立一个新文件，如果文件存在，删除里面的所有东西）a append(追加) 正常返回：FILE * 一个指向文件在内存中的文件信息去的开头 异常返回：NULL，表示打开操作不成功 fclose() fclose:文件关闭 函数原型：int fclose(FILE *fp); 正常返回：0 异常返回：EOF，表示文件在关闭时发生错误 fgetc() fgetc:从fp中读取一个字符，作为返回值返回 函数原型：int fgetc(FILE *fp) 正常返回：返回读取字符的代码 异常返回：返回EOF fputc() fputc: 写一个字符到文件中 函数原型：int fputc(int ch, FILE*fp) 正常返回：要写入的字符的代码 异常返回：返回EOF fgets() 函数原型：char fgets(char str, int n, FILE *fp) fgets：由fp指出的文件中读取n-1个字符，并把他们存放到有str指出的字符数组中区，最后加上一个由字符串结束符'' fputs() 函数原型：char fputs(char str, FILE *fp) fputs：把由str之处的字符串写入到fp所指的文件中去 fprintf（）和 fscanf（） fprintf(fp,\"%s %d\\t\",str,&n); //制表符 printf(\"%s\\t\",str); fscanf(fp,\"%s\\t\",&str); scanf(\"%s\\t\",&str); feof(fp) 如果指针到了文件的末尾，返回false，否则返回true file eof feof if(!feof(fp)){ //如果指针没有到文件的末尾 } 字符串的操作 整数转为字符串 char* itoa(int value,char*string,int radix);//value: 要转换的整数，string: 转换后的字符串,radix: 转换进制数，如2,8,10,16 进制等。 这是库函数，我们可以写一个简单的类似函数 一个位的整数 0-9，怎么转为字符 char = int + '0'; int = char - '0'; 56789154 %10 4 /10 5678915 5 5 0 void reverse(char* str,int k){ //字符数组逆转函数 if(!str||k 写随机数 写随机种子 srand(time(0)); //#include 生成随机数 temp = rand()%100 + 47; //生成47到147的随机数 "},"dataStructure/simple/栈和队列.html":{"url":"dataStructure/simple/栈和队列.html","title":"栈和队列","keywords":"","body":"栈和队列 [toc] 栈的基本概念 同顺序表和链表一样，栈也是用来存储逻辑关系为 \"一对一\" 数据的线性存储结构 栈存储结构与之前所学的线性存储结构有所差异，这缘于栈对数据 \"存\" 和 \"取\" 的过程有特殊的要求： 栈只能从表的一端存取数据，另一端是封闭的 在栈中，无论是存数据还是取数据，都必须遵循\"先进后出\"的原则，即最先进栈的元素最后出栈。 什么是栈 栈是一种只能从表的一端存取数据且遵循 \"先进后出\" 原则的线性存储结构 通常，栈的开口端被称为栈顶；相应地，封口端被称为栈底 int arr[10], top = -1; double arr[100]; int top2 = -1; node arr[100]; int top3 = -1; 栈的实现 栈的具体实现有两种： 顺序栈：采用顺序存储结构可以模拟栈存储数据的特点，从而实现栈存储结构； 链栈：采用链式存储结构实现栈结构； 顺序栈 初始化： int a[100],top=-1; 入栈： a[++top] = value; //将value入栈 if(top != 100){ a[++top] = value; } 出栈 if(top!=-1) value = a[top--]; //出栈，有返回值情况 top--; //无返回值情况 top = -1; //清空栈 链栈 链栈实际上就是一个只能采用头插法插入或删除数据的链表 初始化： typedef struct node{ int value; struct node* next; }node; int main() { node* stack = (node*)malloc(sizeof(node)); stack->next = null; // 入栈 int value = 1; node* q = (node*)malloc(sizeof(node)); q->value = value; q->next = stack->next; stack->next = q; // 出栈 if(stack->next != null) { node* temp = stack->next; stack->next = temp->next; printf(\"%d\", temp->value); // %d, %f, %lf, %c, %s // '' \"\" } } typedef struct node{ //结点存储结构 int data; node* next; }node; node* stack = (node*)malloc(sizeof(node)); //链表头节点，可作为栈来使用 stack->next = NULL; 入栈： void push(node* stack,int i){ //以头插法插入就是入栈 node* temp = (node*)malloc(sizeof(node)); //初始化结点 temp->data = i; temp->next = stack->next; //头插法 stack->next = temp; } 出栈： int pop(node* stack){ //取回第一个结点的值，然后删除第一个结点 if(stack->next==NULL) //栈不空 return 0; node* temp = stack->next; //temp是第一个结点 stack->next = temp->next; temp->next = 0; int i = temp->data; free(temp); return i; } 栈的应用 进制间的转换， 2 6 8 10 16 （这些进制间的互转） temp = 0 // i => n, 把二进制转换为了十进制 while(i){ // 2 进制 if(i%10) // 取个位数 n += power(2,temp); // math.h i /= 10; temp++; } // 将一个十进制的数转换为八进制 int* func(int n) { int arr[100], top = -1; // 初始化一个栈，用来保存余数 int index = 1; if(n void conver(int* stack,int top,int i){ //stack是栈，已经定义过，将i按二进制存进stack中 while(i){ stack[++top] = i%2; //取余数 i /= 2; } } void output(int* stack,int top){ //输出栈 while(top!=-1) printf(\"%d\\t\",stack[top--]); } 括号匹配 （1+[5*6+7-1]-1) ( // 括号匹配 bool func(char* str, int n) { if(!str || n int function(char* str){ //判断str中括号是否匹配 if(!str) // 字符串不存在 return 0; char stack[100],temp; int top=-1; for(int i=0;str[i]!='\\0';++i){ temp = str[i]; if(temp=='('||temp==')'||temp=='['||temp==']'){ if(temp=='('||temp=='[') stack[++top] = temp; else if(top!=-1&&(stack[top]=='('&&temp==')'||stack[top]=='['&&temp==']')) top--; else return 0; //如果括号不匹配的情况 } if(top==-1) return 1; else return 0; } } 队列的基本概念 队列，和栈一样，也是一种对数据的\"存\"和\"取\"有严格要求的线性存储结构。 与栈结构不同的是，队列的两端都\"开口\"，要求数据只能从一端进，从另一端出： 通常，称进数据的一端为 \"队尾\"，出数据的一端为 \"队头\"，数据元素进队列的过程称为 \"入队\"，出队列的过程称为 \"出队\"。 队列中数据的进出要遵循 \"先进先出\" 的原则。 队列的构建 队列存储结构的实现有以下两种方式： 顺序队列：在顺序表的基础上实现的队列结构； 链队列：在链表的基础上实现的队列结构； 顺序队列 初始化： int a[100],front=0,rear=0; //初始化队列，假设最大长度也不超过100 入队： if((rear+1)%100!=front){ //队列不满 a[rear] = value; rear = (rear+1)%100; } 出队： if(front!=rear){ //队列不空 value = a[front]; front = (front+1)%100; } 这只是一个想象图，在真正的实现时，没必要真创建这样一种结构，我们还是使用之前的顺序表，也还是使用之前的程序，只需要对其进行一点小小的改变：整除队列的长度 链队列 链式队列的实现思想同顺序队列类似，只需创建两个指针（命名为 top 和 rear）分别指向链表中队列的队头元素和队尾元素 链式队列的初始状态，此时队列中没有存储任何数据元素，因此 top 和 rear 指针都同时指向头节点。 初始化： //链表中的节点结构 typedef struct QNode{ int data; struct QNode * next; }QNode; //创建链式队列的函数 QNode * initQueue(){ //创建一个头节点 QNode * queue=(QNode*)malloc(sizeof(QNode)); //对头节点进行初始化 queue->next=NULL; return queue; } 入队： QNode* enQueue(QNode * rear,int data){ //1、用节点包裹入队元素 QNode * enElem=(QNode*)malloc(sizeof(QNode)); enElem->data=data; enElem->next=NULL; //2、新节点与rear节点建立逻辑关系 rear->next=enElem; //3、rear指向新节点 rear=enElem; //返回新的rear，为后续新元素入队做准备 return rear; } 出队： void DeQueue(QNode * top,QNode * rear){ if (top->next==NULL) { printf(\"队列为空\"); return ; } // 1、 QNode * p=top->next; printf(\"%d\",p->data); top->next=p->next; if (rear==p) { rear=top; } free(p); } 约瑟夫环 问题描述：有M个人，从1到M编号，按照编号顺序围成一圈。从第一个人开始报数(从1报到N)，凡报到N的人退出圈子。然后下一个小朋友会继续从 1 开始报数，直到只剩一个人为止 问：最后留下的人的编号是几号。 也叫 约瑟夫环问题。 算法思想：每个人的编号存放在一个数组 a 中，主函数中决定人数的个数以及报数的上限值 m，设计一个函数实现对应的操作。函数的形参有整型数组 a、整数 n 和 m，n 用来接收传递的人数，m 用来接收报数上限，函数的返回值为空；函数体中输出出列人的顺序。 函数中利用循环访问数组中 n 个元素，每次访问元素，设定内循环连续访问 m 个元素，元素访问的下标为 k，访问到第 m 个元素时，如果元素不是 0，此时输出元素 a[k]，再设定 a[k] 为 0，继续访问后面的元素。 #include #define N 100 int josef(int n,int m) //约瑟夫环的实现，n个人，数m { int a[100]; for(int i=0;i /约瑟夫环函数,用链表实现 void function(int n,int m){ //实现约瑟夫环 node* p = (node*)malloc(sizeof(node)); //循环链表的初始化 p->next = p; node* tail = p; for(int i=1;idata = i; temp->next = 0; tail->next = temp; temp->next = p->next; tail = temp; } node* temp1 = p,*temp2 = p->next; for(int i=0;inext; temp2 = temp2->next; } temp1->next = temp2->next; temp2->next = 0; printf(\"%d\\t\",temp2->data); free(temp2); temp2 = temp1->next; } } "},"dataStructure/simple/链表.html":{"url":"dataStructure/simple/链表.html","title":"链表","keywords":"","body":"链表 [toc] 线性表： 数组， 链表（指针） 数据结构 基本概念 链表和数组都可用于存储数据，其中链表通过指针来连接元素，而数组则是把所有元素按次序依次存储。 不同的存储结构令他们有了不同的优势： 链表可以方便地删除、插入数据，操作次数是 O(1) 。但也因为这样寻找读取数据的效率不如数组高，在随机访问数据中的操作次数是 O(n) 。 数组可以方便的寻找读取数据，在随机访问中操作次数是 O(1) 。但删除、插入的操作次数却是却是 O(n) 次 顺序表 int a[10]; // a a[1] = 2; *(a + 1) = 2; * & // 指针 什么是指针，我们一般都说 “它是一个地址”，“存储的是变量的地址”，“指向了一个值” 指针是什么： 指针是一个普通的变量； 既然指针是变量，那么肯定有自己的类型； 既然指针是变量，那么肯定有自己的值； 只不过指针的值跟一般变量的值不太一样，指针的值是一个“地址”。 指针指向的数据 总结就是：指针就是一个普通的变量，有自己的类型和值，但是特殊的地方在于它的值和其它变量的值不一样，它的值是一个长的16进制的东西，即地址。 因为指针可以保存地址，计算机就可以利用指针保存任意大小的空间的首地址，可以随时改变指针里面的地址的值 *可以取指针里面的内容 &可以取变量里面的地址 构建链表 一个又一个的结点 typedef struct Node{ int data; // double float 但是它可以不是基本变量，它可以是个很复杂的东西 struct Node* next; // 这一行一般不会变 }Node; Node* N1 = (Node*)malloc(sizeof(Node)); // 为什么我们这么创建 Node N2; // -> . // N1 是个 Node 的指针，可以指向任意的结点 可以换 构建链表实际上是构建了一个结点 一般我们描述的链表是什么？ 一个node型的指针 // 头指针 带空间的node型的指针 // 带头节点的的头指针 关于链表的构建使用到指针的部分比较抽象，光靠文字描述和代码可能难以理解，建议配合作图来理解。 怎么构建链表：一个一个的将结点插入链表中，有两种插入的方法：头插法和尾插法，一般建议使用尾插法 头节点，头指针 头插法，尾插法 头插法 // 插入的时候结点插入头节点和第一个结点，头指针指向它，它再指向第一个结点 尾插法呢 //node* tail; tail->next = temp; tail = temp; 单向链表 单向链表中包含数据域和指针域，其中数据域用于存放数据，指针域用来连接当前结点和下一节点 typedef struct Node { //结点存储结构 int value; //数据域 struct Node *next; //指针域 }Node; 双向链表 双向链表中同样有数据域和指针域，不同之处在于指针域有左右（或上一个、下一个）之分，用来连接上一个节点、当前结点、下一个结点 typedef struct Node { int value; Node *left,*right; // int a,* b, c; }Node; 向链表中插入（写入）数据 单向链表 void insertNode(int i, Node *p) { Node* node = (Node *)malloc(sizeof(Node)); //new和malloc // malloc // int b; int* a; a = &b; *a = 1; b = 1 // int* a = (int*)malloc(sizeof(int)*10) // . -> // . -> // Node node node.value // node->value = i; node->next = p->next; //头插法 p->next = node; } 上面介绍了简单的单向链表的插入数据，有时我们会将链表的头尾连接起来将链表变为循环链表： void insertNode(int i, Node *p) { Node *node = (Node*)malloc(sizeof(Node)); //动态分配空间 node->value = i; node->next = NULL; if (p == NULL) { // 循环链表的特殊点 p = node; node->next = node; } else { node->next = p->next; //头插法 p->next = node; } } 由于是循环的链表，我们在插入数据时需要判断原链表是否为空，为空则自身循环，不为空则正常插入数据循环。具体过程可参考下面这张图。 双向循环链表的插入写法：0 = 0 = 0 1= void insertNode(int i, Node *p) { Node *node = (Node*)malloc(sizeof(Node)); node->value = i; node->next = NULL; //. 和 -> if (p == NULL) { //没有结点的情况 p = node; node->left = node; node->right = node; } else { //链表有结点的情况 node->left = p; node->right = p->right; p->right->left = node; p->right = node; } } 从链表中删除数据 单向（循环）链表 void deleteNode(Node *p) { p->value = p->next->value; Node *t = p->next; p->next = p->next->next; t->next = 0; free(t); } 从链表中删除某个结点时，将 p 的下一个结点 (p->next) 的值覆盖给 p 即可，与此同时更新 p 的下下个结点。 双向链表¶ void deleteNode(Node* p) { //删除p结点 p->left->right = p->right; p->right->left = p->left; p->left = 0; // 考试的时候 0 换成 null p->right = 0; free(p); } 遍历链表 / / 改 void output(node* p){ //遍历链表(有头节点) if(!p) return; p = p->next; while(p){ printf(\"%d\\t\",p->value); // 可以换成很多操作 p = p->next; } } // 函数的写法 翻转链表 p 1 -> 2-> 3 -> 4 -> 5 p -> 2 -> 3 -> 4 ->5 temp -> 1 p -> 1 ->2 ->3 -> 4 ->5 temp ->2 p 2 -> 1 -> 3 -> 4 -> 5 typedef struct{ int data; struct node* next; }node; void reverse(node* a) { // . -> node a . a.next // node* a a->next int b int* b // node* a; int* b; // 我们初始化两个值 a null b 0 // node* a = (node*)malloc(sizeof(node)); 123456 123455 // a->data = 1; // node a; int* b; // a.data = 1; // 1. . -> // 2. 指针能改变地址 if(!a || a->next == null){ return; } node* p = a->next; while(p) { node* temp = p->next; node* first = a->next; if(p != first) { // 防止 1 指向自己了 p->next = first; a->next = p; } p = temp; } } void reverse(node* p){ //翻转链表，头插法 没有消耗其他的空间 if(!p||!p->next) //链表不存在或者没有结点的情况 return; node* first = p->next,*temp = p->next->next; while(temp){ //遍历链表 first->next = temp->next; //将temp提出来 temp->next = p->next; //头插法 p->next = temp; temp = first->next; } } 任务 尝试写一下循环链表的构建、插入、删除和搜索的代码 typedef struct LNode{ //结点存储结构 int data; struct LNode* next; }LNode; bool insertLNode(LNode*p,int i){ //头插法插入i进链表 if(!p) return false; LNode* temp = (LNode*)malloc(sizeof(LNode)); temp->data = i; temp->next = p->next; //头插法 p->next = temp; return true; } bool deteleLNode(LNode* p){ //删除p后一结点 if(!p||p->next==p) //p不存在或者没有结点 return false; LNode* temp = p->next; p->next = temp->next; temp->next = NULL; free(temp); //释放temp结点 return true; } bool search(LNode* p,int i){ //搜索链表p中是否存在值为i的结点 if(!p||p->next==p) //p不存在或者没有结点 return false; LNode* temp = p->next; //temp现在指向第一个结点 while(temp->next!=p){ //遍历链表 if(temp->data==i) return true; temp = temp->next; } return true; } 尝试写一下双向链表的构建、插入、删除和搜索的代码 typedef struct DNode{ //双链表结构 int data; struct DNode* prior,* next; }DNode; bool insertDNode(DNode* p,DNode* s){ //将s插入到p之后 if(!p) return false; s->next = p->next; p->next->prior = s; s->prior = p; p->next = s; return true; } bool deleteDNode(DNode* p){ //删除p的后面个结点 if(!p) return false; DNode* q = p->next; if(!q) return false; p->next = q->next; //删除结点操作 if(q->next != NULL) q->next->prior = p; q->next = NULL; free(q); //将q的空间释放 return true; } DNode* search(DNode* p,int target){ //搜索等于target的结点 if(!p) return 0; p = p->next; while(p){ //遍历链表寻找目标结点 0 false null if(p->data == target) return p; p = p->next; } return 0; } 练手题 若线性表用单链表（带头结点）作为存储结构，写出其就地逆置算法 // 算法思想： 遍历单链表，从第一个开始，每一个结点重新插入到了新的链表中的第一个位置, 即头插法，最终就可以实现单链表的就地逆置 typedef struct Node{ int data; struct Node* next; }Node; void reverse(Node* p) { // 没有重新改变头节点的地址 if(!p) // 指针不存在 return; Node* first = p->next; Node* q = first->next; while(q) { // 遍历结点，逐个插入 Node* temp = second->next; // 保存第三个结点的地址 q->next = first; // 头插法 first->next = temp; // 接上第三个结点 first = q; // first 改变了 q = temp; } } Node* reverse2(Node* p) { if(!p){ // 判断链表是否存在 return 0; } Node* res = (Node*)malloc(sizeof(Node)); Node* temp = p->next; while(temp) { // 遍历链表，逐个头插法 Node* temp2 = temp->next; temp->next = res->next; // 头插法 res->net = temp; temp = temp2; } return res; } // 算法思想： 先判断链表，如果链表结点为0或者1 直接返回，否则从第二个结点开始逐个将其用头插法的方法重新插入一遍 typedef struct Node{ int value; struct Node* next; }Node; void reverse(Node* temp) { // 链表带头节点， 将其逆置 if(!temp || temp->next) { // ,,, return; } Node* first = temp->next, * second = temp->next->next; while(second) { Node* p = second; p->next = first; // 头插法 temp-> = p; first = p; second = second->next; } } typedef struct node{ //存储结构 int data; struct node* next; }node: void reverse(node* linklist){ if(!linklist||p->next) //链表不存在的情况 return; node* first = linklist->next,*temp = linklist->next->next; while(temp){ first->next = temp->text; //取出temp temp->next = linklist->next; //头插法 linklixt->next = temp; temp = first->next; //下一个结点 } } 设单链表中存放 n 个字符，试设计一个算法，使用栈判断该字符串是否中心对称 typedef struct node{ //链表结点的存储结构 char data; struct node* next; }node; bool function(node* linklist){ //带头结点的链表 if(!linklist) return false; char stack[100]; //假设字符串不超过100个字符,构建一个栈 int top = -1; // 栈的写法 node* p = linklist->next; //p指向第一个结点 while(p){ //遍历链表 if(top==-1||stack[top]!=p->data) //入栈的情况 stack[++top] = p->data; else if(stack[top]==p->data) //出栈的情况 top--; p = p->next; } if(top==-1) //判断栈是否为空 return true; else return false; } 编写一算法，以完成在带头节点单链表 M 中第 n 个位置前插入元素 X 的操作 typedef struct node{ //存储结点 int data; struct node* next; }node; void insert(node* M,int X,int n){ //链表的结点数大于n if(!M||ndata = X; temp->next = NULL; node* p = M->next; for(int i=0;inext; temp->next = p->next; //插入temp p->next = temp; } 已知非空线性链表第一个节点由 list 指出，请写一个算法交换 p（不是链表最后那个节点） 所指的节点与其下一个节点在链表中的位置 typedef struct ndoe{ //节点存储结构 int data; struct node* next; }node; bool swap(node* p,node* list){ //交换p和下一个节点的顺序 if(!p||!list) return false; if(p==list){ //p为第一个节点的情况 list = p->next; p->next = list->next; list->next = p; return true; } node* temp = list; while(temp->next!=p) //找到p的前一个节点 temp = temp->next; temp->next = p->next; //交换p和后一节点 p->next = temp->next->next; temp->next->next = p; return true; } 请用链表编程实现：从键盘读数，并按从小到大的顺序输出输入整数中互不相等的那些整数 算法思想：每次读入整数i，将整数 i 找到在链表中的某一个位置，该位置满足前面的数都比 i 小，后面的数都比 i 大，如果存在和 i 相等的数就不插入，否则就在该位置插入值为 i 的结点，每一个整数都这么插进链表中，最后就能得到从小到达互不相等的整数的链表，然后输出即可。 typedef struct node{ //节点存储结构 int data; struct node* next; }node; bool insert(node* p,int i){ //在链表p中按从小到大的顺序插入不相等的整数 if(!p) return false; node* temp1=p,*temp2=p->next; while(temp2&&i>temp2->data){ //找到一个位置，temp1前面的数都比i小，temp2的数大于等于i temp1 = temp1->next; temp2 = temp2->next; } if(temp2&&i==temp2->data) //相等的就不插入了 return false; node* temp = (node*)malloc(sizeof(node)); //初始化i temp->data = i; temp->next = NULL; if(!temp2) //应该插入最后个节点 temp1->next = temp; else{ //中间插入的情况 temp->next = temp2; temp1->next = temp; } return true; } void output(node* p){ //输出链表 if(!p) return; p = p->next; while(p){ printf(\"%d\\t\",p->data); p = p->next; } printf(\"\\n\"); } int main(){ node* p = (node*)malloc(sizeof(node)); //初始化一个链表 p->next = NULL; int i; while(i){ //从键盘中读数，为0的情况下退出 printf(\"Enter i:\\n\"); scanf(\"%d\",&i); insert(p,i); } printf(\"list:\\n\"); output(p); } 假设有两个按元素值递增有序排列的线性表 A 和 B，均以单链表作为存储机构，请编写算法将表 A 和表 B 归并成一个按元素值非递增有序排列的线性表 C typedef struct node{ int data; struct node* next; }node; node* merge(node* A,node* B){ //有序融合A,B node* c=A,*pa=A->next,*pb=B->next; //A作为c表表头 while(pa&&pb){ //A,B都还有节点的情况 if(pa->datadata){ //插入pa c->next = pa; c = pa; pa = pa->next; } else{ //插入pb c->next = pb; c = pb; pb = pb->next; } } if(pa) //将A或者B剩余的节点插入 c->next = pa; else if(pb) c->next = pb; return A; //因为将A作为了C表的表头 } 一直线性表中的元素以值递增有序排列，并以单链表作为存储结构，编写程序，删除表中所有值大于 mink 且小于 maxk 的元素 typedef struct node{ int data; struct node* next; }node; bool delete(node* l,int mink,int maxk){ // if(!l) return false; if(l->datadatanext; while(l&&l->datanext; temp->next = NULL; free(temp); //释放temp空间 } return true; } 8. a 和 b 是两双向链表，其中每一个节点存放一个整数。编写函数将链表 b 和 a 合并，并去除相同的值 ``` c typedef struct node{ //双链表结构 int data; struct DNode* prior,* next; }node; void insert(node* c,node* temp){ //将temp有序插入c if(!c||!temp) return; node* p = c->next; while(p&&p->datadata){ //找到插入的位置 p = p->next; c = c->next; } if(p->data==temp->data) //排除相等的整数结点 return; if(！p) //尾插法 c->next = temp; else{ temp->next = c->next; c->next = temp; } } node* merge(node* A,node* B){ //有序融合A,B，并去除其中整数值相同的结点 node* temp,*pa=A->next,*pb=B->next; node* c = (node*)malloc(sizeof(node)); c->next = NULL; while(pa){ //一个一个将a表的结点插入c temp = pa; pa = pa->next; temp->next = 0; insert(c,temp); } while(pb){ temp = pb; pb = pb->next; temp->next = 0; insert(c,temp); } return c; } "},"dataStructure/simple/字符串.html":{"url":"dataStructure/simple/字符串.html","title":"字符串","keywords":"","body":"字符串 基本概念 数据结构中，字符串要单独用一种存储结构来存储，称为串存储结构。这里的串指的就是字符串。 严格意义上讲，串存储结构也是一种线性存储结构，因为字符串中的字符之间也具有\"一对一\"的逻辑关系。只不过，与之前所学的线性存储结构不同，串结构只用于存储字符类型的数据。 空串：存储 0 个字符的串，例如 S = \"\"（双引号紧挨着）； 空格串：只包含空格字符的串，例如 S = \" \"（双引号包含 5 个空格）； 子串和主串：假设有两个串 a 和 b，如果 a 中可以找到几个连续字符组成的串与 b 完全相同，则称 a 是 b 的主串，b 是 a 的子串。例如，若 a = \"shujujiegou\"，b = \"shuju\"，由于 a 中也包含 \"shuju\"，因此串 a 和串 b 是主串和子串的关系； 子串在主串中的位置，指的是子串首个字符在主串中的位置。 例如，串 a = \"shujujiegou\"，串 b = \"jiegou\"，通过观察，可以判断 a 和 b 是主串和子串的关系，同时子串 b 位于主串 a 中第 6 的位置，因为在串 a 中，串 b 首字符 'j' 的位置是 6。 实现串的模式匹配的算法主要有以下两种： 普通的模式匹配算法； 快速模式匹配算法； 需要掌握的东西： 对文件进行操作 暴力匹配算法 KMP算法 普通模式匹配（BF）算法 普通模式匹配算法，其实现过程没有任何技巧，就是简单粗暴地拿一个串同另一个串中的字符一一比对，得到最终结果。 例如，使用普通模式匹配算法判断串 A（\"abcac\"）是否为串 B（\"ababcabacabab\"）子串的判断过程如下： int function(char* str1,char* str2){ //主串str1，子串str2，暴力匹配 if(!str1||!str2) //字符串不存在 return -1; int i=0,j=0,k=0; while(str1[i]!='\\0'&&str2[j]!='\\0'){ //两个字符串都没有到末尾} if(str1[i]==str2[j]){ ++i; ++j; } else{ k++; i=k; j=0; } } if(str2[j]=='\\0') return i-strlen(str2)+1; //返回子串在主串中的位置 else return -1; } 该算法最理想的时间复杂度 O(n)，n 表示串 A 的长度，即第一次匹配就成功。 ​ BF 算法最坏情况的时间复杂度为 O(n*m) KMP算法 KMP算法：在一个文本串 S 内查找一个模式串 P 的出现位置 假设S匹配到了i位置，P匹配到了j位置 原来的普通匹配算法是如果有不匹配的情况：j 回到第一个位置，i 倒退为k+1。 KMP算法的改进：j 回到了 next[j] 的位置 i要么不变，要么加一 求next数组 首先理解前缀和后缀： next[i] 是前i-1个字符的前缀和后缀匹配的长度的最大值 尝试做一点例子： 模式串 A A B A B A B B 下标 0 1 2 3 4 5 6 7 最长前后缀 0 0 0 1 2 3 4 -1 next值 -1 -1 0 0 1 2 3 4 模式串 A B C S A B C D 顺序 i 0 1 2 3 4 5 6 7 最长前后缀 j 0 0 0 0 1 2 3 0 next值 -1 0 0 0 0 1 2 3 模式串 A B A B C A B C 顺序 0 1 2 3 4 5 6 7 最长前后缀 0 0 1 2 0 1 2 0 next值 -1 0 0 1 2 0 1 2 next[i]的值等于已经匹配过的字符串的子串 Q 的最长匹配的前后缀的长度加1 算法流程 初始化：next[0] = -1; 从第一个字符开始遍历字串 i = 0，一个数用来记录当前匹配的前后缀的长度 j =-1； 开始遍历模式串，即开始循环 while( i 如果 j == -1 或者 next[i] == next [j] ，说明下一个索引 (i+1) 的next数组的值已经确定，为 next[i+1] = j+1; 否则回溯，重新确定下一个索引 (i + 1）的值： j = next[j] 代码： void Next(char* T,int * next){ next[0] = -1; int i=0,j=-1; while(i 理解next数组怎么来的就应该会kmp算法了： int KMP(char const*S, char const*T) { int i = -1,j = -1; int next[20]; mknext(T, next); int S_len, T_len; S_len = strlen(S); T_len = strlen(T); while (i = T_len) return i - T_len; else return -1; } 练手题 删除串 S1 中所有 S2 子串 int function(char* str1,char* str2){ //主串str1，子串str2，暴力匹配 if(!str1||!str2) return -1; int i=0,j=0,k=0; while(str1[i]!='\\0'&&str2[j]!='\\0'){ //两个字符串都没有到末尾} if(str1[i]==str2[j]){ ++i; ++j; } else{ k++; i=k; j=0; } } if(str2[j]=='\\0') return i-strlen(str2)+1; //返回子串在主串中的位置 else return -1; } void delete(char* str1,int i,int length){ //删除子串 if(!str1) return; int j; for(j=i;str1[j]!='\\0';++j) //一个一个替代 str1[j] = str1[j+length]; str1[j] = '\\0'; //末尾变成\\0 } int main(){ char str1[100],str2[20]; printf(\"Enter str1,str2:\\n\"); scanf(\"%s\",str1); scanf(\"%s\",str2); int length = strlen(str2); int i = function(str1,str2); while(i!=-1){ //找到所有子串并删除； delete(str1,i,length); i = function(str1,str2); } printf(\"result:%s\",str1); } 求 S1 和 S2 的最长公共子串 #include #include #include int match(char* str1,char* str2){ //判断str2是不是str1的子串 if(!str1||!str2) return -1; int i=0,j=0,k=0; while(str1[i]!='\\0'&&str2[j]!='\\0'){ if(str1[i]==str2[j]){ i++; j++; } else{ k++; i = k; j = 0; } } if(str2[j]=='\\0') return i-strlen(str2); else return -1; } int main(){ char s1[100],s2[100],s3[100]; //s1和s2字符串,s3保存子串 printf(\"enter s1,s2:\\n\"); scanf(\"%s%s\",s1,s2); int i,j,len; for(len=strlen(s2);len>0;--len){ //子串的长度 for(i=0;i+len 求串 S 中出现的第一个最长重复子串 int match(char* s1,char* s2,int len){ //判断s1和s2是否相等 if(!s1||!s2) return 0; for(int i=0;i0;--len){ //所有长度的子串 for(i=0;i+len 求串 S 中最长单词的位置和长度 void longest(char* s,int* max,int* x){ //x，max保存字符串s中最长单词的位置和长度 if(!s) return; int i=0,j=0; while(s[j]!=' ') //j指向第一个空格 ++j; *max = j-i-1; *x = i; while(s[j]!='\\0'){ //i指向前一个空格，j指向后一个空格 if(s[j]==' '){ if(*max 整数转为字符串输出 void longest(char* s,int* max,int* x){ //x，max保存字符串s中最长单词的位置和长度 if(!s) return; int i=0,j=0; while(s[j]!=' '||s[j]!='\\0') ++j; *max = j-i; *x = i; while(s[j]!='\\0'){ if(s[j]==' '){ if(max 统计单词个数 typedef struct word{ char str[100]; //单词 int n; //个数 } int judge(char c){ //判断是否为字符 ; } int search(word* arr,int n,char* s){//判断s是否再arr中 ; } word arr[100]; //假设不超过100个单词 int n = 0; void function(char* str){ char s[100]; int i,j,k; for(i=0;str[i]!='\\0';++i){ for(j=i+1;judge(str[j];++j){ for(int k=i;k "},"dataStructure/simple/排序.html":{"url":"dataStructure/simple/排序.html","title":"排序","keywords":"","body":"排序 [toc] 概念 排序算法 （英语：Sorting algorithm）是一种将一组特定的数据按某种顺序进行排列的算法。排序算法多种多样，性质也大多不同。 稳定性 稳定性是指相等的元素经过排序之后相对顺序是否发生了改变。 基数排序、计数排序、插入排序、冒泡排序、归并排序是稳定排序。 选择排序、堆排序、快速排序不是稳定排序。 时间复杂度 选择排序 选择排序（Selection sort）是排序算法的一种，它的工作原理是每次找出第 $i$ 小的元素，然后将这个元素与数组第 $i$ 个位置上的元素交换。 由于 swap（交换两个元素）操作的存在，选择排序是一个不稳定排序。选择排序的时间复杂度为 $O(n^2)$ void selection_sort(int* a, int n) { //选择排序 for (int i=0;i 冒泡排序 冒泡排序（英语：Bubble Sort）是一种简单的排序算法。由于在算法的执行过程中，较小的元素像是气泡般慢慢「浮」到数列的顶端，故叫做冒泡排序。 它的工作原理是每次检查相邻两个元素，如果前面的元素与后面的元素满足给定的排序条件，就将相邻两个元素交换。当没有相邻的元素需要交换时，排序就完成了。 经过 $i$ 次扫描后，数列的末尾 $i$ 项必然是最大的 $i$ 项，因此冒泡排序最多需要扫描 $n-1$ 遍数组就能完成排序。 冒泡排序是一种稳定的排序方法。时间复杂度为 $O(n^2)$ void bubble_sort(int *a, int n){ //冒泡排序 int flag = 1; //flag等于1表示序列尚未排完 while(flag){ //尚未排完的情况 flag = 0; for (int i=0;ia[i+1]){ flag = 1; //存在前一个数比后一个大的情况 int t = a[i]; a[i] = a[i+1]; a[i+1] = t; } } } } 插入排序 插入排序（Insertion Sort）是一种简单直观的排序算法。它的工作原理为将待排列元素划分为“已排序”和“未排序”两部分，每次从“未排序的”元素中选择一个插入到“已排序的”元素中的正确位置。 一个与插入排序相同的操作是打扑克牌时，从牌桌上抓一张牌，按牌面大小插到手牌后，再抓下一张牌。 插入排序是一个稳定排序，时间复杂度为 $O(n^2)$，最优时间复杂度为 $O(n)$ void insertion_sort(int* a, int n){ //插入排序 for (int i=1;i=0&&a[j]>key){ //从后往前找到插入的位置 a[j+1] = a[j]; --j; } a[j+1] = key; } } 快速排序 快速排序（英语：Quicksort），又称分区交换排序（partition-exchange sort），简称快排，是一种被广泛运用的排序算法。 原理 快速排序的工作原理是通过 分治 的方式来将一个数组排序。 快速排序分为三个过程： 将数列划分为两部分（要求保证相对大小关系）； 递归到两个子序列中分别进行快速排序； 不用合并，因为此时数列已经完全有序。 快速排序是一种不稳定的排序方法，快速排序的最佳时间复杂度和平均时间复杂度为 $O(n*logn)$，最坏时间复杂度为 $O(n)$ void quick_sort(int* arr,int left,int right){ //快速排序 if(left>=right) //结束条件 return; int i=left,j=right,temp=arr[left]; while(itemp) --j; arr[i] = arr[j]; while(i 归并排序 归并排序是一种采用了 分治 思想的排序算法。 归并排序分为三个过程： 将数列划分为两部分（在均匀划分时时间复杂度为 ）； 递归地分别对两个子序列进行归并排序； 合并两个子序列。 "},"dataStructure/simple/树.html":{"url":"dataStructure/simple/树.html","title":"树","keywords":"","body":"树 树基础 树定义 树(Tree)是n个结点的有限集。 在任意一棵非空树中： 有且仅有一个特定的称为根(Root)的结点 当n > 1时，其余结点可以分为m(m > 0)个互不相交的有限集T1, T2,…,Tm,其中每一个集合本身又是一棵树，并且称为树的子树(SubTree) 由上可以看出，树的定义本身是递归定义的。 树基础概念 结点拥有的子树数称为结点的度 度为0的结点称为叶子或终端结点 树的度是树内各结点的度的最大值 树中结点的最大层次称为树的深度或高度 森林是m(m>0)棵互不相交的树的集合。 对树中每个结点而言，其子树的集合为森林。 森林和树相互递归地定义来描述树 一棵N个结点的树有N-1条边(因为除了root，其它结点都经由一条边出去) 结点的分类 结点：树的结点包含一个数据元素和若干指向其子树的分支。 结点的度（Degree）：结点拥有的子树。 叶子结点（Leaf）/终端结点：度为0的结点。 分支结点/非终端结点：度不为0的结点。 内部结点：除根节点以外，分支结点也称为内部结点。 树的度：树内各结点的度的最大值。 结点之间的关系 孩子（Child）和双亲（Parent）：结点的子树的根，相应的，该结点称为孩子的双亲。（注意是双亲，不是单亲） 兄弟（sibling）：同一个双亲的孩子之间互称兄弟。 结点的祖先：从根结点到该结点所经过分支上的所有结点。 子孙：以某结点为根的子树中的任一结点都称为该节点的子孙。 无序树和有序树：如果将树中结点的各子树看成从左至右是有次序的，不能互换的，则称该数为有序树，否则为无序树。 森林(fores):m(m>=0)棵互不相交的树的集合。 任意的树都可以用儿子(一个结点指向第一个儿子)、兄弟(另一个结点指向下一个兄弟)表示法将其转变成二叉树 树 二叉树 森林 三者之间的转换 可能是一个考点 二叉树 二叉树，首先它是一棵树，它的特定是每个结点至多只有两颗子树(即二叉树中不存在度大于2的结点)。并且，二叉树的子树有左右之分，其次序不能任意颠倒。 二叉树的性质 在二叉树的第i层至多有2^(i-1)个结点(归纳法) 深度为k的二叉树至多有2^k -1 个结点(公式) 对任何一棵二叉树T，如果其终端结点数为n0，度为2的节点数为n2，则n0 = n2 + 1 i 结点的左子树 2i， 右子树 2i+1 假设一棵二叉树有 N 个结点，度为0 ，1，2的结点数目为 n0，n1，n2 ​ N = n0+n1+n2 然后树有一个特点：N 个结点有 n-1条边 所以，N-1 = n1 + 2 n2 $\\rightarrow$ n0+n1+n2-1 = n1 + 2n2$\\rightarrow$ n0 = n2 + 1 这个可能是个证明题 一棵深度为k且有$2^k-1$个结点的二叉树称为满二叉树 深度为k，有n个结点的二叉树，当且仅当其每一个结点都与深度为k的满二叉树编号从1至n的结点一一对应时，称之为完全二叉树 完全二叉树的性质 n 个结点的完全二叉树的深度为 ⌊log2n⌋+1 当 i>1 时，父亲结点为结点 [i/2] 。（i=1 时，表示的是根结点，无父亲结点） 如果 2i>n（总结点的个数） ，则结点 i 肯定没有左孩子（为叶子结点）；否则其左孩子是结点 2i 如果 2i+1>n ，则结点 i 肯定没有右孩子；否则右孩子是结点 2i+1 树的存储 对于存储结构，可能会联想到前面的顺序存储和链式存储结构。但是对于数这种可能会有很多孩子的特殊数据结构，只用顺序存储结构或者链式存储结构很那实现，那么可以将这两者结合，产生主要的三种存储结构表示法：双亲表示法、孩子表示法、孩子兄弟表示法。 双亲表示法 假设以一组连续空间存储数的结点，同时在每个结点中，附设一个指示器指示其双亲结点到链表中的位置 双亲表示的结点结构 data(数据域) parent(指针域) 存储结点的数据信息 存储该结点的双亲所在数组中的下标 /* 树的双亲表法结点结构定义*/ #define MAX_TREE_SIZE 100 typedef int ElemeType; typedef struct PTNode{ // 结点结构 ElemeType data; //结点数据 int parent; // 双亲位置 }PTNode; typedef struct { // 树结构 PTNode nodes[MAX_TREE_SIZE]; // 结点数组 int r; // 根的位置 int n; // 结点数 }PTree; typedef struct node{ char data; int parent; }node; node [100]; 双亲表示法的特点 由于根结点是没有双亲的，约定根结点的位置位置域为-1. 根据结点的parent指针很容易找到它的双亲结点。所用时间复杂度为O(1)，直到parent为-1时，表示找到了树结点的根。 缺点：如果要找到孩子结点，需要遍历整个结构才行。 孩子表示法 把每个结点的孩子结点排列起来，以单链表作为存储结构，则n个结点有n个孩子链表，如果是叶子结点则此单链表为空。然后n个头指针又组成一个线性表，采用顺序存储结构，存放进一个一维数组中。 typedef struct node{ int child; struct node* next; }node; typedef struct TNode{ char data; node* next; }TNode; TNode[10]; 孩子表示法有两种结点结构：孩子链表的孩子结点和表头数组的表头结点 孩子链表的孩子结点 child(数据域) next(指针域) 存储某个结点在表头数组中的下标 存储指向某结点的下一个孩子结点的指针 表头数组的表头结点 data(数据域) firstchild(头指针域) 存储某个结点的数据信息 存储该结点的孩子链表的头指针 /* 树的孩子表示法结构定义*/ #define MAX_TREE_SIZE 100 typedef int ElemeType; typedef struct CTNode{ // 孩子结点 int child; // 孩子结点的下标 struct CTNode * next; // 指向下一结点的指针 }*ChildPtr; typedef struct { // 表头结构 ElemeType data; // 存放在数中的结点数据 ChildPtr firstchild; // 指向第一个孩子的指针 }CTBox; typedef struct { // 树结构 CTBox nodes[MAX_TREE_SIZE]; // 结点数组 int r; // 根的位置 int n; // 结点树 }CTree; 双亲孩子表示法定义 对于孩子表示法，查找某个结点的某个孩子，或者找某个结点的兄弟，只需要查找这个结点的孩子单链表即可。但是当要寻找某个结点的双亲时，就不是那么方便了。所以可以将双亲表示法和孩子表示法结合，形成双亲孩子表示法。 头节点 typedef struct node{ //结点存储结构 int child; struct node* next; }node; typedef struct TNode{ //头节点存储结构 char data; int parent; node* firstChild; }TNode; TNode[10]; /* 树的双亲孩子表示法结构定义*/ #define MAX_TREE_SIZE 100 typedef int ElemeType; typedef struct CTNode{ // 孩子结点 int child; // 孩子结点的下标 struct CTNode * next; // 指向下一结点的指针 }*ChildPtr; typedef struct { // 表头结构 ElemeType data; // 存放在数中的结点数据 int parent; // 存放双亲的下标 ChildPtr firstchild; // 指向第一个孩子的指针 }CTBox; typedef struct { // 树结构 CTBox nodes[MAX_TREE_SIZE]; // 结点数组 int r; // 根的位置 int n; // 结点树 }CTree; 孩子兄弟表示法 任意一棵树，它的结点的第一个孩子如果存在就是唯一的，它的右兄弟存在也是唯一的。因此，设置两个指针，分别指向该结点的第一个孩子和此结点的右兄弟。 孩子兄弟表示法的结点结构 data(数据域) firstchild(指针域) rightsib(指针域) 存储结点的数据信息 存储该结点的第一个孩子的存储地址 存储该结点的右兄弟结点的存储地址 /* 树的孩子兄弟表示法结构定义*/ #define MAX_TREE_SIZE 100 typedef int ElemeType; typedef struct CSNode{ ElemeType data; struct CSNode * firstchild; struct CSNode * rightsib; }CSNode, *CSTree; 二叉树的存储 二叉树有两种存储结构：顺序存储和链式存储 顺序存储 二叉树的顺序存储，指的是使用顺序表（数组）存储二叉树。需要注意的是，顺序存储只适用于完全二叉树。换句话说，只有完全二叉树才可以使用顺序表存储。因此，如果我们想顺序存储普通二叉树，需要提前将普通二叉树转化为完全二叉树。 普通二叉树转完全二叉树的方法很简单，只需给二叉树额外添加一些节点，将其\"拼凑\"成完全二叉树即可 1 2 0 3 0 0 0 完全二叉树的顺序存储，仅需从根节点开始，按照层次依次将树中节点存储到数组即可 由此，我们就实现了完全二叉树的顺序存储。 不仅如此，从顺序表中还原完全二叉树也很简单。我们知道，完全二叉树具有这样的性质，将树中节点按照层次并从左到右依次标号（1,2,3,...），若节点 i 有左右孩子，则其左孩子节点为 2i，右孩子节点为 2i+1。此性质可用于还原数组中存储的完全二叉树 。 链式存储 其实二叉树并不适合用数组存储，其实二叉树并不适合用数组存储，因为并不是每个二叉树都是完全二叉树，普通二叉树使用顺序表存储或多或多会存在空间浪费的现象。 因此，有了二叉树的链式存储 用链式存储二叉树时，其节点结构由 3 部分构成： typedef struct node{ //树结点存储结构 int data; struct node* Lchild,* Rchild; }node; node 和 Node 区别在哪？ node* T; struct node* T = node* T = Node T Node T; struct node* T; int t1,*t2; 这时候的有啥区别？ t1是个整型的变量，t2是个int型的指针 node t1,*t2; t2 = &t1;//t2指向了t1 t1 t2有啥区别？ t1是个结点，t2是个node型的指针 t1.data;t2->data; 指向左孩子节点的指针（Lchild）； 节点存储的数据（data）； 指向右孩子节点的指针（Rchild）； #define TElemType int typedef struct BiTNode{ TElemType data;//数据域 struct BiTNode *lchild,*rchild;//左右孩子指针 }BiTNode; . -> BiTree a; BiTNoe* a; //根据一个数组，将其转变为一棵二叉树 arr[i] = *(arr+i) node* transform(node* root,int* arr,int n,int i){ //根据数组初始化一颗二叉树 if(!root||!arr||i>=n) return 0; root = (node*)malloc(sizeof(node)); root->data = arr[i]; root->left = transform(root->left,arr,n,i*2+1); root->right = transform(root->right,arr,n,i*2+2); return root; } 初始化1： node* init(node* r){ //初始化二叉树 if(!r) return 0; r = (node*)malloc(sizeof(node)); printf(\"Enter data:\\n\"); scanf(\" %c\",&r->data); //输入该结点的数据 int judge; printf(\"是否输入左结点(0为否)：\\n\"); scanf(\"%d\",&judge); if(judge) r->left = init(r->left); else r->left = 0; printf(\"是否输入右节点(0为否)：\\n\"); scanf(\"%d\",&judge); if(judge) r->right = init(r->right); else r->right = 0; return r; } 初始化2： node* init2(char* arr,int n,node* r,int i){ //完全二叉树的序列构建二叉树 if(!arr||!r||nn) //结束条件 return 0; r = (node*)malloc(sizeof(node)); r->data = arr[i-1]; r->left = init2(arr,n,r->left,2*i); r->right = init2(arr,n,r->right,2*i+1); return r; } 树的遍历 二叉树是一种非常重要的数据结构，很多其它数据结构都是基于二叉树的基础演变而来的。对于二叉树，有深度优先遍历和广度优先遍历，深度遍历有前序、中序以及后序三种遍历方法，广度遍历即我们平常所说的层次遍历。因为树的定义本身就是递归定义，因此采用递归的方法去实现树的三种遍历不仅容易理解而且代码很简洁，而对于广度遍历来说，需要其他数据结构的支撑，比如堆和队列。 四种主要的遍历思想为： 前序遍历：根结点 ---> 左子树 ---> 右子树 中序遍历：左子树---> 根结点 ---> 右子树 后序遍历：左子树 ---> 右子树 ---> 根结点 层次遍历：只需按层次遍历即可 前序遍历 递归写法: void preOrder(node* r){ //先序遍历输出 if(!r) return; printf(\"%c -- \",r->data); //输出根，可换成其它操作 preOrder(r->left); preOrder(r->right); } 金字塔，而递归的底层实现依靠的是栈的存储结构，因此，二叉树的先序遍历既可以直接采用递归思想实现，也可以使用栈的存储结构模拟递归的思想实现. 计算机里面有一种虚拟栈的东西来记录着递归运行到了哪一步。 非递归的第一种写法： void preOrder2(node* r){ //先序遍历，非递归的写法 if(!r) return; node* stack[maxsize],*temp; //初始化栈 int top = -1; stack[++top] = r; //入栈 while(top!=-1){ temp = stack[top--]; printf(\"%c -- \",temp->data); // 输出操作，可以换 if(temp->right) //右结点先入栈 stack[++top] = temp->right; if(temp->left) stack[++top] = temp->left; } } 非递归的第二种写法： void preOrder3(node* r){ //先序遍历，非递归的第二种写法 if(!r) return; node* stack[maxsize],*temp = r; //栈 int top = -1; while(temp||top!=-1){ //栈非空或者temp存在 if(temp){ //根存在 printf(\"%c -- \",temp->data); stack[++top] = temp; temp = temp->left; } else{ temp = stack[top--]; temp = temp->right; } } } 中序遍历 递归写法： void inOrder(node* r){ //中序遍历，递归写法 if(!r) return; inOrder(r->left); printf(\"%c -- \",r->data); inOrder(r->right); } 中序遍历过程中，只需将每个结点的左子树压栈即可，右子树不需要压栈。当结点的左子树遍历完成后，只需要以栈顶结点的右孩子为根结点，继续循环遍历即可。 非递归写法： void inOrder2(node* r){ //中序遍历，非递归写法 if(!r) return; node* stack[maxsize],*temp = r; //栈 int top = -1; while(temp||top!=-1){ if(temp){ //temp 不为空，则将其入栈并遍历左子树 stack[++top] = temp; temp = temp->left; } else{ //temp 为空，表面左子树遍历完成，开始遍历上一层结点的右子树 temp = stack[top--]; printf(\"%c -- \",temp->data); temp = temp->right; } } } 后序遍历 递归写法： void postOrder(node* r){ //后序遍历 if(!r) return; postOrder(r->left); postOrder(r->right); printf(\"%c -- \",r->data); } 前序遍历：根结点 ---> 左子树 ---> 右子树 后序遍历：左子树 ---> 右子树 ---> 根结点 把后序遍历看成 根->右子树->左子树，前序遍历和后序遍历的左右刚好反过来。 非递归写法： void postOrder2(node* r){ //后序遍历，非递归实现 if(!r) return; node* stack1[maxsize],* stack2[maxsize],* temp = r; //需要两个栈 int top1 = -1,top2 = -1; while(top1!=-1||temp){ while(temp){ stack2[++top2] = temp; stack1[++top1] = temp; temp = temp->right; } if(top1!=-1){ temp = stack1[top1--]; temp = temp->left; } } while(top2!=-1) printf(\"%c -- \",stack2[top2--]->data); } 层次遍历 层次遍历：按照二叉树中的层次从左到右依次遍历每层中的结点。具体的实现思路是：通过使用队列的数据结构，从树的根结点开始，依次将其左孩子和右孩子入队。而后每次队列中一个结点出队，都将其左孩子和右孩子入队，直到树中所有结点都出队，出队结点的先后顺序就是层次遍历的最终结果。 void hierOrder(node* r){ //层次遍历 if(!r) return; node* queue[maxsize],*temp; //初始化一个队列 int front = 0,rear = 0; queue[++rear] = r; //把根节点入队 while(front!=rear){ //队列不空 front = (front+1)%maxsize; temp = queue[front]; printf(\"%c -- \",temp->data); if(temp->left){ rear = (rear+1)%maxsize; queue[rear] = temp->left; } if(temp->right){ rear = (rear+1)%maxsize; queue[++rear] = temp->right; } } } void funct(int * arr, int len) 赫夫曼树 基础 路径：在一棵树中，一个结点到另一个结点之间的通路，称为路径 路径长度：在一条路径中，每经过一个结点，路径长度都要加 1 。例如在一棵树中，规定根结点所在层数为1层，那么从根结点到第 i 层结点的路径长度为 i - 1 结点的权：给每一个结点赋予一个新的数值，被称为这个结点的权 结点的带权路径长度：指的是从根结点到该结点之间的路径长度与该结点的权的乘积 树的带权路径长度为树中所有叶子结点的带权路径长度之和。通常记作 “WPL WPL = 7 1 + 5 2 + 2 3 + 4 3 = 35 哈夫曼编码：a:0 b 10 c110 d111 赫夫曼树：当用 n 个结点（都做叶子结点且都有各自的权值）试图构建一棵树时，如果构建的这棵树的带权路径长度最小，称这棵树为“最优二叉树”，有时也叫“赫夫曼树”或者“哈夫曼树”。 在构建哈弗曼树时，要使树的带权路径长度最小，只需要遵循一个原则，那就是：权重越大的结点离树根越近 构建赫夫曼树： 在 n 个权值中选出两个最小的权值，对应的两个结点组成一个新的二叉树，且新二叉树的根结点的权值为左右孩子权值的和； 在原有的 n 个权值中删除那两个最小的权值，同时将新的权值加入到 n–2 个权值的行列中，以此类推； 重复 1 和 2 ，直到所以的结点构建成了一棵二叉树为止，这棵树就是哈夫曼树。 构建哈夫曼树 构建一个结点数组，每次从结点数组中选择两个结点，构建成一个新的子树，添加进数组中，n-1次这样的操作过后就只剩下 一个根节点了 n个结点要多少次这样操作能够构建出哈夫曼树？ n-1次 for(int i=1;i 哈夫曼树的编码 // 递归进行哈夫曼编码 void HuffmanCode(node* hufmTree, int depth) // depth是哈夫曼树的深度 { static int code[10]; if (hufmTree) { if (hufmTree->left==0 && hufmTree->right==0) { printf(\"权值为%d的叶子结点的哈夫曼编码为 \",hufmTree->data); int i; for (i=0; ileft, depth+1); code[depth] = 1; //往右走 HuffmanCode(hufmTree->right, depth+1); } } } 1120 1 1*10+1 11*10 + 2 112*10 +0 森林 树 二叉树 练手题 先序序列和中序序列构建一棵二叉树： typedef struct node{ //树结点结构 char data; struct node* lchild,*rchild; }node; node* function(char* str1,char* str2,int n){ //先序序列str1和后序序列str2构建一棵二叉树 if(!str1||!str2||ndata = str1[0]; root->lchild = 0; root->rchild = 0; int i; for(i=0;str2[i]!='\\0';i++) if(str2[i]==str1[0]) break; root->lchild = function(str1+1,str2,i); root->rchild = function(str1+i+1,str2+i+1,n-i-1); return root; } typedef struct node{ //二叉树结点存储结构 char data; struct node* left,* right; }node; node* init(char* str1,char* str2,int n){ //先序序列str1与后序序列str2构建一个二叉树 if(!str2||!str2||ndata = str1[0]; char temp = str1[0]; int i; for(i=0;str2[i]!='\\0';++i) //找到中序序列根节点的下标 if(str2[i]==temp) break; root->left = init(str1+1,str2,i); //构建左子树 root->right = init(str1+i+1,str2+i+1,n-i-1); //构建右子树 return root; } 假设一棵 Huffman 树 T 有 n 个叶子结点，那么树有多少个结点 算法思想：假设n个叶子节点的权值都为1，初始化一个数组，把它当作一个队列，每次出队两个结点，构建一个二叉树再入队，当队列中只剩下一个结点，就构建出了一棵哈夫曼树，并求出其结点个数 typedef struct node{ int judge char data; struct node* lchild,*rchild; }node; int sum(node* root){ //求二叉树有多少个结点 if(!root) return 0; return sum(root->lchild)+sum(root->rchild)+1; } int main(){ node arr[50]; //假设叶子结点不超过50个 int n; printf(\"Enter n:\\n\"); scanf(\"%d\",&n); for(int i=0;i 前序序列和后序序列可以判定N1必定是N2的祖先 算法思想：先构建出二叉树来，分别前序遍历和后序遍历二叉树，如果满足前序遍历中N1先出现，后序遍历中N2先出现，则可以判定N1是N2的祖先 typedef struct node{ //结点结构 int data; struct node* lchild,* rchild; }node; node* creat(node* root){ //构建二叉树 root = (node*)malloc(sizeof(node)); //初始化根 int i; scanf(\"%d\",&i); root->data = i; int judge; printf(\"%d 的左子树？\",i); scanf(\"%d\",&judge); if(judge) //是否继续构建左子树 root->lchild = creat(root->lchild); else root->lchild = 0; printf(\"%d 的右子树？\",i); scanf(\"%d\",&judge); if(judge) //是否继续构建右子树 root->rchild = creat(root->rchild); else root->rchild = 0; return root; } int tag1=0,tag2=0; void preOrder(node* root,int N1,int N2){ //前序遍历判断N1是否先出现 if(!root) //结束条件 return; if(root->data==N1) //先出现N1 tag1 = 1; else if(root->data==N2) tag1 = 2; return; preOrder(root->lchild,N1,N2); preOrder(root->rchild,N1,N2); } void postOrder(node* root,int N1,int N2){ if(!root) return; postOrder(root->lchild,N1,N2); postOrder(root->rchild,N1,N2); if(root->data==N1) tag2 = 1; else if(root->data==N2) tag2 = 2; return; } int main(){ node* root = creat(root); int N1,N2; printf(\"Enter N1,N2：\\n\"); scanf(\"%d%d\",&N1,&N2); if(tag1==2&&tag2==1) //标记情况 printf(\"yes\"); else printf(\"no\"); } 试证明：已知二叉树的前序序列和中序序列，可唯一确定二叉树 证明： ​ 假设前序序列是pre，后序序列是pin，结点个数为n，则 当n=1时，二叉树的根节点为就为序列中的唯一的数； 当n>=2时，令pre的第一个结点为 temp，tem就为二叉树的根节点的值，再pin中找到temp的下标i，i前面的数都是二叉树的左子树的节点，i 后面的数都是二叉树的右子树的结点，在pre中找到接着找 i个数与pin构建出二叉树数的左子树，pre和pin的最后 n-i-1 个数可以构建出二叉树的右子树； 综上所述，已知前序序列和后序序列可唯一确定该二叉树。 "},"dataStructure/simple/图.html":{"url":"dataStructure/simple/图.html","title":"图","keywords":"","body":"图 图的基本概念 图是一种多对多的数据结构，所以我们可以把图抽象为一种由点（vertex)和边（edge）组成的网络。 我们先来看下面两幅图：同构 点和点是邻接，点和边关联 有向图和无向图 权重 路径/最短路径 路径分两个东西：1，中间要经过哪些点，2.路径的长度 连通图/连通分量 树是一种特殊的图 最小生成树 无根树 树是一种任意两点之间都连通且没有环的图 根、节点、叶、度、层、深度、高度、祖先、后代、森林··· 图的构建 存啥：点和边 一维数组就可以存储点，二维数组 图的存储方式有两种：邻接矩阵与邻接表 邻接矩阵 typedef struct //定义图结构 temp i,j,k { int n,e; //顶点数、边数 char vex[maxsize]; //一维数组保存顶点 int edge[maxsize][maxsize]; //二维数组保存边 }gragh; 邻接矩阵：两个数组来表示图，一个一维数组表示顶点（vertex），一个二维数组表示边（edge） 出度和入度 二维数组，行的非零数加起来就是出度，列的非零数加起来就是入度 邻接表 typedef struct node //结点 { int adjvex; //下标 int weight; //权重 struct node *next; //指针 }node; typedef struct //头结点 { char vex; //data域 node* next; //指针 }vexNode; typedef struct //图 { int n,e; //顶点数，边数 vexNode adjlist[maxsize]; //一维数组保存顶点 }graph; 邻接表：对于边数较少的图，邻接矩阵是一种极大的浪费，所以有了邻接表。用一维数组存储顶点（vertex），单链表表示边（edge） 图构建的需要考虑处理字符串 考虑自己的源数据是什么，如果是一张图，转为字符串，如果是字符串，按照字符串的格式读取即可（字符串的基本操作），如果是文件格式（文件的基本操作），则一行一行的读取成字符串，并存储到计算机中。 图构建好以后我们能够进行一些基本操作：图的遍历(DFS、BFS)、读取顶点的出入度、输出目标顶点的邻接点、判断图是否是连通图··· 高级操作：最短路径算法（Dijkstra、Floyd）、最小生成树（Kruskal、Prim）··· 图的遍历 图的遍历有两种：深度优先搜索（DFS, depth first search）和广度优先搜索（BFS, breadth first search） 深度优先遍历（DFS) 深度优先遍历：是从图中的一个顶点出发，每次遍历当前访问顶点的邻接点，一直到访问的顶点没有未被访问过的临界点为止。然后采用依次回退的方式，查看来的路上每一个顶点是否有其它未被访问的邻接点。深度优先搜索是一个不断回溯的过程。 深度优先搜索的过程类似于树的先序遍历，即这是一个递归的函数。 void DFS(gragh *g,int v,int *visit) //DFS深度遍历 { if(visit[v]==1) return; //递归结束条件 visit[v] = 1; printf(\"%c--\",g->vex[v]); //打印结点，可以换成其它操作 for(int i=0;in;++i) { if(g->edge[v][i]==1&&visit[i]==0) DFS(g,i,visit); } } 广度优先搜索（BFS) 广度优先搜索：从图中的某一顶点出发，遍历每一个顶点时，依次遍历其所有的邻接点，然后再从这些邻接点出发，同样依次访问它们的邻接点。按照此过程，直到图中所有被访问过的顶点的邻接点都被访问到。 广度优先搜索类似于树的层次遍历。 void BFS(gragh *g,int v,int *visit) //BFS遍历 { int length=g->n,temp,i; int queue[10]; //借助队列，一层一层的遍历 int front=0,rear=0; queue[rear++] = v; visit[v] = 1; //每次入队的时候赋值为1 while(front!=rear) //队列中还有值 { temp = queue[front]; //出队列 front = (++front)%length; printf(\"%c--\",g->vex[temp]); //可以换成其它操作 for(i=0;in;++i) { if(visit[i]==0&&g->edge[temp][i]==1) { queue[rear] = i; //入队 rear = (++rear)%length; visit[i] = 1; } } } } 很多题都是对图或者树的遍历，然后遍历的时候不是对它的输出，而是在遍历的时候做其它操作了。 最短路径算法 什么叫最短路径？ 最短路径问题是图论研究中的一个经典算法问题，旨在寻找图中两顶点之间的最短路径。算法具体的形式包括： 确定起点的最短路径问题 - 即已知起始结点，求最短路径的问题。 就是两个顶点之间最快的那条路径和该路径的长度。 这是一个抽象的东西，你会怎么保存路径和路径长度？ 一个数组可以保存路径，一个变量就可以保存路径长度了。 最短路径算法有：迪杰斯特拉（Dijkstra）、弗洛伊德（Floyd） 迪杰斯特拉算法 Dijkstra是一种单源最短路径算法，使用类似于广度优先搜索的方法解决赋权图的单源最短路径问题，不可以处理负权图。 S到各点的距离与 SC + C到各点的距离 之比 S到各点的距离与 SD + D到各点的距离 之比 Dijkstra算法的算法思想是： 设G=(V,E)是一个带权图，把图中顶点集合V分成两组，第一组为已求出最短路径的顶点集合（用S表示，初始时S中只有一个源点，以后每求得一条最短路径 , 就将加入到集合S中，直到全部顶点都加入到S中，算法就结束了），第二组为其余未确定最短路径的顶点集合（用U表示），按最短路径长度的递增次序依次把第二组的顶点加入S中。 在加入的过程中，总保持从源点v到S中各顶点的最短路径长度不大于从源点v到U中任何顶点的最短路径长度。 此外，每个顶点对应一个距离，S中的顶点的距离就是从v到此顶点的最短路径长度，U中的顶点的距离，是从v到此顶点只包括S中的顶点为中间顶点的当前最短路径长度。 代码流程： 一个顶点数组vset来判断该点是否已经采集；一个数组dist来存储S到U各个点的最短路径长度（为了选择出距离S的最短的点），选择点后数组要更新；一个数组path来保存路径，选择点后数组要更新，初始化三个数组 每次得到一个从未选择的点集合中选择距离最短的那个点 更新dist数组和path数组 循环2，3步，直到所有点选择完 void Dijkstra(gragh *g,int v,int *dist,int *path) //Dijkstra算法 { int vset[maxsize]; //确定点是否选择 int i,j,k,min=__INT_MAX__; for(i=0;in;++i) //初始化 { vset[i] = 0; dist[i] = min; path[i] = -1; if(g->edge[v][i]!=0) { dist[i] = g->edge[v][i]; path[i] = v; } } vset[v] = 1; dist[v] = 0; for(i=0;in-1;++i) //n-1个点一个个进去 { min = __INT_MAX__; for(j=0;jn;++j) if(vset[j]==0&&dist[j]n;++j) if(vset[j]==0&&g->edge[k][j]!=0&&dist[k]+g->edge[k][j]edge[k][j]; } } } 弗洛伊德算法 Floyd算法是一个多源最短路径的算法，得到任意两点之间的最短路径，可处理负权图。 Floyd的算法思想是： 从任意节点i到任意节点j的最短路径不外乎2种可能，1是直接从i到j，2是从i经过若干个节点k到j。所以，我们假设Dis(i,j)为节点u到节点v的最短路径的距离，对于每一个节点k，我们检查Dis(i,k) + Dis(k,j) 邻接矩阵 A B C D E F A 0 6 2 2 3 $\\infty$ B 6 0 $\\infty$ $\\infty$ 3 2 C 2 $\\infty$ 0 1 2 2 D 2 $\\infty$ 1 0 2 $\\infty$ E 3 3 2 2 0 2 F $\\infty$ 2 2 $\\infty$ 2 0 A B C D E F A 0 6 2 2 3 $\\infty$ B 6 0 4 5 3 2 C 2 $\\infty$ 0 1 2 2 D 2 $\\infty$ 1 0 2 $\\infty$ E 3 3 2 2 0 2 F $\\infty$ 2 2 $\\infty$ 2 0 path数组path数组 A B C D E F A -1 -1 -1 -1 -1 -1 B -1 -1 -1 -1 -1 -1 C -1 -1 -1 -1 -1 -1 D -1 -1 -1 -1 -1 -1 E -1 -1 -1 -1 -1 -1 F -1 -1 -1 -1 -1 -1 void Floyd(gragh *g,int path[][maxsize]) { int i,j,k,a[maxsize][maxsize],max=__INT_MAX__; for(i=0;in;++i) for(j=0;jn;++j) { a[i][j] = g->edge[i][j]; if(g->edge[i][j]==0) a[i][j] = max; path[i][j] = -1; } for(k=0;kn;++k) for(i=0;in;++i) for(j=0;jn;++j) if(a[i][j]>a[i][k]+a[k][j]) { a[i][j] = a[i][k]+a[k][j]; path[i][j] = k; } } 最小生成树 我们定义无向连通图的 最小生成树 （Minimum Spanning Tree，MST）为边权和最小的生成树。 注意：只有连通图才有生成树，而对于非连通图，只存在生成森林。 树基础 一个没有固定根结点的树称为 无根树 （unrooted tree）。 无根树有几种等价的形式化定义： 有$n$个结点 ，$n-1$条边的连通无向图 无向无环的连通图 任意两个结点之间有且仅有一条简单路径的无向图 任何边均为桥的连通图 没有圈，且在任意不同两点间添加一条边之后所得图含唯一的一个圈的图 树定义： 森林（forest） ：每个连通分量（连通块）都是树的图。按照定义，一棵树也是森林。 生成树（spanning tree） ：一个连通无向图的生成子图，同时要求是树。也即在图的边集中选择 条，将所有顶点连通。 结点的深度（depth） ：到根结点的路径上的边数。 树的高度（height） ：所有结点的深度的最大值。 无根树的叶结点（leaf node） ：度数不超过1的结点。 有根树的叶结点（leaf node） ：没有子结点的结点。 有根树 父亲（parent node） ：对于除根以外的每个结点，定义为从该结点到根路径上的第二个结点。 根结点没有父结点。 祖先（ancestor） ：一个结点到根结点的路径上，除了它本身外的结点。 根结点的祖先集合为空。 子结点（child node） ：如果 是 的父亲，那么 是 的子结点。 子结点的顺序一般不加以区分，二叉树是一个例外。 兄弟（sibling） ：同一个父亲的多个子结点互为兄弟。 后代（descendant） ：子结点和子结点的后代。 或者理解成：如果 是 的祖先，那么 是 的后代。 子树（subtree） ：删掉与父亲相连的边后，该结点所在的子图。 特殊的树 完整二叉树（full/proper binary tree） ：每个结点的子结点数量均为 0 或者 2 的二叉树。换言之，每个结点或者是树叶，或者左右子树均非空。 完全二叉树（complete binary tree） ：只有最下面两层结点的度数可以小于 2，且最下面一层的结点都集中在该层最左边的连续位置上。 完美二叉树（perfect binary tree） ：所有叶结点的深度均相同的二叉树称为完美二叉树。 Prim算法 基本思想：从一个顶点开始，不断的加点，加n-1个点。 Prim算法：从任意一个结点开始，将结点分成两类：已加入的，未加入的。每次从未加入的结点中，找一个与已加入的结点之间边权最小值最小的结点。然后将这个结点加入，并连上那条边权最小的边。重复n-1次即可。 证明 证明：还是说明在每一步，都存在一棵最小生成树包含已选边集。 基础：只有一个结点的时候，显然成立。 归纳：如果某一步成立，当前边集为 F，属于T这棵 MST，接下来要加入边e。如果 e属于T，那么成立。否则考虑 T+e 中环上另一条可以加入当前边集的边 f 。 首先，f 的权值一定不小于 e 的权值，否则就会选择 f 而不是 e 了。然后，f 的权值一定不大于 e 的权值，否则 T+e-f 就是一棵更小的生成树了。因此， f 和 e 的权值相等， T+e-f 也是一棵最小生成树，且包含了 f 。 代码流程 一个顶点数组vset来判断该点是否已经采集；一个数组dist来存储S到U各个点的最短路径长度（为了选择出距离S的最短的点），选择点后数组要更新 每次得到一个从未选择的点集合中选择距离最短的那个点 更新dist数组 循环2，3步，直到所有点选择完 char* prim(gragh *g,int v,int *sum) //prim算法，返回最小生成树的边的字符串和总权值 { char *result = (char*)malloc(sizeof(char)*maxsize);int now = 0; //假设100的空间够 int i,j,k,vset[maxsize],lowcost[maxsize],min=__INT_MAX__; //vset确定点是否已被纳入树，lowcost确定当前树到其它点的最小值 for(i=0;in;++i) //初始化 { vset[i] = 0; lowcost[i] = min; if(g->edge[v][i]!=0) lowcost[i] = g->edge[v][i]; } vset[v] = 1; for(i=0;in-1;++i) { min = __INT_MAX__; for(j=0;jn;++j) if(vset[j]==0&&lowcost[j]vex[v]; for(j=0;jvex[k]; for(j=0;jn;++j) //更新lowcost数组 if(vset[j]==0&&g->edge[v][j]!=0&&g->edge[v][j]edge[v][j]; } result[now] = '\\0'; return result; } Kruskal算法 基本思想：从最短的边开始，从小到大找到n-1条不形成环的边。 思路：思路很简单，为了造出一棵最小生成树，我们从最小边权的边开始，按边权从小到大依次加入，如果某次加边产生了环，就扔掉这条边，直到加入了n-1 条边，即形成了一棵树。 证明 证明：使用归纳法，证明任何时候 K 算法选择的边集都被某棵 MST 所包含。 基础：对于算法刚开始时，显然成立（最小生成树存在）。 归纳：假设某时刻成立，当前边集为 F ，令 T 为这棵 MST，考虑下一条加入的边 e 。 如果 e 属于 T，那么成立。 否则， T+e 一定存在一个环，考虑这个环上不属于 F 的另一条边 f （一定只有一条）。 首先，f 的权值一定不会比 e 小，不然 f 会在 e 之前被选取。然后，f 的权值一定不会比 e 大，不然 T+e-f 就是一棵比 T 还优的生成树了。所以，f 的权值等于 e， T+e-f 包含了 f ，并且也是一棵最小生成树，归纳成立。 前置知识 图的存储，在kruskal算法中，由于需要将边按边权排序，需要直接存边。 并查集来判断两点是否属于同一个集合 初始化每个点，将它们的父亲设为自己，当需要将两个点（或集合）合并时，只需要修改它们的父亲，使得一个点为这个集合中所有点的父亲，如果两个点父亲相同，就说明它们在一个集合中。 快速排序 排序算法多种多样 ，性质也大多不同。我们需要关注三个性质：稳定性、时间复杂度、空间复杂度。 排序算法有：选择排序、冒泡排序、插入排序、快速排序、归并排序··· 快速排序是分治地将一个数组排序。 代码过程： 将数列划分为两部分（不是直接分，要求保证相对大小关系） 递归到两个子序列中分别进行快速排序 不用合并，因为此时数列已经完全有序 void quickSort(int* arr,int left,int right){ //快速排序 if(!arr||left>=right) //结束条件 return; int i = left,j = right,value = arr[left]; while(i=value) --j; swag(&arr[i],&arr[j]); //swag是交换两个位置的值 while(i 并查集 并查集是一种树形的数据结构，顾名思义，它用于处理一些不交集的 合并 及 查询 问题。 它支持两种操作： 查找（Find）：确定某个元素处于哪个子集； 合并（Union）：将两个子集合并成一个集合。 初始化 void makeSet(int size) { for (int i = 0; i 查找 通俗地讲一个故事：几个家族进行宴会，但是家族普遍长寿，所以人数众多。由于长时间的分离以及年龄的增长，这些人逐渐忘掉了自己的亲人，只记得自己的爸爸是谁了，而最长者（称为「祖先」）的父亲已经去世，他只知道自己是祖先。为了确定自己是哪个家族，他们想出了一个办法，只要问自己的爸爸是不是祖先，一层一层的向上问，直到问到祖先。如果要判断两人是否在同一家族，只要看两人的祖先是不是同一人就可以了。 在这样的思想下，并查集的查找算法诞生了。 int fa[MAXN]; // 记录某个人的爸爸是谁，特别规定，祖先的爸爸是他自己 int find(int x) { // 寻找x的祖先 if (fa[x] == x) // 如果x是祖先则返回 return x; else return find(fa[x]); // 如果不是则x的爸爸问x的爷爷 } 合并 递归：A B 1 2 3 4 5 6 1 2 3 4 5 6 1 2 3 4 5 6 path 0 1 2 3 4 5 1 2 3 4 5 6 2 2 3 4 6 6 2 6 3 4 6 6 -1 0 0 0 0 2 线段树 关键路径 拓扑排序 宴会上，一个家族的祖先突然对另一个家族说：我们两个家族交情这么好，不如合成一家好了。另一个家族也欣然接受了。我们之前说过，并不在意祖先究竟是谁，所以只要其中一个祖先变成另一个祖先的儿子就可以了。 void unionSet(int x, int y) { // x 与 y 所在家族合并 x = find(x); y = find(y); if (x == y) // 原本就在一个家族里就不管了 return; fa[x] = y; // 把 x 的祖先变成 y 的祖先的儿子 } 代码流程 新建边集数组，快速排序边集数组 初始化一个并查集，然后逐个增加边 增加边的时候判断边的两个顶点是否是一个祖先，如果不是，则这俩点就加入result，并且将这两个点合并 char * kruskal(gragh *g,road *r,int *sum) //kruskal算法，返回路径和权值和 { char *result = (char*)malloc(sizeof(char)*maxsize);int now = 0; //存储路径，假设100的空间够 int i,j,a,b; int vex[6]; //并查集的初始化 for(i=0;in;++i) vex[i] = i; for(i=0;in-1;++i) { a = getroot(r[i].pre,vex); b = getroot(r[i].next,vex); if(a!=b) //不是一个祖先 { result[now++] = g->vex[r[i].pre]; for(j=0;jvex[r[i].next]; for(j=0;j 拓扑排序 拓扑排序的英文名是 Topological sorting。 AOV图， 拓扑排序要解决的问题是给一个AOV图的所有节点排序。 AOV网 定义：在一个表示工程的有向图中，用顶点表示活动，用弧表示活动之间的优先关系，这样的有向图为顶点表示活动的网，我们成为AOV网（Activity On Vertex Network）,AOV网中的弧表示活动之间的某种约束关系。AOV网中不存在回路（即无环的有向图）。 拓扑排序 如果从 u 到 v 有边（u，v），则认为 v 依赖于 u 。如果 u 到 v 有路径（ 可达 ），则称 v 间接依赖于 u 。 在一个有向无环图中，我们将图中的顶点以线性方式进行排序，使得对于任何的顶点 u 到 v 的有向边 （u，v） , 都可以有 u 在 v 的前面。 拓扑排序的目标是将所有节点排序，使得排在前面的节点不能依赖于排在后面的节点。 代码流程 将入度为0的点组成一个集合S 每次从S中取出一个结点 u 放入 L，然后遍历顶点 u 的所有边，并删除，判断该边的另一个顶点，如果在移除这条边之后该顶点的入度变成 0，那么就将这个顶点放入 S 中，不断重复此操作 当 S 集合为空之后，判断图中是否还有任何点，如果有，则这个图肯定有环路，否则就返回 L， L就是拓扑排序的结果 int ToPoSort(gragh* g){ //拓扑排序，如果没有环则返回true if(!g) return 0; int count = 0,temp; //count用于计数 int* stack = (int*)malloc(sizeof(int)*g->n),top=0; //栈 int* v_in = (int*)malloc(sizeof(int)*g->n); //保存每个点的入度 for(int i=0;in;++i){ //初始化数组 int in = 0; //入度 for(int j=0;jn;++j) if(g->edge[j][i]!=0) //行列 对应 出入 ++in; v_in[i] = in; //保存该点的入度 if(!in) { stack[top++] = i; //该点入度为0就入栈 --v_in[i]; //将该点变为-1，不再使用 } } while(top!=0){ //栈不空的情况 temp = stack[--top]; //出栈 printf(\"%c--\",g->arc[temp]); ++count; for(int j=0;jn;++j){ if(g->edge[temp][j]!=0) //有边，减少边顶点的一个入度 --v_in[j]; if(v_in[j]==0){ //现在度为0了，更新栈 stack[top++] = j; //入栈 --v_in[j]; } } } if(count n) /*如果count小于顶点数，说明存在环*/ return 0; else return 1; } 关键路径 关键路径针对的是和 AOV 网相近的 AOE 网。 AOE 网 AOE 网是在 AOV 网的基础上，其中每一个边都具有各自的权值，是一个有向无环网。其中权值表示活动持续的时间。 如果将 AOE 网看做整个项目，那么完成整个项目至少需要多少时间？ 解决这个问题的关键在于从 AOE 网中找到一条从起始点到结束点长度最长的路径，这样就能保证所有的活动在结束之前都能完成。 起始点是入度为 0 的点，称为“源点”；结束点是出度为 0 的点，称为“汇点”。这条最长的路径，被称为”关键路径“。 基础 为了求出一个给定 AOE 网的关键路径，需要知道以下 4 个统计数据： 对于 AOE 网中的顶点有两个时间：最早发生时间（用 Ve(j) 表示）和最晚发生时间（用 Vl(j) 表示）； 对于边来说，也有两个时间：最早开始时间（用 e(i) 表示）和最晚开始时间（ l(i) 表示）。 Ve(j)：对于 AOE 网中的任意一个顶点来说，从源点到该点的最长路径代表着该顶点的最早发生时间，通常用 Ve(j) 表示。 Vl(j)：表示在不推迟整个工期的前提下，事件 Vk 允许的最晚发生时间。 e(i)：表示活动 ai 的最早开始时间，如果活动 ai 是由弧 表示的，那么活动 ai 的最早开始的时间就等于时间 Vk 的最早发生时间，也就是说：e[i] = ve[k]。 l(i)：表示活动 ai 的最晚开始时间，如果活动 ai 是由弧 表示，ai 的最晚开始时间的设定要保证 Vj 的最晚发生时间不拖后。所以，l[i]=Vl[j]-len。 在得知以上四种统计数据后，就可以直接求得 AOE 网中关键路径上的所有的关键活动，方法是：对于所有的边来说，如果它的最早开始时间等于最晚开始时间，称这条边所代表的活动为关键活动。由关键活动构成的路径为关键路径。 关键路径的过程 四种统计信息的准备工作 通过对比 l(i) 和 e(i)，得到关键路径，如果 l(i) = e(i),说明这条边是关键路径的一条弧 Ve（j） V1 V2 V3 V4 V5 V6 V7 V8 V9 0 6 4 5 7 7 16 14 18 Vl（j） V1 V2 V3 V4 V5 V6 V7 V8 V9 2 6 6 8 7 10 16 14 18 e(i) a1 a2 a3 a4 a5 a6 a7 a8 a9 a10 a11 0 0 0 6 4 5 7 7 7 16 14 l(i) a1 a2 a3 a4 a5 a6 a7 a8 a9 a10 a11 0 2 3 6 6 8 7 7 10 16 14 比对结果：a1 a4 a7 a8 a10 a11 总结 图的概念 图（G(V,E))、相邻（关联和邻接）、度数、路径、子图、连通、稀疏图/稠密图、特殊的图··· 图的存储 邻接矩阵、邻接表 邻接矩阵 复杂度：查询是否存在某条边： O(1) ​ 遍历一个点的所有出边: O(n) ​ 遍历整张图：$O(n^2)$ ​ 空间复杂度：$O(n^2)$ 应用：邻接矩阵只适用于没有重边（或重边可以忽略）的情况。 ​ 其最显著的优点是可以 O(1) 查询一条边是否存在。 ​ 由于邻接矩阵在稀疏图上效率很低（尤其是在点数较多的图上，空间无法承受），所以一般只会在稠密图上使用邻接矩阵。 邻接表 复杂度：查询是否存在某条边： $O(d^+(u))$ ​ 遍历一个点的所有出边: $O(d^+(u))$ ​ 遍历整张图：$O(n+m)$ ​ 空间复杂度：$O(m)$ 应用：存各种图都很适合，除非有特殊需求（如需要快速查询一条边是否存在，且点数较少，可以使用邻接矩阵）。 ​ 尤其适用于需要对一个点的所有出边进行排序的场合。 图的遍历 DFS与BFS，这两种都是对图的遍历，但是除了对图的遍历之外，用途完全不同 DFS DFS最显著的特征就是递归调用自身，大致结构如下 DFS(v) // v 可以是图中的一个顶点，也可以是抽象的概念，如 dp 状态等。 在 v 上打访问标记 for u in v 的相邻节点 if u 没有打过访问标记 then DFS(u) end end end 时间复杂度 $O(n+m)$,空间复杂度$O(m)$,在 DFS 过程中，通过记录每个节点从哪个点访问而来，可以建立一个树结构，称为 DFS 树。DFS 树是原图的一个生成树。 BFS BFS每次都尝试访问同一层的节点。 如果同一层都访问完了，再访问下一层，这样到达的每个顶点的路径都是边数最少的路径。BFS需要对队列有一定的熟练度。 大致结构如下： while (队列不为空) { int u = 队首; 弹出队首; for (枚举 u 的邻居) { 更新数据 if (...) 添加到队首; else 添加到队尾; } } 时间复杂度 $O(n+m)$,空间复杂度$O(m)$，应用很多，BFS比DFS难，用处也更多 最短路径 Dijkstra算法和Floyd算法，单源最短路径，多源最短路径 Floyd算法 Digkstra算法 每对结点之间的最短路 单源最短路 没有负环的图 非负权图 $O(n^3)$ $O(mlog(m))$ 最小生成树 无向连通图的 最小生成树 （Minimum Spanning Tree，MST）为边权和最小的生成树。 Prim算法和Kruskal算法，重点是掌握这些算法之后去解决问题 拓扑排序和关键路径 掌握，关键路径应该不会要求代码，拓扑排序也要掌握代码 "},"dataStructure/simple/递归.html":{"url":"dataStructure/simple/递归.html","title":"递归","keywords":"","body":"递归的理解 递归的概念 什么是递归? 是指在函数的定义中使用函数自身的方法。 在数学和计算机科学中，递归指由一种（或多种）简单的基本情况定义的一类对象或方法，并规定其他所有情况都能被还原为其基本情况。 Google递归的时候，是不是突然懂了什么:smiley: Google 递归 简单地说，就是如果在函数中存在着调用函数本身的情况，这种现象就叫递归。 以阶乘函数为例,如下, 在 factorial 函数中存在着 factorial(n – 1) 的调用，所以此函数是递归函数： int factorial(int n){ //阶乘 if(n 进一步剖析「递归」，先有「递」再有「归」，「递」的意思是将问题拆解成子问题来解决， 子问题再拆解成子子问题，…，直到被拆解的子问题无需再拆分成更细的子问题（即可以求解），「归」是说最小的子问题解决了，那么它的上一层子问题也就解决了，上一层的子问题解决了，上上层子问题自然也就解决了,….,直到最开始的问题解决,文字说可能有点抽象。 写递归的步骤 我们在上一节仔细剖析了什么是递归，可以发现递归有以下两个特点 int sum = 0; for(int i = 0; i 100) return 0; return i + sum(i+1); } 一个问题可以分解成具有相同解决思路的子问题，子子问题，换句话说这些问题都能调用同一个函数 从 F(n) F(n-1) ··· F(1) 都能调用同一个函数 经过层层分解的子问题最后一定是有一个不能再分解的固定值的（即终止条件）,如果没有的话,就无穷无尽地分解子问题了，问题显然是无解的。 有终止条件 所以解递归题的关键在于我们首先需要根据以上递归的两个特点判断题目是否可以用递归来解。 步骤： 确定递归函数的功能 参数，返回值 确定递归的结束条件 需要注意一下 确定F(n)与F(n-1)、F(n-2)等等之间的关系， 或者是可以说：寻找问题与子问题间的关系（即递推公式），这样由于问题与子问题具有相同解决思路，只要子问题调用步骤 1 定义好的函数，问题即可解决。所谓的关系最好能用一个公式表示出来，比如 f(n) = n * f(n-1) 这样 它可能是 F(n) 与 F(n-1)有关系，也可能是 F(n) 与 F(n-2) 有关系，也可能是 F(n) 与 F(n-1)、F(n-2)等等 都有关系 开始练题（从初级到高级 阶乘 输入一个正整数n，输出n!的值。其中n!=123…n,即求阶乘 确定递归函数的功能 int function(int n); //传入参数n，求n! 确定递归的结束条件 //第一种结束条件 if(n==1) return n; //第二种结束条件 if(n 确定F(n) = n! 与F(n-1) = (n-1)!、F(n-2)等等之间的关系 F(n) = n * F(n-1); //显然这里的关系是F(n)与F(n-1)之间有关系 return n*function(n-1); 三步走完，基本就可以写出递归的函数了 这里我们已经对阶乘尝试了一种递归的写法，我们来看看循环是什么样的，比较一下两种写法： //递归写法 int function1(int n){ //传入参数n，求n! if(n 递归逻辑很清楚，它寻找的是与F(n-1)、F(n-2)等等之间的关系，循环（迭代）是每一次做同样的一个步骤。在电脑运行过程种，递归都会创建一个类似于栈的东西。 入栈，不断缩小参数范围，直到结束条件 出栈，得到比自己参数大的函数的值 斐波拉契 1 1 2 3 5 ··· n 确定递归函数的功能 int function1(int n); //求第n个的fib数是多少 结束条件 if(n==1||n==2) //结束条件 return 1; 确定F(n)与F(n-1)、F(n-2)等等之间的关系 function1(n) = function1(n-1)+function1(n-2); 故递归写法为： int function1(int n) //求第n个的fib数是多少 { if(n==1||n==2) //结束条件 return 1; return function1(n-1)+function1(n-2); //函数关系 } 台阶问题 一只青蛙可以一次跳 1 级台阶或一次跳 2 级台阶,例如:跳上第 1 级台阶只有一种跳法：直接跳 1 级即可。跳上第 2 级台阶有两种跳法：每次跳 1 级，跳两次；或者一次跳 2 级。问要跳上第 n 级台阶有多少种跳法？ 找关系： n 级别台阶 func(n-1) + func (n-2) 确定递归函数的功能 int function(int n); //n个台阶，求种类 确定结束条件 if (n == 1) return1; //一级台阶的情况 if (n == 2) return2; //二级台阶的情况 确定F(n)与F(n-1)、F(n-2)等等之间的关系 寻找问题与子问题之前的关系 这两者之前的关系初看确实看不出什么头绪，但仔细看题目，一只青蛙只能跳一步或两步台阶，自上而下地思考，也就是说如果要跳到 n 级台阶只能从 从 n-1 或 n-2 级跳， 所以问题就转化为跳上 n-1 和 n-2 级台阶的跳法了，如果 f(n) 代表跳到 n 级台阶的跳法，那么从以上分析可得 f(n) = f(n-1) + f(n-2),显然这就是我们要找的问题与子问题的关系,而显然当 n = 1, n = 2， 即跳一二级台阶是问题的最终解，于是递推公式系为 f(n) = f(n-1) + f(n-2); 三步走完，我们就可以写出递归函数了 int f(int n) { if (n == 1) return 1; if (n == 2) return 2; return f(n-1) + f(n-2); } 二叉树的深度 int func(node* root) { if(!root) return; return func(root-left) > func(root-right)? func(root->left) + 1: func(root-right) + 1; } typedef struct node{ //数结点存储结构 char data; struct node* lchild,*rchild; }node; 确定递归函数的功能 int function(node* root); //传进一个二叉树，返回其深度 确定结束条件 if(!root) return 0; 确定F(n)与F(n-1)、F(n-2)等等之间的关系 因为这是一颗二叉树，没有F(N)，但是有F(root) ，我们这时候就应该判断 F(root) 与 F(root->lchild) 和 F(root->rchild) 之间的关系，显然其关系是根的深度等于左右子树的最大深度加一 F(root) = MAX(F(root->lchild) , F(root->rchild) ) + 1; F(root) = MAX(F(root->lchild), F(root->rchild)) + 1; 故函数可以写为： int function(node* root){ if(!root) return; int left = function(root->lchild); int right = function(root->rchild); return left>right?left:right + 1; } 反转二叉树 反转二叉树 将左边的二叉树反转成右边的二叉树 反转1 void func(node* root) { if(!root) return; // 结束条件 int temp = root->left->data; root-left->data = root->right->data; root->right->data = temp; func(root-left); func(root->right); } 反转2 确定递归函数的功能 node* function(node* root); //传进一棵二叉树，反转二叉树 确定结束条件 if(!root) return root; 确定F(n)与F(n-1)、F(n-2)等等之间的关系 因为这是一颗二叉树，没有F(N)，但是有F(root) ，我们这时候就应该判断 F(root) 与 F(root->lchild) 和 F(root->rchild) 之间的关系 ，显然其关系是左子树和右子树先进行翻转，翻转过后在将左右子树交换 node* left = function(root->lchild); node* right = funciton(root->rchild); root->lchild = right; root->rchild = left; 故函数可写为： node* function(node* root){ //传进一棵二叉树，反转二叉树 if(!root) return root; root->lchild = function(root->rchild); root->rchild = function(root->lchild); } 汉诺塔问题 如下图所示，从左到右有A、B、C三根柱子，其中A柱子上面有从小叠到大的n个圆盘，现要求将A柱子上的圆盘移到C柱子上去，期间只有一个原则：一次只能移到一个盘子且大盘子不能在小盘子上面，求移动的步骤和移动的次数 关系： func(n-1, a, c, b); ​ printf(\"%c => %c\", a, c); ​ func(n-1,b, a, c); 确定函数功能 int count = 0; int function(int n,char a,char b,char c)//汉诺塔，将n个盘子借助b从a移动到c 确定结束条件 if(n==0) //结束条件 return 0; 确定关系 function(n-1,a,c,b); printf(\"%c移到%c\\n\",a,c); ++count; function(n-1,b,a,c); return count; 递归函数： void function(int n,char a,char b,char c){ //汉诺塔，将n个盘子借助b从a移动到c if(n==0) //结束条件 return 0; function(n-1,a,c,b); printf(\"%c移到%c\\n\",a,c); ++count; function(n-1,b,a,c); } 确定递归函数的功能 有三个柱子，我们要把三个柱子都要传进来，怎么代表柱子，三个字符 'A' 'B' 'C' 是不是就可以了，然后还有多少个盘子对不对，所以还有一个 n void hanoid(int n, char a, char b, char c); //汉诺塔 确定结束条件 if (n 确定F(n)与F(n-1)、F(n-2)等等之间的关系 F(n)的意思是将 n 个圆盘从 a 经由 b 移动到 c ，是不是过程是：1.先将 n-1 个圆盘从 a 经由 c 移动到 b ，2. 再将 第 n 个圆盘从 a 移到 c 3. 再将 n-1个圆盘从 b 经由 a 移到 c 而移动的话就是输出一行语句就行了 void move(char a, char b) { //表示将a移动到b printf(\"%c->%cn\", a, b); } void hanoid(int n, char a, char b, char c){ //汉诺塔 if (n 从函数的功能上看其实比较容易理解，整个函数定义的功能就是把 A 上的 n 个圆盘 经由 B 移到 C，由于定义好了这个函数的功能，那么接下来的把 n-1 个圆盘 经由 C 移到 B 就可以很自然的调用这个函数,所以明确函数的功能非常重要,按着函数的功能来解释，递归问题其实很好解析，切忌在每一个子问题上层层展开死抠,这样这就陷入了递归的陷阱，计算机都会栈溢出，何况人脑 树的个数 int sum(node* root){ //返回树的个数 if(!root) //结束 return 0; return sum(root->lchild)+sum(root->rchild)+1; } 树的深度 int depth(node* root){ //返回树的深度 if(!root) return 0; int left = depth(root->lchild); int right = depth(root->rchild); return left>right?left:right + 1; } 树的叶子节点的个数 int* count = (int*)malloc(sizeof(int)); *count = 0; void function(node* root,int* count){ //计算叶节点的个数 if(!root) return; if(root->lchild==null&&root->richild==null) ++(*count); function(root->lchild,count); function(root->rchild,count); } int count(node *root) { if(!root) return 0; if(root-left == null && root-right == null) return 1; return count(root->left) + count(root->right); } 输出树 void function(node* root){ //输出树 if(!root) return; printf(\"%c--\",root->data); function(root->lchild); function(root->rchil); } 总结 1，2 步注意一下，3步是难点，仔细的考虑其逻辑关系，不要死扣，一些比较复杂的递归题需要勤动手，画画图，观察规律，这样能帮助我们快速发现规律，得出递归公式，一旦知道了递归公式，将其转成递归代码就容易多了 编码就是多练，多想，最后解决问题。 考试就是熟能生巧的事了 "},"font/深入理解 ES6.html":{"url":"font/深入理解 ES6.html","title":"深入理解 ES6","keywords":"","body":"深入理解 ES6 块级作用域绑定 var 声明及变量提升（Hoisting）机制 块级声明：let 声明、禁止重声明、const 声明 临时死区（TDZ） 循环中作用域绑定 循环中的函数 循环中的 let 声明 循环中的 const 声明 全局作用域绑定 最佳实践 "},"font/React.html":{"url":"font/React.html","title":"React","keywords":"","body":"React consept [toc] Introducing JSX A syntax extension to JavaScript. Rendering Elements An element describes what you want to see on the screen. Conponents and Props function components function Welcome(props) { return Hello, {props.name}; } class components class Welcome extends React.Component { render() { return Hello, {this.props.name}; } } Always start component names with a capital letter. All React components must act like pure functions with respect to their props. State and LifeCycle State is similar to props, but it is private and fully controlled by the component. convert a function component: create an ES6 class with the same name that extends React.Component. Add a simgle empty method to it called render() Move the body into the render Replace props with this.props in the render() body Delete empty function delaration The render method will be called cach time an update happens, but as long as we rendering. Class components should always call the base constructor with props. In applications with many components, it's very important to free up resources taken by the components when they are destroyed. Do not modify state directly, instead use setState() State updates may be asychronous // Wrong this.setState({ counter: this.state.counter + this.props.increment, }) // Correct this.setState((state, props) => { counter: state.counter + props.increment, }) The data flows down. State is not accessible to any component other than the one that owns and sets it, a component may choose to apss its state down as props to its child components. If you imagine a component tree as a water fall of props, each component's state is like an additional water source that joins it at an arbitrary point but also flows down. Handling Events React events are named using camelCase, rather than lowercase With JSX you pass a function as the event handler, rather than a string preventDefault this: bind, arrow function(In most cases, this is fine, if this callback is passed as a prop to lower components, those components might do an extra re-rendering) this.deleteRow(id, e)}>Delete Row Delete Row Conditional rendering function (if) \\ Element variables \\ logical && operator whenever conditions become too complex, it might be a good time to extrct a component. Lists and keys A component that accepts an array of numbers and outputs a list of elements. function NumberList(props) { const numbers = props.numbers; const listItems = numbers.map((number) => {number} ); return ( {listItems} ); } const numbers = [1, 2, 3, 4, 5]; ReactDOM.render( , document.getElementById('root') ); Keys help React identify which items have changed, are added, or are removed. If you choose not to assign an explicit key to list items then React will default to using indexes as keys, however the order of items may change. Keys only make sense in the context of the surrounding array. Forms Form elements naturally keep some internal state. An input form element whose value is controlled by React in this way is called a \"controlled component\". Lifting state up oftern, several components need to reflect the same changing data. We recommend lifting the shared state up to their closest common ancestor. "},"font/Vue.html":{"url":"font/Vue.html","title":"Vue","keywords":"","body":"Vue 官方教程 [toc] 基础 介绍 vue是什么 有MVVM模式的影响 Vue.js 的核心是一个允许采用简洁的模板语法来声明式地将数据渲染进 DOM 的系统，数据和DOM建立关联，所有的东西都是响应式的 绑定 DOM 文本 v-bind:title 绑定元素的 atribute 处理用户输入 为了交互，v-on 指令添加一个事件监听器，eg： v-on:click v-model 指令，实现表单输入和应用状态之间的双向绑定 条件和循环 v-if 判断条件，不仅可以把数据绑定到 DOM 文本或 attribute，还可以保定到DOM的结构 vue 也提供一个强大的过渡效果系统，可以在vue 插入/更新/删除元素时自动应用过渡效果 v-for 可以绑定数组的数据来渲染一个项目列表 组件化应用 组件系统是 Vue 的另一个重要概念，因为它是一种抽象，允许我们使用小型、独立和通常可复用的组件构建大型应用。 在 Vue 中，组件本质上是一个具有预定义选项的实例。在 Vue 中注册组件很简单：如对 App 对象所做的那样创建一个组件对象，并将其定义在父级组件的 components 选项中 为了将数据从父组件传入子组件，修改一些组件的定义，使之能接受要给prop： app.component('todo-item', { props: ['todo'], template: `{{ todo.text` }) Vue 组件与自定义元素非常类似——它是 Web Components 规范的一部分 它们之间主要的不同在于，Vue 组件的数据模型是作为框架的一部分而设计的，而该框架为构建复杂应用提供了很多必要的附加功能。例如响应式模板和状态管理——这两者都没有被该规范所覆盖。 vue 中涉及的字符串模板和 dom 模板 简书，概念 看官方文档的时候，多次提及字符串模板和 dom 模板，对这个模板比较模糊 字符串模板：字符串模板就是写在 vue 中的 template 中定义的模板，如 .vue 的单文件组件模板和定义组件时 template 属性值的模板。字符串模板不会再页面初始化参与页面的渲染，会被 vue 进行解析编译之后再被浏览器渲染，所以不受限于 html 结构和标签的命名 dom 模板：也称 html 模板，dom 模板就是写在 html 文件中，一打开就会被浏览器进行解析渲染，所以要遵循 html 结构和标签的命名，否则浏览器不解析也就不能获取其内容了 应用&组件实例 创建一个组件实例 每一个vue应用都是通过用 createApp 函数创建一个应用实例开始的 该应用实例是用来在应用中注册全局组件的 应用实例暴露的大多数方法都会返回该同意实例，允许链式 根组件 传递给 createApp 的选项用于配置根组件。当我们挂载应用时，该组件被用作渲染的起点。 与大多数应用方法不同的是，mount 不返回应用本身。相反，它返回的是根组件实例。 组件实例 property 我们认识了 data property。在 data 中定义的 property 是通过组件实例暴露的 还有各种其他的组件选项，可以将用户定义的 property 添加到组件实例中，例如 methods，props，computed，inject 和 setup。我们将在后面的指南中深入讨论它们。组件实例的所有 property，无论如何定义，都可以在组件的模板中访问。 Vue 还通过组件实例暴露了一些内置 property，如 $attrs 和 $emit。这些 property 都有一个 $ 前缀，以避免与用户定义的 property 名冲突 不要在选项 property 或回调上使用箭头函数，比如 created: () => console.log(this.a) 或 vm.$watch('a', newValue => this.myMethod())。因为箭头函数并没有 this，this 会作为变量一直向上级词法作用域查找，直至找到为止，经常导致 Uncaught TypeError: Cannot read property of undefined 或 Uncaught TypeError: this.myMethod is not a function 之类的错误。 生命周期 模板语法 Vue.js 使用了基于 HTML 的模板语法，允许开发者声明式地将 DOM 绑定至底层组件实例的数据。所有 Vue.js 的模板都是合法的 HTML，所以能被遵循规范的浏览器和 HTML 解析器解析。 在底层的实现上，Vue 将模板编译成虚拟 DOM 渲染函数。结合响应性系统，Vue 能够智能地计算出最少需要重新渲染多少组件，并把 DOM 操作次数减到最少。 插值 DOM文本使用 `` 进行查实，也可以通过使用 v-once 指令，你也能执行一次性地插值，当数据改变时，插值处的内容不会更新。但请留心这会影响到该节点上的其它数据绑定 原始HTML 双大括号会将数据解释为普通文本 为了输出真正的 html，需要使用 v-html 这个 span 的内容将会被替换成 property 值直接作为 html——会忽略解析property中的数据绑定 所以说组件更适合作为可重用和可组合的基本单位 Attribute v-bind 绑定 html 的 attribute，如果绑定的值是 null 或 undefined， 那么该attribute 将不会包含在渲染的元素上 对于布尔 attribute (它们只要存在就意味着值为 true) 使用 js 表达式 迄今为止，在我们的模板中，我们一直都只绑定简单的 property 键值。但实际上，对于所有的数据绑定，Vue.js 都提供了完全的 JavaScript 表达式支持。 每个绑定只能包含单个表达式，比如赋值语句就不会生效 指令 指令 (Directives) 是带有 v- 前缀的特殊 attribute。指令 attribute 的值预期是单个 JavaScript 表达式 (v-for 和 v-on 是例外情况，稍后我们再讨论)。指令的职责是，当表达式的值改变时，将其产生的连带影响，响应式地作用于 DOM。 参数 一些指令能够接收一个“参数”，在指令名称之后以冒号表示。例如，v-bind 指令可以用于响应式地更新 HTML attribute： ... 另一个例子是 v-on 指令，它用于监听 DOM 事件： ... 动态参数 也可以在指令参数中使用 JavaScript 表达式，方法是用方括号括起来： ... 这里的 attributeName 会被作为一个 JavaScript 表达式进行动态求值，求得的值将会作为最终的参数来使用。例如，如果你的组件实例有一个 data property attributeName，其值为 \"href\"，那么这个绑定将等价于 v-bind:href。 同样地，你可以使用动态参数为一个动态的事件名绑定处理函数： ... 在这个示例中，当 eventName 的值为 \"focus\" 时，v-on:[eventName] 将等价于 v-on:focus 修饰符 修饰符 (modifier) 是以半角句号 . 指明的特殊后缀，用于指出一个指令应该以特殊方式绑定。例如，.prevent 修饰符告诉 v-on 指令对于触发的事件调用 event.preventDefault()： ... 缩写 v-bind 缩写 ... ... ... v-on 缩写 ... ... ... 注意事项 动态参数预期会求出一个字符串，异常情况下值为 null。这个特殊的 null 值可以被显性地用于移除绑定。任何其它非字符串类型的值都将会触发一个警告 动态参数表达式有一些语法约束，因为某些字符，如空格和引号，放在 HTML attribute 名里是无效的。例如： ... 变通的办法是使用没有空格或引号的表达式，或用计算属性替代这种复杂表达式。 模板表达式都被放在沙盒中，只能访问一个受限的列表，如 Math 和 Date。你不应该在模板表达式中试图访问用户定义的全局变量。在 DOM 中使用模板时 (直接在一个 HTML 文件里撰写模板)，还需要避免使用大写字符来命名键名，因为浏览器会把 attribute 名全部强制转为小写： ... 模板表达式都被放在沙盒中，只能访问一个受限的列表，如 Math 和 Date。你不应该在模板表达式中试图访问用户定义的全局变量。 Data Property 和 方法 Data Property 组件的 data 选项是一个函数。Vue 在创建新组件实例的过程中调用此函数。它应该返回一个对象，然后 Vue 会通过响应性系统将其包裹起来，并以 $data 的形式存储在组件实例中。为方便起见，该对象的任何顶级 property 也直接通过组件实例暴露出来： const app = Vue.createApp({ data() { return { count: 4 } } }) const vm = app.mount('#app') console.log(vm.$data.count) // => 4 console.log(vm.count) // => 4 // 修改 vm.count 的值也会更新 $data.count vm.count = 5 console.log(vm.$data.count) // => 5 // 反之亦然 vm.$data.count = 6 console.log(vm.count) // => 6 这些实例property仅在实例首次创建时被添加，所以你需要确保它们在 data 函数返回的对象中 直接将不包含在 data 中的新 property 添加到组件实例是可行的，但是由于不在背后的响应式 $data 对象中，所以 vue的响应式系统不会自动更新它 方法 我们用 methods 选项向组件实例添加方法，它应该是一个包含所需方法的对象： const app = new Vue.createApp({ data() { return {count: 4} } methods: { increment() { this.count++ } } }) const vm = app.mount('#app') vm.increment() vue 自动为 methods 绑定了 this，以便于它始终指向组件实例，这将确保方法在用作事件监听或者回调时保持正确的this 指向 可以直接从模板调用方法，通常换做计算属性会更好，但是在计算属性不可行的情况下，使用方法可能会很有用 函数防抖和函数节流 函数防抖（debounce）：触发事件后在n秒内函数只能执行一次，如果在n秒内又触发了时间，则会重新计算函数执行时间 函数节流：限制一个函数在一定时间内只能执行一次 函数防抖的应用场景： 搜索框搜索输入。只需用户最后一次输入完，再发送请求 手机号、邮箱验证输入检测 窗口大小Resize。只需窗口调整完成后，计算窗口大小。防止重复渲染。 函数节流的应用场景： 滚动加载，加载更多或滚到底部监听 谷歌搜索框，搜索联想功能 高频点击提交，表单重复提交 函数防抖简单实现，在执行目标方法时，会等待一段时间，当又执行相同方法时，若前一个定时任务未执行完，则 clear 掉定时任务，重新定时 const _.debounce = (func, wait) => { let timer; return () => { clearTimeout(timer) timer = setTimeout(func, wait) } } 函数节流简单实现，是为了限制函数一段时间内只能执行一次。因此，通过使用定时任务，延时方法执行，在延时的时间内，方法若被触发 const _.throttle = (func, wait) => { let timer return () => { if(timer) return } timer = setTimeout(() => { func(); timer = null }, wait) } vue没有内置防抖和节流，可以使用 Lodash 等库实现 计算属性和侦听器 计算属性 computed 模板内的表达式非常遍历，但是设计它们的初衷是用于简单计算的，在模板中放入太多的逻辑会让模板难以维护 所以对于任何包含响应式数据的复杂逻辑，你都应该使用计算属性 Vue.createApp({ data() { return { author: { name: 'Johe Dow', books:['Vue 3 - basic guide'] } } }, computed: { // 计算属性的 getter publishedBooksMessage() { return this.author.books.length > 0 ? 'yes': 'no' } } }) 我们可以将函数定义为一个方法而不是一个计算属性，但是计算属性是基于它们的响应依赖关系缓存的，计算属性只在相关响应式依赖发生改变时它们才会重新求值，比如上例，只要authors.books 没有发生改变，多次访问函数，计算属性会立即返回之前的计算结果，而不必再次执行函数 computed： { now() { return Date.now() // 不再更新 } } 为什么需要缓存？假设我们有一个性能开销大的计算属性 list，它需要遍历一个巨大的数组并做大量的计算，然后我们可能又其它的计算属性依赖于 list， 如果没有缓存，我们将不可避免的多次执行 list 的getter，如果不希望有缓存，用method代替 计算属性默认只有getter，不过在需要时可以提供一个setter // ... computed: { fullName: { // getter get() { return this.firstName + ' ' + this.lastName }, // setter set(newValue) { const names = newValue.split(' ') this.firstName = names[0] this.lastName = names[names.length - 1] } } } 侦听器 虽然计算属性在大多数情况下更合适，但有时需要一个自定义的侦听器，通过 watch 提供一个更通用的方法，来响应数据的变化 当需要在数据变化时执行异步或开销较大的操作时，这个方式是最有用的 ask a yes/no question const watchExampleVM = Vue.createApp({ data() { return { question: '', answer: 'Questions usually contain a question mark. ;-)' } }, watch: { // whenever question changes, this function will run question(newQuestion, old Question) { if(newQuestion.indexOf('?') > -1) this.getAnswer() } }, methods: { getAnswer() { this.answer = 'Thinking...' axios .get('https://yesno.wtf/api') .then(response => { this.answer = response.data.answer }) .catch(error => { this.answer = 'Error ' + error }) } } }).mount('#watch-example') 当你有一些数据需要随着其他数据变动而变动，很容易滥用watch，这时候可能有很多重复代码，更好的做法是使用计算属性而不是watch回调 Class 与 Style 绑定 操作元素的 class 列表和内联样式是数据绑定的一个常见需求。因为它们都是 attribute，所以我们可以用 v-bind 处理它们：只需要通过表达式计算出字符串结果即可。不过，字符串拼接麻烦且易错。因此，在将 v-bind 用于 class 和 style 时，Vue.js 做了专门的增强。表达式结果的类型除了字符串之外，还可以是对象或数组。 data() { return { isActive: true, error: null } }, computed: { classObject() { return { active: this.isActive && !this.error, 'text-danger': this.error && this.error.type === 'fatal' } } } 我们可以把一个数组传给 :class，以应用一个 class 列表： 当你在带有单个根元素的自定义组件上使用 class attribute 时，这些 class 将被添加到该元素中。此元素上的现有 class 将不会被覆盖。 绑定内联样式 data() { return { styleObject: { color: 'red', fontSize: '13px' } } } 可以为 style 绑定中的 property 提供一个包含多个值的数组，常用于提供多个带前缀的值，例如： 条件渲染 v-if 指令用于条件性的渲染一块内容，这块内容只会在指令的表达式返回 truthy 值的时候被渲染 vue 也可以用 v-else 添加一个 else块： test no test 因为 v-if 是一个指令，所以必须将它添加到一个元素上，但是如果想切换多个元素呢？此时可以把一个 元素当作一个不可见的包裹元素，并在上面使用 v-if v-else 元素必须紧跟在 v-if 或者 v-else-if 元素后面，否则它将不会被识别 另一个用于条件渲染的元素是 v-show，不同的是v-show始终会被渲染并被保留在 DOM 中，v-show 只是简单的切换元素的display v-show 不支持 v-if 是“真正”的条件渲染，因为它会确保在切换过程中，条件块内的事件监听器和子组件适当地被销毁和重建。 v-if 也是惰性的：如果在初始渲染时条件为假，则什么也不做——直到条件第一次变为真时，才会开始渲染条件块。 相比之下，v-show 就简单得多——不管初始条件是什么，元素总是会被渲染，并且只是简单地基于 CSS 进行切换。 一般来说，v-if 有更高的切换开销，而 v-show 有更高的初始渲染开销。因此，如果需要非常频繁地切换，则使用 v-show 较好；如果在运行时条件很少改变，则使用 v-if 较好。 不推荐同时使用 v-if 和 v-for 列表渲染 v-for 把一个数组渲染成一组元素 v-for 块中可以访问所有父作用域的property，v-for 还支持一个可选的第二个参数 也可以用 of 替代 in 作为分隔符，这个更接近 JavaScript 迭代器的语法 当 Vue 正在更新使用 v-for 渲染的元素列表时，它默认使用“就地更新”的策略。如果数据项的顺序被改变，Vue 将不会移动 DOM 元素来匹配数据项的顺序，而是就地更新每个元素，并且确保它们在每个索引位置正确渲染。 建议在使用 v-for 时提供 key attribute 有时我们想要显示一个数组经过过滤或者排序后的版本，而不实际变更或重置原始数据，这种情况下，可以创建一个计算属性，来返回过滤或排序后的数组 类似于 v-if，你也可以利用带有 v-for 的 来循环渲染一段包含多个元素的内容 在自定义组件上，你可以像在任何普通元素上一样使用 v-for： 然而，任何数据都不会被自动传递到组件里，因为组件有自己独立的作用域。为了把迭代数据传递到组件里，我们要使用 props： 不自动将 item 注入到组件里的原因是，这会使得组件与 v-for 的运作紧密耦合，明确组件数据的来源能够使组件在其它场合重复使用 Add a todo Add const app = Vue.createApp({ data() { return { newTodoText: '', todos: [ { id: 1, title: 'Do the dishes' }, { id: 2, title: 'Take out the trash' }, { id: 3, title: 'Mow the lawn' } ], nextTodoId: 4 } }, methods: { addNewTodo() { this.todos.push({ id: this.nextTodoId++, title: this.newTodoText }) this.newTodoText = '' } } }) app.component('todo-item', { template: ` Remove `, props: ['title'], emits: ['remove'] }) app.mount('#todo-list-example') 事件处理 我们可以通过 v-on 指令（缩写为 @） 来监听 dom 事件 除了直接绑定到一个方法，也可以在内联 JavaScript 语句中调用方法： Say hi Say what Vue.createApp({ methods: { say(message) { alert(message) } } }).mount('#inline-handler') 有时候需要在内联语句处理器中访问原始的dom事件，可以用特殊变量 $event 把它传入方法 事件处理其中可以有多个方法，这些方法由逗号运算符分隔： Submit 在事件处理程序中调用 event.preventDefault() 或 event.stopPropagation() 是非常常见的需求。尽管我们可以在方法中轻松实现这点，但更好的方式是：方法只有纯粹的数据逻辑，而不是去处理 DOM 事件细节。 为了解决这个问题，Vue.js 为 v-on 提供了事件修饰符。之前提过，修饰符是由点开头的指令后缀来表示的。 .stop .prevent .capture .self .once .passive 使用修饰符时，顺序很重要；相应的代码会以同样的顺序产生。因此，用 v-on:click.prevent.self 会阻止所有的点击，而 v-on:click.self.prevent 只会阻止对元素自身的点击。 按键修饰符 系统修饰符 鼠标按钮修饰符 使用 v-on 或 @ 有几个好处： 扫一眼 HTML 模板便能轻松定位在 JavaScript 代码里对应的方法。 因为你无须在 JavaScript 里手动绑定事件，你的 ViewModel 代码可以是非常纯粹的逻辑，和 DOM 完全解耦，更易于测试。 当一个 ViewModel 被销毁时，所有的事件处理器都会自动被删除。你无须担心如何清理它们。 表单输入绑定 你可以用 v-model 指令在表单 、 及 元素上创建双向数据绑定。它会根据控件类型自动选取正确的方法来更新元素。尽管有些神奇，但 v-model 本质上不过是语法糖。它负责监听用户的输入事件来更新数据，并在某种极端场景下进行一些特殊处理。 复选框 单个复选框，绑定到布尔值 多个复选框，绑定到同一个数组 Jack John Mike Checked names: Vue.createApp({ data() { return { checkedNames: [] } } }).mount('#v-model-multiple-checkboxes') 单选框 One Two Picked: Vue.createApp({ data() { return { picked: '' } } }).mount('#v-model-radiobutton') 选择框 Please select one A B C Selected: Vue.createApp({ data() { return { selected: '' } } }).mount('#v-model-select') 组件基础 组件是带有名称的可复用实例，可以将组件进行任意次的服用 组件有两种注册类型：全局注册和局部注册，全局注册可以在应用中的任何组件的模块中使用 通过prop向子组件传递数据 一个组件默认可以拥有任意数量的 prop，无论任何值都可以传递给 prop，可以使用 v-bind 来动态传递 prop。 监听子组件事件 我们可以在组件的 emits 选项中列出已抛出的事件： app.component('blog-post', { props: ['title'], emits: ['enlargeText'] }) 子组件可以通过内建的 $emit 方法并传入事件名称来触发一个事件 enlarge text 在组件上使用 v-model 等价于 当用在组件上时，v-model 则会这样： 为了让它正常工作，这个组件内的 input 必须： 将其 value attribute 绑定到一个名为 modelValue 的 prop 上 在其 input 事件被触发时，将新的值通过自定义的 update:modelvalue 事件抛出 代码如下： app.component('custom-input', { props: ['modelValue'], emits: ['update:modelValue'], template: ` 现在 v-model 就可以在这个组件上完美的工作起来了 通过插槽分发内容 和 HTML 元素一样，我们经常需要向一个组件传递内容： something bad happened 这可以通过使用 Vue 的自定义 元素来实现 app.component('alert-box', { template:` Error! ` }) 我们使用 作为我们想要插入内容的占位符 动态组件 在不同组件之间进行动态切换是非常有用的，这可以通过 Vue 的 元素加一个特殊的 is attribute 来实现： 解析 DOM 模板时的注意事项 如果想在 DOM直接书写 Vue 模板，Vue 将不得不从 DOM 中获取字符串。这会因为浏览器的原生 HTML 解析行为而导致一些小问题 元素位置受限：有些 HTML 元素，诸如 、、 和 ，对于哪些元素可以出现在其内部是有严格限制的 大小写不敏感：HTML attribute 名不区分大小写，这时候应该使用 - 来命名 深入组件 组件注册 组件名：在注册一个组件的时候，我们始终需要给它一个名字，它就是 app.component 的第一个参数，建议组件名全部小写，如果有多个单词则用连字符符号连接 Vue.component('my-component-name', {...}) 组件名大小写，在定义组件名的方式有两种，一种是连字符（kebab-case），一种是驼峰法（PascalCase），当使用 PascalCase定义一个组件时，你在引用这个自定义元素时两种命名法都可以使用。也就是 和 都可接受。但是在 DOM 中使用时只有 kebab-case 有效 全局注册和局部注册 到目前为止，我们只用过 app.component 来创建组件： Vue.createApp({...}).component('my-component-name', {...}) 这些组件是全局注册的，也就是说它们注册之后可以用在任何新创建的组件实例的模板中 全局注册往往是不够理想的。比如你使用一个像 webpack 这样的构建系统，全局注册所有的组件意味着即便你已经不再使用其中一个组件了，它仍然会被包含在最终的构建结果中，造成代码的无谓增加 在这些情况下，你可以通过一个普通的 JavaScript 对象来定义组件： const app = Vue.createApp({ components: { 'component-a': ComponentA, 'component-b': ComponentB } }) 注意局部注册的组件在其子组件中不可用 模块系统 如果你使用了诸如 Babel 和 webpack 的模块系统，在这些情况下，我们推荐创建一个 components 目录，并将每个组件放置在各自的文件中： import ComponentA from './ComponentA' import ComponentB from './ComponentB' export default{ components: { ComponentA, ComponentB } // ... } Props Prop 类型 目前为止，我们只看到了以字符串数组形式列出的 prop，但是通常希望每个 prop 都有指定的值类型，这时候你可以对象的形式列出 prop： props: { title: String, likes: Number, isPublished: Boolean, commentIds: Array, author: Object, callback: Function, contactsPromise: Promise // 或任何其他构造函数 } 传递静态或动态的 Prop 传入静态的值： 传入动态的值： 传入要给数字，即使数字是静态的，但我们仍需要告诉 Vue 这是一个 JS 表达式，而不是一个字符串： 传入一个布尔值，同数字： 传入一个数组，对象，同数字 如果想要将一个对象的所有 property 都作为 prop 传入，可以使用不带参数的 v-bind： post: { id: 1, title: ',,,' } 等价于： 单向数据流 所有的 prop 都使得其父子 prop 之间形成了一个单向下行绑定：父级 prop 的更新会向下流动到子组件中，但是反过来则不行。这样会防止从子组件意外变更父级组件的状态，从而导致你的应用的数据流动难以理解。 另外，每次父级组件发生变更时，子组件中所有的 prop 都将会刷新为最新的值。这意味着你不应该在一个子组件内部改变 prop 常见的试图变更一个 prop 的情况： 这个 prop 用来传递一个初始值，这个子组件接下来希望将其作为一个本地的 prop 数据来使用，在这种情况下，最好定义一个本地 data property 并将这个 prop 作为其初始值 这个 prop 以一种原始的值传入且需要进行转换。在这种情况下，最好使用这个 prop 的值来计算一个计算属性 prop 验证 我们可以为组件的 prop 只当验证要求： app.component('my-component', { props: { // 基础的类型检查（`null` 和 `undefined` 会通过任何类型的验证 propA: Number, porpB: [String, Number], // 必填的字符串 propC: { type: String, required: true }, // 带有默认值的对象 propE: { type: Object, // 对象和数组的默认值必须从要给工厂函数返回 default() { retrun {message: 'hello'} } }, // 自定义验证函数 propF: { validator(value) { // 这个值必须与下列字符串中的其中一个相匹配 return ['success', 'warning', 'danger'].includes(value) } }, // 具有默认值的函数 propG: { type: Function, default() { return 'Default function' } } }) 非 Prop 的 Attribute 一个非 prop 的 attribute 是指向一个组件，但是该组件并没有相应 props 或 emits 定义 attribute。常见的示例包括 class、style 和 id attribute。可以通过 $property 访问那些 attribute Attribute 继承 当组件返回单个根节点时，非 prop 的 attribute 将自动添加到根节点的 attribute 中。例如，在 date-picker 组件的实例中： app.component('date-picker', { template ` ` }) 如果我们需要通过 data-status attribute 定义 组件的状态，它将应用于根节点 同样的规则也适用于事件监听器 如果你不希望组件的根元素继承 attribute，可以在组件的选项中设置 inheritAttrs: false。禁用 attribute 继承的常见场景是需要将 attribute 应用于根节点之外的其他元素 与单个根节点组件不同，具有多个根节点的组件不具有自动 attribute 行为。如果未显示绑定 $attr，将发出运行时警告 自定义事件并验证 app.component('custom-form', { emits: { // 没有验证 clikc: null, // 验证 submit 事件 submit: ({email, password}) => { if(email && password) { return true } else { console.warn('Invalid submit event payload!') return false } } }, methods: { submitForm(email, password) { this.$emit('submit', {email, password}) } } }) v-model 参数 默认情况下，组件上的 v-model 使用 modelValue 作为 prop 和 update:modelValue 作为事件，我们可以通过向 v-model 传递参数来修改这些名称： 在本例中，子组件将需要一个 title prop 并发出 update:title 事件来进行同步: app.component('my-component', { props: { title: String }, emits: ['update:title'], template: ` 插槽 插槽内容 Vue 实现了一套内容分发的 API，这套 API 的涉及灵感源自 web components 的规范草案，将 元素作为承载分发内容的出口 add to 将会被替换成 ‘add to’ --> add to 除了字符串，插槽还可以包含任何模板代码，包括 HTML 或其它组件，如果 template 中没有包含一个 元素，则该组件和结束标签的任何内容都会被抛弃 渲染作用域 当你想在一个插槽中使用数据时，该插槽可以访问与模板其余部分相同的实例 property（即相同的作用域） 父级模板里的所有内容都是在父级作用域中编译的，子模版里的所有内容都是在子作用域中编译的 备用内容 有时为一个插槽指定备用（也就是默认的）的内容是很有用的，它只会在没有提供内容的时候被渲染，例如： submit 具名插槽 有时我们需要多个插槽，例如对于一个带有如下模板的 的组件： 元素有一个特殊的 attribute：name。通过它可以为不同的插槽分配独立的 ID，也就是能够以此来决定内容应该渲染到什么地方： 一个不带 name 的 出口会带有隐含的名字 default ，，， Provide/Inject 通常，当我们需要从父组件向子组件传递数据时，我们使用 props。想象一下这样的结构，有一些深度嵌套的组件，而深层的子组件只需要父组件的部分内容，在这种情况下，如果仍然将 prop 沿着组件链逐级传递下去，可能会很麻烦 对于这种情况，我们可以使用一对 provide 和 inject。无论组件层次结构有多深，父组件都可以作为其所有子组件的依赖提供者。这个特性有两个部分：父组件有一个 provide 选项来提供数据，子组件有一个 inject 选项来开始使用这些数据 例如，我们有这样的层次结构： Root └─ TodoList ├─ TodoItem └─ TodoListFooter ├─ ClearTodosButton └─ TodoListStatistics 如果要将 todo-items 的长度直接传递给 TodoListStatistics，我们要将 prop 逐级传递下去：TodoList -> TodoListFooter -> TodoListStatistics。通过 provide/inject 的方式，我们可以直接执行以下操作： const app = Vue.createApp({}) app.component('todo-list', { data() { return { todos: ['feed a cat', 'buy tickets'] } }, provide: { user: 'John Doe' }, template: ` ` }) app.component('todo-list-statistics', { inject: ['user'], created() { console.log(this.user) } }) 但是，如果我们尝试在此处 provide 一些组件的实例 property，这将是不起作用的，要访问组件实例 property，我们需要将 provide 转换为返回对象的函数： app.component('todo-list', { data() { return { todos: ['feed a cat', 'bug tickets'] } }, provide() { return { todoLength: this.todos.length } } }) 这使得我们能够更安全地继续开发该组件，而不必单行可能会更改/删除子组件所依赖的某些内容。这些组件之间的接口仍然是明确定义的，就像 prop 一样 实际上，可以将依赖诸如看作是“长距离的prop”，除了： 父组件不需要知道哪些子组将使用了它 provide 的 property 子组件不需要知道 inject 的 property 来自哪里 处理响应式 在上面的例子中，如果我们更改了 todos 的列表，这个变化并不会反映在 inject 的 todoLength property 中。这是因为默认情况下，provide/inject 绑定并不是响应式的。我们可以通过传递一个 ref property 或 reactive 对象给 provide 来改变这种行为。在例子中，如果我们相对祖先中的更改做出响应，我们需要为 provide 的 todolength分配一个组合式 API computed property： app.component('todo-list', { //... provide() { return { todoLength: Vue.computed(() => this.todos.length) } } }) app.component('todo-list-statistics', { inject: ['todoLength'], created() { console.log(`Injected property: ${this.todoLength.value}`) } }) 在这种情况下，任何对 todos.length 的改变都会被正确地反映在诸如 todoLength 的组件中 动态组件 & 异步组件 在动态组将上使用 keep-alive 重新创建一个动态组件的行为通常是非常有用的，但是有些时候我们更希望组件实例能在它们第一次被创建的时候缓存下来，为了解决这个问题，我们可以使用 元素将其动态组件包裹起来 异步组件 在大型应用中，我们可能需要将一个应用分割成一些小的的代码块，并且只在需要的时候才从服务器加载一个模块。为了实现这个效果，Vue 有一个 defineAsyncComponent 方法： const {createApp, defineAsyncComponent} = Vue const app = createApp({}) const AsyncComp = defineAsyncComponent( () => { new Promise((resolve, reject) => { resolve({ template: ' I am async!' }) }) } ) app.component('async-example', AsyncComp) 在局部注册组件时，你也可以使用 defineAsyncComponent: import {createApp, defineAsyncComponent} from 'vue' createApp({ // ... components: { AsyncComponent: defineAsyncComponent(() => import ('./AsyncComponent.vue')) } }) 与 Suspense 一起使用 异步组件在默认情况下是可挂起的。这意味这它在父链中有一个 ，它将被视为该 的异步依赖。在这种情况下，加载状态将由 控制，组件自身的加载、错误、延迟和超时选项都将被忽略 模板引用 尽管存在 prop 和事件，但有时你可能仍然需要在 JavaScript 中直接访问子组件。为此，可以使用 ref attribute 为子组件或 HTML 元素指定引用 ID 如果你希望在组件挂载时，以编程的方式 focus 到这个 input 上： const app = Vue.createApp({}) app.compoennt('base=input', { template: ` `, methods: { focusInput() { this.$refs.input.focus() } }, mounted() { this.focusInput() } }) 此外，还可以向组件本身添加另一个 ref，并使用它从父组件触发 focusInput 事件： this.$refs.usernameInput.forcusInput() $refs 只会在组件渲染完成之后才生效，这仅仅是一个直接操作子组件的备选方案 处理边界情况 控制更新 得益于其响应性系统，Vue 总是知道何时更新（如果你使用正确的话），但是在某些边缘情况下，你可能希望强制更新，尽管事实上没有任何响应式数据发生更新。还有一些情况下，你可能希望防止不必要的更新 强制更新 如果你发现自己需要在 Vue 中强制更新，那么在 99.99% 的情况下，你已经在某个地方犯了错误。例如，你可能依赖于 Vue 响应系统未更新的状态，比如在组件创建之后添加了 data 属性 但是，如果你排除上述情况，必须强制更新，那么你可以使用 $forceUpdate 低级静态组件与 v-once 在 Vue 中渲染 HTML 元素的速度非常快，但有时你可能有一个包含很多静态内容的组件。在这些情况下，可以通过向根元素添加 v-once 只能过来确保只求值一次: app.component('terms-of-service', { template: ` title ` }) 提醒，不要过度使用这种模式。虽然在需要渲染大量静态内容的极少数情况下使用这种模式会很方便，但除非你注意到先前的渲染速度很慢，否则就没有必要这样做——另外，过度使用这种模式可能会在以后引起很多混乱。例如，假设另一个开发人员不熟悉 v-once 或者没有在模板中发现它，他们可能会花上几个小时来弄清楚为什么模板没有正确更新。 过渡&动画概述 Vue 提供了一些抽象概念，可以帮助处理过渡和动画，特别是在响应某些变化时。这些抽象的概念包括： 组件进入和离开 DOM 的钩子时，在 CSS 和 JS 中均可用，使用内置的 组件 过渡模式，以便你在过渡期间编排顺序 处理多个元素就地更新的钩子，使用 组件，通过 FLIP 技术来提高性能 使用 watchers 来处理应用中不同状态的过渡 基于 class 的动画和过渡 尽管 组件对于组件的进入和离开非常有用，但你也可以通过添加一个条件 class 来激活动画，而无需挂载组件： Push this button to do something you shouldn't be doing: Click me Oh no! .shake { animation: shake 0.82s cubic-bezier(0.36, 0.07, 0.19, 0.97) both; transform: translate3d(0, 0, 0); backface-visibility: hidden; perspective: 1000px; } @keyframes shake { 10%, 90% { transform: translate3d(-1px, 0, 0); } 20%, 80% { transform: translate3d(2px, 0, 0); } 30%, 50%, 70% { transform: translate3d(-4px, 0, 0); } 40%, 60% { transform: translate3d(4px, 0, 0); } } const Demo = { data() { return { noActivated: false } } } Vue.createApp(Demo).mount('#demo') 过渡与 Style 绑定 一些过渡效果可以通过插值的方式来实现，例如在发生交互时将样式绑定到元素上 性能 动画中使用了 transforms 之类的东西，并应用了诸如 perspective之类的奇怪的 property，为什么它们是这样实现的呢，而不是仅仅使用margin 和 top ？ 通过关注性能表现，我们可以在 web 上创建极其流畅的动画，我们希望尽可能对元素动画进行硬件加速，并使用不触发重绘的 property Transform 和 Opacity 更改 transform 不会触发任何几何形状变化或绘制。这意味着该操作可能是由合成器线程在 GPU 的帮助下执行。opacity 属性的行为也类似。因此，他们是在 web 上做元素移动的理想选择。 ，，， 可复用&组合 组合式 API 通过创建 Vue 组件，我们可以将界面中重复的部分连同其功能一起提取为重复的代码段。仅此一项就可以使我们的应用在可维护性和灵活性方面走得相当远，然而，光靠这一点可能并不够，想象几百个组件，处理这样的大型应用时，共享和重用代码就变得尤为重要。 使用（data、computed、methods、watch）组件选项来组织逻辑通常都是很有效的，然而，当我们的组件开始变得更大时，逻辑关注点的列表也会增加。尤其是对于刚开始没有编写这些组件的人来说，这会导致组件的难以阅读和理解 这种碎片化使得理解和维护复杂组件变得困难。选项的分离掩盖了潜在的逻辑问题。此外，在处理单个逻辑关注点时，我们必须不断地跳转相关代码的选项块，如果能够将同一个逻辑关注点相关代码收集在一起会更好，而这正是组合式 API 让我们能够做到的 组合式 API 基础 为了开始使用组合式 API，我们受限需要一个可以实际使用它的地方，在 Vue 组件中，我们将此位置称为 setup 新的 setup 选项在组件创建之前执行，一旦 props 被解析，就将作为组合式 API 的入口。在 Setup 中你应该避免使用 this，因为它不会找到组件实例。setup 的调用发生在 data property、computed property 或 methods 被解析之前，所以它们无法在 setup 中被获取 setup 选项是一个接受 props 和 context 的函数，此外，setup 返回的所有内容都暴露给组件的其余部分（计算属性、方法、生命周期钩子等等）以及组件的模板 其它 npm run dev 和 npm run serve 的区别 npm run dev 是 vue-cli2.0 版本使用的，npm run serve 是 vue-cli3.0 版本使用的 vue-cli2.0： \"dev\": \"webpack-dev-server --inline --progress --config build/webpack.dev.conf.js\", \"start\": \"npm run dev\", \"build\": \"node build/build.js\" } 复制代码 vue-cli3.0： \"serve\": \"vue-cli-service serve --open\", \"build\": \"vue-cli-service build\", \"lint\": \"vue-cli-service lint\" } 遇到一个问题，使用 npm run serve 命令可以启动项目，但会包找不到路径的错误，最后使用 npm run dev 终于解决(使用 npm start 也不行，跳出页面不大对)，以下是配置文件 \"scripts\": { \"serve\": \"vue-cli-service serve\", \"dev\": \"npm run ready && concurrently \\\"npm run serve -- --open\\\" \\\"npm run route watch\\\"\", \"start\": \"node bin/my start\", }, 还是没搞懂，以后启动注意使用的脚手架版本，虽然脚本里面有这个命令，但是的确不一定能启动起来 "},"font/Vue.js 的设计与实现.html":{"url":"font/Vue.js 的设计与实现.html","title":"Vue.js 的设计与实现","keywords":"","body":"Vue.js 的设计与实现 1. 框架设计概览 1.1 权衡的艺术 声明式代码的性能不优于命令式代码的性能，因为声明式代码会比命令式代码多出找出差异的性能消耗，框架本身就是封装了命令式代码才实现了面向用户的声明式。那为什么 Vue.js 还要选择声明式的设计方案呢？因为声明式代码的可维护性更强，命令式代码需要维护目标的整个过程，包括手动完成 DOM 元素的创建、更新和删除等工作。而声明式代码展示的就是我们要的结果，看上去更直观，并且做的过程让 Vue.js 封装好了。Vue.js 做的就是在保持可维护性的同时让性能损失最小化 虚拟 DOM 能够让我们在写声明式代码的情况下，保证我们应用程序的下限。虚拟 DOM 创建页面的过程分为两步：第一步是创建 JavaScript 对象，对真实 DOM 的描述；第二步是递归的遍历虚拟 DOM 并创建真实的 DOM。 innerHTML 更新页面是重新构建 HTML 字符串，再重新设置 DOM 元素的 innerHTML 属性（销毁所有旧的 DOM 元素，再全量创建一个新的 DOM 元素），性能因素与模板的大小有关。但是虚拟 DOM 在 JavaScript 层面的运算要比创建页面时多出一个 Diff 算法，但是只更新必要的 DOM，性能因素与数据变化量有关。 innerHTML Render（运行时） -> Compiler、Render（编译 + 运行时） -> Compiler（编译时），如果是纯运行时，我们没有办法分析用户提供的内容，也就不可以做进一步的优化；如果是纯编译时，可能性能会更好，但是会损坏灵活性，即用户提供的内容必须编译后才能使用；Vue.js 仍然保持了运行时 + 编译时的架构，在保持灵活性的基础上尽可能的优化 1.2 框架设计的核心要素 提升用户开发体验：提供友好的警告信息 控制框架代码体积：警告信息再生产环境中不提供 良好的 Tree-Shaking：消除那些永远不会被执行的代码 框架应该输出怎样的产物 特性开关 错误处理：统一的错误处理接口，callWithErrorHandling 良好的 TypeScript 类型支持 1.3 Vue.js 3 的设计思路 1.3.1. 声明式地描述 UI 前端页面设计的内容： DOM 元素：例如这个元素是什么标签 属性：标签上面的属性 事件：click等 元素的层级结构 Vue.js 3 的解决方案有： 使用于 HTML 标签一致的方式来描述 DOM 元素 使用与 HTML标签一致的方式来描述属性 使用：或 v-bind 来描述动态绑定的属性 使用 @ 或 v-on 来描述事件 使用与 HTML 标签一致的方式来描述层级结构 除了这种模板的方式来描述 UI 之外，还可以使用 JavaScript 对象来描述，这样会更加灵活： const title = { tag: 'h1', props: { onClick: handler}, children: [{tag: 'span'}] } 而使用 JavaScript 对象来描述 UI 的方式，就是所谓的虚拟 DOM。一个组件要渲染的内容是通过渲染函数来描述的，也就是代码中的 render 函数，Vue.js 会根据组件的 render 函数的返回值拿到虚拟 DOM，然后就可以把组件的内容渲染出来 1.3.2. 初识渲染器 渲染器 renderer 的作用就是把虚拟 DOM 渲染成真实 DOM，它的工作原理是递归的遍历虚拟 DOM 对象，并调用原生 DOM API 来完成真实的 DOM 的创建，总体来说实现思路分为三步： 创建元素：把 vnode.tag 作为标签名字来创建 DOM 元素 为元素添加属性和事件：遍历 vnode.props 对象，如果 key 以 on 字符开头，按事件处理，否则按属性处理 处理 children：如果 children 是一个数组，就递归地调用 renderer 继续渲染；如果 children 是字符串，则使用 createTextNode 函数创建一个文本节点 function render(vnode, container) { const el = document.createElement(vnode.tag) for(let key in vnode.props) { if(/^on/.test(key)) { el.addEventListener(key.substr(2).toLowerCase(), vnode.props[key]) } } if(typeof vnode.children === 'string') { el.appendChild(document.createTextNode(vnode.children)) } else if(Array.isArray(vnode.children)) { vnode.children.foreach(child => render(child, el)) } constainer.appendChild(el) } 这里只是做了最简单的创建节点，渲染器的精髓阶段在于更新节点的阶段，它需要精确的找到 vnode 对象的变更点并且值更新变更的内容 1.3.3. 组件的本质 组件就是一组 DOM 元素的封装，这组 DOM 元素就是组件要渲染的内容，因此我们可以定义一个函数来代表组件： const MyComponent = function () { return { tag: 'div', props: { onClick: () => alert('hello') }, children: 'click me' } } 然后定义虚拟 DOM 来描述组件，我们可以让虚拟 DOM 对象中的 tag 属性来存储组件函数： const vnode = { tag: MyComponent } 现在 tag 属性不是标签名称，而是组件函数，为了能够渲染组件，我们需要渲染器的支持： function renderer(vnode, container) { if(typeof vnode.tag === 'string') { mountElement(vnode, container) // 和前面的 renderer 函数的内容一致 } else if(typeof vnode.tag === 'function') { mountComponent(vnode, container) } } mountComponent 函数的实现： function mountComponent(vnode, container) { // 调用组件函数，获取要渲染的虚拟 DOM const substree = vnode.tag() render(substree, container) } 组件一定是一个函数吗，当然不是，我们完全可以用一个 JavaScript 对象来表达组件，Vue.js 中有状态组件就是使用对象结构来表达 1.3.4 模板的工作原理 模板的核心就是编译器，编译器将模板编译为渲染函数 模板如下： click me 对于编译器来说，模板就是一个普通的字符串，他会分析该字符串并生成一个功能与之相同的渲染函数 ： render() { return h('div', { onClick: handler}, 'click me') } 并添加到 标签块的组件对象上，添加结果： export default { data() {/* ... */ }, methods: { handler() => {/* ... */ } }, render() { return h('div', {onClick: handler}, 'click me') } } 无论是模板还是直接手写渲染函数，对于一个组件来说，他要渲染的内容最终都是通过渲染函数产生的，然后渲染器再把渲染函数返回的虚拟 DOM 渲染为真实的DOM，这就是模板的工作原理，也是 Vue.js 渲染页面的流程 1.3.5. Vue.js 是各个模块组成的有机整体 组件的实现依赖于渲染器，模板的编译依赖于编译器，并且编译后生成的代码是根据渲染器和虚拟 DOM 的设计决定的，因此 Vue.js 的各个模块之间是互相关联的。 假设模板如下： 编译器会把它编译成一个渲染函数： function render() { return { tag: 'div', props: { id: 'foo', class: 'cls' }, } } 但是这个 cls 变量可能随时发生变化，渲染器的作用就是一直寻找并且只更新变化的内容，与其要花性能寻找到 cls 是变量，还不如编译器刚开始就把这些信息提取出来，直接交给渲染器。Vue.js 的模板是有特点的，可以一眼就看出 ： 和 @ 是动态变化的，所以编译器可以识别哪些是静态的，哪些是动态的，在生成代码的时候完全可以附带这些信息： function render() { return { tag: 'div', props: { id: 'foo', class: 'cls' }, patchFlags: 1 // 假设 1 代表 cls 是动态的 } } 可知，编译器和渲染器是存在交流的，相互配合以提升性能，它们之间交流的媒介就是虚拟 DOM。虚拟 DOM 比模板更加灵活，但是模板比虚拟 DOM 更加直观，其实都是一个信息 2.响应系统 2.1. 响应系统的作用与实现 2.1.1. 响应式数据与副作用函数 这里副作用函数指类似更改 HTML 元素的函数，如果我们数据更改之后，副作用函数自动执行并修改HTML，这样的数据不就是响应式数据了嘛，vue 2在 ES5 时候是通过 Object.defineProperty 函数实现，在现在是通过 Proxy 代理实现的，实现大概思路是： 当副作用函数 effect 执行时，触发对象的字段的读取操作 当修改字段的时候，触发字段的设置操作，从而触发副作用函数的执行 const bucket = new Set() // 存储副作用的桶 const data = {text: 'hello world'} // 原始数据 const obj = new Proxy(data, { get(target, key) { // 拦截读取操作 bucket.add(effect) // 将副作用函数添加到桶中 return target[key] }, set(target, key, value) { // 拦截设置操作 targt[key] = value bucket.forEach(fn => fn()) // 把副作用函数取出并执行 return true } }) 设置拦截函数之后，每次设置操作都会先将原始数据改变，然后取出副作用函数并执行；每次读取操作都会先将副作用函数添加到桶中，然后返回返回值。但是目前的实现还存在很多缺陷：例如只是通过名字（effect）来获取副作用函数，这种硬编码，如果函数名变了或者副作用函数是一个匿名函数就不行了 2.1.2.设计一个完善的响应系统 使用一个全局变量存储副作用函数，将上文的副作用函数 effect 改为用于注册副作用函数的函数 let activeEffect; // 用一个全局变量存储被注册的函数 function effect(fn) { // effect 用于注册副作用函数 activeEffect = fn // 当调用 effect 注册副作用函数时，将副作用函数注册给 activeEffect fn() } const bucket = new Set() const obj = new Proxy(data, { get(target, key) { if(activeEffect) { backet.add(activeEffect) } return target[key] }, set(target, key, value) { target[key] = value bucket.foreach(fn => fn()) return true } }) 在副作用函数与被操作的目标字段之间建立明确的联系 const bucket = new WeakMap() const obj = new Proxy(data, { get(target, key) { if(!activeEffect) return let depsMap = bucket.get(target) // 从桶中取出 depsMap，它也是一个 Map 类型 if(!depsMap){ // 如果不存在，新建一个 Map 并与之联系 bucket.set(target, (depsMap = new Map())) } let deps = depsMap.get(key) // 再根据 key 从 depsMap 中取出 deps，他是一个 Set 类型，存储所有与 key 相关的副作用函数 if(!deps) { deps.Map.set(key, (dep = new Set())) } deps.add(activeEffect) // 最后将当前激活的副作用函数添加到桶里 }, set(target, key, value) { target[key] = value const depsMap = bucket.get(target) // 根据 target 从桶中取得 depsMap if(!depsMap) return const effects = depsMap.get(key) // 根据 key 取得所有副作用函数 effects effects && effects.forEach(fn => fn()) } }) 从这段代码中可以看出构建数据结构的方式：WeakMap、Map 和 Set，WeakMap 由 target --> Map 构成，Map 由 key --> value 构成 为什么要使用 WeakMap：因为 WeakMap 对 key 是弱引用，不影响垃圾回收器的工作。如果 key 被垃圾回收器回收，那么对应的键和值就访问不到了，所以 WeakMap 经常用于存储那些只有当 key 所引用的对象存在时（没有被回收）才有价值的信息。WeakMap 不会导致内存溢出 对以上的代码做一些封装处理。在前面 get 的逻辑的时候，是把所有副作用函数收集到桶里的这部分逻辑，但更好的做法是将这部分逻辑封装到一个 track 函数里 const obj = new Proxy(data, { get(target, key) { track(target, key) return target[key] }, set(target, key, value) { target[key] = value trigger(target, key) } }) function track(target, key) { if(!activeEffect) return let depsMap = bucket.get(target) if(!depsMap) { bucket.set(target, (depsMap = new Map())) } let deps = depsMap.get(key) if(!deps) { depsMap.set(key, (deps = new Set())) } deps.add(activeEffect) } function trigger(target, key) { const depsMap = bucket.get(target) if(!depsMap) return const effects = depsMap.get(key) effects && effects.foreach(fn => fn()) } 2.1.3. 分支切换与 cleanup obj.ok ? obj.text : 'not'分支切换可能会产生遗留的副作用函数，text 只是有些时候会执行，但是也会存储副作用函数，导致不必要的更新。解决思路：每次副作用函数执行时，我们可以先把它从所有与之关联的集合中删除，当副作用函数执行完毕，会重新建立联系，但在新的联系中不会包含遗留的副作用函数 重新定义副作用函数，在 effect 内部定义了 effectFn 函数，并添加了 effectFn.deps 属性，该属性是一个数组，用来存储所有包含当前副作用函数的依赖集合： let activeEffect function effect(fn) { const effectFn = () => { activeEffect = effectFn // 当 effectFn 执行时，将其设置为当前激活的副作用函数 fn() } effectFn.deps = [] // 用来存储所有与之相关的依赖集合 effectFn() // 执行副作用函数 } function track(target, key) { // 收集依赖集合改进 if(!activeEffect) return let depsMap = bucket.get(target) if(!depsMap) { bucket.set(target, (depsMap = new Map())) } let deps = depsMap.get(key) if(!deps) { depsMap.set(key, (deps = new Set())) } deps.add(activeEffect) activeEffect.deps.push(deps) // 将依赖集合添加到 activeEffect.deps 数组中 } let activeEffec function effect(fn) { // 注册函数改进，根据 effectFn.deps 获取所有相关联的依赖集合，进而将副作用函数从依赖集合中移除 const effectFn = () => { cleanUp(effectFn) // 调用cleanUp 完成清楚工作 activeEffect = effectFn fn() } effectFn.deps = [] effectFn() } function cleanUp(effectFn) { for(let i of effectFn.deps) { i.delete(effectFn) // 将 effectFn 从依赖集合中删除 } effectFn.deps.length = 0 // 重置 deps 数组 } 现在已经解决依赖副作用函数的问题了，但是在 trigger 函数的 Set 中，我们会调用执行函数，会把副作用函数从 Set 剔除，但是执行的时候可能又把它加入 Set 中了，会导致这个函数无限循环。解决办法很简单，构造另外一个 Set 集合遍历它 function trigger(target, key, value) { const depsMap = bucket.get(target) if(!depsMap) return const effects = depsMap.get(key) const effectsToRun = new Set(effects) // 新建一个集合来运行，避免无限循环 effects.forEach(effectFn => effectFn()) } 2.1.4. 嵌套的 effect 与 effect 栈 实际上副作用函数没有这么简单，很可能副作用函数里面也嵌套了一个副作用函数（渲染父组件，然后再渲染子组件），所以当我们执行父副作用函数的时候会过多的牵扯多个字段的改变。因为当我们用变量 activeEffect 来存储通过 effect 函数注册的副作用函数时，它只能存储一个，内层的副作用函数会覆盖父副作用函数，并且永远不会恢复原来的值，为了解决这个问题，应该在全局变量 activeEffect 的基础上加一个副作用函数栈 effectStack： let activeEffect // 用一个变量存储当前激活的 effect 函数 const effectStack = [] function effect(fn) { const effectFn = () => { cleanUp(effectFn) activeEffect = effectFn effectStack.push(effectFn) // 在副作用函数调用其将他压入栈中 fn() effectStack.pop() // 当前副作用函数执行完毕后，将当前副作用函数弹出栈，并把 activeEffect 函数还原 activeEffect = effectStack[effectStack.length - 1] } effectFn.deps = [] effectFn() } 2.1.5. 调度执行 obj.foo = obj.foo + 1 这种语句会先读取 obj.foo 的值，然后触发 track 操作，然后设置 obj.foo 的值，触发 trigger 操作。可能导致该副作用函数还在执行中，然后就要开始下一次执行，这样就会导致无限递归调用自己，产生栈溢出。解决方法：在 trigger 将要发生时候添加条件，如果 trigger 触发的副作用函数正在执行中，则不触发执行： function trigger(target, key) { const depsMap = bucket.get(target) if(!depsMap) return const effects = depsMap.get(key) const effectsToRun = new Set() effects && effects.forEach(fn => { if(fn != activeEffect) { // 如果 trigger 触发的副作用函数与当前正在执行的函数相同，则不触发执行 effectsToRun.add(fn) } }) effectsToRun.forEach(fn => fn()) } 可调度性是响应系统非常重要的特性，所谓可调度性就是指当 trigger 动作触发副作用函数执行时，有能力决定副作用函数执行的时机，次数以及方式。所以可以为 effect 函数设计一个选项参数 options，允许用户指定调度器： function effect(fn, options = {}) { const effectFn = () => { cleanUp(effectFn) activeEffect = effectFn effectStack.push(effectFn) fn() effectStack.pop() activeEffect = effectStack[effectStack.length - 1] } effectFn.options = options // 将 options 挂载到 effectFn 上 effectFn.deps = [] effectFn() } 有了调度函数，我们在 trigger 函数中触发副作用函数重新执行时，就可以直接调用用户传递的调度器函数，从而把控制权交给用户： function trigger(target, key) { const depsMap = bucket.get(target) if(!depsMap) return const effects = depsMap.get(key) const effectsToRun = new Set() effects && effects.forEach(effectFn => { if(effectFn != activeEffect) { effectsToRun.add(effectFn) } }) effectsToRun.forEach(effectFn => { if(effectFn.options.scheduler) { // 如果存在一个调度器，则调用该调度器，并将副作用函数作为参数传递 effectFn.options.scheduler(effectFn) } else { effectFn() // 否则直接执行副作用函数，默认行为 } }) } 如上所示，在 trigger 函数执行时，会判断这个副作用函数是否存在调度器，如果存在调度器，则把这个函数作为参数传递给调度器函数执行，一个简单的调度器可以通过一个任务队列实现 const jobQueue = new Set() // 定义一个任务队列 const p = Promise.resolve() // 使用 Promise.resolve() 创建一个 Promise 队列，用它将一个任务添加到微任务队列 let isFlushing = false // 一个标志表示是否在刷新队列 function fulshJob() { if(isFlushing) return // 任务队列正在刷新，什么都不做 isFlushing = true // 代表任务队列正在刷新 p.then(() => { // 在微任务队列中刷新 jobQueue 队列 jobQueue.forEach(job => job()) }).finally(() => { // 结束后重置 isFlushing isFlushing = false }) } effect(() => { console.log(obj.foo) }, { scheduler(fn) { jobQueue.add(fn) // 每次调度时，将副作用函数添加到 jobQueue 中 flushJob() } }) 这个任务队列使用了 Set，具备了副作用函数的自动去重的能力。调度器每次在执行的时候将副作用函数添加到 jobQueue 队列中，再调用 flushJob 函数刷新队列，因为有 isFlushing 标志的存在，类似与 Vue.js 中连续多次修改响应式数据但只会触发更新一次 2.1.6. 计算属性 computed 与 lazy 前文已经了解到利用 effect 函数注册副作用函数，同时它允许执行一些选项参数 options，例如指定 schedule 调度器来控制副作用函数的执行时机和方式；利用 track 函数用来追踪和收集依赖；利用 trigger 函数来触发副作用函数和执行。实际上综合这些，我们可以实现 Vue.js 中一个非常重要并且极具特色的能力：计算属性 比如 lazy 的实现： function effect(fn, options = {}) { const effectFn = () => { cleanup(effectFn) activeEffect = effectFn effectStack.push(effectFn) fn() effectStack.pop() activeEffect = effectStack[effectStack.length - 1] } effectFn.options = options effectFn.deps = [] if(!options.lazy) { //只有非 lazy 的时候，才执行 effectFn() // 执行副作用函数 } return effectFn // 将副作用函数作为返回值返回 } const effectFn = effect(() => { console.log(obj.foo) },{ lazy: true // 指定 lazy ，这个函数就不会立即执行 }) effectFn() // 手动执行副作用函数 但是仅仅能够手动执行副作用函数的意义并不大，如果可以把传递给 effect 的函数换做一个 getter，那么这个 getter 函数可以返回任何值： function effect(fn, options = {}) { const effectFn = () => { cleanUp(effectFn) activeEffect = effectFn effectStack.push(effectFn) const res = fn() // 将 fn 的执行结果存储到 res 中 effectStack.pop() activeEffect = effectStack[effectStack.length - 1] return res } effectFn.options = options effectFn.deps = [] if(!options.lazy) { effectFn() } return effectFn } 通过新增代码可以看到，传递给 effect 函数的参数 fn 是副作用函数，但是我们把它封装了一层，如果是存在 lazy 则返回 effectFn，并且 effectFn 函数中可以拿到fn 的计算结果 现在我们可以实现懒执行的副作用函数了，并且可以拿到副作用函数的执行结果了，这样的话我们就可以实现计算属性了 function computed(getter) { const effectFn = effect(getter, { // 把 getter 作为副作用函数，创建一个 lazy 的 effect lazy: true }) const obj = { get value() { // 当读取 value 时才执行 effectFn return effectFn() } } return obj } 现在实现的计算属性只是还是懒计算，还没有做到对结果值的缓存，多次访问会导致 effectFn 的多次计算，所以添加对值的缓存功能： function computed(getter) { let value // 用来缓存上一次计算的值 let dirty = true // 用来标识是否重新计算值 const effectFn = effect(getter, { lazy: true }) const obj = { get value() { if(dirty) { value = effectFn() dirty = false } return value } } return obj } 这样就做到了缓存，但是当值的确发生变化的时候，需要重新计算一次，也就是需要把 dirty 标志改为 false，解决方法是调度器 schedule function computed(getter) { let value let dirty = true const effectFn = effect(geter, { lazy: true, schedule() { // 添加调度器，在调度器中将 dirty 重置为 true dirty = true } }) const obj = { get value() { if(dirty) { vlaue = effectFn dirty = false } return value } } return obj } scheduler 调度器函数会在 getter 函数中所依赖的响应式数据变化时重新执行，然后将 dirty 重置为 true，当下一次访问值的时候就会重新计算属性了。 但是这里还有一个缺陷，因为现在的计算属性是个懒执行，只能通过副作用函数重新执行拿到缓存，不能在相关联的数据更改之后，缓存就跟着改，所以需要改进。改进方法是当读取计算属性的值的时，手动调用 track 函数进行追踪；当计算属性依赖的响应式数据发生变化时，手动调用 trigger 函数触发响应 function computed(getter) { let value let drity = true const effectFn = effect(getter, { lazy: true, scheduler() { if(!dirty) { dirty = true trigger(obj, 'vlaue') // 当计算属性依赖的响应式数据变化时，手动调用 trigger 函数触发响应 } } }) const obj = { get value() { if(dirty) { value = effectFn() dirty = false } track(obj, 'value') // 当读取 value 时，手动调用 track 函数进行追踪 return value } } return obj } 2.1.6. watch 的实现原理 watch 的本质就是观测一个响应式数据，当数据发生变化时通知并执行响应的回调函数。实际上 watch 的实现本质上就是利用了 effect 以及 options.scheduler 选项 function watch(source, cd){ // watch 函数接收两个参数，source 是响应式数据，cb 是回调函数 effect( () => source.foo, // 触发读取操作，从而建立联系 { scheduler() { cb() // 当数据发生变化, 调用回调函数 } } ) } 现在能观测 source.foo 的变化了，为了让 watch 函数更具有通用性，需要封装一个通用的操作 function watch(source, cb) { effect( () => traverse(source), // 调用 traverse 递归地读取 { scheduler() { cb() } } ) } function traverse(value, seen = new Set()) { if(typeof value != 'object' || value == 'null' || seen.has(value)) return // 如果读取的值是原始值、空、或则被读取过了，则什么都不做 seen.add(value) // 将数据添加到 seen 中，代表遍历地读取过了，避免循环引用引起的死循环 for(const k in value) { // 假设 value 是一个对象 traverse(value[k], seen) } return value } 这样就能读取一个对象上的任意的属性，从而当任意属性发生变化时都能够触发回调函数执行，但是现在的实现还拿不到旧值和新值，这需要充分利用 effect 函数的 lazy 选项 function watch(source, cb) { let getter if(typeof source === 'function') { getter = source } else { getter = () => traverse(source) } let oldValue, newValue // 定义旧值和新值 const effectFn = effect( () => getter(), { lazy: true, scheduler() { newValue = effectFn() cb(newValue, oldValue) oldValue = newValue // 更新旧值，不然下一次会得到错误得旧值 } } ) oldValue = effectFn() // 手动调用副作用函数，拿到的值就是旧值 } watch 的本质其实是对 effect 的二次封装，但是 watch 有两个特性：一个是立即执行的回调函数，另一个是回调函数执行的时机 默认情况下，一个 watch 的回调只会在响应式数据发生变化时候才执行，在 Vue.js 中可以通过选项参数 immediate 来指定回调是否需要立即执行。实际上回调函数的立即执行和后续执行本质上没有任何差别，我们可以把 scheduler 调度函数封装为一个通用函数，分别在初始化和变更的时候调用它 function watch(source, cb, options = {}) { let getter if(typeof source === 'function') { getter = source } else { getter = () => traverse(source) } let oldValue, newValue const job = () => { newValue = effectFn() cb(newValue, oldValue) oldValue = newValue } const effectFn = effect( () => getter(), // 执行 getter { lazy: true, scheduler: () => { if(options.flush === 'post'){ // 在调度函数中判断 flush 是否为 ‘post’， 如果是就放到微任务队列中执行 const p = Promise.resolve() p.then(job) } else { job() } } } ) if(options.immediate) { // 实现立即执行功能 job() } else { oldvalue = effectFn() } } 2.1.7. 过期的副作用 竞态问题通常在多线程或多线程编程中被提及，前端很少提及，但在日常工作中可能早就遇到过相似的场景 let finalData watch(obj, async() => { const res = fetch('/test') finalData = res }) 看着没什么问题，但是如果连续修改 obj 的值，会发送两个请求，最终的结果是哪个值是不确定的，这时候就应先把第一次的设置为过期，避免竞态问题产生错误的结果。过期的作用通过接收一个回调函数，回调函数在当前副作用函数过期时候执行 "},"font/webpack.html":{"url":"font/webpack.html","title":"webpack","keywords":"","body":"webpack Webpack 中文文档 webpack 中文文档 1. 概念 本质上，webpack 是一个用于现代 JavaScript 应用程序的 静态模块打包工具。当 webpack 处理应用程序时，它会在内部从一个或多个入口点构建一个 依赖图(dependency graph)，然后将你项目中所需的每一个模块组合成一个或多个 bundles，它们均为静态资源，用于展示你的内容。 在开始前你需要先理解一些核心概念： 入口（entry）：指示 webpack 应该使用哪个模块 输出（output）：告诉 webpack 在哪里输出它所创建的 bundle，以及如何命名这些文件 loader：webpack 只能理解 JavaScript 和 JSON 文件，loader 让 webpack 能够去处理其他类型的文件 插件（plugin）：执行范围更广的任务，包括打包优化、资源管理、注入环境变量 模式（mode）：相应值的优化，默认值是 production 浏览器兼容性（browser compatibility）：webpack 支持所有符合 ES5 标准的浏览器 环境（environment）：webpack 5 运行于 Node.js v10.13.0+ 的版本 2. 入口起点（entry） 单个入口语法 module.exports = { entry: './test.js' } 对象语法 module.exports = { entry: { app: './src/app.js', test: './src/test/test.js' } } 用于描述入口的对象： dependOn： 当前入口所依赖的入口，它们必须在该入口被加载前加载 filename：指定要输出的文件名称 import：启动时需要加载的模块 library：为当前的 entry 构建一个 library runtime：运行时 chunk 的名字 publicPath：当该入口的输出文件在浏览器中被引用时，为它们指定一个公共 URL 地址 3. 输出（output） 可以通过配置 output 选项，告知 webpack 如何向硬盘写入编译文件，即使可以存在多个 entry 起点，但只能指定一个 output 配置 在 webpack 中，output 属性的最低要求是，将它的值设置为一个对象，然后为将输出文件的文件名配置为一个 output.filename module.exports = { output: { filename: 'bundle.js' } } 此配置将一个单独的 bundle.js 文件输出到 dist 目录中 多个入口起点的情况，应该使用占位符来确保每个文件具有唯一的名称 module。exports = { entry: { app: './src/app.js', search: './src/search.js' }, output: { filename: '[name].js', path: __dirname + '/dist' } } 4. loader loader 用于对模块的源代码进行转换。loader 可以使你在 import 或 \"load(加载)\" 模块时预处理文件 示例 首先安装相关的 loader： npm install --save-dev scss-loader ts-loader 然后指示 webpack 对每个 .css 使用 css-loader，以及对所有 .ts 文件使用 ts-loader: module.exports = { module: { rules: [ {test: /\\.scss$/, use: 'scss-loader'}, {test: /\\.ts$/, ues: 'ts-loader'} ] } } loader 特性 支持链式调用 可以是同步，也可以是异步 运行在 Node.js 中，并且能够执行任何操作 插件带来了更多的特性 5. plugin 插件的目的在于解决 loader 无法实现的其他事。webpack 插件是一个具有 apply 方法的 JavaScript 对象。apply 方法会被 webpack compiler 调用，并且在整个编译生命周期都可以访问 compiler 对象 配置方式 const HtmlWebpackPlugin = require('html-webpack-plugin'); const webpack = require('webpack'); // 访问内置的插件 const path = require('path'); module.exports = { entry: './path/to/my/entry/file.js', output: { filename: 'my-first-webpack.bundle.js', path: path.resolve(__dirname, 'dist'), }, module: { rules: [ { test: /\\.(js|jsx)$/, use: 'babel-loader', }, ], }, plugins: [ new webpack.ProgressPlugin(), new HtmlWebpackPlugin({ template: './src/index.html' }), ], }; Node API 方式 const webpack = require('webpack'); // 访问 webpack 运行时(runtime) const configuration = require('./webpack.config.js'); let compiler = webpack(configuration); new webpack.ProgressPlugin().apply(compiler); compiler.run(function (err, stats) { // ... }); 6. 配置（Configuration) 由于 webpack 遵循 CommonJS 模块规范，因此可以在配置中使用： 通过 require(...) 引入其它文件 通过 require(...) 使用 npm 下载的工具函数 使用 ?: 操作符 对 value 使用常量或变量赋值 编写并执行函数，生成部分配置 基本配置 const path = require('path'); module.exports = { mode: 'development', entry: './foo.js', output: { path: path.resolve(__dirname, 'dist'), filename: 'foo.bundle.js', }, }; 7. 模块（Modules） 在模块化编程中，开发者将程序分解为功能离散的 chunk，并称之为模块。每个模块都拥有小于完整程序的体积，使得验证、调试及测试变得轻而易举。精心编写的模块提供了可靠的抽象和封装边界，使得引用程序中的每个模块都具备了条理清晰的设计和明确的目的。Node.js 从一开始就支持模块化编程。 webpack 模块能以各种方式表达它们的依赖关系： ES 2015 import 语句 Common require() 语句 AMD define 和 require 语句 css/sass/less 文件中的 @import 语句 stylesheet url(...) 或者 HTML 文件中的图片链接 8. 模块解析（Module Resolution） resolver 是一个帮助寻找模块绝对路径的库。一个模块可以作为另一个模块的依赖模块，然后被后者引用。resolver 帮助 webpack 从每个 require/import 语句中找到需要引入到 bundle 中的模块代码 webpack 能解析三种文件路径，解析规则： 绝对路径 import '/home/me/file' 相对路径 import '../src/file1'; import './file2'; 模块路径 import 'module' import 'module/lib/file' 9. Module Federation 多个独立的构建可以组成一个应用程序，这些独立的构建之间不应该存在依赖关系，因此可以单独开发和部署它们（这通常称为微前端，但是不仅如此） ，，， 深入浅出 Webpack 深入浅出 Webpack 不得不说，写的是真的好！ 1. 入门 1.1. 前端的发展 近年来 Web 应用变得更加复杂和庞大，Web 前端技术的应用也更加广泛。从复杂庞大的管理后台到对性能要求苛刻的移动网页，再到类似 ReactNative 的原生应用开发方案，Web 前端工程师再面临更多机遇的同时也会面临更大的挑战 1.1.1. 模块化 模块化是指把一个复杂的系统分解到多个模块一方便编码。很久以前通过命名空间来组织代码的方式有一些问题： 命名空间冲突，两个库可能会使用同一个名称 无法合理地管理项目的依赖和版本 无法方便地控制依赖的加载顺序 1.1.2. CommonJS CommonJS 是一种使用广泛的 JavaScript 模块化规范，核心思想是通过 require 方法来同步地加载依赖的其它模块，通过 module.exports 导出需要暴露的接口 // 导入 const moduleA = require('./moduleA') // 导出 module.exports = moduleA.someFunc CommonJS 的优点是： 代码可复用于 Node.js 环境下并运行 通过 NPM 发布的很多第三方模块都采用了 CommonJS 规范 1.1.3.AMD AMD 也是一种 JavaScript 模块化规范，与 CommonJS 最大的不同在于它采用异步的方式去加载依赖的模块。 AMD 规范主要是为了解决针对浏览器环境的模块化问题，最具代表性的实现是 requirejs // 定义一个模块 define('module', ['dep'], function(dep) { return exports; }) // 导入和使用 require(['module'], function(module) {}) AMD 的优点在于： 可在不转换代码的情况下直接在浏览器中运行 可异步加载依赖 可并行加载多个依赖 代码可运行在浏览器环境和 Node.js 环境下 AMD 的缺点在于JavaScript 运行环境没有原生支持 AMD，需要先导入实现了 AMD 的库后才能正常使用 1.1.4. ES6 模块化 它将逐步取代 CommonJS 和 AMD 规范，称为浏览器和服务器通用的模块解决方案 // 导入 import{ readFile } from 'fs' import React from 'react' // 导出 export function hello() {} export default { // ... } ES6 虽然是未来的模块化方案，但是有些浏览器环境不支持 ES6，必须通过工具转换成标准的 ES6 后才能运行 1.1.5 样式文件中的模块化 处理 JavaScript 开始模块化改造，前端开发里的样式文件也支持模块化。以 SCSS 为例，把一些常用的样式片段放进一个通用的文件里，再在另一个文件里通过 @import 语句去导入和使用这些样式片段 // util.scss @mixin center { // 水平垂直居中 position: absolute; left: 50%; top: 50%; transform: translate(-50%, -50%) } // main.scss @import 'util'; #box { @include center; } 1.2 常见的构建工具及对比 前端技术发展之快，各种可以提高开发效率的新思想和框架被发明。但是这些东西都有一个共同点：源代码无法直接运行，必须通过转换后才可以正常运行。 构建就是做这件事情，把源代码转换成发布到线上的可执行 JavaScrip、CSS、HTML 代码，包括如下内容： 代码转换：TypeScript 编译成 JavaScript、SCSS 编译成 CSS 等 文件优化：压缩 JavaScript、CSS、HTML 代码，压缩合并图片等 代码分割：提取多个页面的公共代码、提取首屏不需要执行部分的代码让其异步加载 模块合并：在采用模块化的项目里会有很多个模块和文件，需要构建功能把模块分类合并成一个文件 自动刷新：监听本地源代码的变化、自动重新构建、刷新浏览器 代码校验：在代码被提交到仓库前需要检验代码是否符合规范，以及单元检测是否通过 自动发布：更新完成代码后，自动构建出线上发布代码并传输给发布系统 构建其实是在工程化、自动化思想在前端开发中的体现，把一系列流程用代码去实现，让代码自动化地执行这一系列复杂的流程。构建给前端开发注入了更大的活力，解放了我们的生产力 1.2.1. npm Script npm Script 是一个任务执行者，是 npm 内置的一个功能，允许在 package.json 文件中使用 scripts 字段定义任务： { 'scripts': { 'dev': 'node dev.js', 'pub': 'node build.js' } } Npm Script的优点是内置，无须安装其他依赖。其缺点是功能太简单，虽然提供了 pre 和 post 两个钩子，但不能方便地管理多个任务之间的依赖。 1.2.2. Grunt Grunt 相当于进化版的 Npm Script，有大量现成的插件封装了常见的任务，也能管理任务之间的依赖关系，自动化执行依赖的任务，每个任务的具体执行代码和依赖关系写在配置文件 Gruntfile.js 里，但是集成度不高，需要些很多配置之后才可以用，无法做到开箱即用 1.2.3. Gulp Gulp 是一个基于流的自动化构建工具。 除了可以管理和执行任务，还支持监听文件、读写文件。Gulp 被设计得非常简单，只通过下面5个方法就可以胜任几乎所有构建场景： 通过 gulp.task 注册一个任务； 通过 gulp.run 执行任务； 通过 gulp.watch 监听文件变化； 通过 gulp.src 读取文件； 通过 gulp.dest 写文件。 Gulp 的最大特点是引入了流的概念，同时提供了一系列常用的插件去处理流，流可以在插件之间传递。Gulp 的优点是好用又不失灵活，既可以单独完成构建也可以和其它工具搭配使用。其缺点是和 Grunt 类似，集成度不高，要写很多配置后才可以用，无法做到开箱即用。 可以将Gulp 看作 Grunt 的加强版。相对于 Grunt，Gulp增加了监听文件、读写文件、流式处理的功能。 1.2.4. Webpack Webpack 是一个打包模块化 JavaScript 的工具，在 Webpack 里一切文件皆模块，通过 Loader 转换文件，通过 Plugin 注入钩子，最后输出由多个模块组合成的文件。Webpack 专注于构建模块化项目： Webpack 的优点是： 专注于处理模块化项目，能做到开箱即用 通过 Plugin 扩展，完整好用又不失灵活（sass-loader) 使用常见不仅限于 Web 开发 社区活跃，开发体验良好 Webpack 的缺点是只能用于采用模块化开发的项目 1.2.5. 为什么选择 Webpack 上面介绍的构建工具是按照它们诞生的时间排序的，它们是时代的产物，侧面反映出 Web 开发的发展趋势如下： 在 Npm Script 和 Grunt 时代，Web 开发要做的事情变多，流程复杂，自动化思想被引入，用于简化流程； 在 Gulp 时代开始出现一些新语言用于提高开发效率，流式处理思想的出现是为了简化文件转换的流程，例如将 ES6 转换成 ES5。 在 Webpack 时代由于单页应用的流行，一个网页的功能和实现代码变得庞大，Web 开发向模块化改进。 1.3 安装 Webpack 还是得自己实践一下，这种事就得 show your code npm init，npm i -D webpack |-- index.html |-- main.js |-- show.js |-- webpack.config.js // main.js 这里是 commonJS 规范 const show = require('./show.js'); // 执行 show 函数 show('Webpack'); // show.js // 操作 DOM 元素，把 content 显示到网页上 export function show(content) { window.document.getElementById('app').innerText = 'Hello,' + content; } // webpack.config.js const path = require('path') module.exports = { entry: './main.js', output: { filename: 'bundle.js', path: path.resolve(__dirname, './dist') } } npm run build ，多了一个build 文件夹，里面有一个 bunddle.js 文件，打开html 就可以看到运行结果 Webpack 是一个打包模块化 JavaScript 的工具，它会从 main.js （入口文件）出发，识别出源码中的模块化导入语句，递归的寻找出入口文件的所有依赖，把入口和其所有依赖打包到一个单独的文件中。从 Webpack 2 开始，已经内置了对 ES6、CommonJS、AMD 模块化语句的支持 1.4. 使用 loader 安装 css-loader style-loader 可能会失败，需要指定版本 添加一个 css 文件并在项目中使用 安装相应 loader，添加这段代码进入 webpack.config.js，use 从右到左执行，minimize 是压缩文件，style-load 把 CSS 内容注入到 JavaScript 里 module: { rules: [ { test: /\\.css$/, use: ['style-loader', 'css-loader?minimize'] } ] } 能明显发现 build.js 的代码内容变多了，且出现了 css 内容，style-loader 将 CSS 内容用 JavaScript 的字符串存储起来，在网页执行 JavaScript 时通过 DOM 操作动态地王 HTML head 标签插入 HTML style 标签。这样做可能会导致 JavaScript 变大并导致加载网页时间变长，想让 Webpack 单独输出 css 文件，可以通过 Plugin 机制实现 1.5 使用 Plugin Plugin 是用来扩展 Webpack 功能的，通过在构建流程里注入钩子实现，它给 Webpack 带来了很大的灵活性，修改如下： const path = require('path'); const ExtractTextPlugin = require('extract-text-webpack-plugin') module.exports = { // JS 执行入口文件 entry: './main.js', output: { // 把所有依赖的模块合并输出到一个 bundle.js 文件 filename: 'bundle.js', // 输出文件都放到 dist 目录下 path: path.resolve(__dirname, './dist'), }, module: { rules: [ { test: /\\.css$/, use: ExtractTextPlugin.extract({ // 转换 .css 文件需要使用的 Loader use: ['css-loader'] }) } ] }, plugins: [ new ExtractTextPlugin({ filename: `[name]_[contenthash:8].css` }) ] }; 但是这么些得自己重新引入 css 文件了 1.6 使用 DevServer 前面几节只是让 Webpack 正常运行起来了，但是在实际开发中，你可能会需要： 提供 HTTP 服务而不是使用本地文件预览 监听文件的变化并自动刷新网页，做到实时预览 支持 Source Map，以方便调试 Webpack 原生支持上述2，3点，再结合官方提供的工具 DevServer 也可以方便地做到第 1 点。DevServer 会启动一个 HTTP 服务器用于服务器网页请求，同时会帮助启动 Webpack，并接收 Webpack 发出的文件变更信号，通过 WebSocket 协议自动刷新网页做到实时预览 使用 DevServer 之后我没有该 js 文件路径也可以运行，改了之后也可以运行，应该是缓存和本地的文件都读到了？ 1.6.1. 实时预览 Webpack 在启动时可以开启监听模式，开启监听模式后 Webpack 会监听本地文件系统的变化，发生变化时重新构建出新的结果。启动 Webpack 时可以通过 webapck --watch 来开启监听模式。DevServer会让 Webpack 在构建出的 JavaScript 代码里注入一个代理客户端用于控制网页，网页和 DevServer 之间通过 WebSocket 协议通信。 1.6.2. 模块热替换 除了通过重新刷新整个网页来实现实时预览，DevServer 还有一种被称作模块热替换的刷新技术。 模块热替换能做到在不重新加载整个网页的情况下，通过将被更新过的模块替换老的模块，再重新执行一次来实现实时预览。 1.6.3. 支持 Source Map 在浏览器中运行的 JavaScript 代码都是编译器输出的代码，这些代码的可读性很差。如果在开发过程中遇到一个不知道原因的 Bug，则你可能需要通过断点调试去找出问题。 在编译器输出的代码上进行断点调试是一件辛苦和不优雅的事情， 调试工具可以通过 Source Map 映射代码，让你在源代码上断点调试。 Webpack 支持生成 Source Map，只需在启动时带上 --devtool source-map 参数。 加上参数重启 DevServer 后刷新页面，再打开 Chrome 浏览器的开发者工具，就可在 Sources 栏中看到可调试的源代码了。 1.7 核心概念 Webpack 的核心概念： Entry：入口，Webpack 执行构建的第一步将从 Entry 开始，可抽象从输入 Module：模块，在 Webpack 中一切皆模块，一个模块对应着一个文件 Chunk：代码块，一个 Chunk 由多个模块组合而成，用于代码合并和分割 Loader：模块转换器，用于把模块原内容按照需求转换成新内容 Plugin：扩展插件，在 Webpack 构建流程中注入扩展逻辑来改变扩展结果 Ouptput：输出结果，经过 Webpack 一系列处理得到的最终结果 Webpack 启动后会从 Entry 里配置的 Module 开始递归解析 Entry 依赖的所有 Module。 每找到一个 Module， 就会根据配置的 Loader 去找出对应的转换规则，对 Module 进行转换后，再解析出当前 Module 依赖的 Module。 这些模块会以 Entry 为单位进行分组，一个 Entry 和其所有依赖的 Module 被分到一个组也就是一个 Chunk。最后 Webpack 会把所有 Chunk 转换成文件输出。 在整个流程中 Webpack 会在恰当的时机执行 Plugin 里定义的逻辑。 2.配置 配置 Webpack 的方式有两种： 通过一个 JavaScript 文件描述配置，例如使用 webpack.config.js 文件里的配置 通过命令行参数传入，例如 webpack --devtool source-map 2.1. Entry entry 是配置模块的入口，可抽象成输入，Webpack 执行构建的第一步将从入口开始搜寻及递归解析所有入口依赖的模块 2.1.1. context Webpack 在寻找相对路径的文件时会以 context 为根目录，context 默认为执行启动 Webpack 所在的当前工作目录。如果想改变 context 的默认配置，则可以在配置文件中这样设置它： module.exports = { context: path.resolve(__dirname, 'app') } context 必须是一个绝对路径的字符串 2.1.2. Entry 类型 Entry 类型可以是以下三种中的一种或者相互组合： string：'./app/entry' 入口模块的文件路径，可以是相对路径 array：['./app/entry1', './app/entry2'] 入口模块的文件路径，可以是相对路径 object：{a: './app/entry-a', b: './app/entry-b'} 配置多个入口，每个入口生成一个 chunk 2.1.3. chunk 名称 Webpack 会为每个生成的 chunk 取一个名称，Chunk 的名称和 Entry 的配置有关： 如果是 entry 是一个 string 或 array，就只会生成一个 Chunk，这时候 Chunk 的名称是 main 如果entry 是一个 Object，就可能会出现多个 Chunk，这时候 Chunk 的名称是 Object 里面的键值的名称 2.1.4. 配置动态 Entry 假如项目里有多个页面需要为每个页面的入口配置一个 Entry，但这些页面的数量可能会不断增长，这时候 Entry 的配置会受到其它因素的影响导致不能写成静态的值，所以需要设置成一个函数动态的放回上面的配置： // 同步函数 entry: () => { return { a:'./pages/a', b:'./pages/b', } }; // 异步函数 entry: () => { return new Promise((resolve)=>{ resolve({ a:'./pages/a', b:'./pages/b', }); }); }; 2.1.5. ,,, 3. 实战 如何用 Webpack 去解决世纪项目中常见的场景，按照不同的场景划分成以下几类 使用新语言：ES6、TypeScript、Flow、SCSS、PostCSS 使用新框架：React、Vue、Angular 单页应用：为单页应用生成 HTML、管理多个单页应用 不同环境的项目：构建同构应用、构建 ELectron 应用、构建 Npm 模块、构建离线应用 搭配其它工具使用：Npm Script、检查代码、通过 Node.js API 启动 Webpack、使用 Webpack Dev Middleware 加载特殊类型的资源：加载图片、加载 SVG、加载 Source Map 3.1. 使用 ES6 语言 虽然目前部分浏览器和 Node.js 已经支持 ES6，但由于它们对 ES6 所有的标准支持不全，这导致在开发中不敢全面地使用 ES6，所以需要把ES6 编写的代码转换成目前已经支持良好的 ES5 代码，这包含 2 件事： 把新的 ES6 语法用 ES5 实现，例如 ES6 的 class 用 ES5 的 prototype 实现 给新的 API 注入 polyfill，例如项目使用 fetch API 时，只有注入对应的 polyfill 后才能在低版本浏览器中正常运行 3.1.1. Babel Babel 可以方便的完成以上两件事，Babel 是一个 JavaScript 编译器，能将 ES6 代码转为 ES5 代码。在 Babel 执行编译的过程中，会从项目根目录下的 .babelrc 文件读取配置。.babelrc 是一个 JSON 格式的文件，内容大致如下： { \"plugins\": [ [ \"transform-runtime\", { \"polyfill\": false } ] ], \"presets\": [ [ \"es2015\", { \"modules\": false } ], \"stage-2\", \"react\" ] } plugins 属性告诉 Babel 要使用哪些插件，插件可以控制如何转换代码 presets 属性告诉 Babel 要转换的源码使用了哪些新的语法特性 3.2. 使用 TypeScript 语言 TypeScript 是 JavaScript 的一个超集，主要提供了类型检查系统和对 ES6 语法的支持，但不支持新的 API，目前没有任何环境支持原生的 TypeScript 代码，必须通过构建把它转换成 JavaScript 代码后才能运行 TypeScript 官方提供了能把 TypeScript 转换成 JavaScript 的编译器，你需要在当前项目根目录下新建一个用于配置编译选项的 tsconfig.json 文件，编译器默认会读取和使用这个文件，配置内容大致如下： { \"compilerOptions\": { \"module\": \"commonjs\", // 编译出的代码采用的模块规范 \"target\": \"es5\", // 编译出的代码采用 ES 的哪个版本 \"sourceMap\": true // 输出 Source Map 方便调试 }, \"exclude\": [ // 不编译这些目录里的文件 \"node_modules\" ] } 通过 npm install -g typescript 安装编译器到全局后，可以哦通过 tsc hello.ts 命令编译出 hello.js 和 hello.js.map 文件 3.2.1 集成 Webpack 要让 Webpack 支持 TypeScript，需要解决以下 2 个问题： 通过 Loader 把 TypeScript 转换成 JavaScript Webpack 在寻找模块对应的文件时需要尝试 ts 后缀 相关配置： const path = require('path'); module.exports = { // 执行入口文件 entry: './main', output: { filename: 'bundle.js', path: path.resolve(__dirname, './dist'), }, resolve: { // 先尝试 ts 后缀的 TypeScript 源码文件 extensions: ['.ts', '.js'] }, module: { rules: [ { test: /\\.ts$/, loader: 'awesome-typescript-loader' } ] }, devtool: 'source-map',// 输出 Source Map 方便在浏览器里调试 TypeScript 代码 }; 3.3. 使用 React 框架 其中 JSX 语法是无法在任何现有的 JavaScript 引擎中运行的，所以在构建过程中需要把源码转换成可以运行的代码，例如： // 原 JSX 语法代码 return hello, world // 转换成正常的 JavaScript 代码 return React.createElement('h1', null, 'Hello, world') 目前 Babel 和 TypeScript 都提供了对 React 语法的支持，下面分别来介绍如何在使用 Babel 或 TypeScript 的项目中接入 React 框架 3.3.1 React 与 Babel 要在使用 Babel 的项目中接入 React 框架，只需要加入 React 所依赖的 Presets babel-preset-react，安装完依赖后，再修改 .babelrc 配置文件加入 React Presets： \"presets\": [\"react\"] 3.3.2. React 与 TypeScript TypeScript 相比于 Babel 的优点在于它原生支持 JSX 语法，你不需要重新安装新的依赖，只需修改一行配置。 但 TypeScript 的不同在于： 使用了 JSX 语法的文件后缀必须是 tsx。 由于 React 不是采用 TypeScript 编写的，需要安装 react 和 react-dom 对应的 TypeScript 接口描述模块 @types/react 和 @types/react-dom 后才能通过编译。 3.4 使用 Vue 框架 Vue 是一个渐进式的 MVVM 框架，想比于 React、Angular 它更灵活。它不会强制性地内置一些功能和语法，你可以根据自己的需要一点一点地添加功能，威力方便编码，大多数项目都会采用 Vue 官方的单文件组件的写法去编写项目。Vue 和 React 一样，它们都推崇组件化和由数据驱动视图的思想，视图和数据绑定再一起，数据改变视图会跟着改变，而无需直接操作视图 3.4.1 接入 Webpack 目前最成熟和流行的开发 Vue 项目的方式都是采用 ES6 加 Babel 转换，这和基本的采用 ES6 开发的项目很相似，区别在于要解析 .vue 格式的单文件组件，好在 Vue 官方提供了对应的 vue-loader 可以很方便的完成单文件组件的转换，修改 Webpack 配置如下： module: { rules: [ { test: /\\.vue$/, use: ['vue-loader'], }, ] } vue-loader：解析和转换 .vue 文件，提取出其中的逻辑代码 script，样式代码 style，以及 HTML 模板 template，再分别把他们交给对应的 loader 去处理 3.4.2. 使用 TypeScript 编写 Vue 应用 从 Vue 2.5.0+ 版本开始，提供了对 TypeScript 的良好支持，使用 TypeScript 编写 Vue 是一个很好的选择，因为 TypeScript 能检查出一些潜在的错误 新增 tsconfig.json 配置文件，内容如下： { \"compilerOptions\": { // 构建出 ES5 版本的 JavaScript，与 Vue 的浏览器支持保持一致 \"target\": \"es5\", // 开启严格模式，这可以对 `this` 上的数据属性进行更严格的推断 \"strict\": true, // TypeScript 编译器输出的 JavaScript 采用 es2015 模块化，使 Tree Shaking 生效 \"module\": \"es2015\", \"moduleResolution\": \"node\" } } Webpack 配置如下： const path = require('path'); module.exports = { resolve: { // 增加对 TypeScript 的 .ts 和 .vue 文件的支持 extensions: ['.ts', '.js', '.vue', '.json'], }, module: { rules: [ // 加载 .ts 文件 { test: /\\.ts$/, loader: 'ts-loader', exclude: /node_modules/, options: { // 让 tsc 把 vue 文件当成一个 TypeScript 模块去处理，以解决 moudle not found 的问题，tsc 本身不会处理 .vue 结尾的文件 appendTsSuffixTo: [/\\.vue$/], } }, ] }, }; ,,, 4. 优化 优化开发体验的目的是为了提升开发时的效率，其中又可以分为以下几点： 优化构建速度：缩小文件搜索范围、使用 DllPlugin、HappyPack、ParalleUglifyPlugin 优化使用体验：使用自动刷新，开启模块热替换 优化输出质量的目的是为了给用户呈现体验更好的网页，例如减少首屏加载时间、提升性能流畅度等： 减少首屏加载时间：区分环境、压缩代码、CDN 加速、使用 Tree Shaking、提取公共代码、按需加载 提升流畅度，也就是提升代码性能：使用 Prepack、开启 Scope Hoisting ，，， 5. 原理 了解 Webpack 整体架构、工作流程，学会区分一个功能的实现是通过 Loader 合适还是 Plugin 更合适 5.1 工作原理概括 Webpack 以其使用简单著称，在使用它的过程中，使用者只需把它当作一个黑盒，需要关心的只有它暴露出来的配置 5.1.1. 流程概括 Webpack 的运行流程是一个串行的过程，从启动到结束会依次执行以下流程： 初始化参数 开始编译 确定入口 编译模块 完成模块编译 输出资源 输出完成 5.1.2. 流程细节 Webpack 构建流程可以分为以下三大阶段： 初始化：启动构建，读取与合并配置参数，加载 Plugin，实例化 Comiler 编译：从 Entry 发出，针对每个 Module 穿行调用对应的 Loader 去翻译文件内容，再找到该 Module 依赖的 Module，递归的进行编译处理 输出：对编译后的 Module 组合成 Chunk，把 Chunk 转换成文件，输出文件系统 ，，， "},"font/WebSocket.html":{"url":"font/WebSocket.html","title":"WebSocket","keywords":"","body":"WebSocket [toc] 知乎 教程 概念 WebSocket是一种通信协议，可在单个TCP连接上进行全双工通信。WebSocket使得客户端和服务器之间的数据交换变得更加简单，允许服务端主动向客户端推送数据。在WebSocket API中，浏览器和服务器只需要完成一次握手，两者之间就可以建立持久性的连接，并进行双向数据传输。 WebSocket.onopen： 连接成功后的回调 WebSocket.onclose： 连接关闭后的回调 WebSocket.onerror： 连接失败后的回调 WebSocket.onmessage： 客户端接收到服务端数据的回调 webSocket.bufferedAmount： 未发送至服务器的二进制字节数 WebSocket.binaryType： 使用二进制的数据类型连接 WebSocket.protocol ： 服务器选择的下属协议 WebSocket.url ： WebSocket 的绝对路径 WebSocket.readyState： 当前连接状态，对应的四个常量 WebSocket.CONNECTING: 0 WebSocket.OPEN: 1 WebSocket.CLOSING: 2 WebSocket.CLOSED: 3 方法： WebSocket.close() 关闭当前连接 WebSocket.send(data) 向服务器发送数据 Frp gitHub doc frp是一种快速反向代理，可帮助您将NAT或防火墙后面的本地服务器公开到Internet。到目前为止，它支持TCP和UDP以及HTTP和HTTPS协议，在这些协议中，请求可以通过域名转发到内部服务。 "},"font/被删的前端游乐园.html":{"url":"font/被删的前端游乐园.html","title":"被删的前端游乐园","keywords":"","body":"被删的前端游乐园 博客地址 [toc] 感想 先粗略的看了一遍，写的真的好，前端入门梳理出了前端的大概的东西，被删佬的文字也很吸引人 "},"font/浏览器.html":{"url":"font/浏览器.html","title":"浏览器","keywords":"","body":"浏览器 location 对象允许我们读取当前的 url， 并且可以将浏览器重定向到新的 url DOM 将 HTML 表示为标签的树形结构 在 DOM 中， null 就意味着不存在 子节点 子孙元素 childNodes 集合列出了所有子节点，包括文本节点 firstChild lastChild hasChildNodes sibling 可以使用 for of 对集合进行迭代，不能使用 for in 来迭代集合 children 仅作为元素节点的子代的节点 firstElementChild parentElement table.rows 元素的结合 节点属性：type，tag 和 content 可以使用 instanceof 来检查继承 console.log console.dir 给定一个 DOM 节点，我们可以从 nodeName 或者 tagName 属性中来读取它的标签名 innerHTML 可以加入元素进去， outerHTML 属性包含了元素的完整 HTML querySelector querySelectroAll 与 innerHTML 不同，写入 outerHTML 不会改变元素，而是在 DOM 中替换它 innerHTML 仅对元素节点有效， nodeValu 和 data 属性两者在实际使用中作用几乎相同 hidden 与 style=\"display:none\" 做的是相同的事，但是 hidden 更简洁 特性和属性（Attributes and properties），大多数标准的HTML特性（attributes）会自动变成 DOM 对象的属性 // 创建一个div let div = document.createElement('div') div.className = 'alert' div.innerHTML = 'hi' document.body.append(div); before after preappend append node.remove() elem.cloneNode(true) elem.cloneNode(false) elem.innerHTML 会识别标签的， elem.append(document.createTextNode(text)) elem.textContent = text 只是单纯的替换里面的文本 let ul = document.createElement('ul') document.body.append(ul) while(true) { let data = prompt('Enter the text for the list item', ''); if(!data){ break; } let li = document.createElement('li'); li.textContent = data; ul.append(li) } 遍历对象最简单的就是使用递归 将一个对象变成一个列表 let data = { \"Fish\": { \"trout\": {}, \"salmon\": {} }, \"Tree\": { \"Huge\": { \"sequoia\": {}, \"oak\": {} }, \"Flowering\": { \"apple tree\": {}, \"magnolia\": {} } } }; function createTree(container, obj) { container.innerHTML = createTreeText(obj); } function createTreeText(obj) { let li = ''; let ul; for (let key in obj) { li += '' + key + createTreeText(obj[key]) + ''; } if(li) { ul = '' + li + ' 样式和类，相较于将样式写入style属性，我们应该首选通过css类的方式来添加样式，仅当类无法处理时，才选择style属性的方式 elem.className 对应于 class 特性，elem.classList 是一个特殊的对象，它具有 add/remove/toggle 单个类的方法 elem.style 是一个对象，对应与 style 特性中所写的内容 document.body.style.display = 'none' setTimeout(() => document.body.style.display = '', 1000) style属性仅对 style 特性值起作用，而没有任何的css级联，因此我们无法使用 elem.style 读取来自 css 类的任何内容 let computedStyle = getComputedStyle(document.body) alert(computedStyle.marginTop) alert(computedStyle.color) CSS 的全名叫做 Cascading Style Sheets，翻译为层叠样式表，也可以叫做级联样式表，层叠：可以简单理解为冲突的解决方案 计算（computed) 样式值是所有 css规则和 css 继承都应用后的值，这是这是css级联（cascade）的结果，它看起来像是 height: 1em 或 font-size: 125% 解析样式值是最终应用于元素的样式值，单位是固定的，且绝对单位，如 height: 20px 很久以前就有 getComputedStyle 来获取计算值，但事实证明，解析值要方便得多，所以现在getComputedStyle实际上返回的是属性的解析值 注意滚动条，如果没有滚动条，内容宽度将是300px，因为有了滚动条，所以宽度会有所减少 如果元素中有很多文本，并且溢出了，那么浏览器会在 padding-bottom 处显示溢出文本 offsetWidth/Height 这两个属性是最简单的，它们提供了元素的外部 width/height ，换句话说，它的完整大小（包括边框） // 用来检查一个元素是否被隐藏 function isHidden(elem) { return !elem.offsetWidth && !elem.offsetHeight } clientLeft 左边框宽度， clientTop 上边框宽度 为了获取窗口（window）的宽度和高度，我们可以使用document.documentElement 的 clientWidth/clientHeight 大多数情况下，我们需要可用的窗口宽度以绘制或放置某些东西 DOCTYPE 很重要，当 HTML 中没有 时，顶层几何属性的工作方式可能有所不同，在现代 HTML中，我们始终都应该写 DOCTYPE 必须在 DOM 完全构建好之后才能通过 js 滚动页面 大多数 js 方法处理的是以下两种坐标系中的一个： 相对于窗口，类似于 position: fixed ，从窗口的顶部/左侧边缘计算得出，表示为 clientX/clientY 相对于文档，类似于 position: absolute ，从文档的顶部/左侧边缘计算得出， 表示为 pageX/pageY elem.getBoundingClientRect() 返回最小矩形的窗口坐标，属性：x/y 矩形原点相对于窗口的 x/y 坐标，width/height 浏览器事件 为了对事件做出响应，我们可以分配一个处理程序，一个在事件发生时运行的函数，处理程序是在 action 时运行 JavaScript 代码的一种方式，有几种处理程序的方法 HTML 特性 处理程序可以设置在html 中名为 on 的特性（attribute）中 html 特性不是编写大量代码的好地方，因此我们最好创建一个 JavaScript 函数，然后在 html 特性中调用这个函数 html 特性名是大小写不敏感 DOM 属性 我们可以使用 DOM 属性 on 来分配处理程序 elem.onclick = function() { alert('thank you') } elem.onclick = function() { alert('after'); } 移除一个处理程序，赋值 elem.onclick = null 访问元素：this 处理程序中 this 的值是对应的元素，也就是处理元素所在的那个元素 click me 可能出现的错误 button.onclick = sayThanks; button.onclick = sayThanks; // 错误 但在标记中，我们确实需要括号 addEventListener 上述分配处理程序的方式的根本问题是：我们不能为一个事件分配多个处理程序 假如，我们点击一个按钮，一部分想要高亮，一部分想要显示信息，新的dom属性会覆盖现有的dom属性，移除是removeEventListener element.addEventListener(event, handler[, options]); options 具有以下属性的附加可选对象：once capture passive 如果我们不讲函数存储在一个变量，那么我们就无法移除它 function handler1() { alert('thanks!') } function handler2() { alert('thanks again!') } elem.onclick = () => alert('Hello') elem.addEventListener('click', handler1) elem.addEventListener('click', handler2) 有些事件只能通过 addEventListener 处理设置程序，如 DOMContentLoaded 事件对象 elem.onclick = function(event) { alert(event.type + ' at ' + event.currentTarget) alert('coordinates: ' + event.clientX + ':' event.clientY) } event 对象的一些属性：event.type event.currentTarget event.clientX/clientY 无论 addEventListener 怎样，button.onclick 处理程序都会触发 冒泡与捕获 当一个事件发生在一个元素上，它会首先运行在该元素上的处理程序，然后运行其父元素的处理程序，然后一直向上到其它祖先的处理程序 引发事件的那个嵌套层级最深的元素称为目标元素，可以通过 event.target 访问 停止冒泡： event.stopPropagation() 捕获与冒泡允许我们实现一种被称为事件委托的事件处理模式，即如果我们有许多以类似方式处理的元素，我们就不必为每个元素分配一个处理程序，而是将单个处理程序放在它们的共同祖先上 let selectedTd; table.onclick function(event) { // let target = event.target; // if(target.tagName != 'TD') return; let td = event.target.closest('td'); if(!td) return; // 先判断是否存在td if(!table.contains(td)) return; // 判断table中是否有td heightLight(target); } function heightLight(td) { if(selectedTd) { selectedTd.classList.remove('heighlight') } selectedTd = td; selectedTd.classList.add('highlight'); } 委托示例： 标记中的行为 例如，我们想要编写一个有“保存”、“加载”和“搜索”等按钮的菜单。并且，这里有一个具有 save、load 和 search 等方法的对象。如何匹配它们？ 第一个想法可能是为每个按钮分配一个单独的处理程序。但是有一个更优雅的解决方案。我们可以为整个菜单添加一个处理程序，并为具有方法调用的按钮添加 data-action 特性（attribute）： Click to save Save Load Search class Menu{ constructor(elem) { this._elem = elem; elem.onclick = this.onClick.bind(this); } save() {} load() {} search() {} onClick(event) { let action = event.target.dataset.action if(action) { this[action] (); } } } new Menu(menu) 行为： 切换器 点击一个具有 data-toggle-id 特性的元素将显示/隐藏 具有给定id 的元素： show the subscription from your mail: document.addEventListener('click', function(event) { let id = event.target.dataset.toggleId; if(!id) return; let elem = document.getElementById(id); elem.hidden = !elem.hidden }) 树形菜单 将每个树节点的标题都包装到 中。然后我们可以在 :hover 上使用 CSS 样式，并精确地处理文本上的点击事件，因为 的宽度恰好是文本的宽度（与没有宽度不同）。 为 tree 的根节点设置一个处理程序，来处理 标题上的点击事件。 for (let li of tree.querySelectorAll('li')) { let span = document.createElement('span'); li.prepend(span); span.append(span.nextSibling); // move the text node into span } // catch clicks on whole tree tree.onclick = function(event) { if (event.target.tagName != 'SPAN') { return; } let childrenContainer = event.target.parentNode.querySelector('ul'); if (!childrenContainer) return; // no children childrenContainer.hidden = !childrenContainer.hidden; } 许多事件会自动触发浏览器执行某些行为。 点击一个链接 —— 触发导航（navigation）到该 URL。 点击表单的提交按钮 —— 触发提交到服务器的行为。 在文本上按下鼠标按钮并移动 —— 选中文本。 表单熟悉和方法 表单（form）以及 （input）的控件（control）元素有许多特殊的属性和事件 当我们有一个表单之后，任何元素都可以通过命名的集合 form.elements 来获取到 let form = document.forms.my let elem = from.elements.one alert(elem.value) Fieldset 作为 子表单 反向引用 element.form input.value, input.checked, select 有三个重要的属性 options, value, selectedIndex 提交表单时，会触发 submit 事件，它通常用于在将表单发送到服务器之前对表单进行校验，或者中止提交 HTML 页面的生命周期包含三个重要事件： DOMContentLoaded —— 浏览器已完全加载 HTML，并构建了 DOM 树，但像 和样式表之类的外部资源可能尚未加载完成。 load —— 浏览器不仅加载完成了 HTML，还加载完成了所有外部资源：图片，样式等。 beforeunload/unload —— 当用户正在离开页面时。 每个事件都是有用的： DOMContentLoaded 事件 —— DOM 已经就绪，因此处理程序可以查找 DOM 节点，并初始化接口。 load 事件 —— 外部资源已加载完成，样式已被应用，图片大小也已知了。 beforeunload 事件 —— 用户正在离开：我们可以检查用户是否保存了更改，并询问他是否真的要离开。 unload 事件 —— 用户几乎已经离开了，但是我们仍然可以启动一些操作，例如发送统计数据。 当浏览器加载 HTML 时遇到 ... 标签，浏览器就不能继续构建 DOM。它必须立刻执行此脚本。对于外部脚本 也是一样的：浏览器必须等脚本下载完，并执行结束，之后才能继续处理剩余的页面。 这会导致两个重要的问题： 脚本不能访问到位于它们下面的 DOM 元素，因此，脚本无法给它们添加处理程序等。 如果页面顶部有一个笨重的脚本，它会“阻塞页面”。在该脚本下载并执行结束前，用户都不能看到页面内容： 幸运的是，这里有两个 特性（attribute）可以为我们解决这个问题：defer 和 async。 defer 特性仅适用于外部脚本 async async 特性与 defer 有些类似。它也能够让脚本不阻塞页面。但是，在行为上二者有着重要的区别。 async 特性意味着脚本是完全独立的： 浏览器不会因 async 脚本而阻塞（与 defer 类似）。 其他脚本不会等待 async 脚本加载完成，同样，async 脚本也不会等待其他脚本。 DOMContentLoaded 和异步脚本不会彼此等待： DOMContentLoaded 可能会发生在异步脚本之前（如果异步脚本在页面完成后才加载完成） DOMContentLoaded 也可能发生在异步脚本之后（如果异步脚本很短，或者是从 HTTP 缓存中加载的） 动态脚本 此外，还有一种向页面添加脚本的重要的方式。 我们可以使用 JavaScript 动态地创建一个脚本，并将其附加（append）到文档（document）中： let script = document.createElement('script') script.src = ',,,' document.body.append(script) 默认情况下，动态脚本的行为是 异步 的 但是可以设置 script.async = false ，则可以改变这个规则 跨源策略 这里有一条规则： 来自一个网站的脚本无法访问其它网站的内容，更确切的说，一个源（域/端口/协议三者）无法获取另外一个源（origin）的内容 要允许跨域， 标签需要具有 crossorigin 特性，并且远程服务器提供特殊的header 这里有三个级别的跨源访问： 无 crossorigin 特性： 禁止访问 crossorigin='anonymous'： 如果服务器的响应带有包含 * 或我们的源的 header Access-Control-Allow-Origin ，则允许访问，浏览器不会将授权信息和 cookie 发送到远程服务器 crossorigin='use-credentials'： 如果服务器发送带有我们源的header Access-Control-Allow-Origin 和 Access-Control-Allow-Credentilas: true 则允许访问，浏览器会将授权信息和 cookie 发送到远程服务器 通常，图片在被创建时才会被加载。所以，当我们向页面中添加 时，用户不会立即看到图片。浏览器首先需要加载它。 为了立即显示一张图片，我们可以“提前”创建它，像这样： let img = document.creteElement('img') img.src = 'my.jpg' function preloadImages(sources, callback) { let counter = 0; function onLoad() { counter++; if (counter == sources.length) callback(); } for(let source of sources) { let img = document.createElement('img'); img.onload = img.onerror = onLoad; img.src = source; } } // ---------- The test ---------- let sources = [ \"https://en.js.cx/images-load/1.jpg\", \"https://en.js.cx/images-load/2.jpg\", \"https://en.js.cx/images-load/3.jpg\" ]; // add random characters to prevent browser caching for (let i = 0; i "},"font/图解HTTP.html":{"url":"font/图解HTTP.html","title":"图解HTTP","keywords":"","body":"图解HTTP [toc] temp, 第一遍大概的看了一些 TCP/IP： 应用层、传输层、网络层、数据链路层 http请求 分割，标记序号和端口号 MAC地址 IP地址的两个重要的条件： IP地址和MAC地址（Media Access Control Access） ip地址是节点被分配的地址，mac地址是网卡所属的固定地址 ARP协议凭借 MAC地址进行通信，根据通信方的 ip地址就可以反查出对应的 mac地址 tcp提供可靠的字节流服务，为了准确的将数据送到目标，tcp协议采用了三次握手策略： 标有syn的数据包发给你了， 我收到你发给我的数据包了（syn/ack的数据包），明白（发送ack的数据包） DNS（domain name system）服务是和http协议一样位于应用层的协议，它提供域名到ip地址之间的解析服务： 我想访问某网页，把它的IP告诉我吧， 它是xx， 我向xx发送请求了 http协议的职责是生成针对目标web服务器的http请求报文 URI 和 URL(uniform resource locator) 请求报文的构成：方法、uri、协议版本、请求首部字段、内容实体 响应报文的构成：协议版本 状态码 原因短语 响应首部字段 主体 http是一种不保存状态的协议，但是有了Cookie就可以管理状态了 HTTP方法： get：我想访问你的某个资源啊 post：我要把这条信息告诉你 put：我要把这份文件传给你 head：把那个相关的信息告诉我 delete：快把那份文件删掉吧 options：你支持哪些方法哇 connect：让我通过一下吧 必须进行多次通信好累啊，所有连接默认都是持久连接 管线化可以看成是异步吗 cookie技术通过在请求和响应报文中写入cookie信息来控制客户端的状态，cookie会根据从服务端发送的响应报文中的一个叫做set-cookie的首端字段信息，通知客户端保存cookie，下次客户端再往该服务器发送请求时会自动在报文中加入cookie 生成cookie，记住是向谁发送的 啊，原来是刚才那家伙哇 http报文大致可以分为报文首部和报文主题两块 编码以提升传输速率： 紧紧的压缩 多部分对象集合包含的对象如下： multipart/form-data multipart/byteranges range: 把那剩余的部分给我 206 内容协商（content negotiation）返回最合适的内容 状态码告知从服务器端返回结果：2xx，进展很顺利 4xx，5xx似乎不行啊 1正在处理 2正常处理完毕 3重定向 4服务器无法处理请求 5服务器处理请求出错 204 没资源返回 206我只要一部分 301资源的uri已经更新，你也更新一下吧 302资源临时定位到其它位置了，暂时你换个uri访问吧 303uri已经更新，你要按新的来访问吗 304资源已找到，但是不符合要求 307我和302差不多 400 我无法理解这个请求，是不是错了 401我需要认证的 403不允许访问那个资源啊 404服务器上没有该资源啊 500貌似内部资源出故障了 503抱歉，我正在忙呢 状态码和状态经常不一致，有时候后端已经出错了，但是也返回了 200 ok 的状态码 用单台虚拟主机实现多个域名，若是部署在同一个服务器上，它们的ip地址会相同，由于相同的ip地址，所以在发送HTTP请求时必须在host首部内完整指定主机名或域名的uri 通信数据转发程序：代理、网关、隧道 报文首部：在客户端和服务器处理时起至关重要作用的信息几乎都在这里 报文主体：所需要的用户和资源的信息都在这里 HTTP首部字段传递重要信息，首部字段是由首部字段名和字段值组成，中间用： 分隔，首部字段分为以下四种：通用首部字段、请求首部字段、响应首部字段、实体首部字段 端到端首部，逐跳首部 Cache-Control操作缓存的工作机制：如果有缓存请给我、我喜欢你不要对此做缓存 Cache-Control: private：这份缓存只可以提供给那个家伙使用喔 Cache-Control: no-cache：我不要缓存过的，请给我从源服务器那里拿来资源 你可以缓存，但每次使用前先向我确认一下 Cache-Control: max-age=604800：要是缓存没超过一周，就把他给我吧 一周内不必向我确认，你直接支配该缓存就好了 Connection: 控制不在转发给代理的首部字段，管理持久连接：把这个删除后再转发喔 这下我和你的关系结束了 Accept：该字段可通知服务器，用户代理能够处理的媒体类型以及媒体类型的优先级 http + 加密 + 认证 + 完整性 = https websocket 1. 了解Web及网络基础 框架 TCP/IP协议簇分为四层：应用层（FTP（file transition protocol）、DNS（domain name system））、传输层（TCP（transition control protocol）、UDP（user data protocol））、网络层（Internet protocol）、链路层 应用层：决定向用户提供用户服务时的通信活动 传输层：提供网络连接中两台计算机之间的数据传输 网络层：处理网络上流通的数据包，规划路径 链路层：处理连接网络的硬件部分 TCP/IP通信传输流 负责传输的IP协议 TCP/IP协议簇的IP指的就是网络协议，在名称中就占据了一半的位置，可见其重要性。 IP协议是 Internet Protocol，它包括 IP 地址和 MAC(media access control address) IP 地址和 MAC地址的区别 IP协议的作用是把各种数据包传送给对方，而要保证确实传送到对方那里，则需要满足各类条件，其中最重要的两个条件是 IP 地址和 MAC 地址，IP地址指明了节点被分配的地址，MAC地址指明了网卡所属的固定地址 利用 ARP 协议凭借 MAC 地址进行通信 IP 间的通信依赖 MAC 地址，在网络上，通信的双方在同一局域网（LAN）的情况是很少的，通常要经过多次中转才能连接对方。而在进行中转时，会利用下一站中转设备的MAC地址来搜索下一个中转目标。ARP协议通过ip地址反查出mac地址 确保可靠性的 TCP 协议 TCP协议位于传输层，提供可靠的字节流服务 字节流服务：为了方便将大块数据分割以报文段（segment）为单位的数据包进行管理。TCP协议为了更容易传送大数据才把数据分割，而TCP协议能够确认数据最终是否传送给了对方 确保数据能够到达目标 为了确保无误的将数据送达目标处，TCP协议采用了三次握手（three-way handshaking），四次挥手策略 三次握手，四次挥手 其它 DNS（Domain Name System）服务是和HTTP协议一样位于应用层的协议，它提供域名到IP地址之间的解析服务 各种协议与HTTP协议之间的关系 URL(uniform resource locator) 统一资源定位符 URI（uniform resource identifier）统一资源标识符 url 就是使用定位的方式实现 uri 2. 简单的HTTP协议 针对HTTP协议的结构进行讲解，主要是 HTTP/1.1 版本 基础概念 HTTP 协议用于客户端和服务端之间的通信，在应用 HTTP 协议的时候，必定是一端担任客户端，一端担任服务端。HTTP 通过请求和响应达成通信，请求必定是由客户端发出，然后服务端才进行响应。请求报文是由请求方法、请求 URI、协议版本、可选的请求首部字段和内容实体构成的： POST /form/entry HTTP/1.1 Host: hacker.jp Connection: keep-alive Content-Type: application/x-www-form-urlencoded Content-Length: 16 name=test&age=20 接收到请求的服务器，会将请求内容的处理结果以响应的形式返回，响应通常是由协议版本，状态码，状态码原因短语，响应首部字段，实体主体组成： HTTP/1.1 200 OK Date: Tue, 10 Jul 2012 06:50:15 GMT Content-Length: 555 Content-Type: text/html ... HTTP 是不保持状态的协议，HTTP 协议自身不对请求和响应之间的通信状态进行保存。使用 HTTP 协议，每当有新的请求发送时，就会有对应的新的响应产生。协议本身并不保留之前一切的请求或响应报文的信息，这是为了更快的处理大量事物，并确保协议的可伸缩性，而特意把 HTTP 协议设计的如此简单的。但是有些时候期望能够保持状态，就慢慢发展了 Cookie、Session、WebSocket 等技术 请求 URI HTTP 协议利用请求 URI 定位资源，请求 URI 的方式主要由三种： 完整的 URI 请求 GET http://test.com/index.htm HTTP/1.1 在首部字段写明域名或者 IP 地址 GET /index.htm HTTP/1.1 Host: test.com 不是访问特定资源，只是对服务器本身发起请求，用 * 代替 URI OPTIONS * HTTP/1.1 Host: test.com 持久连接节省通信量 在 HTTP 协议的初始版本中，每进行一次 HTTP 通信就要断开一次 TCP 连接。以当年的通信情况来说，因为都是些小容量的文本传输，所以即使这样传输也没有什么问题。可随着 HTTP 的普及，文档中包含大量图片的情况多了起来。比如使用浏览器浏览一个包含多张图片的 HTML 页面时，在发送请求 HTML 页面的同时，也会请求页面中包含的图片等资源。因此，每次请求都会造成无谓的 TCP 连接建立和断开，增加通信的开销 为了解决上述问题， HTTP/1.1 和 一部分的 HTTP/1.0 提出了持久连接（HTTP Persistent Connections，也称为 HTTP keep-alive 或 HTTP connection reuse）方法。持久连接的特点是只要任意一端没有明确的提出断开连接，则保持 TCP 连接状态。持久连接的好处是减少了 TCP 连接的重复建立和断开所造成的额外开销，减轻了服务器端的负载。另外，减少了开销的那部分时间， Web 页面的速度也相对提高了。在 HTTP/1.1 中，所有的连接都是默认的持久连接 持久连接使得多数请求以管线化（pipelining）方法发送成为可能。从前发送请求后需等待响应，收到响应后才能发送下一个请求。管线化技术出现后，不用等待就可以直接发送下一个请求，时间能更加节省一点 使用 Cookie 的状态管理 HTTP 是无状态协议，不对之前发生过的请求和响应的状态进行管理。也就是说，无法根据之前的状态进行本次的请求处理。但是假设要求登录认证的 Web 页面本身无法进行状态的管理（不记录已登录的状态），那么每次跳转新页面就要再次重新登录，或者要在请求报文中附加参数来管理登录状态。这时候就需要有状态管理的功能，于是引入了 Cookie 技术。Cookie 技术通过在请求和响应报文中写入 Cookie 信息来控制客户端的状态 Cookie 会根据从服务器端发送的响应报文内的一个叫做 Set-Cookie 的首部字段，通知客户端保存 Cookie。当下次客户端再往该服务发送请求时，客户端会自动在请求报文中加入 Cookie 值后发送出去。服务器发现客户端发送过来 Cookie 后，回去检查究竟是从哪个客户端发送来的连接请求，然后对比服务器上的记录，最后得到之前的状态信息 没有Cookie信息的状态： GET /reader HTTP/1.1 Host: test.com 响应报文，服务端生成 Cookie： HTTP/1.1 200 OK Date: Thu, 12 Jul 2012 07:12:20 GMT Server: Apache Set-Cookie: sid=111; path=/; expires=Wed, 10-Oct-12 07:12:20 GMT> Content-Type: text/plain charset: UTF-8 请求报文，自动发送保存着的 Cookie 信息 GET /image HTTP/1.1 Host: test.com Cookie: sid=111 HTTP 方法 HTTP 方法主要有：GET POST PUT HEAD DELETE OPTIONS GET：获取资源 GET 方法用来请求访问已被 URI 识别的资源。指定的资源经服务器解析后返回响应内容。如果请求的资源是文本，那就保持原样返回，如果是像 CGI（Common Gateway Interface，通用网关接口）那样的程序，则返回经过执行后的输出结果 GET /index.htm HTTP/1.1 Host: test.com POST: 传输实体主体 POST 方法用来传输实体主体。虽然 GET 方法也可以传输实体的主体，但一般都是使用 POST 方法。 POST /submit HTTP/1.1 Host: test.com Content-Length: 666 PUT: 传输文件 PUT 方法用来传输文件。就像 FTP 协议的文件上传一样，要求在请求报文的主体包含文件内容，然后保存到请求 URI 中指定的位置一样。但是由于 HTTP/1.1 的 PUT 方法自身不带验证机制，任何人都可以上传文件，存在安全性问题，因此一般 Web 网站也不使用该方法。若配合 Web 应用程序的验证机制，或者采用 REST 架构设计的同类 Web 网站可能就会开放使用 PUT 方法 PUT /example.htm HTTP/1.1 Host: test.com Content-Type: text/html Content-Length: 666 HEAD:获得报文首部 HEAD 方法和 GET 方法一样，只是不返回报文主体部分。用于确认 URI 的有效性及资源的更新时间等 HEAD /index.htm HTTP/1.1 Host: test.com DELETE: 删除文件 DELETE 方法用来删除文件，是与 PUT 方法相反的方法，通过 URI 请求来删除指定资源。但是 DELETE 方法和 PUT 方法一样不带验证机制，所以一般的 Web 网站也不使用 DELETE 方法。当配合 Web 应用程序的验证机制或遵守 REST 标准的时候还是有可能开放的 DELETE /example.htm HTTP/1.1 Host: test.com OPTIONS: 询问支持的方法 OPTIONS 方法用来查询针对请求 URI 指定资源的支持的方法 OPTIONS * HTTP/1.1 Host: test.com TRACE: 追踪路径 TRACE 方法是让 Web 服务器端将之前的请求通信返回给客户端的方法。发送请求时，在 Max-Forwards 首部字段填入数值，每经过一个服务端就将该数字减 1，当数值刚好减到 0 的时候，就停止继续传输，最后接收到请求的服务器端则返回状态码 200 OK 的响应。 客户端通过 TRACE 方法可以查询送出去的请求是怎么被加工修改的。这是因为请求想要想要连接到目标服务器可能会通过代理中转，TRACE 方法就是用来确认连接中发生的一系列操作的。但是 TRACE 一般都不用，再加上它容易引发 XST（Cross-Site Tracing, 跨站追踪）的攻击，通常就更不会用了 TRACE / HTTP/1.1 Host: test.com Max-Forwards: 2 CONNECT: 要求用隧道协议连接代理 CONNECT 方法要求在与代理服务器通信时建立隧道，实现用隧道协议进行 TCP 通信。主要使用 SSL（Secure Socket Layers，安全套接字）和 TLS（Transport Layer Security，传输层安全）协议把通信内容加密后利用隧道进行传输。 CONNECT test.com:8080 HTTP/1.1 Host: test.com 3. HTTP 报文内的 HTTP 信息 HTTP 通信过程包括从客户端发往服务器端的请求及从服务器端发往客户端的响应。本章主要介绍请求和响应是怎么运作的 报文及其结构 用于 HTTP 协议交互的信息称为 HTTP 报文，请求端称为请求报文，服务端称为响应报文。HTTP 报文本身是由多行（用 CR + LF 作换行符）数据构成的字符串文本。HTTP 报文大致可分为报文首部和报文主体两块。两者由最初出现的空行（CR + LF）来划分。 HTTP 报文结构 .jpg) 请求报文（上）和响应报文（下）的结构 请求行：包含用于请求的方法，请求 URI 和 HTTP 版本 状态行：包含表明响应结果的 HTTP 版本，状态码和原因短语 首部字段：包含表示请求和响应的各种条件和属性的各类首部，一般由四种首部：请求首部，响应首部，通用首部，实体首部 编码提升传输速率 HTTP 在传输数据时可以按照数据原貌直接传输，但也可以在传输过程中通过编码提升传输速率。通过在传输时编码，能有效处理大量的访问请求。但是，编码操作需要计算机来完成，所以会浪费一些 CPU 等资源 报文主体和实体主体的差异： 报文：HTTP 通信中的基本单位，由 8 位字节流（octet sequence）组成，通过 HTTP 通信传输 实体：作为通信或响应的有效载荷数据被传输，其内容由实体首部和实体主体组成 报文主体就是用于传输请求或响应的实体主体，通常报文主体就是实体主体。只有当传输过程中发生编码，实体主体的内容发生变化，才导致它和报文主体发生变化 压缩传输的内容编码 向待发送的邮件增加附件的时候，为了使邮件容量变小，会用 zip 压缩文件后再添加附件发送。 HTTP 协议中有一种被称为内容编码的功能也能进行类似的操作。内容编码指明应用在实体内容上的编码格式，并保持信息原样压缩。内容编码后的实体由客户端接收并负责解码 常用的内容编码有以下几种： gzip（GNU zip） compress（UNIX 系统的标准压缩） deflate（zlib） identity（不进行编码） 分割发送的分块传输编码 在 HTTP 通信过程中，请求的编码实体资源尚未全部传输完成之前，浏览器无法显示请求页面。在传输大容量数据时，通过把数据分割成多块，能够让浏览器逐步显示页面。这种把实体主体分块的功能称为分块传输编码（Chunked Transfer Coding） 分块传输编码会将实体主体分成多个部分。每一块都会用十六进制来标记块的大小，而实体主体的最后一块会用“0（CR+LF）”来标记。使用分块传输编码的实体主体会由接收的客户端负责解码，恢复编码前的实体主体 发送多种数据的多部分对象集合 MIME（Multipurpose Internet Mail Extension, 多用途因特网邮件扩展）允许邮件处理文本、图片、视频等多个不同类型的数据。在 MIME 扩展中会使用一种称为多部分对象集合（Multipart）的方法，来容纳多份不同类型的数据。相应的，HTTP 协议也采纳了多部分对象集合（Multipart）的方法，它的对象如下： multipart/form-data 在 Web 表单文件上传时使用 multipart/byteranges 状态码 206 响应报文包含多个范围的时候使用 如果 HTTP 要使用 Multipart，需要在首部字段里面先加上 Content-Type。使用 boundary 字符串来划分多部分对象集合指明的各类实体。多部分对象集合的每个部分类型中，都可以包含首部字段。另外，可以在某个部分中嵌套使用多部分对象集合 获取部分内容的范围请求 以前用户没有高速的带宽，如果下载过程中出现网络中断的情况，就需要重头开始。为了解决上述问题，需要一种可恢复机制。所谓恢复指能从之前下载中断处恢复下载。要实现该功能需要指定下载的实体范围。对一份10000字节大小的资源，如果使用范围请求，可以只请求 5001~10000 字节内的资源。执行范围请求时，会用到首部字段 Range 来指定资源的 byte 范围 GET /index.png HTTP/1.1 Range: bytes=5001-10000 Range: bytes=5001- 针对范围请求，响应会返回状态码 206 partial content 的响应报文。另外对于多种范围的范围请求，响应会在首部字段Content-Type 标明 multipart/byteranges 后返回响应报文 内容协商返回最合适的内容 同一个Web网站有可能存在着多份相同内容的页面。比如英语版和中文版的 Web 页面，它们内容上虽相同，但是使用的语言却不同。当浏览器的默认语言是英语或则中文的时候，访问相同的 URI 的 Web 页面则会显示对应的英文或者中文的 Web 页面，这样的机制称为内容协商机制 内容协商机制是指客户端和服务端就响应的资源进行交涉，然后提供给客户端最为合适的资源。内容协商会以语言、字符集、编码方法等为基准判断响应的资源 判断基准的首部字段如下： Accept Accept-Charset Accept-Encoding Accept-Language Content-Language 内容协商技术有以下三种类型： 服务器驱动协商：以请求的首部字段作为参考，在服务器端自动处理 客户端驱动协商：用户从浏览器显示的可选项列表中手动选择 透明协商：是服务器驱动和客户端驱动的结合体 4. 返回结果的 HTTP 状态码 HTTP 状态码负责表示客户端 HTTP 请求的返回结果、标记服务器端的处理是否正常、通知出现的错误等工作。借助状态码，用户可以知道服务器端是正常处理了请求还是出现错误。仅记录在 RFC2616 上的 HTTP 状态码就达到 40 种，算上其它的，可达到 60 种，但是实际上经常使用的只有 14种 2XX 成功 2XX 的响应结果表明请求被正常处理了 200 OK：表示从客户端发来的请求在服务器端被正常处理了 204 No Content：请求处理成功，但在返回的响应报文种不含实体的主体部分 206 Partial Content：表示客户端进行了范围请求，而服务器成功执行了这部分的 GET 请求，其中 Conent-Range 指定范围 3XX 重定向 3XX 响应结果表明浏览器需要执行某些特殊的处理以正确执行请求 301 Moved Permanently：永久性重定向，该状态码表明请求的资源已被分配了新的 URI 302 Found：临时性重定向。表示请求的资源已被分配了新的 URI，希望用户（本次）能够使用新的 URI 访问 303 See Other：另一个URI。由于请求对应的资源存在着另一个 URI，应使用 GET 方法定向获取请求的资源。303 和 302 一样，但是 303 明确表示客户端应当使用 GET 方法请求资源 304 Not Modified：资源已找到，但不符合请求。客户端发送附带条件的请求时，服务端也允许访问资源，但是因为发生请求未满足条件的情况，直接返回 304，不包含任何响应的主体部分。304 虽然划分到 3XX 类比，但是和重定向没有任何关系 307 Temporary Redirect：临时重定向。和 302 有相同的含义，差不多相同的作用 4XX 客户端错误 4XX 的响应结果表明客户端是发生错误的原因所在 400 Bad Request：表示请求报文种存在语法错误，需修改请求的内容后再次发送，浏览器回像 200 OK 一样对待该状态码 401 Unauthorized：表示发送的请求需要有通过 HTTP 认证（BASIC、DIGEST 认证）的认证信息 403 Forbidden：表明对请求资源的访问被服务器拒绝了，服务器端没有必要给出拒绝的详细理由 404 Not Found：服务器上没有请求的资源，也可以表示拒绝但是不想说明原因 5XX 服务前错误 5XX 的响应结果表明服务器本身发生错误 500 Internal Server Error：表明服务器端在执行请求时发生了错误，服务器存在一些 bug 或者一些故障 503 Service Unavailable：表明服务器暂时处于超负载或正在停机维护，现在无法处理请求。可以在响应中写入 Retry-After 表明什么时候可以恢复 状态码和状态不一致 不少返回的状态码响应都是错误的，但是用户可能察觉不到这点。比如 Web 应用程序内部已经发生错误了，但是还是返回了 200 OK，这种情况很多，自己写后台的时候尽量返回正确的响应吧，写前端的时候也多判断一层吧。 5. 与 HTTP 协作的 Web 服务器 一台 Web 服务器可搭建多个独立域名的 Web 网站，也可作为通信路径上的中转服务器提升传输效率 5.1 用单台虚拟主机实现多个域名 虚拟主机技术可以用一台服务器为多位客户服务，为每位客户的不同域名运行不同的网站 在互联网上，域名通过 DNS 服务映射到 IP 地址（域名解析）之后访问目标网站，实际上当请求发送到服务器的时候已经是通过 IP 地址的形式访问了 在相同 IP 地址的情况下，由于虚拟主机可以寄存多个不同主机名和域名的 Web 网站，因此在发送 HTTP 请求的时候，必须在 HOST 首部内完整指定主机名或域名的 URI 5.2 通信数据转发程序：代理、网关、隧道 HTTP 通信时，除了客户端和服务器以外，还有一些用于通信数据转发的应用程序：代理、网关、隧道 代理：是一种有转发功能的应用程序，它接收由客户端发送的请求并转发给服务器，同时也接收来自服务器的响应并返回给客户端 网关：网关是转发其他服务器通信数据的服务器，接收来自从客户端发送的请求时，它就像自己是拥有资源的服务器一样对请求进行处理。 隧道：隧道是在相隔甚远的客户端和服务器两者之间进行中转，并保持双方通信连接的应用连接 5.2.1 代理 代理服务器的基本行为是接收客户端发送的请求后转发给服务器。代理不改变请求 URI，会直接发送给持有资源的服务器。持有资源的服务器称为源服务器，从源服务器返回的响应经过代理服务器后在传给客户端。每次通过代理服务器转发请求或响应时，都会追加写入 Via 首部信息 在 HTTP 通信过程中，可级联多台代理服务器。请求和响应的转发会经过数台类似锁链一样连接起来的代理服务器。转发时，需要用 Via 首部字段以标记出经过的主机信息 使用代理服务器的理由有：利用缓存技术减少网络带宽的流量，组织内部针对特定的网站的访问控制，获取访问日志等目的 缓存代理：代理转发响应时，缓存代理（Caching Proxy）会预先将资源的副本保存在代理服务器上，当代理再次接收到对相同资源的请求时，就可以不从源服务器那里获取资源，直接返回缓存资源 透明代理：转发请求或响应时，不对报文做任何加工的代理类型称为透明代理，反之称为非透明代理 5.2.2 网关 网关的工作机制和代理非常像，而网关能允许通信线路上的服务器提供非 HTTP 协议服务。利用网关能提高通信的安全性，因为可以在客户端与网关之间的通信线路上加密以确保连接的安全。比如，网关可以连接数据库，通过 SQL 语句查询数据，利用在 Web 购物网站上进行信用卡结算时，网关可以和信用卡结算系统联动 5.2.3 隧道 隧道可按要求建立一条与其他服务器的通信线路，届时使用 SSL 等加密手段进行通信。隧道的目的是确保客户端能与服务器进行安全通信。通过隧道的传输，可以和远距离的服务器安全通信。隧道本身是透明的，客户端不用在意隧道的存在 5.3 保持资源的缓存 缓存是指代理服务器或客户端本地磁盘内保持的资源副本，利用缓存可减少对源服务器的访问，因此也就节省了通信流量和通信时间 5.3.1 缓存的有效期限 即便缓存服务器内有缓存，也不能保证每次都会返回对同资源的请求，因为这关系到被缓存资源的有效性问题。即使存在缓存，也会因为客户端的要求、缓存的有效期等因素，向源服务器确认资源的有效性。若判断缓存失效，缓存服务器将会再次从源服务器上获取更新的资源 5.3.2 客户端的缓存 缓存不仅可以存在于缓存服务器内，还可以存在于客户端浏览器中，以 Internet Explorer 程序为例，把客户端缓存称为临时网络文件（Temporary Internet File） 浏览器缓存如果有效，就不必再向服务器请求相同的资源了，直接从本地磁盘内读取 6. HTTP 首部 HTTP 协议的请求和响应报文中必定包含 HTTP 首部，只是我们平时在使用 Web 的过程中感受不到它，这章将 HTTP 首部的结构，以及首部中各字段的用法 6.1 HTTP 报文首部 HTTP 报文首部 在请求中，HTTP 报文由方法、URI、HTTP 版本、HTTP 首部字段等部分组成 在响应中，HTTP 报文由 HTTP 版本、状态码（数字和原因短语）、HTTP 首部字段 3 部分构成 在报文众多的字段中，HTTP 首部字段包含的信息最为丰富。首部字段同时存在于请求和响应中，并涵盖 HTTP 报文相关的内容信息 6.2 HTTP 首部字段 6.2.1 HTTP 首部字段传递重要信息 在客户端与服务端以 HTTP 协议进行通信的过程中，无论是请求还是响应都会使用首部字段，它能起到传递额外重要信息的作用。使用首部字段是为了给浏览器和服务器提供报文主体大小、所使用的语言、认证信息等内容 6.2.2 HTTP 首部字段结构 HTTP 首部字段是由首部字段名和字段值构成的，中间用冒号“：”分隔 当 HTTP 报文首部中出现了两个或两个以上具有相同首部字段时会怎样？没有具体规范，以实际情况为准，的那我们要避免这种情况的发生 6.2.3 4 种 HTTP 首部字段类型 通用首部字段：请求报文和响应报文两方都会使用的首部 请求首部字段：从客户端向服务端发送请求报文时使用的首部。补充了请求的附加内容、客户端信息、响应内容相关优先级等信息 响应首部字段：从服务器端向客户端返回响应报文时使用的首部。补充了响应的附加内容，也会要求客户端附加额外的内容信息 实体首部字段：针对请求报文和响应报文的实体部分使用的首部。补充了资源内容更新时间等与实体相关的信息 6.2.4 HTTP/1.1 首部字段一览 HTTP/1.1 规范定义了如下 47 种首部字段 表 6-1： 通用首部字段 首部字段名 说明 Cache-Control 控制缓存的行为 Connection 逐跳首部、连接的管理 Date 创建报文的日期时间 Pragma 报文指令 Trailer 报文末端的首部一览 Transfer-Encoding 指定报文主体传输编码方式 Upgrade 升级为其他协议 Via 代理服务器的相关信息 Warning 错误通知 表 6-2：请求首部字段 首部字段名 说明 Accept 用户代理可处理的媒体类型 Accept-Charset 优先的字符集 Accept-Encoding 优先的内容编码 Accept-Language 优先额自然语言 Authoriaztion Web 认证信息 Expect 期待服务器的特定行为 From 用户的电子邮箱地址 Host 请求资源所在的服务器 If-Match 比较实体标记（ETag） If-Modified-Since 比较资源的更新时间 If-None-Match 比较实体标记（与 If-Match 相反） If-Range 资源未更新时发送实体 Byte 的范围请求 If-Unmodified-Since 比较资源的跟新时间（与 If-Modified-Since 相反） Max-Forwards 最大传输逐跳数 Proxy-Authorization 代理服务器要求客户端的认证信息 Range 实体的字节范围请求 Referer 对请求中 URI 的原始获取方法 TE 传输编码的优先级 User-Agent HTTP 客户端程序的信息 表 6-3：响应首部字段 首部字段名 说明 Accept-Ranges 是否接受字节范围请求 Age 推算资源创建经过时间 ETag 资源的匹配信息 Location 令客户端重定向至指定 URI Proxy-Authenticate 代理服务器对客户端的认证信息 Retry-After 对再次发起请求的时机要求 Server HTTP 服务器的安装信息 Vary 代理服务器缓存的管理信息 WWW-Authenticate 服务端对客户端的认证信息 表6-4：实体首部字段 首部字段名 说明 Allow 资源可支持的 HTTP 方法 Content-Encoding 实体主体适用的编码方式 Content-Language 实体主体的自然语言 Content-Length 实体主体的大小（字节） Content-Location 替代对应资源的 URI Content-MD5 实体主体的报文摘要 Content-Range 实体主体的位置范围 Content-Type 实体主体的媒体类型 Expires 实体主体过期的日期 Last-Modified 资源的最后修改日期 HTTP 首部字段将定义成缓存代理和非缓存代理，分成两种类型 端到端首部（End-to-end Header）：此类别的首部会转发给请求/响应对应的最终接收目标，且必须保存在由缓存生成的响应中，另外规定它必须被转发 逐跳首部（Hop-by-hop Header）：此类别的首部只对单次转发有效，会因通过缓存或代理而不再转发，在 HTTP/1.1中，如果要使用 Hop-by-hop 首部，需提供 Connection 首部字段 逐跳字段只有以下 8 个，除此之外都是端到端首部： Conenction Keep-Alive Proxy-Authention Proxy-Authenticate Trailer TE Transfer-Encoding Upgrade 6.3 HTTP/1.1 通用首部字段 通用首部字段指请求和响应双方都会使用到的首部 6.3.1 Cache-Control 通过 cache-control 首部字段的指令，就能操作缓存的工作机制 指令参数是可选的，多个指令之间通过“，”分隔 HTTP/1.1 200 OK Cache-Control: private, max-age=0, no-cache 表6-5：缓存请求指令 指令 参数 说明 no-cache 无 强制向源服务器再次验证 no-store 无 不缓存请求或响应的任何内容 max-age=[秒] 必须 响应的最大Age值 (max-stale=[秒]) 可省略 接收已过期的响应 min-fresh=[秒] 必须 期望在指定时间内的响应仍有效 no-transform 无 代理不可更改媒体类型 only-if-cached 无 从缓存获取资源 cache-extension - 新指令标记（token） 表6-6：缓存响应指令 指令 参数 说明 public 无 可向任意方提供响应的缓存 private 可省略 仅向特定用户返回响应 no-cache 可省略 缓存前必须向确认其有效性 no-store 无 不缓存请求或响应的任何内容 no-transform 无 代理不可更改媒体类型 must-revalidate 无 可缓存但必须再向源服务器进行确认 proxy-revalidate 无 需要中间缓存服务器对缓存有效性再次确认 max-age=[秒] 必须 响应的最大 Age 值 s-maxage=[秒] 必须 公共缓存服务器响应的最大 Age 值 cache-extension - 新指令标记（token） public 指令表示任何用户都可以使用该缓存 private 指令表示特定用户可以使用该缓存 no-cache 指令从客户端的角度来说就是不要缓存，从源服务器重新获取，从服务器的角度就是缓存服务器可以缓存，但是需要向源服务器确认，使用 no-cache 指令的目的是为了防止从缓存中返回过期的资源 no-store 指令是暗示请求或响应中包含机密信息，该指令规定缓存不能在本地存储请求或响应的任一部分 Cache-Control: s-maxage=604800 s-maxage 指令的功能和 max-age 的功能差不多，但是 s-maxage 指令只适用于供多位用户使用的公共换从服务器，对于向同一用户重复返回响应的服务器来说，这个指令没有任何意义。另外，当使用 s-maxage 指令以后，则直接忽略对 Expires 首部字段和 max-age 指令的处理 Cache-Control: max-age=60480 当客户端发送的请求里面包含 max-age 指令时候，如果判定缓存服务器的时间数值比指定时间小，那么客户端就接收缓存的资源，当 max-age 的值为 0 时候，那么缓存服务器通常需要将请求转发给源服务器 当服务器返回的响应中包含 max-age 指令时候，缓存服务器将不对资源的有效性再作确认，而max-age 的数值代表资源保存为缓存的最长时间 Cache-Control: min-fresh=60 min-fresh 指令要求缓存服务器返回至少还未过指定时间的缓存资源，当指定 min-fresh 为 60 秒后，在这 60 秒以内如果有超过有限期限的资源都无法作为响应返回 Cache-Control: max-style=3600 使用 max-stale 可指示缓存资源，即使过期也照常接收，如果未指定参数，无论经过多久也接受，如果指定参数，即使资源过期也照常接收 Cache-Control: only-if-cached only-if-cached 指令表示客户端仅在缓存服务器本地缓存目标资源的情况下才会要求其返回 must-revalidate 指令使用后，代理会向源服务器再次验证即将返回的缓存是否任然有效，若代理无法连通源服务器获取到有效资源的话，返回一条 504 的状态码，使用该指令的时候会忽略 max-stale 指令 proxy-revalidate 指令要求所有缓存服务器在接收到客户端带有该指令的请求返回响应前，必须再次验证缓存的有效性 no-transform 指令表示无论是在请求还是响应中，缓存都不能改变实体主体的媒体类型 6.3.2 Connection Connection 首部字段具有如下两个作用： 控制不再转发给代理的首部字段 管理持久连接 Connection: 不在转发的首部字段名 在客户端发送请求和服务器返回响应内，使用 Connection 首部字段，可控制不在转发给代理的首部字段 Connection: close HTTP/1.1 版本默认连接都是持久连接，为此，客户端会在持久连接上连续发送请求，当服务器想明确断开连接，则指定 Connection 首部字段的值为 close GET / HTTP/1.1 Connection: Keep-Alive HTTP/1.1 200 OK Keep-Alive: timeout=10, max=500 Connection: Keep-Alive HTTP/1.1 之前的版本默认连接都是非持久连接，为此，如果想要在旧版本的 HTTP 协议上维持持续连接，则需要指定 Connection 首部字段的值是 Keep-Alive 6.3.3 Date Date 首部字段表明 HTTP 报文创建的时间和日期，日期时间的格式有三种 6.3.4 Pragma Pragma: no-cache 历史遗留字段，为了向后兼容而定义，该字段只用于请求，会要求所有中间服务器不返回缓存的资源 如果所有中间服务器都能以 HTTP/1.1 为基准，那么直接采用 Cache-Control: no-cache 指定缓存的处理方式是最佳的，但是整体掌握所有服务器使用的 HTTP 版本是不现实的，所以我们一般使用两个字段 Cache-Control: no-cache Pragme: no-cache 6.3.5 Trailer 首部字段 Trailer 会事先说明在报文主体后记录了哪些首部字段，该首部字段可应用在 HTTP/1.1 版本分块传输编码时 HTTP/1.1 200 OK Content-Type: text/html Trailer: Expires temp: ...(报文主体)··· Expires： Tue··· 6.3.6 Transfer-Encoding Transfer-Encoding: chunked 首部字段 Transfer-Encoding 规定了传输报文主体时采用的编码方式， HTTP/1.1 的传输编码方式仅对分块传输编码有效 6.3.7 Upgrade 首部字段 Upgrade 用于检测 HTTP 协议及其他协议是否可使用更高的版本进行通信，其参数值可以用来指定一个完全不同的协议 GET /index.htm HTTP/1.1 Upgrade: TLS/1.0 Connection: Upgrade HTTP/1.1 101 Switching Protocols Upgrade: TLS/1.0 HTTP/1.1 Connection: Upgrade 一般使用 Upgrade 也会使用 Connection，表示 Upgrade 仅作用于它与相邻的服务器 6.3.8 Via 使用首部字段 Via 是为了追踪客户端与服务器之间的请求和响应报文的传输路径。报文在经过代理或网关时，会先在首部字段 Via 中附加该服务器的信息，然后再转发。Via 首部是为了追踪传输路径，所以经常会和 TRACE 方法一起使用，比如代理服务器接收到由 TRACE 方法发送过来的请求（其中 Max-Forwards: 0）时，代理服务器就不再转发请求了 6.3.9 Warning HTTP/1.1 的 Warning 首部是从 HTTP/1.0 的响应首部（Retry-After ）演变过来的，该首部通常会告知用户一些与缓存相关的问题的警告 Warning: 113 gw.hacker.jp:8080 \"Heuristic expiration\" Tue, 03 Jul 2012 05:09:44 GMT Warning 首部格式如下，日期可以省略： Warning: [警告码][警告主机:端口号]\"[警告内容]\"([日期时间]) HTTP/1.1 定义了 7 种警告，警告具有扩展性 表6-7：HTTP/1.1 7 种警告 | 警告码 | 警告内容 | 说明 | | ------ | -------------------------------- | -------------------------------------- | | 110 | Response is stale | 代理返回已过期的资源 | | 111 | Revailidation failed | 代理再次验证资源有效性时失败 | | 112 | Disconnection operation | 代理与互联网之间的连接被故意切断 | | 113 | Heuristic expiration | 响应使用期超过 24 小时 | | 199 | Miscellaneous warning | 任意的警告内容 | | 214 | Transformation applied | 代理对内容编码或媒体类型执行了某些操作 | | 299 | Miscellaneous persistent warning | 任意的警告内容 | ### 6.4 HTTP/1.1 请求首部字段 请求首部字段是从客户端往服务器发送请求报文中所使用的字段，用于补充请求的附加信息、客户端信息、对响应内容相关的优先级等内容 #### 6.4.1 Accept ```tex Accept: text/plain; q=0.3, text/html ``` Accept 首部字段可以通知服务器，用户代理能够处理的媒体类型及媒体类型的优先级。可使用 type/subtype 这种形式，一次指定多种媒体类型 - 文本文件：text/html, text/plain, text/css··· application/xhtml+xml, application/xml··· - 图片文件：image/jpeg, image/gif, image/png ··· - 视频文件：video/mpeg, video/quicktime ··· - 应用程序使用的二进制文件：application/octet-stream, application/zip··· 若想要给显示的媒体类型增加优先级，则使用 q= 来额外表示权重，类型用分号（；）分隔。权重的范围是0~1，如果不指定，默认是 1 #### 6.4.2 Accept-Charset ```tex Accept-Charset: iso-8859-5, unicode-1-1; q=0.8 ``` Accept-Charset 首部字段可用于通知服务器用户代理支持的字符集及字符集的优先级 #### 6.4.3 Accept-Encoding ```tex Accept-Encoding: gzip, deflate ``` Accept-Encoding 首部字段用来告知服务器用户代理支持的用户编码及用户编码的优先级顺序，可一次性指定多种编码 - gzip：由文件压缩程序 gzip(GNU zip) 生成的编码格式（RFC1952） - compress：由 UNIX 文件压缩程序 compress 生成的编码格式 - deflate：组合使用 zlib 格式及由 deflate 压缩算法生成的编码格式 - identity：不执行压缩或不会变化的默认编码格式 #### 6.4.4 Accept-Language ```tex Accept-Language: zh-cn, zh; q=0.7, en-us,en; q=0.3 ``` Accept-Language 首部字段用来告知服务器用户代理能够处理的自然语言集及其优先级 #### 6.4.5 Authorization ```http GET /index.htm HTTP/1.1 Authorization: Basic ··· ``` 首部字段 Authorization 用来告知服务器，用户代理的认证信息（证书值） #### 6.4.6 Expect ```tex Expect: 100-continue ``` Expect 首部字段用来告知服务器，期望出现的某种特定行为 #### 6.4.7 From From 首部字段告知服务器用户代理的用户使用的电子邮件地址 #### 6.4.8 Host ```tex Host: www.hacker.jp ``` 虚拟主机运行在同一 IP 上，因此使用首部字段 Host 加以区分 #### 6.4.9 If-Match ```tex If-Match: 123456 ``` 形如 If-xxx 这种形式的请求首部字段，都可以称为条件请求。服务器在接收到条件请求的时候，只有判断条件为真时，才会执行请求 If-Match 首部字段会告知服务器匹配资源所用的实体标记（ETag）值，服务器会比对 If-Match 的首部字段值和资源的 ETag 值，仅当两者一致的时候才执行请求 #### 6.4.10 If-Modified-Since ```http GET /index.htm HTTP/1.1 If-Modiefied-Since: Thu, 15 Apr 2004 00:00:00 GMT ``` 如果在 If-Modeified-Since 指定的日期之后资源发生了更新，服务器才会接收请求 #### 6.4.11 If-None-Match ```http PUT /index.htm HTTP/1.1 If-None-Match: * ``` 只有在 If-None-Match 的字段值与 ETag 值不一致时，可处理该请求。与 If-Match 首部字段的作用相反 #### 6.4.12 If-Range If-Range 字段值若是跟 ETag 值或更新的日期时间匹配一致，那么就作为范围请求处理 #### 6.4.13 If-Unmodified-Since 首部字段 If-Unmodified-Since 与 If-Modified-Since 作用相反，它的作用是告知服务器，指定的请求资源只有在字段值指定的时间之后未发生更新的情况下，才能处理请求 #### 6.4.14 Max-Forwards 通过 TRACE 方法或 OPTIONS 方法，发送包含首部字段 Max-Forwards 的请求时，该字段以十进制整数形式指定可经过的服务器的最大数目 #### 6.4.15 Proxy-Authorization 接收到从代理服务器发来的认证质询时，客户端会使用这个首部字段指定认证信息 #### 6.4.16 Range 对于只需要获取部分资源的请求，包含首部字段 Range 即可告知服务器资源的指定范围 #### 6.4.17 Referer 告知源服务器请求的的原始资源的URI #### 6.4.18 TE TE 告知服务器客户端能够处理响应的传输编码以及相对优先级 #### 6.4.19 User-Agent 首部字段 User-Agent 会将创建请求的浏览器和用户代理名称等信息传达给服务器。 ### 6.5 响应首部字段 响应首部字段是由服务器端向客户端返回响应报文中所使用的字段，用于补充响应的附加信息、服务器信息，以及对客户端的附加要求等 #### 6.5.1 Accept-Ranges ```tex Accept-Ranges: bytes ``` 首部字段 Accept-Ranges 是用来告知客户端服务器是否能处理范围请求，以指定获取服务器端某个部分的资源。可指定的字段值有两种，可处理的范围请求是其值为 bytes，反之为 none。当不能处理范围请求时，Accept-Ranges: none #### 6.5.2 Age 首部字段 Age 能告知客户端，源服务器在多久前创建了响应，单位是秒。若创建该响应的是缓存服务器， Age 值是指缓存后的值再次发起认证到认证结束的时间 #### 6.5.3 ETag 首部字段 ETag 能告知客户端实体标记。它是一种可将资源以字符串形式做唯一性标识的方式。服务器会为每份资源分配对应的 ETag 值。另外，当资源更新时，ETag 值也需要更新。生成 ETag 值时，并没有统一的算法准则，仅仅由服务器来分配 资源的 URI 并没有变，但是资源更新后，ETag 值会随之改变。资源被缓存时，就会被分配唯一性标识。比如中英文的资源的 URI 是相同的，所以仅凭 URI 指定缓存的资源是相当困难的。若在下载过程中出现中断、再连接的情况，都会依照 ETag 值来指定资源 ETag 值有强弱之分。强 ETag 值无论实体有多么细微的变化都会改变其值。弱 ETag 值只用于提示资源是否相同。只有资源发生了根本性改变，产生差异时才会改变 ETag值 #### 6.5.4 Location 使用首部字段 Location 可以将响应接收方引导至某个与请求 URI 位置不同的资源。基本上，该字段会配合 3xx：Redirection 的响应，提供重定向的 URI。几乎所有浏览器在接收到包含首部字段 Location 的响应后，都会强制性地尝试对已提示的重定向资源的访问 #### 6.5.5 Proxy-Authenticate 首部字段 Proxy-Authenticate 会把由代理服务器所要求的认证信息发送给客户端。它与客户端和服务器之间的 HTTP 的访问认证的行为相似，不同之处在于其认证行为是在客户端与代理之间进行的 #### 6.5.6 Retry-After 首部字段 Retry-After 告知客户端应该在多久之后再次发送请求。主要配合状态码 503 Service Unavailable 响应，或 3xx Redirect 响应一起使用 #### 6.5.7 Server 首部字段 Server 告知客户端当前服务器上安装的 HTTP 服务器应用程序的信息 #### 6.5.8 Vary 首部字段 Vary 可对缓存进行控制。源服务器会向代理服务器传达关于本地缓存使用方法的命令。从代理服务器接收到源服务器返回 Vary 指定项的响应之后，若要再次进行缓存，仅对请求中包含相同 Vary 指定首部字段的请求返回缓存。 #### 6.5.9 WWW-Authenticate 首部字段 WWW-Authenticate 用于 HTTP 访问认证。它会告诉客户端适用于访问请求 URI 所指定资源的认证方案（Basic 或是 Digest）和带参数提示的质询（challenge） ### 6.6 实体首部字段 实体首部字段是包含在请求报文和响应报文中的实体部分所使用的首部，用于补充内容的更新时间等与实体相关的信息 #### 6.6.1 Allow 首部字段 Allow 用于通知客户端能够支持 Request-URI 指定资源的所有 HTTP 方法。当服务器接收到不支持的 HTTP 方法时，会以状态码 405 Method Not Allowed 作为响应返回，与此同时，还会把所有能支持的 HTTP 方法写入首部字段 Allow 返回 #### 6.6.2 Content-Encoding ```tex Content-Encoding: gzip ``` 首部字段 Content-Encoding 会告知客户端服务器对实体的主体部分选用的编码方式。内容编码是指在不丢失实体信息的前提下所进行的压缩 主要采用四种方式进行压缩：gzip, compress, deflate, identity，参考 6.4.3 #### 6.6.3 Content-Language 实体使用的自然语言 #### 6.6.4 Content-Length 表明实体主体部分的大小（单位是 byte），对实体内容使用内容编码进行传输时，不能再使用 Content-Length 首部字段 #### 6.6.5 Content-Location 首部字段 Conent-Location 给出与报文主体部分相对应的 URI #### 6.6.6 Content-MD5 客户端会对接收的报文主体执行相同的 MD5 算法，然后与首部字段 Content-MD5 的值进行比较 首部字段 Content-MD5 是一串由 MD5 算法生成的值，其目的在于检查报文主体在传输过程中是否保持完整，以及确认传输是否到达 对报文主体执行 MD5 算法获得 128 位二进制数，在通过 Base64 编码后将结构写入 Content-MD5 字段值。由于 HTTP 首部无法记录二进制值，所以要通过 Base 64 编码处理。 #### 6.6.7 Conent-Range 针对范围请求时，返回响应时使用首部字段 Conent-Range，能告知客户端作为响应返回的实体的哪个部分符合范围请求 #### 6.6.8 Content-Type ```tex Content-Type: text/html, charset=UTF-8 ``` 首部字段 Content-Type 说明了实体主体内对象的媒体类型。和首部字段 Accept 一样，字段值用 type/subtype 形式赋值 #### 6.6.9 Expires 首部字段 Expires 会将资源失效的日期告知客户端 #### 6.6.10 Last-Modified 指明资源最终修改时间 ### 6.7 为 Cookie 服务的首部字段 管理客户端与服务端之间的 Cookie 虽然没有被编入标准化，但在 web 网站方面得到了广泛的应用 Cookie 的工作机制就是用户识别和状态管理。Web 网站为了管理用户的状态，会通过 Web 浏览器，把一些数据临时写入用户的计算机内。接着当用户访问该 Web 网站时，可通过通信的方式取回之前存放的 Cookie 为Cookie服务的由两个字段 - Set-Cookie：开始状态管理所使用的 Cookie 信息，响应首部字段 - Cookie：服务器接收到的 Cookie 信息，请求首部字段 #### 6.7.1 Set-Cookie 当服务端准备开始管理客户端的状态信息时，会事先告知各种信息 Set-Cookie 字段的属性 属性 说明 NAME=VALUE（必需） 赋予Cookie的名称和值 expires=DATE Cookie 的有效期（若不明确指定就默认到浏览器关闭） path=PATH 将服务器上的文件目录作为 Cookie 的适用对象 domain=域名 作为 Cookie 适用对象的域名 Secure 仅在 HTTPS 安全通信时才会发送 Cookie HttpOnly 加以限制，使 Cookie 不能被 JS 脚本访问 6.7.2 Cookie Cookie: status=enable 首部字段 Cookie 会告知服务器，当客户端想要获得 HTTP 状态管理支持时，就会在请求中包含从服务器接收到的 Cookie 6.8 其他首部字段 HTTP 首部字段是可以自行扩展的，会出现各种非标准字段 6.8.1 X-Frame-Options X-Frame-Options: DENY 该字段属于 HTTP 响应首部，用于控制网站内容在其他 Web 网站的 Frame 标签内的显示问题。其主要目的是为了防止点击劫持（clickjacking）攻击 它有两个可指定的字段值 DENY：拒绝 SAMEORIGIN：仅同源域名下的页面匹配时许可 6.8.2 X-XSS-Protection X-XSS-Protection: 1 首部字段 X-XSS-Protection 属于 HTTP响应首部，它是针对跨站脚本攻击（XSS）的一种对策，用户控制浏览器 XSS 防护机制的开关 可选字段值有两个： 0：将 XSS 过滤设置为无效状态 1：将 XSS 过滤设置为有效状态 6.8.3 DNT DNT: 1 首部字段 DNT 属于请求首部，其中 DNT 是 Do Not Track 的简称，意为拒绝个人信息被收集，是表示拒绝被精准广告追踪的一种方法 字段值有两个： 0：同意被追踪 1：拒绝被追踪 7.确保 Web 安全的 HTTPS 在 HTTP 协议中可能存在信息窃听或身份伪装等安全问题。使用 HTTPS 通信机制可以有效的防止这些问题 7.1 HTTP 缺点 HTTP的缺点有： 通信使用明文（不加密），内容可能被窃听 不验证通信方的身份，因此有可能遭遇伪装 无法验证报文的完整性，所以有可能遭遇篡改 这些缺点不仅在 HTTP 上面出现，其他未加密的协议也会有这类问题 7.1.1 通信使用明文可能被窃听 由于 HTTP 本身不具备加密的功能，所以因也无法做到对通信整体的加密 TCP/IP 是可能被窃听的网络 如果要问为什么通信时不加密是一个缺点，这是因为，按 TCP/IP 协议簇的工作机制，通信内容再所有的通信线路上都有可能被窥视。即使已经加密处理的通信，也会被窥视到通信内容，只是说通信经过加密，还是有可能让人无法破解报文信息的含义。互联网上的任何角落都存在通信内容被窃听的风险 窃听相同段上的通信并非难事。只需要收集在互联网上流动的数据包（帧）就行了，对于收集来的数据包的解析工作，可交给那些抓包工具即可 加密处理防止被窃听 在目前如何防止窃听保护信息的集中对策中，最为普及的就是加密技术。加密技术的对象可以有这么几个 通信的加密：HTTP 协议中没有加密机制，但可以通过和 SSL (secure socket layer, 安全套接层) 或 TLS(Transport Layer Security，安全传输层协议) 组合使用，加密 HTTP 的通信内容。服务器与客户端之间建立起安全的通信线路之后开始通信 内容的加密：由于 HTTP 协议中没有加密协议，那么就对 HTTP 协议传输的内容进行加密。为了做到有效的内容加密，前提是客户端和服务器同时具备加密和解密的机制。但是这个内容仍然有被篡改的风险 7.1.2 不验证通信方的身份可能遭遇伪装 HTTP 协议中的请求和响应不会对通信方进行确认。也就是说存在 \"服务器是否就是发送请求中 URI 真正指定的主机，返回的响应是否真的返回到实际提出请求的客户端\" 的问题 任何人都可以发起请求 在 HTTP 协议通信时，由于不存在确认通信方的处理步骤，任何人都可以发起请求。另外，服务器子只要接收到请求，不管对方是谁都会返回一个响应（仅限于 IP 地址和端口号没有被限制访问的前提下），所以会存在以下隐患 可能是已伪装的服务器 可能是已伪装的客户端 无法确定正在通信的对方是否具体访问权限 无法判定请求来自何方，出自谁手 即使是无意义的请求也会照单全收。无法阻止海量请求下的 DoS 攻击（Denial fo Service，拒绝服务攻击） 查明对手的证书 虽然使用 HTTP 协议无法确定通信方，但如果使用 SSL 则可以。 SSL 不仅提供加密处理，而且还使用了一种被称为证书的手段，可用于确定通信方。证书由值得信任的第三方机构颁发，用以证明服务器和客户端是实际存在的。客户端在开始通信之前先确认服务器的证书。 7.1.3 无法证明报文完整性，可能以遭篡改 所谓完整性是指信息的准确度。若无法证明其完整性，通常也就意味着无法判断信息是否准确 接到的内容可能有误：没有任何办法确认，发出的请求/响应和接收到的请求/响应是前后相同的，像这样，请求或响应在传输途中，遭攻击者拦截并篡改内容的攻击行为称为中间人攻击（Man-in-the-Middle attack, MITM） 如何防止篡改：常用的是 MD5 和 SHA-1 等散列值校验的方法，以及用来确认文件的数字签名，但是并不可靠，因为既然攻击者能篡改内容，验证值也是可以篡改的。为了防止这些弊端，有必要使用 HTTPS 7.2 HTTP + 加密 + 认证 + 完整性保护 = HTTPS 7.2.1 HTTP 加上加密处理和认证以及完整性保护后即是 HTTPS 经常会在 Web 的登录页面和购物结算界面等使用 HTTPS 通信。使用 HTTPS 通信时，不再用 http://，而是改用 https:// 7.2.2 HTTPS 是身披 SSL 外壳的 HTTP HTTPS 并非是一种新的协议，只是 HTTP 通信接口部分用 SSL 和 TLS 协议代替而已。 通常，HTTP 直接和 TCP 通信。当使用 SSL 时候，则演变成先和 SSL 通信，再由 SSL 和 TCP 通信了。所谓 HTTPS，其实就是身披 SSL 协议这层外壳的 HTTP。SSL 是当今世界上应用最为广泛的网络安全技术 7.2.3 相互交换密匙加密技术 SSL 采用一种叫做公开密匙加密（Public-key cryptographic）的加密处理方式。近代的加密方法中加密算法是公开的，但是密匙是保密的。通过这种方式得以保持加密方法的安全性 共享密钥加密的困境：加密和解密同用一个密匙的方式称为共享密匙加密（Common key cryto system），也成为对称密匙加密。以共享密匙方式加密时必须将密匙也发给对方。但是发送密匙就有被窃听的风险，但是不发送，对方就不能解密。再说，如果密匙能够安全送达，那数据也能安全送达了 使用两把密匙的公开密匙加密：公开密匙加密使用一对非对称的密匙，一把叫私有密匙，一把叫公开密匙。使用公开密匙加密方式，发送密文的一方使用对方的公开密匙进行机密处理，对方收到被加密的信息后，再使用自己的私有密匙进行解密。攻击者根据密文和公开密钥恢复到信息原为是异常困难的 HTTPS 采用混合加密机制：若密匙能够实现安全交换，那么有可能会考虑仅使用公开密匙加密来通信。公开密匙加密处理起来比共享密匙加密方式更为复杂，因此若在通信时使用公开密匙加密方式，效率就很低。首先使用公开密匙加密方式安全的交换稍后共享密匙加密中要使用的密匙，然后确保交换的密匙是安全的前提下，使用共享密匙加密方式进行通信 7.2.4 证明公开密匙正确性的证书 遗憾的是，公开密匙加密方式还有一些问题。那就是无法证明公开密匙本身就是货真价实的公开密匙。如何证明收到的公开密匙就是原本预想的那台服务器发行的公开密匙，可以使用由数字证书认证机构和其他相关机构颁布的公开密匙证书 7.2.5 HTTPS 的安全通信机制 这个网址讲的不错：HTTPS安全通信机制及SSL握手过程 SSL是一个介于HTTP协议与TCP之间的一个可选层，为数据通讯提供安全支持。SSL协议可分为两层： SSL记录协议（SSL Record Protocol）：它建立在可靠的传输协议（如TCP）之上，为高层协议提供数据封装、压缩、加密等基本功能的支持。 SSL握手协议（SSL Handshake Protocol）：它建立在SSL记录协议之上，用于在实际的数据传输开始前，通讯双方进行身份认证、协商加密算法、交换加密密钥等。 SSL协议握手以及https的通信过程如下： （1）客户端请求建立SSL链接，并向服务端发送一个报文，内容包括TSL协议版本、用于生成对话密钥的随机数1、支持的加密方法、支持的压缩方法，此时是明文传输。 （2）服务端回复客户端一个报文，内容包括确认使用的加密通信协议版本、用于生成对话密钥的随机数2、确认加密方法、服务器证书（包含非对称加密的公钥）。 （3）客户端验证证书，如果证书不是可信机构颁布，或证书域名与实际域名不符，或者证书已经过期，就会向访问者显示一个警告，是否继续通信。 （4）客户端确认证书没有问题，就会取出证书中的服务器公钥，然后生成新的随机数3并通过服务端下发的公钥及加密方法进行加密，发送给服务器。 （5）服务端收到客户端的回复，利用已知的加解密方式进行解密，同时利用上述3个随机数通过一定的算法生成HTTP链接数据传输的对称加密key – session key。 此后的HTTP链接数据传输即通过对称加密方式进行加密传输。 SSL 速度慢吗：HTTPS 存在一些问题，那就是当使用 SSL 时，它的处理速度会变慢。由于 HTTPS 还需要做服务器、客户端双方加密及解密处理，因此会消耗 CPU 和内存等资源。和 HTTP 通信相比，SSL 通信部分消耗网络资源，而 SSL 通信部分，由因为要对通信进行处理，所以时间上又延迟了 与纯文本相比，加密通信会消耗更多的 CPU 和内存资源，如果每次通信都加密，那么会消耗相当多的资源，特别是每当那些访问量较多的 Web 网站进行加密处理时，它们所承担的负载不容小觑。因此只有敏感信息才会使用 HTTPS 通信。除此之外，想要节约购买证书的开销也是原因之一。 8. 确认访问用户身份的认证 某些Web 页面只想让特定的人浏览，或者干脆仅本人可见。为达到这个目标，必不可少的就是认证功能。 8.1 何为认证 计算机本身无法判断坐在显示器前的使用者的身份。为了弄清是在访问服务器，就需要对方的客户端自报家门，核对的信息通常指一下这些： 密码：本人才会知道的字符串信息 动态令牌：仅限本人持有设备内显示的一次性密码 数字证书：仅限本人（终端）持有的信息 生物认证：指纹和虹膜等本人的生理信息 HTTP 使用的认证方式： BASIC 认证（基本认证） DIGEST 认证（摘要认证） SSL 客户端认证 FormBase 认证（基于表单认证） 8.2 BASIC 认证 BASIC 认证是从 HTTP/1.0 就定义的认证方式，认证步骤如下： 客户端发送请求 服务端返回状态码 401 Authorization Required 告知客户端需要进行认证 用户 ID 和用户密码以 Base64 方式编码后发送 认证成功返回 200，认证失败返回 401 BASIC 认证虽然采用 Base64 编码方式，但这不是加密处理。不需要任何附加信息就可对其解码。如果被人窃听，被盗可能性极高 8.3 DIGEST 认证 为了弥补 BASIC 认证存在的弱点，从 HTTP/1.1 就有了 DIGEST 认证。DIGEST 认证同样使用质询/响应的方式（challenger/response），但不会像 BASIC 认证那样直接发送明文密码 所谓质询响应方式是指，一开始一方会先发送认证要求给另一方，接着使用从另一方那接收到的质询码计算生成响应码，最后将响应码返回给对方进行认证的方式。因为发送给对方的只是响应摘要及由质询码产生的结果，所以比起 BASIC 认证，密码泄露的可能性就降低了 DIGEST 认证步骤： 客户端发送请求 服务端发送临时的质询码（随机数，nonce）以及告知需要认证的状态码 401 客户端发送摘要以及由质询码计算出的响应码（response） 认证成功返回 200， 失败返回 401 DIGEST 认证提供防止密码被窃听的保护机制，但不存在防止用户伪装的保护机制。DIGEST 认证和 BASIC 认证一样，使用上不那么便捷灵敏。适用范围有限 8.4 SSL 客户端认证 从使用用户 ID 和密码的认证方面来讲，只要二者的内容正确，即可认证是本人。但如果用户 ID 和密码被盗，就很有可能被第三方盗用。利用 SSL 客户端认证的方式可以避免该情况的发生 SSL 客户端认证是由 HTTPS 的客户端证书完成认证的方式。为达到 SSL 客户端认证的目的，需要事先将客户端证书分发给客户端，且客户端必须安装证书 SSL 客户端认证的步骤： 接收到需要认证资源的请求，服务器会发送 Certificate Request 报文，要求客户端提供客户端证书 用户选择将发送的客户端证书后，客户端会把客户端证书信息以 Client Certificate 报文方式发送给服务器 服务器验证客户端证书，验证通过后方可领取证书内客户端的公开密匙，然后开始 HTTPS 加密通信 在多数情况下，SSL 客户端认证不会仅依靠证书完成认证，一般会基于表单认证组合成一种双因素认证（Two-factor authentication）。认证过程中不仅需要密码这个因素，还需要申请认证者提供其它持有信息 8.5 基于表单认证 基于表单认证方法并不是在 HTTP 协议中定义的。客户端会向服务器上的 Web 应用程序发送登录信息（Credential），按登录信息的验证结果验证 8.5.1 认证多为表单验证 由于使用上的便利性及安全性问题，HTTP 协议标准提供的 BASIC 认证和 DIGEST 认证几乎不怎么使用。另外，SSL客户端认证由于费用问题，也尚未普及 8.5.2 Session 管理及 Cookie 应用 基于表单验证标准规范尚未有定论，一般会使用 Cookie 来管理 Session（会话） 基于表单认证本身是通过服务器端的 Web 应用，将客户端发送过来的用户 ID 和密码与之前登录过的信息做匹配来做验证 但是 HTTP 本身是无状态协议，之前已经认证成功的用户状态无法通过协议层面保存下来，即无法实现状态管理。于是我们会使用 Cookie 来管理 Session，以弥补HTTP 协议中不存在的状态管理 客户端通过 HTTPS 发送已登录信息（用户 ID，密码） 服务器发送包含 Session ID 的 Cookie（Set-Cookie：···） 客户端发送包含 Session ID 的Cookie，通过验证 Session ID 来判定对方是否是真实用户 9. 基于 HTTP的功能追加协议 虽然 HTTP 协议既简单有简捷，但随着时代的发展，其功能使用上捉襟见肘的疲态已经凸显 9.1 基于 HTTP 的协议 在建立 HTTP 协议规范时候，制定者主要是想把 HTTP 当作传输 HTML 文档的协议。随着时代的发展，Web 的用途更具有多样性，比如演化成在线购物网站，SNS（社交网络服务）、企业管理工具等。而这些网站所追求的功能可通过 Web 应用和脚本程序实现。即使这些功能已经满足需求，在性能上却未必是最优，这是因为 HTTP 协议上的限制以及自身性能有限 HTTP 功能上的不足可通过创建一套全新的协议来弥补。可是目前基于 HTTP 的 Web 浏览器的使用环境已遍布全球，因此无法完全抛弃 HTTP。有一些新的协议的规则是基于 HTTP 的 9.2 消除 HTTP 瓶颈的 SPDY Google 在 2010 发布了 SPDY（取自 SPeeDY），其开发目标旨在解决 HTTP 的性能瓶颈，缩短 Web 页面的加载时间 9.2.1 HTTP 的瓶颈 在 Facebook 和 Twitter 等 SNS 网站上，几乎能够实时观察到海量用户公开发布的内容。当几百、几千万的用户发布内容时，Web 网站为了保存这些新增内容，在很短的时间内就会发生大量的内容更新。为了尽可能的实时的显示这些内容，服务器上一有内容更新，就需要直接把那些内容反馈到客户端界面上，虽然看起来挺简单的，但 HTTP 无法妥善的处理这项任务 使用 HTTP 协议探知内容是否更新，就必须频繁的向服务器进行确认，容易产生徒劳的通信，以下 HTTP 标准会成为瓶颈： 一条连接只可以发送一个请求 请求只能从客户端开始，客户端不可以接收除响应外的指令 请求/响应未经压缩就发送，首部信息越多延迟就越大 发送冗长的首部。每次互相发送相同的首部造成的浪费较多 可任意选择数据压缩格式。非强制压缩发送 Ajax 的解决办法：Ajax 是一种有效利用 JavaScript 和 DOM 的操作，以达到局部 Web 页面替换加载的异步通信手段。由于它只更新一部分页面，响应中传输的数据量也会更少。但是利用 Ajax 实时的从服务器获取内容，有可能导致大量请求产生。另外，Ajax 仍未解决 HTTP 协议本身存在的问题 Comet 的解决办法：一旦服务器有内容更新了，Comet 不会让请求等待，而是直接给客户端返回响应。这是一种通过延迟应答，模拟服务端向客户端推送的功能。虽然内容上可以做到实时更新，但为了保留响应，一次连接的连续时间也变长了。期间，为了连接会消耗更多的资源。另外，Comet 也未解决 HTTP 协议本身存在的问题 SPDY 的目标：为了进行根本性的改善，需要有一些协议层面上的改动。 9.2.2 SPDY 的设计与功能 SPDY 没有完全改写 HTTP 协议，而是在 TCP/IP 的应用层与传输层之间通过新家会话层的形似运作，同时考虑到安全性问题，SPDY 规定通信中使用 SSL。SPDY 以会话层的形式加入，控制对数据的流动，但还是采用 HTTP 建立通信连接。因此，可照常使用 HTTP 的方法、Cookie 以及 HTTP 报文等 使用 SPDY 后，HTTP 协议额外获得以下功能： 多路复用功能：单一的 TCP 连接处理多个 HTTP 请求 赋予请求优先级：SPDY 不仅可以无限制的并发请求，还可以给请求逐个分配优先级顺序 压缩 HTTP 首部 推送功能 服务器提示功能 9.2.3 SPDY 消除 Web 瓶颈 Web 浏览器和 Web 服务器都要为对应 SPDY 做出一定程度上的改动，把该技术导入实际的 Web 网站的效果不佳。因为 SPDY基本上只是将单个域名（IP 地址）的通信多路复用，所以当一个 Web 网站上使用的多个域名下的资源的时候，效果就有限制。SPDY 的确是一种可以消除 HTTP 瓶颈的技术，但是很多 Web 网站的问题并非仅仅是由 HTTP 瓶颈导致的 9.3 使用浏览器进行全双工通信的 WebSocket 利用 Ajax 和 Comet 技术进行通信可以提升 Web 的浏览速度。但问题在于通信若使用 HTTP 协议，就无法彻底解决瓶颈问题。WebSocket 网络技术就是为解决这些问题而实现的一套新协议及 API 9.3.1 WebScoket 的设计与功能 WebSocket 技术主要是为了解决 Ajax 和 Comet 里 XMLHttpRequest 附带的缺陷所引起的问题 9.3.2 WebSocket 协议 一旦 Web 服务器与客户端之间建立起 WebSocket 协议的通信连接，之后所有的通信都依靠这个专用协议进行。通信过程中可互相发送 JSON、XML、HTML 或图片等任意格式的数据。由于是建立在 HTTP 基础上的协议，因此连接的发起方仍是客户端。 WebSocket 协议的主要特点：推送功能，减少通信量 握手·请求 为了实现 WebSocket 通信，需要用到 HTTP 的 Upgrade 首部字段，告知服务器通信协议发生改变，以达到握手的目的 GET /chat HTTP/1.1 Host: Server.com Upgrade: websocket Connection: Upgrade Sec-WebSocket-Key: ,,, Sec-WebSocket-Protocol: chat, superchat Sec-WebSocket-Key 字段内记录着握手过程中必不可少的键值，Sec-WebSocket-Protocol 记录着使用的子协议 握手·响应 对于之前的请求，返回状态码 101 Switching Protocols 的响应 HTTP/1.1 101 Switching Protocols Upgrade: websocket Connection: Upgrade Sec-Websocket-Accept: ,,, Sec-Websocket-Protocol: chat Sec-Websocket-Accept 的字段值是由 Sec-Websocket-Key 的字段值生成的，成功握手确立 WebSocket 连接之后，通信不再使用 HTTP 的数据帧，而采用 WebSocket 独立的数据帧 WebSocket API 以下是 JavaScript 调用 WebSocket API，每 50ms 发送一次数据的实例 var socket = new WebSocket('ws://test.com:12010/updates') socket.open = () => { setInterval(() => { if(socket.bufferedAmount == 0) { socket.send(getUpgradeData()) } }) } 期盼已久的 HTTP/2.0 HTTP/2.0 围绕着 7 项技术进行讨论（2012年） 9.5 Web 服务器管理文件的 WebDAV WebDAV（Web-based Distributed Authoring and Versioning，基于万维网的分布式创作和版本控制）是一个可对 Web 服务器上的内容直接进行文件复制、编辑等操作的分布式文件系统。 10. 构建 Web 内容的技术 在 Web 刚出现时，我们只能浏览那些页面样式简单的内容，如今，Web 使用各种各样的技术，来呈现更加丰富多彩的内容 10.1 HTML 10.1.1 Web 页面几乎全由 HTML 构建 HTML（HyperText Markup Language，超文本标记语言）是为了发送 Web 上的超文本（HyperText）而开发的标记语言。超文本是一种文档系统，可将文档中任意位置的信息与其他信息（文本或图片等）建立关联，即超链接文本 10.1.2 HTML 的版本 2014年推出了 HTML5 标准 10.1.3 设计应用 CSS CSS（Cascading Style Sheets，层叠样式表）可以指定如何展现 HTML 内的各种元素，属于样式表标准之一。即使是相同的 HTML 文档，通过改变应用的 CSS，用浏览器看到的页面外观也会随之改变 10.2 动态 HTML 10.2.1 让 Web 页面动起来的动态 HTML 所谓动态 HTML，是指使用客户端脚本语言将静态的 HTML 内容完成动态的技术的总称。动态 HTML 技术是通过调用客户端脚本语言 JavaScript，实现对 HTML 的 Web 页面的动态改造。利用 DOM 可指定欲发生动态变化的 HTML 元素 10.2.2 更易控制 HTML 的 DOM DOM 是用以操作 HTML 文档和 XML 文档的 API，使用 DOM 可以将 HTML 内的元素当作对象操作。 10.3 Web 应用 10.3.1 通过 Web 提供功能的 Web 应用 Web 应用是指通过 Web 功能提供的应用程序。原本应用 HTTP 协议的 Web 机制就是对客户端发来的请求，返回事先准备好的内容。可是随着 Web 越来越普及，仅在这样的作法已不足以应对所有的需求，更需要引入由程序创建 HTML 内容的做法 10.3.2 与 Web 服务器及程序协作的 CGI CGI（Common Gateway Interface，通用网关接口）是指 Web 服务器在接收到客户端发送过来的请求后转发给程序的一组机制。 10.3.3 因 Java 而普及的 Servlet Servlet 是一种能在服务器上创建动态内容的程序。 之前提及的 CGI，由于每次接到请求，程序都要跟着启动一次，因此一旦访问量过大，服务器承担相当大的负载。而 Servlet 运行在与 Web 服务器相同的进程中，因此受到的负载较小（Servlet 常驻内存）。 10.4 数据发布的格式及语言 10.4.1 可扩展标记语言 XML（eXtensible Markup Language，可扩展标记语言）是一种可按应用目标进行扩展的通用标记语言。 10.4.2 发布更新信息的 RSS/Atom RSS(简易信息聚合) 和 Atom 都是发布新闻或博客日志等更新信息文档的格式的总称，两者都用到了 XML 10.4.3 JavaScript 衍生的轻量级易用 JSON JSON（JavaScript Object Notation）是一种以 JavaScript（ECMAScript）的对象表示法为基础的轻量级数据标记语言。能够处理的数据类型由 7 种：true/false/null/对象/数组/数字/字符串 11. Web 的攻击技术 互联网上的攻击大都将 Web 站点作为目标。本章讲解具体有哪些攻击 Web 站点的手段，以及攻击会造成什么样的影响 11.1 针对 Web 的攻击技术 简单的 HTTP 协议并不存在安全性问题，因此协议本身几乎不会成为攻击的对象。应用 HTTP 协议的服务器和客户端，以及运行在服务器上的 Web 应用资源才是攻击目标 11.1.1 HTTP 不具备必要的安全功能 几乎现今的所有 Web 网站都会使用会话（session）管理、加密处理等安全性方面的功能，而 HTTP 协议内并不具备这些功能。因此开发者需要自行设计并开发认证及会话管理功能来满足 Web 应用的安全。而自行设计就意味着会出现各种形形色色的实现。结果安全等级并不完备，可仍在运作的 Web 应用背后却隐藏这各种容易被攻击者滥用的安全漏洞的 Bug 11.1.2 在客户端即可篡改请求 在 Web 应用中，从浏览器那接收到的 HTTP 请求的全部内容，都可以在客户端自由地变更、篡改。所以 Web 应用可能会接受到与预期数据不相同的内容 在 HTTP 请求报文内加载攻击代码，就能发起对 Web 应用的攻击。通过 URL 查询字段或表单、HTTP 首部、Cookie 等途径把攻击代码传入，若这时 Web 应用存在安全漏洞，那内部信息就会遭到窃取，或被攻击者拿到管理权限 11.1.3 针对 Web 应用的攻击模式 对 Web应用的攻击模式有以下两种：主动攻击、被动攻击 以服务器为目标的主动攻击 主动攻击是指攻击者通过直接访问 Web 应用，把攻击代码传入的攻击模式。由于该模式是直接针对服务器上的资源进行攻击，因此攻击者需要能够访问到那里的资源。代表性的攻击是：SQL 注入攻击和 OS 命令注入攻击 以服务器为目标的被动攻击 被动攻击是指利用圈套策略执行攻击代码的攻击模式。 11.2 因输出值转义不完全引发的安全漏洞 实施 Web 应用的安全对策可大致分为以下两部分： 客户端验证 服务端验证：输入值验证，输出值转义 多数情况下采用 JavaScript 在客户端验证数据，可是客户端允许用户篡改数据或关闭 JavaScript，所以不适合将 JavaScript 验证作为安全的防范对策。保留客户端只是为了尽早辨别输入错误，起到提高 UI 体验的作用 服务端的输入值验证按 Web 应用内的处理则有可能被误认为是具有攻击性意义的代码。从数据库或文件系统、HTML、邮件等输出 Web 应用处理的数据之际，针对苏好处做值转义处理是一项至关重要的安全策略。当输出值转义不完全时，会因触发攻击者传入的攻击代码，而给输出对象带来损害 11.2.1 跨站脚本攻击 跨站脚本攻击（Cross-Site Scripting，XSS）是指通过存在安全漏洞的 Web 网站注册用户的浏览器内运行非法的 HTML 标签或 JavaScript 进行的一种攻击。XSS 攻击可能造成以下影响： 利用虚假输入表单骗取用户个人信息 利用脚本窃取用户的 Cookie 值，被害者在不知情的情况下，帮助攻击者发送恶意请求 显示伪造的文章或图片 11.2.2 SQL 注入攻击 SQL注入（SQL Injection）是指针对 Web 应用使用的数据库，通过运行非法的 SQL 而产生的攻击。该安全隐患有可能引发极大的威胁，有时会直接导致个人信息和机密信息的泄露，有可能会造成以下影响： 非法查看或篡改数据库内的数据 规避认证 执行和数据库服务器业务关联的程序等 11.2.3 OS 命令注入攻击 OS 命令注入攻击（OS Command Injection）是指通过 Web 应用，执行非法的操作系统命令达到攻击的目的。 11.2.4 HTTP 首部注入攻击 HTTP 首部注入攻击是指攻击者通过在响应首部字段内插入换行，添加任意响应首部或主题的一种攻击，可能造成以下影响： 设置任何 Cookie 信息 重定向至任意 URL 显示任意的主体（HTTP 响应截断攻击） 11.2.5 邮件首部注入攻击 邮件首部注入攻击是指 Web 应用中的邮件发送功能，攻击者通过向邮件首部 To 或 Subject 内任意添加非法内容发起的攻击。 11.2.6 目录遍历攻击 目录遍历攻击是指对本无意公开的文件目录，通过非法截断其目录路径，达成访问目的的一种攻击。 11.2.7 远程文件包含漏洞 远程文件包含漏洞是指当部分脚本内容需要从其他文件读入时，攻击者利用指定外部服务器的 URL 充当依赖文件，让脚本读取之后，就可以运行任意脚本的一种攻击。 11.3 因设置或设计上的缺陷引发的安全漏洞 因设置或设计上的缺陷引发的安全漏洞是指，错误设置 Web 服务器，或是由设计上的一些问题引发的安全漏洞 11.3.1 强制浏览 强势浏览安全漏洞是指，从安置在 Web 服务器的公开目录下的文件中，浏览那些原本非资源公开的文件，可能造成以下影响： 泄露顾客的个人信息等重要情报 泄露原本需要具有访问权限的用户才可查阅的信息内容 泄露未外连到外界的文件 11.3.2 不正确的错误消息处理 不正确的错误消息处理是指 Web 应用的错误消息内包含对攻击者有用的信息 11.3.3 开放重定向 开放重定向是一种对指定的任意 URL 作重定向跳转的功能 11.4 因会话管理疏忽引发的安全漏洞 会话管理是用来管理用户状态的必备功能，但是如果在会话管理上有所疏忽，就会导致用户的认证状态被窃取等后果 11.4.1 会话劫持 绘画接触是指攻击者通过某种手段拿到了用户的会话 ID，并非法使用此会话 ID 伪装成用户，达到攻击的目的 11.4.2 会话固定攻击 对以窃取目标会话 ID 为主动攻击手段的会话劫持而言，会话固定攻击会强制用户使用攻击者指定的会话 ID 11.4.3 跨站点请求伪造 跨站点请求伪造（Cross-Site Request Forgeries，CSRF）攻击是指攻击者通过设置好的陷阱，强制对已完成认证的用户进行非预期的个人信息或预设信息等某些状态更新，属于被动攻击 11.5 其它安全漏洞 密码破解 点击劫持 Dos 攻击 后门程序 其它 Content-Type MDN Content-Type 实体头部用于指示资源的 MIME 类型(media type，指示文件类型的字符串) 在响应中，Content-Type 标头告诉客户端实际返回的内容的内容类型；在请求中（如 POST 或 PUT），客户端告诉服务端实际发送的数据类型 句法： Content-Type: text/html; charset=utf-8 Content-Type: multipart/form-data; boundary=something Content-Type 在 HTML 表单中 在通过 HTML form 提交生成的 POST 请求中，请求头的 Content-Type 由 form 元素上的 enctype 属性指定 Submit 请求头看起来像这样（在这里省略了一些 headers）： POST /foo HTTP/1.1 Content-Length: 68137 Content-Type: multipart/form-data; boundary=---------------------------974767299852498929531610575 ---------------------------974767299852498929531610575 Content-Disposition: form-data; name=\"description\" some text ---------------------------974767299852498929531610575 Content-Disposition: form-data; name=\"myFile\"; filename=\"foo.txt\" Content-Type: text/plain (content of the uploaded file foo.txt) ---------------------------974767299852498929531610575 MDN 的内容有点少啊，又看了一下简书的内容， Content-Type 常见的 Content-Type HTML文档标记 ：text/html 普通ASCII 文档标记： text/html JPEG 图片标记：image/jpeg gif 图片编辑：image/gif js文档标记： application/javascript xml文件标记： application/xml application/x-www-form-urlencoded HTTP会将请求参数用 key1 = val1 & key2 = val2 的方式进行组织，并放到请求实体里面，如果是中文或特殊字符则会自动进行URL转码，一般用于表单提交，不支持文件 请求 http 请求报头 multipart/form-data 与 application/x-www-form-urlencoded 不同，这是一个多部分多媒体类型，首先生成了一个 boundary 用于分割不同字段，在请求实体里每个参数以 --------boundary 开始，然后是附加信息和参数名，然后是空行，最后是参数内容。多个参数将会有多个 boundary 块，如果参数是文件会有特别的文件域。最后以 ------boundary- 为结束标志，multipart/form-data 支持文件上传的格式，一般需要上传文件的表单则用该类型 请求参数 http 请求报文 application/json json是一种轻量级的数据格式，以键值对的方式组织的数据，使用这个类型，需要参数本身就是json格式的数据，参数会被直接放到请求实体里，不进行任何处理，服务端/客户端会按json格式解析数据（约定好的情况下） 请求参数 http 请求报文 application/xml 和 text/xml 与application/json类似，这里用的是xml格式的数据，text/xml的话，将忽略xml数据里的编码格式 Content-Type的使用 request 的 Content-Type 一般我们在开发过程中需要注意客户端发送请求（Request）的 Content-Type 设置，特别是使用 ajax 的时候，如果设置得很不准确，很有可能会导致请求失败。比如在 spring 中，如果接口使用了 @RequestBody，spring 强大的自动解析功能，会将请求实体的内容自动转换为 Bean，但前提是请求的 Content-Type 必须设置为 application/json，否则会返回 415 错误 415 unsupported media type，即不支持的媒体类型 建议： 如果是一个 restful 接口（json格式），一般将 Content-Type 设置为 application/json; charset=utf-8 如果是文件上传，一般是设置为 multipart/form-data 如果是普通的表单提交，一般是设置为 application/x-www-form-urlencoded response 的 Content-Type 服务端响应（response）的 Content-Type 最好也保持准确，虽然一般 web 开发中，前端解析响应的数据不会根据 Content-Type，并且服务端一般能自动设置准备的 Content-Type，但是如果乱设置的情况下可能会有些问题，比如导出文件，比如导出文件，打开图片等，如果在 spring 项目里使用 @ResponseBody，spring 会将响应的 Content-Type 设置为 application/json； charset=utf-8；可能会导致文件无法导出 response 的 Content-Type 设置建议： 一般情况下不需要显示设置 如果是文件导出，Content-Type 设置为 mulitpart/form-data，并且添加一个 Content-Disposition 设置为 attachment;fileName =文件.后缀 注：Content-Disposition 是 Content-Type 的扩展，它告诉浏览器弹窗下载框 例子： 未正确设置 response 的 Content-Type 的情况，客户端会将 json 数据当成普通文本 Content-Type: text/html;charset=utf-8 正确设置 response 的Content-Type 的情况，客户端将 json 数据自动解析 Content-Type: application/json; charset=utf-8 子网划分、子网掩码 网络基础知识_子网划分 基础 网络发展过程 计算机与通信的融合过程就是计算机网络的发展过程，利用通信线路把位于不同的点上的多个计算机系统相互连接起来便形成了计算机网络，在网络中，通过功能完善的网络软件的管理，可以共享某些软件、硬件和数据资源。计算机网络的发展经历了三个阶段：具有通信功能的单机系统，具有通信功能的多级系统和计算机网络 LAN 局域网（LAN）的发展：LAN 有三种基本的拓扑结果：总线型，环形，星型，市场提供三种使用的传输介质：双绞线，电缆和光纤 ip地址的定义和分类 定义 ip地址是唯一标识网络上的计算机，ip 由一个 32 位的0，1字符串组成，额也可以点分十进制表示，网络中每个路由或者主机都会拥有一个独一无二的 ip 地址用来区分用户，根据 tcp/ip 协议，连接在 Internet 上的每个设备都必须有一个 ip 地址 ip 地址表示 分类 32bit的ip地址被分为两个部分：网络号（NetWork ID，NID），主机号（Host ID， HID） IPv4定义了5类IP地址：A, B, C, D, E 类 地址分类 地址分类范围 特殊的 ip 地址 网络地址：用于表示网络本身，具有正常的网络号部分，而主机号部分全部为0的ip地址称之为网络地址，如172.16.45.0就是一个B类网络地址 广播地址：用于向网络中的所有的设备进行广播。具有正常的网络号部分，而主机号部分全为1(即255)的ip地址称之为广播地址，如172.16.45.255就是一个B类的广播地址 有限广播地址：指的是32位全位1(即255.255.255.255)的ip地址，用于本网广播 回送地址：网络地址不能以十进制的127作为开头，在地址中数字127保留给系统作为诊断用，称为回送地址，如127.0.0.1用于回路测试 私有地址：只能在局域网内使用，不能在internet上使用的ip地址称为私有ip地址，私有ip地址有： 10.0.0.0～10.255.255.255，表示一个A类地址 172.16.0.0~172.31.255.255,表示16个B类地址 192.168.0.0～192.168.255.255，表示256个C类地址 0.0.0.0:指已经不是真正意义上的ip地址，它表示的是所有不清楚主机和目的网络，这里的不清楚指的是在本机路由表里没有特定条目指明如何到达 子网掩码 子网掩码是一个 32 位的 2 进制数，其对应网络地址的所有位置都是 1，对应与主机地址的所有位置都是 0。将子网掩码和 IP 地址按位进行逻辑与运算，得到 IP 地址的网络地址，剩下的部分就是主机地址，从而区分出任意 IP 地址中的网络地址和主机地址 子网掩码 ip 判断 子网掩码告知路由器，IP 地址的前多少位是网络地址，后多少位是主机地址，使路由器正确判断任意IP地址是否是本网段的，从而正确的进行路由，例子： 主机1： ip 221.21.160.5 子网掩码：255.255.255.192 主机2： ip 222.21.160.73 子网掩码：255.255.255.192 现在主机1 向 主机 2 发送数据，首先要判断两个主机是否在同一网段，逻辑与运算后，显然前三位的值都是 221.21.160，C 类地址判断前三位是否相同，即可确定2个IP地址是否在同一网段内，但本例中的222.21.160.6与222.21.160.73不在同一网段，因为这两个C类IP地址已经做了子网划分就不能只判断前三位是否相同就确认这两个IP是否在同一网段。其中222.21.160.6在222.21.160.1-222.21.160.62 段，222.21.160.73在222.21.160.65-222.21.160.126 段，所以不在同一网段[2] ，如果要通信需要通过路由器转发。 子网划分 子网划分的概念 子网划分的定义：Internet 组织机构定义了五种 IP 地址，由 A, B, C 三类地址，每个 A 类网络可能由 1600 百多万台主机，它们处于同一广播域，而在同一广播域中由这么多节点是不可能的，网络会因为广播通信而饱和，结果造成大部分地址没有分配出去。可以基于每类的IP网络进一步的分成更小的网络。每个子网由路由器界定并分配一个新的子网网络地址，子网地址是借用基于每类的网络地址的主机部分创建的。划分子网后，通过使用掩码，把子网隐藏起来，使得从外部来看网络没有任何变化。 当我们对一个网络进行子网划分时，基本上就是将它分成小的网络。比如，当一组IP地址指定给一个公司时，公司可能将该网络“分割成”小的网络，每个部门一个。这样，技术部门和管理部门都可以有属于它们的小网络。通过划分子网，我们可以按照我们的需要将网络分割成小网络。这样也有助于降低流量和隐藏网络的复杂性。 子网划分是通过借用 ip 地址的若干位主机位来充当子网地址，从而将原来的网络分为若干个彼此隔离的子网实现的 子网划分 注意： arp 协议通过 ip 地址获取目标主机的mac地址这一过程是使用的广播的方式，这个广播地址就是通过子网地址于子网掩码计算而来的，只有计算出的这一子网内的主机才能收到这个 arp 广播包 子网划分和 vlan 都可以做到隔离广播域，只是子网划分是三层隔离，vlan 是二层隔离 c 类子网划分 c 类网络子网划分 划分子网时，随着子网地址借用主机位数的增多，子网的数目随之增加，而每个子网中的可用主机数逐渐减少。以C类网络为例，原有8位主机位，2的8次方即256个主机地址，默认子网掩码255.255.255.0。借用1位主机位，产生2个子网，每个子网有126个主机地址；借用2位主机位，产生4个子网，每个子网有62个主机地址……每个网中，第一个IP地址（即主机部分全部为0的IP）和最后一个IP（即主机部分全部为1的IP）不能分配给主机使用，所以每个子网的可用IP地址数为总IP地址数量减2；根据子网ID借用的主机位数，我们可以计算出划分的子网数、掩码、每个子网主机数，列表如下： ​ ① 划分子网数 ② 子网位数 ③子网掩码（二进制） ④ 子网掩码（十进制） ⑤ 每个子网主机数 ​ ① 1～2 ② 1 ③ 11111111.11111111.11111111.10000000 ④ 255.255.255.128 ⑤ 126 　　 ① 3～4 ② 2 ③ 11111111.11111111.11111111.11000000 ④ 255.255.255.192 ⑤ 62 　　 ① 5～8 ② 3 ③ 11111111.11111111.11111111.11100000 ④ 255.255.255.224 ⑤ 30 　　 ① 9～16 ② 4 ③ 11111111.11111111.11111111.11110000 ④ 255.255.255.240 ⑤ 14 　　 ① 17～32 ② 5 ③ 11111111.11111111.11111111.11111000 ④ 255.255.255.248 ⑤ 6 　　 ① 33～64 ② 6 ③ 11111111.11111111.11111111.11111100 ④ 255.255.255.252 ⑤ 2 ​ 如上表所示的C类网络中，若子网占用7位主机位时，主机位只剩一位，无论设为0还是1，都意味着主机位是全0或全1。由于主机位全0表示本网络，全1留作广播地址，这时子网实际没有可用主机地址，所以主机位至少应保留2位。 子网划分步骤 确定要划分的子网数以及每个子网的主机数 求出子网数目对应的二进制的位数 N 及主机数目对应的二进制数的位数 M 对该ip地址的原子网掩码，将其主机地址部分的前N位置1(其余全部置0)或后M位置0(其余全置1)即得出该ip地址划分子网后的子网掩码 eg：给 C 类网络 211.168.10.0 划分 5 个子网 22-23-2所以需要3位网络号，主机号为8-3=5 子网掩码为255.255.255.224 每个子网可容纳2**5-2=30台主机 为什么要子网划分 Internet组织机构定义了五种IP地址，用于主机的有A、B、C三类地址。其中A类网络有126个，每个A类网络可能有16，777，214台主机，它们处于同一广播域。而在同一广播域中有这么多结点是不可能的，网络会因为广播通信而饱和，结果造成16，777，214个地址大部分没有分配出去，形成了浪费。而另一方面，随着互连网应用的不断扩大，IP地址资源越来越少。为了实现更小的广播域并更好地利用主机地址中的每一位，可以把基于类的IP网络进一步分成更小的网络，每个子网由路由器界定并分配一个新的子网网络地址,子网地址是借用基于类的网络地址的主机部分创建的。划分子网后，通过使用掩码，把子网隐藏起来，使得从外部看网络没有变化，这就是子网掩码。 很简单的说 就是，一个公司不可能使用254个公网地址，A公司想用6个地址，B公司也想用6个地址，如果把这两个公司的地址都放在一个大网段里面，这两个公司的地址就能够直接互通 子网划分的优点 减少网络流量 提高网络性能 简化管理 易于扩大地理范围 子网划分注意事项 在子网划分时不仅需要考虑目前需要，还应该了解将来需要多说子网和主机。子网掩码使用较多的主机位，可以得到更多子网，节约了ip地址资源，若将来需要更多的子网时，不用再重新分配ip地址，但每个子网的主机数量有限；反之，子网掩码使用较少的主机位，每个子网的主机数允许有更大的增长，但可用子网数有限 一般来说，一个网络中的节点数太多，网络会因为广播通信而饱和，所以网络中的主机数量的增长是有限的，也就是说，在条件允许的情况下，应将更多的主机位用于子网位 "},"gis/GDAL.html":{"url":"gis/GDAL.html","title":"GDAL","keywords":"","body":"GDAL [toc] GDAL源码剖析与开发共9章分3个部分： 第一部分为前五章，GDAL简介，ORG库，GDAL库以及GDAL的数据格式和配置项 第二部分是6到8章，GDAL的高级使用说明，包括GDAL格式扩展，GDAL算法和CPL库 第三部分是第9章，介绍GDAL工具的使用 GDAL简介 什么是GDAL？ GDAL提供了一系列算法接口，比如矢量栅格化，栅格矢量化，图像校正以及DEM相关的算法接口 GDAL源码目录结构 alg：提供算法的源代码，算法有：DEM生成登高线，图像纠正算法，栅格矢量化，矢量栅格化，格网计算，分类图小碎斑块去除 apps：存放的是GDAL库中提供的一些命令行工具集的源代码，eg：gdalinfo data：配置文件，eg：各种投影文件 doc：帮助文档 frmts：gdal针对不同图像格式解析的源代码 gcore：gdal的灵魂，抽象类的数据集，波段，图像读写接口都在这里面 ogr：emmm，负责读写矢量的 port：gdal库的底层的支持库，基本操作的实现，eg：字符串的操作，文件处理，网页请求，数据库连接，哈希表，字符加密文件压缩等 swig：封装库的工具 编译gdal C++ nmake -f makefile.vc 有坑，gdal3版本以上的编译的时候需要proj库的支持 又重新下载了2.4.1版本的 编译结果： 生成gdal_vs2017.vcxproj这个文件 执行：generate_vcxproj.bat 15.0 64 gdal_vs2017（虽然我是2019的环境，但是好像没有影响） 有这个文件之后就可以编译了 打开该文件，生成解决方案（可能会要求重定解决方案目标）即可 Python python编译就很简单，有环境就行，但是我记得好像有坑，对，就是版本不符合的情况，需要环境对应的版本，所以不能使用conda和pip的方式安装，需要自己下载对应的版本 OGR空间参考 空间参考简介 大地水准面：由静止海水面向大陆延伸所形成的不规则的封闭曲面 地球椭球体：人们选用的一个同大地水准面相近的可以用数学方法来表达的椭球体（规则曲面） 基准面：特定区域内与地球表面极为吻合的椭球体 地图投影 把地球表面的任意点利用一定的数学法则，转换到地图平面上的理论和方法 地理坐标系（GCS) 用于确定地物在地球上位置的坐标系，一般是基于某一个基准面使用三维球面来定义位置。GCS应该包括：角度测量单位、本初子午线、基准面。 投影坐标系（JCS） 投影坐标系是基于地理坐标系的，使用x，y值来描述地球上某个点的位置 OGR实现空间参考 空间参考主要有以下十种表示方法（gdal默认格式为WKT）： 在OGR中，类OGRSpatialReference封装了投影和基准面的定义。 导入坐标系： ImportFromWkt() ImportFromEPSG() ImportFromProj4() ImportFromESRI() ImportFromPCI(, , ) ImportFromUSGS(, ) ImportFromXML() 导出坐标系： ExportToWkt() ExportToPrettyWkt() ExportToProj4() ExportToPCI() ExportToUSGS() ExportToXML() OGR空间参考的转换是基于PROJ4库来实现的。OGR中进行坐标转换的类是OGRCoordinateTransformation，转换的时候先创建一个对象，然后调用Transform方法来进行坐标转换。 对一个几何形状进行投影变换（Linux环境下）： sourceSR = osr.SpatialReference() sourceSR.ImportFromEPSG(32612) #UTM 12N WGS84 targetSR = osr.SpatialReference() targetSR.ImportFromEPSG(4326) #Geo WGS84 coordTrans = osr.CoordinateTransformation(sourceSR, targetSR) geom.Transform(coordTrans) 这个过程很可能会失败，因为它可能使用了PROJ.4库不支持的投影或者转换的几何对象中有一个以上没有定义的数字。 OGR库说明 OGR主要由以下七个部分组成： Geometry：类Geometry (包括OGRGeometry等类)封装了OpenGIS的矢量数据模型，并提供了一些几何操作，WKB(Well Knows Binary)和WKT(Well Known Text)格式之间的相互转换，以及空间参考系统(投影)。 Spatial Reference：类OGRSpatialReference封装了投影和基准面的定义。 Feature：类OGRFeature封装了一个完整feature的定义，一个完整的feature包括一个geometry和geometry的一系列属性。 Feature Definition：类OGRFeatureDefn里面封装了feature的属性，类型、名称及其默认的空间参考系统等。一个OGRFeatureDefn对象通常与一个层(layer)对应。 Layer：类OGRLayer是一个抽象基类，表示数据源类OGRDataSource里面的一层要素(feature)。 Data Source：类OGRDataSource是一个抽象基类，表示含有OGRLayer对象的一个文件或一个数据库。 Drivers：类OGRSFDriver对应于每一个所支持的矢量文件格式。类OGRSFDriver由类OGRSFDriverRegistrar来注册和管理。 Geometry（几何对象） Geometry包括了各种各样的矢量图形 # 创建一个点 point = ogr.Geometry(ogr.wkbPoint) point.AddPoint(1198054.34, 648493.09) # 创建一条线 line = ogr.Geometry(ogr.wkbLineString) line.AddPoint(1116651.439379124, 637392.6969887456) line.AddPoint(1188804.0108498496, 652655.7409537067) line.AddPoint(1226730.3625203592, 634155.0816022386) line.AddPoint(1281307.30760719, 636467.6640211721) # 创建一个面 # 先创建一个ring ring = ogr.Geometry(ogr.wkbLinearRing) ring.AddPoint(1179091.1646903288, 712782.8838459781) ring.AddPoint(1161053.0218226474, 667456.2684348812) # 把ring添加进面 poly = ogr.Geometry(ogr.wkbPolygon) poly.AddGeometry(ring) print(\"point:\\n\",point,\"\\nline:\\n\",line,\"\\npolygon:\\n\",poly) # 从不同格式中创建点 # WKT wkt = \"POINT (1120351.5712494177 741921.4223245403)\" point1 = ogr.CreateGeometryFromWkt(wkt) # WKB wkb = b64decode(\"AIAAAAFBMkfmVwo9cUEjylouFHrhAAAAAAAAAAA=\") point2 = ogr.CreateGeometryFromWkb(wkb) # GeoJSON geojson = \"\"\"{\"type\":\"Point\",\"coordinates\":[108420.33,753808.59]}\"\"\" point3 = ogr.CreateGeometryFromJson(geojson) # GML gml = \"\"\"108420.33,753808.59\"\"\" point4 = ogr.CreateGeometryFromGML(gml) # 打印数据 print(\"point1:\\t\",point1,\"\\tpoint2:\\t\",point2,\"\\npoint3:\\t\",point3,\"\\tpoint4\\t\",point4) Geometry还提供了常用的空间分析方法，如求并、交、缓冲区等（基于GEOS库），但是也有很多空间分析方法也没有实现，如叠加 Spatial Reference(空间参考) OGR的空间参考系统数据模型继承了OpenGIS的WKT格式，还有一个基于PROJ.4库实现的OGRCoordinateTransformation类用以在不同的坐标系中进行转换 Feature/Feature Definition（要素/要素定义） OGRFeature包含了一个OGRGeometry对象，此外还有要素属性、要素ID和要素的类别信息 对于属性表来说，属性的类型、名称是通过OGRFeatureDefn类来定义的，通常一个图层（Layer）对应一个属性表（OGRFeatureDefn），同样类型的要素及其属性表的定义是相同的。 Layer（图层） OGRLayer类用来表示一个数据源中一个图层的所有要素，它包含了从数据源中读取要素的方法，OGRLayer可以认为是从数据源中读写要素数据的途径。 OGRLayer包含顺序和随机的读写数据的方法，时间顺序读取所有的要素（GetNextFeature），空间过滤器按照地理范围来找需要的要素（SetSpatialFileter，只能对一个指定图层），更复杂的Fileter可以执行SQL查询语句 layerSites.SetSpatialFilterRect(460000, 4590000, 490000, 4600000) #SQL过滤 result = dsSites.ExecuteSQL(\"select * from sites where cover = 'grass' order by id desc\") resultFeat = result.GetNextFeature() while resultFeat : printf(resultFeat.GetField('id')) resultFeat = result.GetNextFeature() dsSites.ReleaseResultSet(result) #将查询结果释放 OGRLayer 类和 OGRFeatureDefn类是独立的，但是一个OGRLayer类总是对应一个OGRFeatureDefn类，为什么不将它们合并为一个类呢？ 定义的OGRFeature和OGRFeatureDefn是不需要依赖任何OGRLayer 的，所以他们可以在内存中独立存在而不需要依赖数据源中的某个图层 SF CORBA模型没有图层的概念 Data Source（数据源） 一个DataSource是一系列OGRLayer的组合，通常表示为一个文件。OGRDataSource是一个抽象基类，从该类派生的每个子类都是一种文件格式驱动的实现，我们不能直接实例化该类，而是实例化OGRSFDriver类。 Drivers（格式驱动） 每一个OGRSFDriver对象都是一个OGR支持的一种文件格式的实现，OGRSFDriver对象使用OGRSFDriverRegistrar类来进行注册的。 GDAL库说明 GDAL数据集总体概况 GDAL使用抽象数据模型来解析它所支持的数据格式，抽象数据模型包括以下几部分：数据集（Dataset），坐标系统（Coordinate System），仿射地理坐标转换（Affine GeoTransform），地面控制点（GCPs），元数据（Metadata），子数据集域（Subdatasets Domains），图像结构域（Image_Structure Domain）、RPC域（RPC Domain）、XML域（XML Domian），栅格波段（Raster Band），颜色表（Color Table）和快视图（Overviews） 数据集（Dataset）是有栅格波段和一些相关信息共同组成，在一个数据集中所有波段具有相同的大小，相关信息包括数据的地理坐标、投影信息和一些元数据信息等 坐标系统使用WKT格式来表示，GDAL数据集中有两种方式来表示栅格序列号坐标和地理坐标之间的关系，第一种是利用仿射变换来表示，另外一种是利用GCP（地面控制点）点对来表示，数据集中一般会包含一个仿射地理坐标转换参数或GCP点。GDAL数据模型中不会存储用GCP点对进行图像纠正的转换方程，这个转换方程有应用程序处理 元数据是对数据的辅助说明，与影像在磁盘中的存储方式没有特定关系。 子数据集域是包含有很多个子数据集的字符串列表，提供指向多个影像的指针 图像结构域，与图像的格式及存储机制紧密关联，定义的项目主要有以下几个：compression：数据集或者波段的压缩方式，nbits：当前数据集中一个或多个波段实际占用的比特数，等 RPC域（RPC Domain）：与仿射变换一个作用，都是用来表示图像行列号与空间参考位置间的变换，但是它保存的是有理函数模型的系数 栅格波段（Raster Band），在GDAL中栅格波段使用GDALRasterBand类表示，它表示一个栅格波段、通道或者图层。栅格波段包含以下属性：行列数（可以是金字塔的行列数），数据类型，块大小（通过块读取数据是最高效的方式），元数据，以及一些可选的属性 快视图（Overviews），每个快视图都是一个独立的GDALRasterBand，是通过原始图像进行降采样得到的，用于图像的快速显示。 GDAL常用类说明 GDALDataset是相关栅格波段的集合；GDALDriver是格式化的驱动，这个类的每个实例都支持一种格式，并且管理该格式的相关信息；GDALDriverManager是管理文件格式驱动的注册信息的类；GDALRasterBand是处理一个单波段的栅格数据 GDAL元数据说明 元数据中存储的是对图像数据的描述信息，比如JPG图像中的EXIF信息，HDF数据中的一些描述信息，关于元数据信息可以通过gdalinfo工具进行查看 gdalinfo HYP_50M_SR_W.tif 我们得到的信息有： •图像驱动是“ GTiff / GeoTIFF” •图像尺寸为10800x5400 •图像四个角的坐标 •没有坐标系 RasterIO使用说明 使用GDAL读写图像是最基本的操作了，RasterIO类就是最常用的函数了，RasterIO分为GDALRasterBand类的和GDALDataset类的，两者大多数情况是一致的 图像金字塔 图像金字塔是以多分辨率来解释图像的一种结构，一幅图像的金字塔是一系列以金字塔形状排列的分辨率逐步降低的图像集合。目前遥感图像的金字塔格式主要有两种：rrd格式，ovr格式。 颜色表 颜色表是GDALRasterBand中的一个属性，颜色表的本质是给每一种灰度值设置一个颜色，用以让一个灰度图像变成彩色图像，最常用的就是分类图了，网络地图的矢量切片地图也用颜色表，可以在保持图像色彩不变的情况下大大减少数据量，一般我们认为图像的一个瓦片是一个三波段的PNG图像，实际上它只是一个单波段的带有颜色表的图像。 图像统计信息 图像统计信息包括直方图信息，最大最小值，均值和标准差，在计算统计值的时候，对于大图像的计算量是很大的，所以在第一次计算的时候就把计算的结果信息保存，GDAL使用了一个.aux.xml的辅助文件来将这些信息存储 GDAL数据格式及配置项说明 GDAL库中提供了大多数的图像数据和矢量数据的支持，但是对于某些数据而言，在读写（尤其是创建和更新数据时）时候要按照一定的规则来进行处理，这一章接下来的都是对格式的介绍了，没变要细看 GDAL格式扩展说明 如果算法库是基于GDAL进行编写的，那么要支持一种新的格式，就需要将所有的算法重新编写，这样势必产生大量的重复性工作，但是GDAL提供了格式扩展说明，即使我们处理一些目前GDAL不支持的数据格式，比如自定义的图像个格式，也可以通过GDAL进行格式扩展，使之能够读写自定义的格式，这样就不必修改上层的算法，更新以下GDAL库即可。 栅格格式扩展 一般来说，GDAL对新格式的扩展需要对GDALDataset类和GDALRasterBand类的继承来实现，然后为一个新格式创建一个GDALDriver的实例，然后通过GDALDriverManager类将新格式的驱动进行注册，实现一个新格式的驱动主要包含以下九部分的内容： 从Dataset继承 从RasterBand继承 栅格驱动（Driver） 添加驱动到GDAL中 添加地理参考信息 金字塔（快视图） 创建文件 RawDataset和RawRasterBand类 元数据和其它外部扩展 改代码演示了如何创建一个读取日本地理测量学会定义的DEM数据格式的驱动，网址 Dataset继承：通过重载GDALDataset中的一些虚函数来为驱动重新实现这些特殊功能，但是Open()函数不是基类的虚函数，所以需要一个独立的函数来实现该功能。 先尝试驱动是否支持该类型，如果可以则将所有波段与当前的GDALDataset对象绑定 好复杂，不想看了，自己感觉也用不上 矢量格式扩展 对OGR库扩展的一般流程就是从OGRSFDriver类，OGRDataSource类和OGRLayer类继承三个子类，然后从OGRSFDriver类继承的子类使用OGRSFDriverRegistrar进行注册。 以一个简单的文本存储的点文件格式为例，对OGR库的扩展进行一些说明，主要包括三个方面：实现OGRSFDriver类，从数据源中读取数据，读取图层 实现OGRSFDriver类 实例化函数 void RegisterOGRSPF () { OGRSFDriverRegistrar::GetRegistrar()->RegisterDriver(new OGRSPFDriver()); } 驱动类一般实现对该格式的读取（Open）、创建（CreateDataSource）和删除（DeleteDataSource)，驱动类定义如下： class OGRSPFDriver : public OGRSFDriver{ public:~OGRSPFDeiver(); const char* GetName(); OGRDataSource* GetName(); OGRDataSource* Open(const char*, int); OGRErr DeleteDataSource(const char* pszName); int TestCapability(const char*); } 构造函数使用默认即可： OGRSPFDriver::~OGRSPFDriver(){ } GETName返回一个字符串： OGRSPFDriver::~OGRSPFDriver::GetName(){ return \"SPF\"; } Open函数： OGRDataSource* OGRSPFDriver::Open(const char* pszFileName, int bUpdate){ OGRSPFDataSource* poDS = new OGRSPFDataSource(); if(!poDS->Open(pszFileName, bUpdate)){ delete poDS; return NULL; } else return poDS; } TestCapability()来判断驱动、数据源和图层中的某些功能是否可用，驱动的操作只有创建和删除两种，都返回false即可 int OGRSPFDriver::TestCapaility(const char* pszCap){ return FALSE; } 从数据源读取数据 实现只读的数据驱动，数据源的主要功能就是管理图层，对于SPF格式来说，一个数据源就只有一个图层，所以需要在Open函数中图层的名称进行设置，然后对当前的数据格式进行重写 、、、（又没读下去，我真是废物） GDAL算法的使用说明 GDAL算法进行说明，实现一些常用的图像处理功能 GDAL算法处理基础 大图像处理策略：随着影像的分辨率越来越高，数据愈来愈大，处理大图像最常用的策略是分块，每次只处理一块数据，直到处理完所有的块，常用的分块有：按行分块、按正方形分块和其它矩形分块 按行分块就是一次性处理一行数据，常用于图像邻域无关的算法，比如图像融合、数据拉伸等；如果正方形分块，在处理的时候最右边和最下边的分块可能就是不规则的正方形分块。分块的时候有一个总的原则，分块要尽可能大，这样才能减少图像的I/O次数。 如果处理时间长，所以可以加上一个进度条 GDALWarp说明 GDAL中的Warp类的功能有：图像重采样，图像镶嵌，图像裁切（规则裁切或则AOI裁切），图像校正（RPC、GCP校正），波段合并等 GDALWarp中主要由GDALWarpOperation和GDALWarpOptions两大部分组成，其中前者是用来进行变换操作，后者是构造进行变换操作的选项 图像重投影和后面的投影校正，本质上就是对图像的坐标进行转换，然后进行重采样得到新的图像，它们的步骤基本上是一样的，唯一的区别是坐标转换的函数不同而已 GDAL坐标转换 GDAL中，所有的坐标转换函数都是有统一的形式的，每一种坐标转换都由三个函数组成，分别是create，destroy，transform GDAL地形分析 DEM地形分析中，坡度，坡向，地表粗糙指数，地形方位指数，粗糙度五个算法的实质就是3*3空间卷积算法 格网插值 利用离散的数据点创建一个栅格图像的过程，目前的插值算法由三种：反距离权重插值，移动均值插值，最邻近插值 小碎斑去除 矢量栅格化 栅格矢量化 CPL库介绍 CPL（Common Portability Library）里面封装了大量通用函数，主要有常用的数据结构，文件读写，数据库操作，网络数据读取，多线程等 "},"gis/Geomorphology-Based Hydrological Model.html":{"url":"gis/Geomorphology-Based Hydrological Model.html","title":"Geomorphology-Based Hydrological Model","keywords":"","body":"Geomorphology-Based Hydrological Model Blog NetCDF(network Common Data Form)网络通用数据格式是一种面向数组型并适于网络共享的数据的描述和编码标准。目前，NetCDF广泛应用于大气科学、水文、海洋学、环境模拟、地球物理等诸多领域。用户可以借助多种方式方便地管理和操作 NetCDF 数据集。 部署与运行 请在 linux 操作系统中进行部署，下面是简要的部署过程，如遇到问题可以联系 李轶博(li-yb16@mails.tsinghua.edu.cn) 准备工作 准备模型和相关文件 $ export basedir=/WORK/thu_ztcong_1/gbhm $ ls $basedir esmf-intel-mpich3.rc README.md src test 安装依赖 安装 MPICH3, hdf5, netcdf-c, netcdf-fortran, esmf， 可以通过源码编译安装，也可通过系统有包管理器安装dev版本。 下面是 esmf 源码安装的步骤，请根据实际情况调整: $ cd $basedir $ git clone https://github.com/esmf-org/esmf.git $ cd esmf $ git checkout ESMF_7_1_0rp1_beta_snapshot_07 $ source $basedir/esmf-intel-mpich3.rc $ make -j 4 $ make install 编译和运行 在 test 目录中有一测试用算例，编译模型后运行该模拟算例。 $ source $basedir/esmf-intel-mpich3.rc $ cd $basedir/src && make $ cd $basedir/test && mpirun -n 20 $basedir/src/app.exe $basedir/test/config.rc Clock ---------------------------------- currTime = Time ----------------------------------- 2010-01-01T00:00:00 end Time ------------------------------- end Clock ------------------------------ Clock ---------------------------------- ... 结果检查 在 result 文件夹下是结果，包括径流模拟结果和状态变量历史文件。 status.nc 是什么 $ tree $basedir/test/result test/result/ ├── discharge.txt ├── hist │ ├── hist_20100101.nc │ ├── hist_20100102.nc │ ├── hist_20100124.nc │ ├── hist_20100124.nc │ ├── hist_20100124.nc ... 输入数据 pres_201001.nc rain_201001.nc rhum_201001.nc sun_201001.nc temp_201001.nc wind_201001.nc lai lai_2010.nc "},"gis/GIS标准.html":{"url":"gis/GIS标准.html","title":"GIS标准","keywords":"","body":"现在我们有一些点： 点应该在坐标系上（什么坐标系） 为了别人也能用这些点，人与人之间的交流，需要定义一种规范（OGC) 如何保存到计算机中，肯定要用OGC规范了，常用的工具有： 常常保存的格式有：（格式不同一般就是结构不一样） 讲一个常用的工具：GDAL，准确的说法应该是GDAL/OGC wkt规范在GDAL中怎么存的 点在GDAL中怎么存的 点可以了，线和面呢 GIS开发主要看OGC规范 GDAL使用抽象数据模型(abstract data model)来解析它所支持的数据格式，抽象数据模型包括数据集(dataset)，坐标系统，仿射地理坐标转换(Affine Geo Transform)， 大地控制点(GCPs)， 元数据(Metadata)，栅格波段(Raster Band)，颜色表(Color Table)，子数据集域(Subdatasets Domain)，图像结构域(Image_Structure Domain)，XML域(XML:Domains)。 空间矢量数据交换文件由四部分组成： 第一部分为文件头。包含该文件的基本特征数据，如图幅范围、坐标维数、比例尺等。 第二部分为地物类型参数及属性数据结构。地物类型参数包括地物类型代码、地物类型名称、几何类型、属性表名等。属性数据结构包括属性表定义、属性项个数、属性项名、字段描述等。 第三部分为几何图形数据及注记。包含目标标识码、地物类型码、层名、坐标数据等。注记包含了字体、颜色、字型、尺寸、间隔等。 第四部分为属性数据，包含属性表、属性项等。 1.提出3个问题 2.OGC规范（主要讲解WKT） 3.GDAL的介绍和简单操作 4.GeoJSON的介绍 5.结论 GeoJSON支持以下几何类型：Point，LineString， Polygon，MultiPoint，MultiLineString，和MultiPolygon。具有其他属性的几何对象是Feature对象。要素集包含在FeatureCollection对象中。 GIS抽象数据模型=》OGC? GDAL基于OGC? GeoJson基于OGC？ 但是我们测量的结果只是一个.dat格式的文件，所以说我们需要格式的转换。 怎么将测量数据真正应用到实际生产中？ 数据没有了标准就好比坐标没有了坐标系——没有实用价值了 "},"gis/GIS算法基础.html":{"url":"gis/GIS算法基础.html","title":"GIS算法基础","keywords":"","body":"聚类算法 wiki 距离 元素可以联系起来 Clustering by fast search and find of density peaks 局部密度 截断距离 一个为离散值，一个为连续值 如果决策图不好的情况 该算法可以作为其它算法的预处理（确定聚类中心的个数及初始的聚类中心） "},"gis/Google Earth Engine.html":{"url":"gis/Google Earth Engine.html","title":"Google Earth Engine","keywords":"","body":"[toc] Google Earth Engine 参考 网络资源 知乎， Google Earth Engine小史 作者就是这个出来的数据科学家，他的专栏的“地球云计算”是我在中文资源能看到的最好的资源，专栏中的一下文章值得看一下，但是后面没有更新了，所有的新的内容也没有了 b站，经典论文的汉译版 GEE相关的最经典的Google Earth Engine: Planetary-scale geospatial analysis for everyone论文的汉译版，但是只翻译了一半，而且有些地方翻译的有问题 PANGEO 用于云原生地球系统分析的封闭平台与开放架构 比较了几个平台 参考论文 Google Earth Engine: Planetary-scale geospatial analysis for everyone GEE最经典的论文 An Overview of Platforms for Big Earth Observation Data Management and Analysis 比较了相关的几个平台，没来及的看 论文1. Google Earth Engine: Planetary-scale geospatial analysis for everyone Abstract Google Earth Engine 是一个基于云计算的星球级地理空间分析平台，它将谷歌庞大的计算能力用于解决各种高影响的社会问题，包括森林砍伐、干旱、疾病、食品安全、水管理、气候监测和环境保护。它在该领域是一个独一无二的综合平台，因为它不仅可以提高了传统遥感科学家分析的能力，还弥补了用户缺乏利用传统超级计算机或大规模商品云计算资源所需的技术能力的鸿沟。 1. Introduction 目前，超级计算机和高性能计算系统逐渐性能过剩，大量级的云计算以商品的形式变得触手可及。与此同时，来自 NASA、 U.S. Geological Survey 和 NOAA 等多个美国政府机构和 European Space Agency 的 PB 级别存档遥感数据已免费对外提供，相应的地理信息数据大量级处理技术（如 TerraLib、Hadoop、GeoSpark 和 GeoMesa）也日臻成熟。 但是要充分利用这些海量数据资源仍然有相当高的技术要求。其中一个主要障碍就是基础的 IT 管理：数据的获取和存储；解析晦涩难懂的文件格式；管理数据库、机器分配、任务和任务队列、CPUs、GPU、网络；使用众多的地理空间数据处理框架等等； 这种负担可能使许多研究人员和业务用户无法使用这些工具，从而限制了研究人员对于海量遥感数据的研究。 针对以上问题，Google Earth Engine（GEE）应运而生。Google Earth Engine是一个基于云的平台，它使人们可以很容易地获得高性能的计算资源来处理非常大的地理空间数据集，不需要先掌握复杂的IT技术。此外，与大多数超级计算中心不同，Earth Engine的设计也是为了帮助研究人员轻松地将他们的成果分享给其他研究人员、政策制定者、非政府组织、现场工作人员，甚至是普通公众。一旦一个算法在地球引擎上被开发出来，用户就可以在Earth Engine的支持下制作系统的数据产品或部署可交互的应用程序，而不需要用户首先成为应用程序开发、网络编程或HTML方面的专家。 由谷歌、卡内基梅隆大学和美国地质调查局联合开发的 GEE 是目前世界上先进的 PB 级地理数据科学分析及可视化平台。GEE 面向用户提供海量卫星影像数据集与地理数据集，包括 40 多年历史卫星影像数据与欧空局的卫星影像数据。同时，GEE 提供基于 JavaScript 和 Python 语言的 API 接口、分析算法与工具，方便用户实现大型数据的处理分析与信息挖掘。 2. Platform overview Google Earth Engine 提供了多个类别 PB 级的可供分析的数据以及高性能并行计算服务，二者均可通过 API 获取及控制，并且 GEE 集成了基于 Web 的 IDE（Interactive Development Environment）使得快速原型实现和结果可视化成为可能。 Google Earth Engine 的数据库保存了大量的公共地理信息数据，包括各类卫星、航拍得到的光学和非光学波长的观测数据、环境变化、天气和气候的预报及后判、地形数据、社会经济学数据等等。所有这些数据都是经过一定预处理且保证不丢失相关信息的可直接使用形式（ready-to-use but information-preserving）。 用户可以使用和分析来自公共目录下的数据，也可以通过 API 调用数据库操作器来添加自己的私人数据库。该操作器是集成到大型并行处理系统的，能够自动划分算力，提供高通量的分析能力。用户既可以通过一个体量很小的 Client Library，也可以通过在该 Client Library 基础上构建的交互开发环境来直接调用这些 API，如图1 所示。 Fig 1. The Earth Engine interactive development environment 用户可以在地球引擎的主页上注册访问，并访问用户界面以及用户指南、教程、实例、培训视频、功能参考和教育课程。虽然之前对GIS、遥感和脚本的经验使其更容易上手。如果有编写脚本的经验会让你更容易上手，但这并不是严格的要求，而且用户指南也是面向用户领域新手的。每个帐户有一个上传个人数据和保存中间产品的配额，任何输入或结果都可以下载供离线使用。 3. The data catalog Google Earth Engine 公共数据目录是一个多维度 PB 级地理信息数据集。主要包括来自 Landsat、Sentinel-1、Sentinel-2 的地球观测遥感完整存档数据，以及诸如气候、地表覆盖数据等其他环境、地理信息和社会经济学数据（如Table 1 所示）。数据量还在以每天近 6000 scenes（时延约 24 小时）的速度持续增加和更新。用户可以直接使用这些公共目录下的数据，也可以通过 REST 交互界面上传自己的私人数据且可以自由选择是否共享给他人。 Earth Engine 运行在一个轻量级的 “图像” 容器中，使用基于 2D 网络栅格波段的简单且高度通用的数据模型。单一谱段的像素点需在数据类型、分辨率和投影上保持一致，但是图像可以包含任意数量的谱段且一幅图中的谱段不需要有统一的数据类型和投影。每幅图也具有相关键值对的元数据来存储诸如图像的拍摄位置、拍摄时间和条件等信息。 相关的图像，比如同一个 Sensor 产出的数据分成一组，构成一个数据集。数据集的高速筛选和分类能力使得用户可以轻松地在数以百万计的图像中搜索和选择满足特定区域、时间和其他标准的数据。 导入 Earth Engine 的数据都会经过预处理以达到快速并有效查询使用的目标。 首先，图片按照原有的投射和分辨率切成瓦片存储到高效且备份的瓦片数据库中。每幅瓦片尺寸为 256×256，这是在载入不需要的数据和预加载额外请求数据之间采取的折衷方案。与传统的 “data cube” 系统不同，这种数据摄入处理能够做到不丢失数据信息：数据仍然保持其原有的投影、分辨率和 bit 位，从而避免了数据在重采样到一个固定网格下而产生解构导致可能会不适用于特定的应用。 另外，为了在计算开发过程中能够快速可视化，每幅图都会对应有降低分辨率的瓦片图组成的金字塔模型存储在对应瓦片图数据库中。金字塔中的每一层都是通过对上一层以 1/2 的比例进行缩减像素采样（向下采样）得来的。在向下采样时，连续值谱段通常采取平均采样模式，而对离散值谱段（例如分类标签）使用最小、模式化、最大或固定采样模式中的一种进行采样。当只需要一幅图的一部分数据在降低分辨率下计算时，只有最合适的金字塔层级下相关的瓦片图才会从数据库中被调取出来供使用。这种指数级缩量方式使得数据能够在不同量级都能够使用而又不用耗费大量的存储，同时也能够满足基于 web 的地图展示。 Table 1. Frequently used datasets in the earth engine data catalog 4. System architecture Earth Engine 是建立在 Google data center 环境下的一系列技术基础之上的。其中包括 Borg 集群管理系统、Bigtable、Spanner 分布式数据库、Colossus（Google File System 的接班者）以及用于并行管道计算的 FlumeJava 框架。另外，Earth Engine 还可以与 Google Fusion Tables（一种基于 web 的数据库，支持带有属性的点、线、多边形等几何类型的数据表）进行互操作。 Fig. 2. A simplified system architecture diagram. 如图 所示。Code Editor 和第三方 Web Apps 可以借助客户端库通过 Web REST API 来向系统发送交互或批量请求。即时请求通过 Front End servers 进行处理并向 Compute Master 发送下一级请求。Compute Master 则负责在 Compute Servers 资源池中进行分布式计算的任务规划。Batch Computation 的运行逻辑与此基本一致，只不过是通过 FlumeJava 框架来管理分布规划。支持这两个计算系统的是一系列的数据服务，包括 Asset Database（存有每幅图的元数据并具有高效筛选能力）。前面提到的 Borg 集群管理软件则负责管理系统的每个组件和每项服务在多用户之间的负载均衡。任何单一用户的请求失败只会导致重新发起查询请求而不会对系统造成其他影响。 向 Earth Engie 发送的请求是基于功能进行整合和求解的。用户通过从 Earth Engine 的 800 多个函数中选取自己需要的组合起来构建自己的数据或数据处理请求，这里面既有用于地理信息处理的简繁不等的数学函数，又有机器学习、图像处理等相关的操作函数。这个算法库使得用户可以通过图像代数方法很轻松地处理图像数据，并且支持高阶的函数比如：map（）和 iterate（）（二者均支持对一系列图像应用随机函数）、reduce（）（用来计算按照区域、滑窗、时域、光谱或其他形式组织的统计数据）。在客户端库中包含的各种类型的函数和算法。 该库的基于图像的函数的大部分是对每个像素进行代数运算，在每个频段或频段之间的基础上运行，涵盖整数和浮点数学运算，逻辑比较，位操作，类型转换，条件替换和用于处理像素数组值化的多维数组操作。另外还包括常见的像素操纵函数，例如表查找，分段线性插值，多项式求解和普遍存在的归一化差异等。该库利用几个预制的机器学习工具包，可以轻松访问 20 多种类型的监督分类，回归和无监督集群，以及用于准确性求解的混淆矩阵操作。对于机器视觉任务，可以使用常见的基于内核的窗口操作，例如卷积，形态操作，距离和纹理分析，以及简单的基于邻域的操作，例如梯度，斜率，宽高比和连通性。其他功能还包括图像和波段元数据操作，投影和重采样操作，屏蔽和裁剪，图像到图像位移和配准以及遥感应用常用的各种专用工具，包括约束光谱分离，区域增长和成本映射操作等等。 用户可以组合这些库函数以构建希望执行的计算描述。该计算描述最终以有向非循环图（DAG）的形式呈现给 Earth Engine，其中每个节点代表一个单一函数或数据访问器的执行，并包含命名函数参数的键 / 值对。实质上，这是一个纯函数式编程环境，而 Earth Engine 利用了函数式语言常用的标准技术，例如参考透明度和惰性求值，以实现显著的优化和效率提升。 用户使用客户端库（目前可用 Python 和 JavaScript 语言）编写 Earth Engine 程序，允许用户使用熟悉的程序式编程范式来描述如何处理图表。客户端库为图像、集合和其他数据类型（如数字，字符串，几何和列表）提供代理对象。用户脚本操纵这些代理对象，这些对象记录操作链并将它们组装成能够表达完整计算的 DAG。然后将此 DAG 发送到 Earth Engine 服务进行求解。 DAG 的求解是通过一系列的图表转换实现的。转换后的子图表如果可能的话会立即进行进一步求解来实现贪婪简化，从而避免冗余计算以及任何并行计算不可用的地方。比如，在子图表中表达式 3+7 会立即被简化成 10 这种值的形式。图中的其他节点会被扩展，例如当求解一个指向图像集合的节点时，它会被扩展为一个图像序列以便后续处理批量化执行。表示复杂处理操作的节点可以采用下一节中描述的分布式处理的几种策略中的任何一种。 Earth Engine 旨在支持快速，交互式探索和分析空间数据，允许用户平移和缩放结果来每次查看图像的一个子集。为此，Earth Engine 使用惰性计算模型，该模型仅允许计算满足当前请求所需的特定部分来进行输出。 举个例子，比如说用户可能希望计算两个季节合成图像之间的差异，进而突出显示由于气候或者积雪引起的变化情况。最简单的实现方式就是通过 Earth Engine 的客户端库拉取两个复合图像的差集。 Listing 1. Computing the difference of median composites from two seasons. 此代码创建了两个过滤的集合，其中一个是 11 月，12 月和 1 月的所有 Landsat 8 图像，另一个是 6 月，7 月和 8 月的所有 Landsat 8 图像。首先计算每个数据集中每个谱段的时域插值（目的是为了最小化云和云阴影的影响），然后减去所得到的复合图像结果来计算值的变化。该计算描述的 DAG 表示如图 所示. The DAG produced for Listing 1 传统（非惰性）计算环境可能会在处理表达式后立即开始计算一个或两个复合材料的像素，这通常需要提前将输入数据集预处理为公共地图投影，分辨率和感兴趣区域。 相反，Earth Engine 采用了不同的方法：它推迟计算输出像素，知道它清楚了解到这些结果是在什么样的情况下是必须的。例如，如果结果当前显示在交互式地图上，则地图的缩放级别和视图边界可以动态地决定输出的投影和分辨率，并且可以将像素计算限制为仅可查看的像素。或者，如果结果当前要被用作另一计算的输入，则该计算可以请求所需像素的适当投影，分辨率和边界。此信息用于动态地自动重新采样和重新投影输入数据，从而可以快速可视化结果或在更复杂的计算中使用该表达式，而无需用户预先指定需要哪些像素。默认情况下，使用输入的最近邻重采样来对所请求的输出投影进行重新投影和重采样（从每个输入的下一个最高分辨率金字塔等级中选择像素），以保持频谱完整性。但是，当用户对如何管理这种重投影有偏好时，他们可以选择精确控制投影网格，并可以选择双线性和双三次采样模式。 这种方式更有助于采用交互模式和迭代模式来开展数据挖掘和算法开发。一旦用户完成算法的开发并想要大规模应用，他们可以向 Earth Engine 提交一个批处理请求来计算得到完整结果并在 Earth Engine 中实例化为一副图像或者是可供下载的多幅图像、表格甚至是视频文件。 Table 2. Earth Engine function summary 5. Data distribution models Earth Engine 库中的功能使用多种内置并行化和数据分布模型来实现高性能。每种模型都针对不同的数据访问模式进行了优化。 5.1. 图像瓦片处理 在遥感中使用的许多光栅处理操作是局部的：任何特定输出像素的计算仅取决于某个固定距离内的输入像素。比如例如频带数学计算或频谱解混，以及诸如卷积或纹理分析的邻域操作等针对但像素的操作。通过将区域细分为区块并独立地计算每个区域，可以很容易地并行处理这些操作。处理每个输出图块通常需要为每个输入仅检索一个或少量图块。这与金字塔输入和合理的缓存相结合，可以在任何要求的比例或投影中快速计算结果。如前所述，输入会根据需要随时重新投影以匹配投影输出的需求。当然，如果用户确定不希望使用向下采样或重新投影输入，则可以在输入的投影和比例中明确指定计算方式。 大多数基于图块的操作都是使用两种策略中的一种在 Earth Engine 中实现的，具体取决于它们的计算成本。 针对成本较高的操作以及一次性计算整个瓦片具有显著优势的操作，会将结果写入瓦片尺寸相匹配的输出缓冲区。 瓦片通常为 256×256 像素，以匹配输入预处理的瓦片大小。 对于成本低的单像素运算，是通过在一个可直接相互调用的图表中执行图像处理的界面中按照每次一个像素来进行。这种结果目的是为了充分利用这些操作在 Java 虚拟机（JVM）环境中执行的优势，该环境具有即时（JIT）编译器，编译器负责提取并编译重复发生的函数调用序列。结果表明，在多数情况下，原始图像操作的任意链式操作都可以像手工编译的代码一样有效地执行。 5.2. 空间聚合 正如某些类别的计算本质上是局部的，其他类别本质上是非局部的，例如区域或全局统计的计算，光栅到矢量的转换，或者采样图像以训练分类器。 这些操作或它们的一部分通常仍然可以并行执行，但计算最终结果需要将许多子结果聚合在一起。 例如，计算整个图像的平均值可以通过细分图像，在每个部分上并行计算和计数，然后对这些部分和计数求和来得到所需结果。 在 Earth Engine 中，这些类型的计算使用分散 - 聚集模型作为分布式进程执行。需要执行聚合的空间区域会被划分为子区域分配给分布式算力资源池中的算力单元以便进行批量求解。 每个算力单元获取或计算所需的输入像素，然后运行所需的累积操作以计算其部分结果。 这些结果将被发送回主计算器进行此计算，该计算将它们组合并将结果转换为最终形式。 例如，当计算平均值时，每个算力单元将计算总和与计数，主运算收集并汇总这些中间结果，并以总和除以总计数得到最终计算结果。 5.3. 流式聚合 处理大型遥感数据集的另一个常见操作是时间序列分析。应用在空间上的相同统计聚合操作也可以应用于计算整个图像堆栈中随着时间变化的像素级变化情况。 这些操作都是通过瓦片组合来实现的。以前述方式使用延迟图像求解并行计算得到每个瓦片的输出。在每个瓦片图内，针对每个像素都会执行聚合操作。来自输入图像集合的像素数据是批量请求的，并且通过单像素聚合器进行一次性 “流式传输”。 与输出瓦片相交的所有输入处理完成后，就会在每个像素处都应用最终转换以生成输出结果。 对于具有小中间状态的聚合（比如计算最小值），该分布模型可以做到快速且有效。但是对于不具有中间状态的聚合来说，可能就会非常耗费内存（比如计算 Pearson 的相关性，就需要在计算最终结果之前在每个像素上都存储完整的数据序列）。不过，只要瓦片的大小是明显小于完整图像的，那么即使是非常大的数据集合，流式传输仍然可以做到非常快。例如，对于 Lansat5、7、8 的完整数据集堆栈，包含超过 500 万张图片，在任意一点都只有少于 2000 张瓦片的深度，平均来看其实只有 500 张的深度。 5.4. 缓存以及常见的子表达式消除 Earth Engine 中的许多处理操作的成本和数据密集度都非常高，因此避免冗余计算将回事非常有价值的。例如，在地图上查看结果的单个用户将触发对输出区块的多个独立请求，所有输出区块经常依赖于一个或多个公共的子表达式，例如大空间聚合或监督分类器的训练等。为了避免重新计算先前已经请求的值，使用子图的散列作为高速缓存键将成本较高的的中间结果存储在分布式的高速缓存中。虽然多个用户可能共享缓存中的项目，但两个独立用户独立地进行相同查询的情况并不常见。但是，单个用户在增量算法开发期间重复相同的查询并因此受益于这种缓存机制就是非常常见的了。在单个查询的分布式执行期间，高速缓存还用作共享存储器的形式，存储对应于查询的子图的中间结果。 当对相同计算的后续请求到达时，较早的计算可能已经完成或者仍可能正在进行中。在开始成本高昂的操作之前，会优先去检索缓存并返回之前计算的结果。为了处理早期计算仍在进行中的情况，所有计算都是通过少量计算主服务器发送给分布式算力单元的。这些服务器会在任何给定时刻跟踪群集中正在执行的计算。当新查询到达时，如果它依赖于某些正在进行的计算，该查询将会直接加入原始查询序列中去以等待计算完成。如果计算主机出现失败，则正在进行的计算的处理可能会丢失，这种情况下可能会允许启动冗余计算，但前提是在现有计算任务完成之前就重新请求查询。 6. Efficiency, performance, and scaling 地球引擎利用常规的图像处理的Java即时编译器（JIT）的优势来优化每个像素操作链的执行。为了评估JIT编译器带来的效率提升，我们进行了一系列的实验来比较三种执行模式的性能：使用JIT编译器在Java中运行一个计算图。 使用JIT编译器在Java中执行一个计算图；使用一个类似的在C++中的通用包运行一个图；最后，编写了专门的本地C++ 代码，所有相同的调用是直接进行的，而不是通过一个图，从而避免了函数的虚拟化。五个测试案例，每个案例都测试了不同类型的图像计算图，结果如下 SingleNode: 一个简单的图，其单一节点由一个图像数据缓冲器组成。这个测试简单地计算了一个缓冲区中所有数值的总和。 NormalizedDifference: 这个图计算两个输入缓冲区的差异。这个小图的场景总共包含五个节点：两个输入节点，一个和，一个积和一个商。 DeepProduct: 一个由64个二进制产品节点组成的链的图，计算65个输入节点的乘积。 DeepCosineSum: 一个结构与DeepProduct相同的图。但每个节点都计算更复杂的二进制运算cos(a + b)。 SumOfProducts: 一个计算40个输入的所有成对积的总和的图。这个图有40个输入节点，780个积注，以及一棵由779个和节点组成的树。这里的节点总数比输入节点的数量要多得多，这使我们能够评估原始操作复杂图的性能。我们可以在固定数量的输入数据上评估复杂的原始操作图的性能，这是一个常见的现实世界的场景。 这些测试都是基于 Intel Sandy Bridge 公司的 2.6 GHz处理器的单线程执行环境的配置，在一个256×256像素点上进行的，该配置代表了商业云数据中心环境，并且禁用所有非必要的系统服务以尽量减少剖析噪音。表3的结果显示，在这些测试案例中，5个中有4个使用JIT编译器的效果超过了C++中类似的通用包，其中有1个案例中JIT编译器的效果甚至超过了直接用C++代码写的效果 Table 3. Results from Java JIT vs. C++ efficiency tests. 6.1 系统吞吐量性能 在Google数据中心有着丰富的CPU，在该环境下，原始效率虽然也很重要，但是更重要是如何在许多机器上有效的分配复杂的计算，Earth Engine 的大部分性能是基于它有能力代表用户调集和管理大量的CPU。单一的硬件即使通过代码或者查询优化，最终也会达到一个上限，但是可以利用的额外的计算资源很少有限制，从而可以达到更高的上限。 经过实验证明Earth Engine 可以以横向的尺度缩放，如 Fig.4 所示。在这次测试中，两幅大的在这个测试中，两个大型的Landsat 图像集图像被重新投影到一个共同的投影坐标系上， 在每个像素的基础上进行时间上的汇总，并在空间上汇总成一个数字，同时改变每次运行的CPU数量。这两个数据集包括从 2014.1.01 到 2016-12-31 的所有的 Lanssta 8 Level-1T图像，图像覆盖美国本土（26,961个场景，1.21万亿像素）和非洲（77,528个场景，3.14万亿像素）。测试是使用共享的生产资源运行了几天，即使捕捉到自然变化。结果显示，吞吐量与机器的数量几乎呈线性扩展。 Fig. 4. Horizontal scaling tests results. Application Earth Engine 正广泛应用于各个领域，涵盖全球森林变化，全球地表水变化、作物产量估算、稻田制图、城市测绘、洪水测绘、火灾恢复和疟疾风险绘图等等不同主题。它还被整合到许多第三方应用中，例如分析物种栖息地范围（Map of Life）、监测气候（Climate Engine）和评估土地利用变化（Collect Earth）等等。这些应用中的一些细节将说明 Earth Engine 的能力是如何被利用的。 Hansen 使用从广泛的数据集中生成的决策树，描述了2000年至2012年的森林范围、损失和增加的特点。他利用从大量的训练数据中产生的决策树和大量的陆地卫星场景中计算出的深层指标，对2000年至2012年的森林范围进行了描述。数据目录支持的过滤操作将当时研究期间的生长季节场景的130万个陆地卫星场景减少到654,178个。这些影像通过云层、云影和水进行筛选，并将其从原始的 Landsat 数字转换为规范化的大气顶部反射率。系统自动处理所有必要的数据访问、格式转换、制图和重新取样。利用 API 中的操作计算输入指标，例如每个波段的百分位值和反射率的线性回归值与图像日期的线性回归。这些指标与训练数据一起。被用来生成决策树，这些决策树被应用于指标来产生最终的输出数据。这些结果被用于出版，并作为地球引擎目录的一部分提供给其他人去进一步分析。 之后许多包括科学界和业务界的其它用户，都成功的在 Hansen 的基础上利用 Earth Engine 产生了其它成果。 Global Forest Watch 将其纳入使用地球引擎的交互式分析应用程序，以进行即时的汇总统计计算。Joshi 使用Earth Engine 来 追踪老虎栖息地的变化，提取每年保护区内的森林损失，并发现最适合野生老虎数量翻番的地区也是保护得最好的地区。 在其它例子中，Lovell 将数百个作物模型的模拟结果与植被指数联系起来，例如绿色叶绿素植被指数（GCVI），这些指数可通过卫星数据进行测量。然后，他们将模拟产量与测量的植物指数和生长季节早期的天气相关联。这就产生了一个早/晚日期的每一对组合的回归系数表。他们在每个像素的基础上使用 Earth Engine 选择早晚的最佳Landsat场景，使用 Earth Engine 的 SimpleCloudScore 功能自动去除多云场景，计算 GCVI 值，最终得到最高GCVI 的场景。一旦为一个特定的像素确定了最好的一对陆地卫星场景，存储在地球引擎和GCVI中的天气数据就可以用来计算预测的产量。这个方法被应用于美国中西部大约675万公顷的玉米和大豆田，计算出2008到2012年的年产量。每年每10,000平方公里的总计算量大约在2分钟内完成。 8. Challenges and future work 使用Earth Engine的一个好处是，用户几乎完全不需要考虑在并行处理中工作的细节。该系统处理并隐藏了如何管理计算的几乎每一个方面，包括资源分配、并行性、数据分配和重试。这些决定纯粹是管理性的，它们都不会影响查询的结果，只会影响查询的速度。从这些细节中解放出来的代价是用户无法影响它们：系统完全负责决定如何运行一个计算。这导致了一些有趣的在系统的设计和使用方面都有一些有趣的挑战。 8.1. 规模化挑战 Earth Engine系统作为一个整体可以管理及其庞大的计算，但其底层基础设施最终是由低端服务器组成的集群。在这种环境下，配置任意大的机器的选项是不可取的，而且对可以带入任何单个服务器的数据量有一个硬性限制。这意味着用户只能通过使用Earth Engine库中提供的并行处理语言来表达大型计算，而一些非并行的操作根本无法在这个环境中有效执行。此外，要求使用Earth Engine 来表达也意味着现有的算法和工作流程必须被转换为使用Earth Engine API 来利用这个平台。 Earth Engine设计的API能轻松的表达极大的计算。例如，它可以只用几行代码就可以请求聚合一个全球8000亿像素的Hansen森林覆盖图：虽然这种计算是很直接简单的，但是只是从存储中检索所有的输入像素也会涉及到大量的资源和时间。通过在广泛的空间尺度上对大型数据集进行链式操作，很容易表达成本相差很多的查询，并描述即使在先进的并行计算环境中也不可行的计算。 由于地球引擎是一种共享的计算资源，因此限制和其他防御措施是必要的，以确保用户不会垄断系统。对于交互式会话，Earth Engine 对请求的最大持续时间目前为270秒、每个用户同时请求的总数量为40，同时一些复杂操作如空间聚合的同时执行次数限制为25。虽然交互式计算有一个时间限制，但是该限制足够在一个单一的工作流程中完成以下工作：检索覆盖加利福尼亚和内华达州一年的所有Landsat 8图像（1177个场景），用它们来计算最大NDVI综合指数，并由此得出17个IGBP土地覆盖等级（73.5万平方公里）中每个等级的平均峰值-NDVI（735000km^2）。这个例子的大部分时间是花在传输全分辨率的空间聚合的原始像素，简单地创建和显示最大NDVI的合成，只需几秒钟就能完成。 当在批处理环境中调用查询时没有限制，在批处理的情况下，更大数量级的工作可以直接运行。但是当一个请求涉及到基于瓦片的计算时，每台机器所能容纳的数量仍然是有限的，因为这些计算不能用目前的数据模型进行流化或进一步的分布。这些内存限制并不会直接的转换为空间和时间上的限制，但是这类请求的最大尺寸有一个经验：每个像素的堆栈深度不超过2000字节。目前RPC和缓冲系统有一个在互动情况或者批处理都存在的额外的限制：缓存的单个对象大小不能超过100MB。这个限制最常发生在聚合操作输出的很大的情况下，当我们提取数据来训练一个机器学习算法时，它可能会限制训练集中的总点数。 批量作业是独立运行的，这使得它们很难对彼此产生负面的影响，但是为了防止垄断，作业仍然使用一个共享的排队系统进行管理，在负荷大的情况下，工作可能会在队列中等待，直到资源变得可用。 8.2.计算模型不匹配 虽然可并行化的操作在遥感领域非常普遍。但是有许多其他的操作是不能并行化的，或者是不能被Earth Engine中的并行计算结构所容纳的。该平台很适合于每个像素和有限邻域的操作，如带状数学、形态学操作、光谱解混、模板匹配和纹理分析，以及这些操作的长链（数百到数千）。它还高度优化了可应用于流式数据的统计操作，如计算图像的时间序列堆栈的统计数据，并且可以轻松地处理非常深的堆栈（eg: 数以百万、亿万计的像素）。但是它对于以下情况表现很差：局部数值可能受到任意距离的输入影响的操作，如分水岭分析或经典的聚类算法；需要同时掌握大量数据的操作，如训练许多经典的机器学习模型；以及涉及长周期迭代的操作，如有限元分析或基于代理的模型。此外，一些数据密集型模型需要大量的数据，而这些数据在地球引擎中并不存在，这可能需要大量的工作来准备数据。 这些计算技术仍然可以在地球引擎中应用。但往往有很大的限制。将Earth Engine扩展到支持新的计算模型是一个活跃的研究和开发领域。用户如果遇到不符合地球引擎计算模型的问题，可以在谷歌云平台的其他地方运行计算。平台中的其他地方运行计算，以利用靠近底层数据的计算，同时还可以利用Earth Engine的数据目录、预处理、后处理和可视化的优势。 8.3.C/S 编程模型 Earth Engine的用户往往不熟悉客户机-服务器编程模型。所以Earth Engine的客户端库试图提供一个更熟悉的程序化编程环境。但这可能导致用户忘记他们不是本地编程，本身并未执行任何计算，这时候会导致一些混乱。整个操作链是由客户端的代理对象记录，并发送到服务器上执行，但这意味着不可能将Earth Engine库的调用与标准的本地的处理习惯混合在一起。这些习惯包括一些基本的语言功能，如依赖计算值的条件语句和循环，以及标准的数值包。用户仍然可以使用这些外部工具，但他们不能把它们直接应用到地球引擎的代理对象上，这有时会导致导致混乱。幸运的是，这些编程错误通常 一旦发现就很容易解决。 值得注意的是，这种风格的编程模型在大规模云计算中正变得越来越普遍，同时它也被用于TensorFlow中构建和执行图。 8.4. 提高技术水平 Earth Engine不仅让监测、跟踪和管理地球环境和资源成为可能，而且变得容易，从而在社会最需要的地方取得一定进展。为了跟踪和管理地球的环境和资源，不仅需要提供大量的数据和计算能力，还需要提供越来越复杂的分析技术的同时也易于使用。 因此，我们正在进行一些实验：整合深度学习技术，并促使可扩展的基础设施（如谷歌计算引擎和BigQuery）能轻松访问。 涉及技术 Introduction 地理信息数据的处理技术： TerraLib、 Hadoop、GeoSpark 和 GeoMesa The data catalog Earth Engine 运行在一个\"图像\"容器（？） 瓦片数据库 金字塔模型 System architecture Borg 集群管理系统 Bigtable Spanner 分布式数据库 Colossus（Google File System 的接班者） 并行管道计算的 FlumeJava 框架 Google Fusion Tables（一种基于 web 的数 据库，支持带有属性的点、线、多边形等几何类型的数据表） 进行互操作 Compute Master进行任务规划 计算描述DAG Data distribution models Geodata Pipleline：地理数据处理链线，有人喜欢叫工作流（workflow），有人喜欢叫processing（数据处理），都可以。Pipe是从Linux过来的概念，意思是将上一个命令的输出作为下一个命令的输出。这样的话数据处理结果是文件、还是字符流、还是数据库就都被抽象掉了。我很喜欢这个概念，因为遥感数据里也是各种类型文件、各种处理，比较乱，用pipeline比workflow一类的宽泛概念要强得多（流应该是gee中很重要的一个设计） 子表达式消除 Efficiency, performance, and scaling JIT编译器 Challenges and future work C/S 编程模型 谷歌计算引擎 BigQuery 评价 谷歌在构建这个工具方面投入了大量的工程专业知识。它确实是一个令人惊叹且令人印象深刻的平台，并导致了许多重要的科学发现. 当我们在 2013 年第一次开始考虑大地球数据时，我们了解了 GEE，并立即认为这就是未来：我们都会迁移到 GEE。那显然没有发生。虽然 GEE 对许多科学家来说显然是一个有价值的工具，但事实仍然是该平台是封闭的——它不是开源的。它由谷歌控制。他们决定它可以做什么和不可以做什么，哪些数据集可用，如何分配资源等等（他们当然对科学界非常慷慨。）但 GEE 从根本上说是一个卫星图像平台。有许多类型的地球系统数据和分析方法在 GEE 中根本不可能实现，科学界也没有明显的方法来改变这一事实。您也不能在自己的服务器上安装 GEE。 随着封闭平台的发展，很难击败 GEE。但其他人正在尝试。 论文2. An Overview of Platforms for Big Earth Observation Data Management and Analysis 产品演化路径 产品演化路径必然离不开产品的历史，但是设计GEE的历史技术没有找到相关了网络资源 历史发展 Graphics 公司使用了什么技术 Keyhole公司使用了什么技术，Google通过它一下子拥有了巨大的地图服务 刚开始 GEE 只是为了 Landsat数据的处理，怎么设计的，用了什么技术 现行技术体系 第二篇论文讲的就是这个，但是还没来得及细看 "},"gis/Landsat影像格式.html":{"url":"gis/Landsat影像格式.html","title":"Landsat影像格式","keywords":"","body":"Landsat影像格式 文件说明：https://earth.esa.int/documents/10174/679851/LANDSAT_Products_Description_Document.pdf Landsat8 文件名称含义 文件名 卫星数据类型 LC = Combined（both OLI and TIRS data） LO = OLI data only . Pixel Size : OLI Multispectral bands 30 meters || OLI panchromatic band 15 meters LT = TIRS data only Pixel Size : TIRS Thermal bands: 100 meters (resampled to 30 meters to match multispectral bands 产品分类Collection Category Tier1(T1) - 包括最高质量的Level-1 Precision Terrain(L1TP)地面数据，地理坐标已配准，误差满足(RMSE Tier2(T2) - 包括没有达到L1TP标准的影像，包括Level-1 Systematic Terrain(L1GT)和Systematic(L1GS)影像 Real-Time(RT) - 尚未进行改正处理的新影像。 数据夹文件内容 共14个文件 ​ ①文本文件：分为_ANG与_MTL两个 ​ _ANG Angle，是对影像的投影方式，等等数据的记录，应该可以拿来做几何 ​ _MTL _MeTadata File影像元数据介绍 ​ ③影像文件：均为tif格式，11个波段文件，因为Landsat 8 有两个传感器11个波点，一个BQA影像 数据处理（gdal） // 图像信息 gdalinfo [图像路径] // 图像融合 gdal_merge.py [-o out_filename] [-of out_format] [-co NAME=VALUE]* [-ps pixelsize_x pixelsize_y] [-tap] [-separate] [-q] [-v] [-pct] [-ul_lr ulx uly lrx lry] [-init \"value [value...]\"] [-n nodata_value] [-a_nodata output_nodata_value] [-ot datatype] [-createonly] input_files // 裁剪 "},"gis/NetCDF.html":{"url":"gis/NetCDF.html","title":"NetCDF","keywords":"","body":"NetCDF NetCDF(network Common Data Form)网络通用数据格式是一种面向数组型并适于网络共享的数据的描述和编码标准。目前，NetCDF广泛应用于大气科学、水文、海洋学、环境模拟、地球物理等诸多领域。用户可以借助多种方式方便地管理和操作 NetCDF 数据集。 GMT(Generic Mapping Tools) GMT具有强大的绘图功能和数据处理功能 绘图方面，GMT支持绘制多种类型的底图：除30多种地图投影外，还有笛卡尔线性坐标轴、对数轴、指数轴、极坐标系；支持绘制统计直方图、等值线图、2D网格图以及3D视角图等；也支持绘制线段、海岸线、国界、多种符号、图例、色标、文字等。 数据处理方面，GMT具有数据筛选、重采样、时间序列滤波、二维网格滤波、三维网格插值、多项式拟合、线性回归分析等功能。 知乎，gis数据格式 2017.12.01 wiki,gis文件格式 file format list "},"gis/OSMnx.html":{"url":"gis/OSMnx.html","title":"OSMnx","keywords":"","body":"OSMnx [toc] OSMnx的作用 OSMnx example tour This notebook provides a quick tour of some of OSMnx's key features including how to: download/model street networks calculate stats visualize centrality impute speeds/travel times and calculate shortest path attach and visualize elevation data and edge grades download/model other infrastructure types download points of interest data 图或网络中的中心性 博客 图或网络中的中心性：点度中心性、中介中心性、接近中心性、特征向量中心性、PageRank 点度中心性（degree centrality） 背后的假设是重要的节点就是拥有许多连接的节点（你的社会关系越多，你的影响力就越强） 在上面的蝴蝶结网络中，节点D的连接数是6，和网络中的所有人都建立了直接联系，其他节点的连接数都是3，因此节点D的点度中心性最高。整个网络一共有7个节点，意味着每个人最多可以有6个社会关系。因此，节点D的点度中心性是6/6=1，其他节点的点度中心性是3/6=0.5。 中介中心性（betweenness centrality） 如果一个成员位于其它成员的多条最短路径上，那么该成员就是核心成员，就具有较大的中介中心性。计算网络中任意两个结点的所有最短路径，如果这些最短路径中很多条都经过了某个节点，那么就认为这个节点的中介中心性搞 中介中心性的现实意义 鲍勃徘徊在两个女人之间，他贪恋爱丽丝的美丽和谈吐，亦无法舍弃卡若琳娜的乐天和无忧无虑。但他必须小心谨慎，生怕自己在其中任何一个人面前露馅，这样的关系充满了压力和焦虑 银行家以5%的利率接受A公司的存款，以7%的利率贷款给B公司，这样的关系给银行家带来了巨大的利益。它的前提是，市场中的A公司和B公司不能直接接触，或至少无法轻易地找到对方 鲍勃和银行家的故事尽管截然不同，但他们都处于一种被称为被禁止的三元组(forbidden triad)的关系中，需要确保三元组的末端不能直接联系。没有联系就像网络中出现了一个洞，因此也被称为结构洞。 接近中心性（closeness centrality） 点度中兴性仅仅利用了网络的局部特征，即节点的连接数有多少，但一个人连接数多，并不代表他处于网络的核心位置。接近中心性和中介中心性一样，都利用了整个网络的特征，即一个节点在整个结构中所处的位置。如果节点到图中其它节点的最短距离都很小，那么它的接近中心性就很高，相比中介中心性，接近中心性更接近几何上的中心位置 特征向量中心性（eigenvector centrality） 特征向量中心性的基本思想是，一个节点的中心性是相邻节点中心性的函数。也就是说，与你连接的人越重要，你也就越重要。 有向图和PageRank PageRank是衡量有向网络中节点重要性的重要指标 我们将万维网抽象成有向图：（1）每个网页抽象成一个节点，假设有A、B、C、D四个节点；（2）用户通过超链接在网页之间跳转，这种跳转是有方向的（directed），从网页A跳转到网页B不代表可以从网页B链接到网页A，这种节点之间的有方向的连接被抽象成有方向的边。整个网络构成一个有向图。 你可以很轻易地找到最受欢迎的网页。但是，PageRank的思想认为，指标最好还需要考虑到指向你的那些网页。也就是说，来自受欢迎的网页的跳转应该重于不太受欢迎的网页的跳转。这就是PageRank思想的精华，Google就是利用这一思想来给网站排名的。这里的思想依据和特征向量中心性其实是一致的。 小结 点度中心性：一个人的社会关系越多，他/她就越重要 中介中心性：如果一个成员处于其他成员的多条最短路径上，那么该成员就是核心成员 接近中心性：一个人跟所有其他成员的距离越近，他/她就越重要 特征向量中心性：与你连接的人社会关系越多，你就越重要 PageRank：来自受欢迎的网页的跳转应该重于不太受欢迎的网页的跳转 "},"gis/城市规划中人性、人文和人本的关系.html":{"url":"gis/城市规划中人性、人文和人本的关系.html","title":"城市规划中人性、人文和人本的关系","keywords":"","body":"城市规划中人性、人文和人本的关系 城市规划中人性、人文、人本的理解 城市塑造人的思想 人性：人普遍所以具有的心理属性 人是一根会思考的芦苇，人的生命像芦苇一样脆弱，但是他会思考。在城市这一头巨兽中，我们会思考，思考生活中的小事，思考我们对这个城市的想法，思考很多很多的事情。我认为城乡规划中的人性应该是人如何去塑造了我们生活这个城市，这个城市又如何塑造了我们的人性。 直到高中以前看到城中村，第一印象总是这是一个脏乱差的地方，这里生活的人应该不会很幸福。然后会基于这一点做出一些自以为是的思考，如：全部拆了重新修成高楼大厦多好、城中村的人是不是都是钉子户，城中村的人怎么就不知道治理一下呢。后来开始上大学，思想稍微成熟一点之后，再看到城关村，又有了一些新的想法。事物的存在必定有它存在的理由，不是谁都能住进舒适的小洋房的，底层大众很多，当活下去是一个困难的事情的时候，谁会把活得好作为第一考虑的事呢。当中国经济在腾飞，一座座高楼在拔地而起，谁会去考虑城市里面的人是不是都愿意承载这个城市的重量呢？城中村固然是一个严重影响城市风貌，不符合人民生活的地方，但这些“城中村”有着它存在的历史价值，这是来城市打工人、生活落魄的者的幸福港湾了。我的看法之所以会有着巨大的改变，我觉得最重要的就是屁股决定了脑袋，我从这个一个城市里的高中生成为了一个城市里的大学生，我的思考被城市的许许多多东西所改变着。 城乡规划中的人性是人对城市的思考，是这个城市对不同阶层不同背景的人的思想塑造。大多数的人和城市有着很高的相关性，他们的人性或多或少的正在被自己生活的城市塑造着。用一句文艺点的话说，城市是个大戏台，众生在城市里面唱着戏。 城市日积月累的文化 人文：人类社会的各种文化现象 每个人每一天都离不开衣、食、住、行四个字，作为城市的重要组成元素的人，人们的衣食住行慢慢演化出了城市中的服饰文化、饮食文化、建筑文化、交通文化。当然，人除了衣食住行，有些人可能还有自己的教育、宗教信仰、工作等待，在这些部分人的文化中也会演化出城市的形形色色的文化。至今，每个城市都有着自己巨大的框架，有着不同的缤纷与华丽，却不一定拥有着自己的巨大框架匹配的人文品质和人文情怀。就和人一样，不同的人过着属于自己的人生，但不是所有人都有着情怀。 深圳，简称“深”，别称鹏城，我们从历史课本上学到的知识就是深圳乘着改革开放的春风，一夜从一个小渔村发展成了一个国际大都市，但是鲜有人讨论深圳这座城市的文化。提起北京，我们会想到这是我们的首都，是一座历史悠久的城市；提起维也纳，我们甚至一点都不知道它的样子，但是我们的概念会离不开音乐二字；提起巴黎，我们会想到时尚和艺术······那么，现在让我们来提一提深圳，我们会想到什么呢？一个城市的巨大框架，可能能在十年二十年的时间建立起来，它的高楼大厦会像树杈一样蓬勃生长，它的交通路线会像树根一样密密麻麻，这个城市会很快的长成一棵参天大树，但是这个城市有什么特色吗？如果这棵参天大树是长在了寺庙，来寺庙参拜的人们会把写有愿望的红绳系上它的枝桠，日积月累，我们就可以说这棵树是一棵许愿树。一个城市，如果有了许许多多的“红绳”，这个“红绳”可以是任何东西，可以是科技、文化、教育等宽泛的东西，甚至可以是斗牛、足球、篮球等一些小东西，这些“红绳”多了之后，我们就可以说这个城市有了某某文化了。这种内蕴性的东西不是一时能做出来的，就像罗马也不是一天建成的一样。 城市的核心在人 人本：以人为本的思想 人本主义作为近年来新起的词，在各式各样的的法律法规中频繁出现，城市规划中的人本思想不再是新鲜的事 物。但是一个实际性的问题一直出现在电影、音乐、文学作品中，也被无数的人问过：我生活的城市是谁的城市？ 我生活的房子，如果有了一个房产证，我可以认为这个房子是我的。但是城市是没有城市证的，那么这个城市应该是谁的呢？古希腊时期，人本主义对人类社会的普遍关怀在城市建设中得到了体现，庙宇遍布希腊各地，人们不仅在庙宇中举办各种宗教活动，而且还通过庙宇举行各种活动。关于城市的定义：城市是为美好生活而维持很小规模的一个社区。现在的城市不只是一个小小的社区，一个个大社区的人是一个个的节点，节点又会有一个或多个小中心。但是一个好的城市的设计，应该是以人为本，充分考虑人的内在和外在需求的产物。人本主义的城市要又公众的参与，每个人都是城市的主人。随着信息时代的到来,我们有理由相信，新技术的支持及城市规划本身的需要将使“人本” 得到发展，“城市让生活更美好”是一种正在实现的理念，而不只是一种美好愿景。 城市规划中人性、人文、人本的思考 我认为，城市规划中，人本是出发点，人性是灵魂，人文是结果，这三者是息息相关且不可分割的。人本是根，如果一个城市，一个人类的生活环境都没将人考虑进去，这个产物必然不合适现实规律，是一个本末倒置的东西。人性是人与城市的互相作用，人按照自己的意愿去塑造自己的城市，城市给予人相应的反馈，人性也是这个城市的品性，是这个城市中最宝贵的东西。人本是一种文化，是城市和城市中的人奋斗的产物，是一种传承与信仰，我们可以说，当人文的氛围随着时间开始积淀，开始让城市的人们活在某一种状态之中的时候，这个城市就是一个活的城市，活在这个城市中的人是又信仰的。 人是一个简单又复杂的东西，我们也总是对自己生活的地方有着复杂的情感。哲学有三个难题，我是谁，我从哪来，我又将到哪去。也许城市也会有自己的疑问吧，城市会想自己是谁，自己从哪来的，我以后又将是什么样子。人性，人文，人本可能就是城市的哲学与根吧。愿我的城市以人为本，我们塑造城市，城市塑造我们的人性，最终能演化出一种文化，一种生生不息的传承。 "},"gis/地理大数据探索.html":{"url":"gis/地理大数据探索.html","title":"地理大数据探索","keywords":"","body":"地理大数据探索 [toc] 起因 起因是自己GEE调研报告，了解了大数据与云计算的起源，具体内容参考Google三大技术及其衍生和调研报告，大概清楚了大数据、分布式、云计算的2015年前的发展。诚然，大数据云计算的时代，和地理的关系又是什么样的呢。中间偶然看到一个专栏：地球云计算（专栏前半段讲的可以，后半段都是具体技术去了），讲的很好。然后在作者的github上看到了一句话，感觉很有意思： $$ Data\\ Geoscienc \\neq Geodata\\ science\\ Geospatial\\ ML \\neq ML\\ using\\ Geo\\ Features\\ Only\\ insights\\ can\\ save\\ yourself\\ from\\ information\\ overload. $$ 引用自奋进号历险记（下） 地学计算是计算密集型还是数据密集型？地学计算的数据量的确大，大家为了操作问题，得先找能算、能把数据处理出来的方法，不得不简单粗暴一些，由此就会掩盖了地学问题的复杂实质。深度学习和机器学习已经云化了，大数据现在都处理什么对象呢：人脸、车牌、数字、语音、文本。但是实际上的真实地表不应该比这个复杂多了吗，不是不能密集计算，但是解不出，算不完。 目前的复杂计算问题，很大程度上还是基础学科方面的，人们为了解决数值的、动力的、动态的、高复杂性的、演化性的问题，发展了很多方法和模型，设置了不同的初始条件、驱动变量，放到机器里面一顿猛算、模拟，这种模拟很大程度上也只是在丰富人们的知识，或者像是一些工程模拟一样，节省下材料和人工 地学问题，是一种高复杂性问题，像生命科学一样，人们也许永远也搞不清楚这背后的机理、分异，但是可以用不断收集到的地表数据去充实材料，去提取规模，让机器去强化，标识某些规律和信息，这就是说，地学问题就像是一只被沉重肉身束缚在表相之下的巨兽，一旦笼子被突破，宅男马上变成猛男。 老实说，现在不都是通过大量的实验或者模拟来增强自身的知识，而且很多东西也的的确确只是数据密集型（还是大量异构数据密集型），高复杂性的问题很难由我们这种小人物来完成的，比如气候变暖，就是通过 IPCC 成百上千的科学家工作几年才有一些报告结果，这些东西还只是定性的，黑箱的，怎么转为定量的已经不是搞技术的能做的了。 地理信息科学到底是地理学的核心还是外缘 地理信息科学:地理学的核心或是外缘 地理学碰上“大数据”：热反应与冷思考 刚开始是地理信息系统，这是一个采集、管理、分析、表达、模拟地理空间数据的系统，研究揭示地理现象和要素的分布形态、相互作用、动态演化和驱动机理，从而服务于地理空间决策支持。Goodchild（1992）提出了地理信息科学的概念 "},"gis/地理信息安全技术与进展心得体会.html":{"url":"gis/地理信息安全技术与进展心得体会.html","title":"地理信息安全技术与进展心得体会","keywords":"","body":"地理信息安全技术与进展心得体会 地理大数据的安全保护尤为重要 作为半个互联网人，我们都被大量关于数据存储和处理的时髦词汇轰炸过了： NoSQL、区块链、分布式、大数据、云服务、MapReduce、实时······这些听起来很牛皮的词总是让人不明觉厉但又不知其意，但是归根结底，这些词都是围绕着如何高效安全存储与数据服务这一核心主题的。数据越来越“大”的同时，数据安全问题日益严重。作为完整的地信人，我们深知技术的发展给地信领域带来了全新的动力，深刻的影响着社会发展和人们的日常生活，但是地理信息产业具有促发展与保安全的双重属性，维护地理信息安全是促进地理信息产业发展的前提，没有国家安全就没有产业的可持续发展。 位置服务应用有隐患 当前很多应用在使用时，都会询问用户是否“允许使用位置服务定位应用”。据2016年12月腾讯位置服务团队宣布的数据显示，其定位服务日均调用量突破500亿次，峰值突破520亿次，覆盖用户数6.8亿人，其调用量是2012年同期的25倍。在物流行业、O2O、智能出行、警务安全和运动健康等均有涉及。这仅是腾讯一家的数据，由此可见当前社会对位置服务需求量的巨大。当前人们常用的社交、出行、旅游、购物、健康等众多应用都要必须开启或记录位置信息，严重依赖位置信息技术，如果不做好安全防范，则暗藏一定的安全风险，轻则隐私泄露，重则失密泄密。例如，2014年，苹果手机的定位服务曾引起社会争议。在苹果手机的定位服务里有一项“常去地点”功能为默认开启状态，在这里可以看到用户所有去过的地方、停留时间、前往次数等数据，还能在地图上显示。对于重视隐私的用户，就会担忧这些数据是否存在隐患，以及是否会被用作他途。另据近期解放军报报道，有士兵通过手机软件预订外卖，不仅暴露了个人信息，连营区位置也被精准定位。还有部队人员训练后，在朋友圈里展示自己的训练成果，当点开他发布的运动轨迹时，营区的周边信息也一览无遗。看似种种方便的举动，却违反了安全保密规定，军事部门对这些有失泄密隐患的手机软件已高度重视。在大数据时代，通过对各种应用收集而来的用户位置、轨迹等数据的分析，特定用户的活动特点可被精确掌握，敏感地理信息可被精准定位，这对地理信息安全监管工作提出了新的挑战。 无人机监管逐渐加强 无人机行业近年来高速发展，不仅在测量测绘、航空摄影、遥感地图、应急救灾等专业领域大显身手，而且随着无人机的越来越小型化和越来越低廉的价格，消费级无人机市场也迅速升温，走入了百姓的日常生活。 由于人们的法律意识淡薄和实际操作技能差的原因，关于无人机航摄活动影响空防安全的事件屡屡见报，但这只是无人机安全隐患的一方面。很多使用者在不具备航空摄影测绘资质且未申请空域的情况下，往往有意无意地进行航空测绘活动，涉嫌非法测绘地图。 按照测绘方面的有关规定，使用测绘型无人机必须取得相关资质，每次使用起飞前，必须进行审批、报告，向空管部门和测绘主管部门报告飞行区域、高度、经纬度。如果使用无人机进行的测绘涉及到国家秘密，还会受到保密等相关部门的依法惩处。2016年4月14日，北京国遥星图航空科技有限公司员工在无航拍资质、未申请空域的情况下，操纵无人机进行非法航拍测绘，被发现后，公司法人和操作人员均被判处有期徒刑。 地图标注无序威胁国家安全 2005年，Google公司推出了谷歌地球（Google Earth）全球动态地图，它把卫星照片、航空照相和GIS布置在一个地球的三维模型上。用户可以通过客户端软件，免费浏览全球各地的高清晰度卫星图片。 好奇的网民们发现，在这里不仅能发现世界上各大城市、风景点，同时还能清晰地看到在市面出版发行的地图上，没有标出的涉及国家机密的隐蔽设施或军事建筑。有专家认为，根据这些解析度很高的卫星成像地图可以计算出相应数据，从而掌握一些重要设施的建筑位置和外形资料，有泄露国家机密的隐患。 如果说在目前卫星满天飞的情况下，卫星图片已经可以公开获得，那些可以看见的军事设施已不是什么秘密，不具备重要价值，但Google Earth的“标注”功能，即可以在地图上标注具体位置的信息，可以使得一些未被发现的隐秘地点暴露在大众面前。 科技的发展，使得人人都能参与到地图标注中来。据媒体报道，美国人柯蒂斯·梅尔文从2006年开始，利用多方搜集的资料，对朝鲜全境地图进行标注，包括餐厅、学校、医院、集市、全国电网图、铁路网图、精确行政区划界乃至领导人官邸等，至今仍在更新，成为“全球除情报机构外最全面的朝鲜地图信息库”。 而在我国，有些军事爱好者乐于在谷歌地图上标注军事设施的地点，甚至详细到了部队具体驻地、军事基地具体坐标。也有的地图爱好者，在标注时不经意间泄露了身边敏感地区的位置，而相应的卫星地图往往会被替换成更新的高清图，引发网友的“更正”热情。 2010年，一个名为“月光论坛”的网站，其中很多军事爱好者把大量涉及国家军事的地理坐标和信息，如机场、舰艇码头等在谷歌地图上标注出来，这是一起典型的地理信息涉密行为，已经得到当地主管部门的查办。月光论坛出现的问题并不是个例，还有很多网络社区也存在同样问题，不仅是军用机场、导弹阵地、雷达阵地、海军港口、部队驻地的准确位置和坐标，甚至连中南海、西昌卫星发射中心的地标文件都被人在谷歌地图上发布。 军事专家认为，这种行为导致有的互联网地图其作用甚至超过了某些军事侦察卫星，让人不费吹灰之力就能得到一些需要花费数年才能得到的测绘信息，给国家安全带来了隐患。这不仅是谷歌地球软件自身服务功能引发的泄密，也是用户在使用过程中的行为导致的泄密。 地理信息数据泄密，也同样可以带来商业上的损失。曾经中国某重要能源公司所属3万多口油井的地理坐标和储量信息的数据库，被国外公司非法获得，直接威胁到了我国相关行业的经济利益。还有我国900兆瓦以上装机容量的200多座电站的具体位置的地标文件，也被网友发布到网上，这些都直接影响到我国的国家安全。 由此可见，地理信息安全就在我们身边，在我们不经意的一举一动之间。作为社会大众，我们在享受地理信息带来种种便利的同时，不仅要保护好自己的个人隐私数据，更要提高安全认识，从战略高度上来看待地理信息安全。往往可能只是好奇或者炫耀之举，但可能帮了一些别有用心之徒，更是泄露了国家机密。 地图水印信息隐藏与加密技术方法 到目前为止，国内外数字水印技术的研究主要集中在图像、视频和声音等多媒体信息的版权保护上，在GIS空间数据中，通过隐藏水印信息并对其加密、压缩以实现其安全保护的研究还很少，这是数字水印技术应用的一个新领域、新尝试，也是GIS空间数据安全管理方法中一项具有挑战性的创新技术研究。GIS空间数据水印信息文件隐藏与文件加密是对GIS空间图形数据实行安全保护的两种核心方法，两者对数据的保护都可转化为对水印密钥的保护，因此，GIS空间数据水印信息隐藏技术可以沿袭传统加密与信息隐藏技术的一些基本思想和概念，但两者采用的保护信息的手段是不相同的。GIS空间数据数字水印信息隐藏技术是把一个具有版权意义的水印信息隐藏在普通GIS空间数据文件中，申明数据生产单位的版权及该数据的使用权属，从而达到利用技术手段间接保护GIS空间数据版权的目的。采用数字水印信息隐藏技术需满足如下条件：GIS空间数据中隐藏的水印信息不能直接被数据用户感知；水印信息的隐藏不影响GIS空间数据的使用；隐藏的水印信息必须具有很高的鲁棒性，即隐藏在GIS空间数据中的水印信息难以被非法数据用户擅自干扰或去除。 在地理数据数字水印技术研究中，需要着重考虑地理数据本身结构的特点，基于数字水印思想，进行地理数据数字水印模型和算法的深入研究。地理数据总体可分为矢量地理数据、栅格地理数据、数字高程模型(DEM)数据这3类，因此地理数据数字水印技术的研究主要围绕这3类数据开展进行。矢量地理数据是通过点、线、面及其组合体实现对地理空间要素的描述，并记录对象的属性信息，具有空间信息和属性信息的并存特征。地理坐标作为矢量地理数据中空间信息的载体，也为水印信息提供了一定的承载空间。从水印嵌入域划分，矢量地理数据数字水印算法主要分为基于空间域的水印算法和基于变换域的水印算法。栅格数据在存储方式与表现形式上与普通图像数据具有相似性，因而对于栅格地理数据水印算法的研究在一定程度上可以借鉴普通图像的水印算法。然而栅格地理数据在量测、精度与空间分析等方面又具有自身的特性与应用需求，使得栅格地理数据的水印算法设计需要考虑栅格地理数据自身特性，不能照搬普通图像水印算法。按照数据类型的不同，栅格地理数据的数字水印算法研究可分为遥感影像数字水印算法和栅格地图数字水印算法。遥感影像具有数据量大、纹理丰富、多波段等特点，因此在研究遥感影像的数字水印算法时，需要充分考虑遥感影像的数据特征。考虑到抗差性的需求，目前遥感影像的水印算法主要为变换域算法。DEM是地形表面形态的数字化表示，有着数据精度要求高、组织方式多样、空间特性强的特点。从DEM的数据组织方式的角度，DEM可分为规则格网DEM和不规则三角网DEM，因此DEM的数字水印算法同样可分为规则格网DEM数字水印算法和不规则三角网数字水印算法。 随着地理数据应用价值的日益凸显、地理数据共享需求的日益旺盛，地理数据的安全问题变得愈发不容忽视。数字水印和加密控制作为地理数据安全保护方面的前沿技术，在地理数据安全保护中扮演着重要的、不可替代的角色。面对大数据时代的地理数据，只有深刻分析地理数据安全特征，不断深入挖掘与研究数据安全的关键理论，紧跟信息技术的前沿思想和潮流，结合实际推动技术手段的应用、扩展、融合与完善，才能真正发挥数字水印和加密控制对于地理数据的安全保护作用，实现地理数据的安全共享与交换。 "},"gis/面向地理共享与集成的数据适配方法研究.html":{"url":"gis/面向地理共享与集成的数据适配方法研究.html","title":"面向地理共享与集成的数据适配方法研究","keywords":"","body":"面向地理共享与集成的数据适配方法研究 作者：乐老师 时间：2016.3 摘要 地理模型的共享与集成在具体的实现与应用时，最终都要面对模型能否正确运行的问题。模型的正确运行与数据有着直接的关系：必须通过输入数据来驱动模型运行，通过输出数据来获得计算结果。由于模型本身所定义的数据规格与模型使用者所提供的数据之间往往并不直接匹配，针对模型运行的数据兼容性处理成为了模型应用过程中繁琐而关键的工作。在跨学科跨领域背景下的开放式地理模型共享与集成中，这种从原始数据向模型的数据规格之间的适配问题更加突出，也亟需解决。 本文以模型使用者正确理解地理模型的数据规格为切入点，通过设计地理模型数据规格的结构化描述方法，实现模型的数据需求的无歧义传递。在此基础上，提出了一套完整的模型数据适配方法，通过模型数据接口的统一映射和数据重构方法库的建立，形成融合数据表达、数据接口映射与数据重构的数据适配方案，从而将模型构建、数据处理和模型集成应用之间解耦。 主要研究内容与结论如下： 地理模型数据规格的结构化描述 地理模型数据接口的统一映射 地理模型数据重构方法库的构建 地理模型数据适配方案的构建 四个研究内容之间相互联系又相互解耦，模型数据规格的描述是整个研究的基础，模型数据接口的统一映射为数据适配提供统一的数据视图，数据重构方法为数据适配提供可组合可重用的方法组件，最终形成了同样可共享的数据适配方案资源。在开放式网络环境中的构建原型系统，对数据适配资源的组织管理服务、共享平台门户和辅助应用工具进行了相应的实现，验证了数据规格描述、数据接口映射、数据重构等方法的可行性。通过典型目标驱动的集成模拟实验和典型探索驱动的综合模拟实验，对数据适配方法的实用性进行了验证。 绪论 即使数据蕴含了模型运行所需要的全部信息，数据规格的微小差异都将导致程序不能正确运行。 地理模型数据的这种控制性、决定性作用使得数据转换成为驱动模型运行重要而繁琐的工作。地理信息领域对于空间数据的不兼容问题进行过一系列的研究，包括开发相关的数据转换系统、制定统一的数据格式和交换标准、开发统一的数据访问API等等工作，开源领域的GDAL/OGR、SDO，商业领域的FME、SDX+、OGC/TC211的相关标准都是这些工作的部分成果，空间数据的兼容性问题得到一定程度的解决。然而，地理模型所提出的数据兼容性问题涉及的层面比传统空间数据所面临的兼容性问题具有更大的综合性和复杂性：首先，地理模型的专业性使得其依赖的数据不单纯是经典的空间数据形态，其数据模型、结构和编码表现为对建模原理、领域传统和实现策略的多重依赖；其次，地理模型的数据交换，往往代表了物质、能量的传递，支撑参数表达的时空离散结构和尺度往往成为这种不兼容性的一部分；第三，地理模型数据蕴含的语义与约束是模型正确运行的必要条件，比如数据的量纲、单位等，即使数据结构完全一致，这些差异依然会导致模型执行无法得到正确的结果。第四，地理模型的输入、输出和控制参数会依赖模型的实现策略通过接口参数、内存结构、数据文件、数据库等不同的编码机制进行传递。第五，模型数据的处理往往需要在运行时完成，这又与具体运行环境有极大的相关性。 因而，目前亟需找到一种具有高度柔性的数据适配方法，在模型知识共享层次能够适应于不同领域的地理模型，在模型集成运行层次能够动态配制出地理模型所需要的数据，从而降低综合地理模拟研究过程中的协作难度，提高异构地理模型共享、重用与集成的便捷度。 本文所研究的地理模型数据适配方法，其核心目标是提供解除模型运行与数据规格之间紧密耦合关系的工具，在数据蕴含足够的信息的前提下，通过对模型的输入、输出、控制数据进行解析表达，对数据的时空离散、组织结构、量纲/单位、编码方法等方面进行重构和映射，便捷的实现模型与数据的匹配。 另一方面，数据作为地理空间信息建模的重要内容，为了适应于不同的应用和表达需求，诸多数据模型和数据格式被设计和发展。地理信息领域经典的数据模型以矢量和栅格表达为基础，相关的发展有对象数据模型、场数据模型、矢-栅一体化数据模型、三维数据模型、时空数据模型、几何代数的多维统一数据模型等（Molenaar，1990；Egenhofer，1991；李德仁，1997；Brown，1998；吴立新，2007；俞肇元，2013；Yuan et al., 2013）。基于这些空间数据模型发展而成的相关数据格式常常被具体的地理模型采用为其输入/输出数据的格式，如GeoTIFF，ASCII Grid，NetCDF，Shapefile等数据格式。不同的地理模型开发者针对所研究的对象，并结合自身的编码习惯，从空间信息领域中常用的数据格式中，选择一种数据格式作为模型执行程序关联的数据格式，形成默认的数据交互接口。 地理模型数据的异构性特征并不仅仅体现在数据格式这个层次上，在进行综合地理模拟的过程中，来自不同学科不同领域的地理模型数据通常具有其复杂的语义属性特征 为了实现不同系统间的数据交换，不同领域制定了大量的数据交换格式和交换方法。总的来说分为以下几类： 成熟的商业软件提供的公开数据交换格式 国家制定的空间数据转换标准，以标准数据格式实现数据交换 国家及不同领域的组织参与制定的统一地理数据模型 第二章 地理模型数据规格及其结构化描述方法 地理模型是对地理过程与机理的抽象与表达 面向共享与集成的地理模型特征 在本文中，服务于构建一个能够支撑复杂地理问题求解的综合地理模拟情景，所涉及的“地理模型”是指能够在特定计算平台上执行相关计算的“实体” 地理模型的运行特征： 开发模式方面： 基于过程函数的开发模式 面向对象的开发模式 组件插件式的开发模式 面向服务的开发模式（SOA) 总结起来，无论是在开发模式，运行平台还是执行风格方面，地理模型在程序运行方面的异构性特征都较为突出。 地理模型共享与集成的特征 通过地理模型的分类体系和元数据信息描述，建模研究者可以通过统一的入口便捷的访问到所需的地理模型资源；在此基础上，建模研究者需要能够利用模型资源、驱动模型程序计算，这就涉及到地理模型异构的运行特征。考虑到地理模型在执行接口和数据接口上的差异性，按照特定的模型封装方法对异构的地理模型进行统一的包装，进而形成标准化的模型组件，是当前地理模型共享、集成建模框架等相关研究领域的常用方法。在某一个集成建模框架中，根据其所提供的模型封装标准，能够将异构的地理模型包装成在该建模框架内可以统一调用、组合、连接的模型组件；另一方面，地理模型作为网络服务来发布和共享时，还需要与网络服务的消息通信机制和数据传输方法相结合，形成面向服务的地理模型封装。虽然封装方法各有不同，但地理模型封装的主要目标是屏蔽模型程序执行的异构性，使之能够按照统一的方法调用，这在技术理念上与地理模型的组件插件式开发模式也是一致的。 主要有两种方式来实现这种模型集成工作。一种是通过代码编写的方式，在集成程序中引入不同的地理模型资源，调用其执行接口，按照其数据接口提供相应的数据，并在模型与模型之间的流转中加入定制式的数据处理。另一种是通过科学工作流的方式，制定模型间连接、组合、循环、嵌套的基本框架，将模型资源按照“节点”的方式插入到配置的工作流中； 按照地理模型的特定运行需求来准备数据，首先就需要能够正确理解模型对数据的需求；从用户使用地理模型的角度，这种数据需求可以归结为模型的数据规格。 从地理模型计算运行的一般特征出发，地理模型数据可分为输入数据、输出数据和运行控制数据。模型数据规格的一个最直接的体现就是数据格式。 xml（Extensible Markup Language）格式 XML 被设计为传输和存储数据，其焦点是数据的内容。HTML 被设计用来显示数据，其焦点是数据的外观。 从模型数据参数的描述，到数据接口的封装，再到数据参数的传递和交换，这三者贯穿于整个地理模型共享和集成过程，三者既各有分工，又内在联系。通过地理模型的集成来进行综合的地理模拟需要在科学原理正确、物理机制合理的基础上进行，而最终制约这个“集成了的地理模型”能否正确运行的一个关键要素就是地理模型数据。 模型数据规格的表现形式： 自定义的数据格式：如文本文件，二进制文件，数据库等；在特定的地理模型程序中，如果读取的是自定义数据格式，则读取的规则和数据内容的组织必须完全一致。 领域通用的数据格式：如Shapefile，ASCII Grid，NetCDF，GeoTIFF等；这种数据格式往往是结合领域应用特征，具有特定数据模型支撑的数据格式。 内存变量形式：如主函数的命令参数，API函数的参数序列等。 常用的数据组织形式： 常用特定的分隔符来区别不同的数值。 数据头和数据体是常用的组织方法。 数组、键值对和数据表是常用的数据结构。 数据内容中通常含有一些注释字符串。 数据规格的内蕴信息 地理模型规格的常用描述方法 基于元数据的描述方法 在地理信息领域，元数据的内容除了对一般属性信息的描述之外，还需要能够提供空间的相关信息。 面向地理处理服务的数据描述方法 在地理信息处理服务相关的研究中，也没有直接采用元数据标准来描述地理信息服务中的数据信息。最为典型和常用的WPS规范（Web Processing Service）是OGC继WFS（Web Feature Service），WMS（Web Mapping Service），WCS（Web Coverage Service）推出的关于地理处理网络服务的规范。在此规范中，地理模型被当做一个个GeoProcessing来管理。 面向集成建模研究的数据描述方法 OpenMI的设计理念是提供一种组件式开发模型的接口标准，规定了模型运行时各模型之间交换数据应遵循的规范。在OpenMI中，模型数据的描述并没有采用某一种元数据规范，也没有利用WPS中的DataType方法，而是直接面向模型的计算和模型集成时的数据交换。 OpenMI作为被OGC认可并推广的地理模型集成标准，其对模型数据的描述是直接面向模型集成计算的，侧重于数据在程序执行层面跟模型需求的匹配。如前文所述，地理模型的正确运行并不仅仅依赖于数据类型和文件格式匹配，模型对数据内蕴的语义相关信息同样提出了限制条件。而OpenMI在数据的语义信息描述方面，仅通过简单的字符串描述，其描述能力显得较为不足。 面向虚拟环境仿真的数据描述方法 基于环境数据编码和语义信息关联的方式，在方法上能够有效的实现地理模型数据的语义描述。基于SEDRIS规范可以用结构化的方法描述出数据的内容和逻辑组织，且数据内容中的每个要素都可以进行灵活扩展；通过节点之间的自由组合，理论上可以实现任意数据内容的表达。但将SEDRIS应用到地理模型的共享与集成中时，这种由组织容器类-环境数据类-要素类构成的数据组织模式相比于WPS和OpenMI而言又过于繁琐和复杂。而且地理模型的共享与集成涉及到大量跨学科跨领域的概念和知识，在这个层次上EDCS的兼容性还比较欠缺。此外，地理模型对数据内容的约束性信息虽然可以通过EDCS中的相关概念条目得以体现，但诸如数据取值范围、数据单位量纲之类的信息并没有能够很好的体现出来。 现有方法的总结与分析 综上所述，在模型数据规格描述的方法层面，利用层次化的组合来描述模型数据的内容结构信息成为当前公认的有效方法；无论是在地理处理服务领域，集成建模领域，还是在虚拟环境仿真领域，复杂多样的数据内容结构都采用这种方法来描述。信息关联的方式也普遍被用于数据内容的信息附加，比如单位量纲信息、空间参考信息、语义概念信息等均可以采用标签关联、URL地址关联的方式进行描述。这几种方法中，基于元数据的方法更侧重于数据的相关属性信息的表达；WPS基于地理处理网络服务的应用需求，结合网络数据传输的特点，对数据的描述直观、简练；OpenMI作为集成建模的规范，相比于其他方法而言，对空间离散网格和时间步长等信息的描述更为全面；SEDRIS面向综合环境仿真的研究目标，与其他方法相比，在数据的语义概念信息方面设计了系统的描述方法。 但是现有的方法大多集中于数据本身的信息，跟模型运行相关的语义和约束信息较少地融入到其中。虽然不同的数据格式能够利用后缀名和URL关联的方式加以描述，但这种方式却难以适应于地理建模领域中纷繁多样的自定义数据格式。在地理模型的共享与集成过程中，由于涉及到多个学科领域的异构地理模型，对于模型数据规格的描述应该是独立于具体的技术平台。地理模型相关联的数据既有空间数据，也有非空间数据，既可以是一个简单的数值，也可以是一组相互引用的数据文件，所以对模型数据规格的描述应具有较强的扩展性和灵活性。 面向地理模型运行的数据规格结构化描述方法 基于以上对地理模型共享与集成中数据规格描述方法的分析，本研究从模型使用者需要了解某个地理模型能够正确运行的数据需求出发，探索地理模型数据规格的结构化描述方法。本文作者在对分布式地理建模环境的多年追踪研究中，设计了统一数据表达-交换模型（Universal Data Description eXchange Model，UDX），该模型借鉴结构化程序设计方法中使用有限结构元素表达任意程序算法的思路，力图通过构造式的方法来实现地理模型数据规格的描述，并支撑数据描述和具体数据内容的直接映射。本文从模型使用者理解地理模型、获取地理模型运行所需数据条件的角度，针对地理模型数据规格的描述需求，对统一数据表达-交换模型进行扩展。 变量类型有：原子类型（Atomic）、数组类型（List）、组合类型（Union） 在统一数据表达-交换模型中，主要有两个基本元素：节点（Node）与核（Kernel）。Node负责组织模型数据的结构，每个Node都拥有自己的名称（Name）和子节点（NodeChildren）；在NodeChildren中又包含了相应的节点及其子节点。通过这种层次化的组织，能够灵活的构造出各种数据结构。Kernel负责对具体数据的存储，其中Kernel的数据类型由DTKernel来管理。总体上，Node控制数据的组织结构，Kernel管理数据的具体类型和内容。 对于DTKernel而言，主要有三大类：简单数值类型（DTKValue），数组类型（DTKValueList）和复杂容器类型（DTKContainer）。这三大类Kernel可以分别对应到W3C规范所定义的原子类型，数组类型和组合类型。 一个节点的Kernel属于DTKValue或者DTKValueList类型，则该节点都不可以拥有子节点。而节点的Kernel属于DTKContainer类型时，则该节点可以拥有任意个数的子节点。在DTKContainer中，有四种具体的容器类型：DTKStructure，DTKList，DTKKeyValue，DTKTable。 eg： 地理模型数据规格的形式及结构描述 在数据内容的组织结构上，统一数据表达-交换模型包含两个主要实现。一个是统一数据表达UDX Schema，还有一个是统一数据交换UDX Data，两者共同构成了统一数据表达-交换模型的内容。UDX Schema和UDX Data两者在结构层次是同构的，都是基于统一的Node-Kernel结构。而UDX Schema负责对模型数据内容进行详尽的描述，UDX Data则是严格匹配于UDX Schema的具体数据内容。 对于地理模型数据，UDX Data是具体数据内容的存储，UDX Schema则对地理模型数据规格在形式和结构层面的描述。 如上所述，基于统一数据表达-交换模型可以进行构造式的数据描述，但这种Node-Kernel结构的UDX Schema只是在形式和结构层面描述了地理模型的数据规格，数据内容的内蕴信息并没有描述。 （没看完） 地理模型数据接口的统一映射方法 地理模型数据接口的统一映射 虽然地理模型的数据接口在外观上表现出来的是某种格式的数据文件、某种类型的变量，但在内容上则是对特定信息的依赖 领域通用数据格式都会有其相应的数据读写API（Application Programable Interface）；利用数据读写API可以控制数据内容，能够在数据的表现形式（即数据格式）和程序内存布局之间进行完整地转换。 从数据储存和数据读写API的模式考虑，领域通用数据格式主要有两种： 一种是数据内容与数据读写API一致的数据格式 这种数据格式中的数据内容可以是变化的，但是其组织的模式是固定的（第几行代表什么数据，前多个字符是什么数据，这些都是固定的）；读取这种数据格式需要严格按照某个特定的数据读取方案，典型的如ASCII Grid格式，GeoTIFF格式，WKT格式，WKB格式，DXF格式，3ds格式，BIL格式，BIP格式，BSQ格式等； 一种是数据内容与数据读写API不一致的数据格式 如XML（Extensible Markup Language）格式和JSON格式（JavaScript Object Notation），这两种数据格式都是在建模领域中常用的数据格式，但是XML和JSON提供的是上层的数据组织方法，对于特定的地理模型而言，需要根据自身的需要定制出相应的结构。比如说GML就是基于XML结构对空间矢量数据的一种实现，GeoJSON是对JSON在空间矢量数据的一种实现。另外还有结构表（Table）类型数据格式，如Excel、关系数据库等. 原始的领域通用数据格式到基于Node-Kernel结构的UDX Data之间，可以通过API函数和数据节点操作两者的映射来进行直接的交换。 eg: 传统的数据转换方法会从一种数据格式的文件转变为新的数据文件，而原始数据格式与UDX Data之间的转换不会产生新的数据文件 本文设计了数据格式映射方法库，支撑地理模型提供者将所构建的UDX Data与API函数映射的结果积累下来，成为可共享的资源。 模型自定义格式映射机制 数据内容与分隔符抽象 基于状态机的自定义格式映射 模型自定义格式的数据文件中包含的数据内容通常按照各种不同的形式进行组织，将其映射到UDX Data的Node-Kernel结构时，最直接的方法就是进行顺序的逻辑判断（如If-Else，Switch-Case等语句），但在面对诸多不确定组织的数据文件时，这种逻辑判断往往会变得非常庞杂。状态机是一种在信息技术领域中的经典设计模式，应用程序开发中也经常使用此方法来简化复杂的事务处理流程。常用的OpenGL库，其底层设计就采用了状态机的原理，通过有限的接口函数实现各种各样的三维渲染效果。 (也没看完，重点是后面感觉与我想看的没有多大关系了) 设计某种特定的数据格式来将所有地理模型的数据接口都转换为该格式，这种方法在满足几个地理模型应用需求的同时，在面对广泛的跨学科跨领域的地理模型时又产生了难以适用的问题。UDX是一种构造式的数据表达元模型，通过对信息内容的灵活组装，可以配置出与不同数据结构相对应的UDX Data 本章从数据接口的内外存实现策略方面将地理模型数据接口主要分为领域通用数据格式、模型自定义数据格式和编程语言相关的内存结构。针对领域通用数据格式，设计了可扩展的数据格式映射方法，并由此设计了数据格式映射方法库。针对模型自定义数据格式，设计了基于分隔符-状态机的自定义数据格式统一映射方法。针对语言相关的内存结构，设计了基于扩展注释的内存变量映射方法。 地理模型数据的重构方法 地理建模从现实世界→概念模型→逻辑模型→源代码→可执行程序→数据IO接口→程序运行，经过多层的信息传递和转化，人们对地理世界语义的理解在源代码阶段已经相当弱化 尤其是在不同地理模型集成的过程中，模型输入输出数据之间存在着单位、坐标系、空间剖分、数据组织结构等诸多方面的不统一 在第三章将模型数据接口映射到所构建的统一数据视图的基础上，本章主要研究如何通过有效的、可重用的数据重构方法来生成对于模型运行而言合理的数据，由此驱动模型正确执行并支撑模型之间集成运行。 地理模型数据的重构需求 与实现无关的信息内容重构 在这个例子中所涉及的“矢-栅转换”就是一种典型的与实现无关的信息内容层次的数据重构。 与实现相关的数据组织重构 地理模型数据重构方法库 基于统一数据视图的数据重构 对于模型数据的重构，最直接的方式就是通过编写相应的程序代码来实现源数据与目标数据规格之间的匹配；但这种方式导致模型数据适配工作只能在较低水平上重复，无法形成通用方法和工作成果积累。将地理模型数据接口统一映射到UDX的Node-Kernel结构上，能够为整个地理模型重构工作放置到一个统一的数据视图之上，可以屏蔽数据的内外存组织的异构性。在Node-Kernel结构支撑的统一数据视图上，所进行的数据重构工作将会转变为以节点操作为主导的信息内容处理。 数据重构方法的原子操作设计 数据重构方法的统一接口设计 地理模型数据的基本重构方法 传统的数据处理方法都是严格依赖于特定的内存数据模型的，而基于Node-Kernel结构能够将复杂的数据重构统一到以数据节点操作为基础的信息组装上来。通过UDX Schema和UDX Data两者之间的关联，设计了数据节点的原子操作函数，从数据结构层次和数据内容层次实现了构建数据内容框架ConstructFrame函数、连接节点LinkNode函数、单个数值的获取/设置函数和对数组元素的获取/添加函数。通过数据节点的原子操作函数的组合嵌套可以更为便捷的构建不同的数据重构方法，本章进而设计了数据重构方法的统一接口，用以包装不同的数据重构逻辑，对外提供统一的调用接口。通过对数据重构方法统一地描述，设计了数据重构方法资源的组织管理方法，从而支撑构建一个开放共享的数据重构方法库。 面向地理模型运行的数据适配方案 （后面都没看了，等有机会再看吧） 路线 地球系统作为一个复杂的巨系统，其综合性和复杂性特征导致了难以基于单一模型来解释其中的所有现象与过程。因此，地理模型的共享与集成逐渐成为了地理学综合研究的普遍方法。 地理模型的共享与集成在具体的实现与应用时，最终都要面对模型能否正确运行的问题。模型的正确运行与数据有着直接的关系，针对模型运行的数据兼容性处理成为了模型应用过程中繁琐而关键的工作。 以模型使用者正确理解地理模型的数据规格为切入点，通过设计地理模型数据规格的结构化描述方法（表现形式、内容结构和内蕴信息），实现模型的数据需求的无歧义传递。 在此基础上，提出了一套完整的模型数据适配方法，通过模型数据接口的统一映射和数据重构方法库的建立，形成融合数据表达（Node-Kernel结构)、数据接口映射（地理模型数据Node-Kernel结构的映射）与数据重构（地理模型数据重构方法库）的数据适配方案(要素组织、数据规格匹配和数据接入的设计)，从而将模型构建、数据处理和模型集成应用之间解耦。 另外，这种基于Node-Kernel的地理模型应用和集成运行，对于某个特定的地理模型而言似乎增加了数据处理的过程。但在综合地理模拟中，涉及到多个不确定的地理模型之间的集成与运行，通过直接的数据格式转换虽然能够方便于某一个特定模型的运行，但对于整个集成模拟应用又造成了新的不便：首先体现在广泛的自定义格式难以直接进行转换，模型使用者在不了解数据内容的前提下进行的数据转换往往具有尝试性，增加了模型使用的不便；其次，模型相关的数据格式多种多样，同源的信息可以表现为异构的数据组织，孤立的数据转换难以避免重复的代码编写；还有，异构地理模型的集成不仅仅只是对数据格式的简单转换，其中涉及到的大量信息的抽取和重构，特定数据格式支撑下的数据处理成果难以形成积累，也难以重用。 "},"gis/太阳辐射模型的回顾.html":{"url":"gis/太阳辐射模型的回顾.html","title":"太阳辐射模型的回顾","keywords":"","body":"太阳辐射模型综述 发表时间：2012.12.29 发表者：A. K. Katiyar，C. K. Pandey 基于Angstrom模型估算太阳辐射 Angstrom模型 公式： $H/H_0 = a + b(S/S_o)$ $H$是水平面上的每天每平方米的太阳辐射量 $S$是水平面上的每天的日照时长 $H_0$是水平面上的每天每平方米的太阳辐射量的理论最大值 $S_0$是水平面上的每天的日照时长的理论最大时长 输入参数：维度$L$ ,一年中的第几天$D_n$ 根据一系列公式可计算出 $H_0$，$S_0$ 根据观测站数据得出 $H$, $S$ ，然后线性回归可以到 $a , b$ 值，如果以天文辐射为起始值，$a,b$系数反映了大气对太阳辐射的削弱作用；如果以晴天太阳总辐射为起始值，$a,b$系数反映了云量遮蔽度的影响（稳定性较差）；如果以理想大气总辐射为起始值，$a,b$系数主要反映了大气中 1.低阶模型 由Angstrom模型衍生出了30个低阶的模型 model 地点 时间 放弃 1 1 2 也门 3 1 4 印度 5 1 6 意大利 7 约旦 8 赞比亚 9 1 10 巴基斯坦 11 意大利 12 全球 13 美国 14 $60N-70N$ 1 15 印度 16 1 17 1 18 土耳其 19 阿尔及利亚 20 土耳其 夏冬 21 土耳其 22 巴基斯坦 23 中国 24 埃及 25 土耳其 26 中国 27 孟买 28 1 29模型基于平均气温和降水 30基于太阳磁偏角 2.高阶模型 由于基于气候的线性模型不一定适合求极值，因为它高估了没有云的时候的总辐射 model 地点 时间 放弃 31 1 32 全球站点 33 土耳其 34 斯里兰卡 35 土耳其 36 美国 37 土耳其 38 土耳其 39 利比亚 40 土耳其 41 土耳其 42 土耳其 43 土耳其 44 土耳其 45 巴基斯坦 46 土耳其 47 土耳其 48 土耳其 49 印度 50模型使用了相对湿度 51模型使用了相对湿度，最高温度 3.基于环境温度的太阳总辐射估算 52模型使用了温差 53模型使用月最高温度和月最低温度 54模型使用了最高和最低气温 总结 作者总结 为了开发合适的太阳辐射模型，需要给定位置的太阳辐射信息，但因为缺乏可信赖数据，所以需要经验模型来预测和估计全球太阳辐射 从Angstrom模型衍生出30个线性模型，经验系数由第一阶回归分析结果的到，由于误差存在了对全球辐射的高估，但是一阶计算量少，且相关性超过第二和第三阶数，常常用来估计水平表面上的平均太阳辐射量 Katiyar和Pandey模型被认为是最精确的模型（就是该文作者:happy:），基于温度的模型具有发展潜力，它可用于估计无法获得持续日照地区的太阳辐射量 本人总结 统计了54个模型，7个模型使用了气候方面的参数（即很难无法实现的模型），13个模型没有说明适用于哪个地点或者直接就说适用于全球的太阳辐射估计（对于该点本人是持怀疑的态度），剩下的模型地点重复率很高（如土耳其可能就占了三分之一以上） 故，实现效果可就 emmm，:cry: 中国相关文献阅读 知网上搜索了大概有八篇相关的论文，其中有一篇为外国论文，按时间顺序阅读结果如下 1. 中国地区太阳总辐射的空间分布特征 时间：1963 因为总辐射的观测站少，当时的学者就已经有了寻求日照或者云量与总辐射的经验关系。 作者指出，青藏高原占全国面积四分之一以上，且平均海拔约为4000米，辐射情况特殊，宜将中国分为青藏高原区和平原区进行讨论，最终得到了一副中国年总辐射的分布图，并从空间分布特征的角度上对其进行了解释。 ps: 按行政区划分来寻求模型参数可能并不好，作者在解释的时候多次提到了云量的影响，Angstrom公式并未考虑气候方面的参数 2. Angstrom公式参数对$ET_0$的影响及$FAO$建议值适用性评价 时间：2010 该文讨论了Angstrom公式参数取值对参照腾发量（$ET_0$）的影响，公式参数$a,b$的合理性及其地区分布规律，提出了在无辐射资料的情况下，$a,b$的取值方法,对FAO的参数建议作出了一个评价 该文根据气候特征把以下的104个气象站分为了7组 Anogstrom公式是有Anogstrom于1924年提出，后来有一些学者对其进行了持续的改进，提出了各种形式，但目前任广泛使用其基本的线性形式。（引用的该文）式子中的参数$a,b$反映了外空辐射通过大气层过程中的衰减特征，（引用）该文是在太阳辐射在植物腾发量上的一个应用，因为$a,b$的偏差引起了太阳辐射$R_s$的相对变化，经$K$(推导出的一个系数)缩放引起了$ET_0$的变化，关系如下： 104个站点的$K$值计算结果如下，过程及原理作者未说明： 根据$FAO$建议值，$a,b$的偏差与$R_s$的相对误差关系为： 讨论$\\delta a,\\delta b$各自对$R_s$的影响程度，再比较7个分组计算出的$a, b$参数，就可对$FAO$建议值适用性进行客观准确的评价 最后的结论大概就是影响较大，适用性在东北和西北适用，在其余地方适用性并不高。 ps: 这是Angstrom公式的应用，$a,b$显然要进行合理的地区综合取值，但是$FAO$的$a,b$建议值范围扩大到了整个中国，在这个明显有问题的前提下，鞠晓慧、翁笃鸣等学者做出了一些研究，在这些研究已经说明的情况下，本文作者在其基础上扩展到了参照腾发量，因为$a,b$选取值的不合理产生了多少误差，将中国划分了7个区域，哪些能适用与$FAQ$的建议，然后就成功的写了一篇论文:happy: ，思路很清晰，工作量和论文质量都很好，后面可以考虑review。 刚不久和乐老师、昊凌一起讨论了一下我们全球太阳能辐射量计算项目的做法，在这里想mark一下：首先我得看论文，有一个大概的思路： 先看论文：全球总共有多少相关模型，是否都是由Angstrom公式衍生出来的，哪些模型更加好； 数据方面得找到全球记录太阳辐射的站点，模型不应根据行政区来选取，可能是根据地理气候特征来选取，也可能是根据气象站点记录数据的相似性和空间上的相近（这其实也是看论文，或者再讨论来决定的） 论文与数据做完，设计系统应该具备哪些功能，应该是什么样的，这时候我应该去咨询张锴师兄其他人怎么计算出太阳辐射的（或者就这几天也可？） cesium做前端（想加上vue？），python处理数据，组成一个系统 3. 关于不同海拔的太阳辐射计算 时间:2015 基础知识 看这篇论文的时候去补了一点基础知识 太阳辐射 大气层外太阳频谱： 地球表面太阳频谱： 不同维度所有太阳辐射强度 大气层 国际标准大气 比尔定律 克里金插值 这篇博客讲的很好 地理学第一定律：All attribute values on a geographic surface are related to each other, but closer values are stronger related than are more distant ones. 继续论文阅读 改论文首先也说明了站点不够需要建立模型来计算太阳辐射，然后介绍了的是一些适用于海平面或低海拔地区的理论模型（这是我第一次看到），作者提出这些模型都是基于均质大气，然后作者提出了非均质大气模型下计算任意海拔的太阳辐射，然后作者又将非均质大气模型分为标准大气模型和概率统计大气模型进行了推导。 单波长太阳辐射：单位面积单位时间单波长的太阳辐射能量 全波长太阳辐射：单波长太阳辐射对全波长的积分 太阳辐照度：太阳光经过大气层的吸收、反射、散射等作用后到达地球某表面的单位面积单位时间的太阳辐射能量 太阳辐照量：太阳光经过大气层的吸收、反射、散射等作用后到达地球某表面的单位面积某段时间的太阳辐射能量 太阳常数：$S_c = 1361 W/m^{-2}=4.92MJ/(m^2*h)$ 太阳辐射计算中，主要考虑对流层和平流层对太阳辐射的消弱作用（未知） 太阳光抵达地表的过程中，并不是和路径总长度（经过大气层的路径）成正比的，而是与抵达地表的过程中所碰撞的空气分子的总数目成正比的。所以可以提出均质大气层的概念。均质大气层的合理性，在引文24有解释 为了计算不同海拔的太阳辐射，提出了标准大气模型和概率统计大气模型来计算不同的海拔上的太阳辐射。因为将大气看成是水平的了，所以需要有一个修正的过程（这里面没有细看了，和我做的相关性并不高） 然后作者居然讨论不同季节、维度和时间对太阳辐射的影响！！！ 作者认为计算天顶角，就可以得到相同天气的任何季节任何时间任何地方的光谱辐照密度，从而可以计算不同时间、维度、季节和海拔高度的太阳分布图（还是得根据气候对地球进行划分啊，我觉得有必要验证一下作者引用的那几个模型与Angstorm公式的正确性了） 最后作者对大气模型进行了修正。均质大气模型误差因素有：曲率（实际上就是天顶角的修正），混合气体；非均质大气模型的误差因素：曲率，有效高度的确认，混合气体，然后修正过程也没有细看（后悔数学没学好了），最后是对比验证，感觉验证结果不是那么好。 ps:在读这篇论文的过程中补充了一些基础知识，然后这里面提出了几个理论模型，晚上再看吧，目前对太阳光从外太空抵达地球表面有了一个认知，结合昨晚我看的计算太阳辐射的网站，是否考虑做出一个3D的，具有较为真实的大气层（每个大气层的厚度是不一样的）的模拟呢？然后计算其太阳辐射。这篇论文思路很好，已经有了计算海平面的很好的模型，我怎么应用到不同的海拔上去呢，靠着这个思路该文作者做了一系列研究。现在我就是在已经有PVGIS这么一个庞然大物，我是否能在其基础上做点什么东西呢？ 该论文不合理，太阳光是很多的，它只考虑了一束太阳光，难道要在半个地球的大气层上进行积分吗？如果该积分的好积分的话，可以考虑做一做，而且中间过程实在太复杂了，怪不得都用经验公式了 4. 淮北平原Angstrom公式参数校正及太阳总辐射时空特征分析 时间：2018 使用最小二乘法和遗传算法对Angstorm公式的$a,b$参数进行了率定，遗传算法更优，总结了淮北平原的$R_s$的趋势与特征 引文10到14找机会看一下，上一篇一句话没有提到Angstrom公式，是否不太合理。提及了左大康将该公式引入的中国。参数率定讲了最小二乘法和遗传算法 评价指标：平均误差、平均绝对误差、均方根误差、相关系数（我也可以） 结论和第二篇类似，$FAO$建议值并不适用于淮北平原，且遗传算法优于最小二乘法，得到了淮北平原$R_s$的时空分布特征 ps: 看完第二篇再看这一篇论文，感觉收获不大，可能是第二篇很多页，这一篇论文页数很少的原因吧。 5. 基于Angstrom-Prescott公式的中国太阳辐射与日照时间的关系研究 时间：2019 这篇论文的写的真好。中国目前有739个常规气象观测站，但仅有130个太阳辐射观测站，其中只有114个站具备日照观测数据，各种研究进展就不赘述了，后面提的几个问题也是我关心的重点：时间上该公式是否能准确预测，空间上已有站点是否能扩展到其他缺资料的地区，按行政区划分是否不合理。 中国气象网提供114个太阳辐射观测站数据，存在缺失情况，进行了一些预处理，分析采用方法是最小二乘法，以两种方法进行了验证：1. 四分之三训练集，四分之一测试集 2. 空间上对站点进行了分割，选择113个站点作为训练集拟合公式得到公式系数，对113个站点的公式系数进行空间插值，采用了经验贝叶斯克里金法插值得到剩余站点的公式系数，然后用剩余站点的数据进行验证（是否分配不合理，就一个站点作为测试集），第一种方法预测时间，第二种方法预测空间 评价标准：决定系数（$R^2$)，平均绝对误差（$NAME$），均方根误差（$NRMSE$） 这引文16，17得看。 ps：写的真好，赶时间看完的，会review的 6. 基于Anstrom-Prescott模型和空间插值的山东省月太阳辐射再估算 时间：2020 和上一篇一样，介绍历史介绍的更为详细了，拟合方法也是最小二乘法，只是空间插值也是变为三个了，而且范围只是山东省，感觉就是上一篇的翻版，要是没有它的引文我都不信。结论是最小曲率法可能是较优的插值法 ps：该作者是研究生，感觉水平不如上一篇了(我这个菜鸡有什么资格说这个，，)，看懂上一篇可以不用再看这一篇了 7. 基于年内尺度的中国大陆地区Angstrom公式参数校正和优选 时间：2020 对数据进行预处理，数据从中国气象数据网下载，$R_a$使用了$FAO56$建议的计算程序，农业区划来自国标。 方法也是最小二乘法，过程就不说了，结果是中国大陆个农业区Angstrom公式参数年内的推荐值。 ps：站点更新为121个了，这篇论文也是讨论了$FAO$建议值是否适用了，结果就是建议值与实际拟合的系数进行结合适用更好。但是该文的亮点在于，统一了农业区划尺度下的$a,b$取值，其实我要做的就是全球尺度下，按气候划分的各区域的$a,b$取值，再加一个交互好看的系统出来（好难啊） 8. 需要review的论文 外国相关论文阅读 1. A comprehensive review of empirical models for estimating global solar radiation in Africa 作者：尼日利亚卡拉巴尔大学理学院物理系 P.O. Box 发表时间：2017 大意是：太阳辐射应用方面很多，但是非洲大部分地球无法获得太阳辐射的测量数据，但是有很多的经验模型，该论文旨在分类和审查估算非洲太阳辐射的模型。目前的经验模型的输入分为六个主要类别，文献记录了732个模型和65中功能形式。 太阳辐射是气象参数、地理参数、天文学参数、物理参数的函数，气象参数有：蒸发，云层，相对湿度，降水，温度，日照时长，地外太阳辐射和一些环境的参数；地理参数有：经纬度，海拔，方位角等；天文学参数：太阳常数，日地距离，太阳偏角等； 物理参数：空气分子的散射，水蒸气含量，粉尘，大气分子的散射 Angstrom第一个提出经验模型来测量晴天的太阳辐射，Prescott和Page使用地外太阳辐射代替晴空辐射，使模型式子更加简介，前十年，一些学者在其基础上发展了一些新的模型，使用了同样的参数。该文是review了估计非洲的太阳辐射的相关模型，，，（没大看懂英文） 根据气象参数，模型可分为一下六类： 基于日照的模型（我前面一直看的都是这个模型） 基于云的模型 基于温度的模型 基于相对湿度的模型 基于降水的模型 基于混合参数的模型 该文提出的模型都给出了具体的地点，提出了很多模型，应该覆盖了非洲的大部分地区 基于阳光的模型提出了很多模型，应该也是最主要的模型，大部分是线性的，也有二阶，三阶，非线性等形式，分了12个子类，没有进行评价，也只是列出来所有模型 基于温度的模型适用于没有日照时间的地区，根据每日的最高温度、平均温度、最低温度等可以得出其太阳辐射，分了18个子类 基于相对湿度的模型是因为大部分气象站都是测量的气象参数，没有日照时长和温度等数据，所以有了基于相对湿度的模型，模型较少，就分了两个子类 基于云量的模型，模型较少，就分了两个子类 基于降水的模型，模型很少 基于混合参数的模型，参数包括但不限于已经提到的参数，分为14个子类，提出了大量的模型，但是也没有进行评价 最后作者在讨论的时候表明，有研究人员将太阳辐射计算模型分为了基于日照、云、温度和混合参数等四个类型，普遍认为基于日照的模型使用的最多，可能是因为它在大多数气象站都使用，基于温度模型可以的进行校准，基于云层的模型可以作为替代方案，基于混合参数的模型一般精度很高，但是大多数参数不容易获得。作者在它的基础上加了两个类别：基于相对湿度和降水，总体而言，有732个经验模型，各种类型占比如下： 通常，不可能用一个（没写完 2. Estimation of Hourly, Daily and Monthly Global Solar Radiation on Inclined Surfaces: Models Re-Visited 作者：马来西亚布特拉大学电气与电子工程系 Seyed Abbas Mousavi Maleki 时间：2017 摘要大意：倾斜表面的太阳辐射大于水平表面的，各种预测倾斜表面的太阳辐射模型有对应的特殊要求。该文提供了各个国家/地区的最佳倾斜角度。 背景，缺乏不同位置识别最准确模型的审查研究，然后作者说：让我来。然后作则对各种不同的知名模型进行了全面综述，为不同地理位置提供介绍精度最好的那几个模型。 然后介绍了几个参数：太阳偏角，时角，太阳方位角，维度，每小时地外太阳辐射，水平面上每小时太阳辐射量。 地表接受的太阳辐射有：直接的太阳辐射和漫射的太阳辐射。当太阳光穿过大气层的时候，其中有一些被称为光束的辐射到地表，有明显的阴影，这种直接的辐射可以通过温度计测量。漫射的太阳辐射是穿过太阳光的一部分，被水蒸气，颗粒物消耗，分散，反射，这种辐射没有阴影，无法聚焦，此类辐射的收集需要精确的仪器，漫反射模型可分为参数模型和分解模型。 参数模型： ASHRAE 模型提供了一种简单的方法，该方法被工程学和建筑社区广泛使用 Machler and Iqbal 模型专门研究了每小时太阳辐射中的漫反射 Parishwad 模型 使用了统计的方法估计ASHRAE模型，对印度不同地点的六个地方进行了指标分析 Nijegorodov 模型 使用计算机预测了ASHRAE模型的常数 分解模型： 分解模型通常仅使用与全球辐射有关的数据来估计扩散来自全球太阳辐射数据的辐射，分解模型基于在水平面上的漫射和总辐射，接下来作者就又介绍了很多个分解模型，基本都是高阶的，参数为净度系数（$M_t$)，该系数与当地的气候有关 后面就开始讲倾斜表面的太阳辐射了，就没仔细看了（其实一直没有仔细看:cry:） 跳了很多，直接跳到结论了。漫射辐射模型受到维度影响很大，其余都是讲倾斜表面了。 ps：该文作用不大，不适合我，都是讲倾斜表面的了，而且没有介绍一点关于经验模型的知识 需要review的文章 1.2 研究进展 一个为期16年（2000-2015年）的高分辨率（3 h，10 km）全球地面太阳辐射数据集 作者：唐文君 青高所 时间：2019 最近发布的国际卫星云气候项目（ISCCP）HXG云产品和新的ERA5再分析数据使我们能够生成全球地表太阳辐射（SSR）数据集：16年（2000–2015）的高分辨率（3 h ，10 km）的全球SSR数据集，使用改进的物理参数化方案。 输入数据 云产品 ISCCP-HXG ERA5重新分析数据（表面压力，水蒸气和臭氧） 气溶胶和反照率（MODIS） 经验模型结果讨论 代码： 数据： lat:35.8043 lon:-84.0260 结果： "},"gis/太阳能模型筛选系统.html":{"url":"gis/太阳能模型筛选系统.html","title":"太阳能模型筛选系统","keywords":"","body":"太阳能模型筛选系统 前端 问题 模型的文字描述怎么映射到地图上（是否有必要将文字转为图形） eg：江苏省南部、华北平原、全球适用 怎么根据绘制图形得到模型的图形 包含或则相交吗 可以用网格编码的形式吗 分类 时间（年月日） 空间尺度，经纬度，海拔 水平、倾斜，朝向 辐射分类（直射，散射，反射） 适用领域，建筑，农业 基于卫星，基于已知的气候测量值 经验方法，半经验方法，物理方法 经验方法：建立函数关系。经验方法在某些地方可能效果很好，但是将其覆盖范围扩展到更广泛区域的能力是有限的。 半经验方法：通常将晴朗天空条件的物理模型与多云条件的经验方案结合在一起。 物理方法：考虑了太阳辐射从大气层到地球表面的传输过程。 太阳辐射计算器 计算方法：Klien S A, Theilacker J C ​ 计算倾斜表面的每月平均太阳辐射 PVGIS 太阳辐射概论 在垂直于射线的平面上到达大气层顶部的太阳辐射，即所谓的太阳常数，其平均值为1361-1362 W / m 2，该值随地球在其椭圆轨道上的位置而有所不同。 当太阳辐射穿过大气层时，会经历不同的吸收，扩散或散射过程，从而导致地球表面接收到的太阳辐射水平较低。这些是由于大气成分（例如臭氧或CO 2）以及悬浮的固体和液体颗粒（如气溶胶或水蒸气）造成的。但是，衰减的主要来源是云层。不仅宽带值不同，而且吸收和衰减的这些过程也对太阳辐射的波长产生不同的影响，因此，太阳辐射在地平面的光谱分布与地外光谱不同。 在地面上接收到的太阳辐射（称为全局辐射）是三个分量的总和。第一个称为射束或直接辐射，是到达地面但没有被大气衰减的太阳辐射的一部分，可以将其建模为直接来自太阳圆盘。第二部分或扩散部分是太阳辐射，它在被大气反射或散射之后到达地面，并被认为是从整个穹顶到达的。并非总是考虑到的第三部分是来自地面或附近障碍物的反射辐射。仅当太阳圆盘没有被云阻挡时，光束分量才可用，而漫射分量始终可用，这是每当云片阻挡太阳圆盘时唯一可用的辐射。 在晴朗的天空条件下（无云）以及干净干燥的大气中，太阳辐射是一个非常重要的参数，因为它提供了有关任何位置可用的最大辐射的信息。通常将此值建模，并用作其他模型的输入数据，这些模型用于估算正常大气条件下的太阳辐射。 通过PVGIS网站的页面，我们讨论了太阳辐射并以一种通用的方式使用它，但是我们还使用了其他应解释的术语。应该阐明诸如辐照度和辐照度的概念。辐照度是太阳能在单位面积和单位时间内落入地面的过程。因此，以W / m 2表示。辐照是一段时间内每单位面积接收的太阳能量，因此，能量以Wh / m 2表示。PVGIS提供的数据包含辐照度和辐照值。 太阳辐射衰减的主要因素是云层 无云、干净干燥的大气条件下的测量得到的太阳辐射是一个重要的参数，通常作为其它模型的输入数据 辐照度（$W/m^2$、$J*s^{-1}/m^{2}$）、辐照量（$Wh/m^2$ ) 估算太阳辐射强度 采用的半经验方法： 毫无疑问，测量太阳辐射的最佳方法是在地面上使用高质量的传感器。但是有用的是，这些测量应满足许多条件： 仅应使用高质量的测量传感器。 应至少每小时进行一次测量。 传感器应定期校准。 传感器应定期清洁。 数据应可长期使用，最好是10年或更长时间。 满足所有这些条件的地基辐射测量的数量相对较少，并且测站之间的距离通常很远。 由于这些原因，使用卫星数据来估计到达地球表面的太阳辐射变得越来越普遍。通常，这些方法使用对地静止气象卫星的数据。使用此类数据的优点是： 然后，可以在卫星图像覆盖的整个区域中获得太阳辐射数据，例如，METEOSAT卫星覆盖了非洲，欧洲和亚洲大部分地区，直至大约60°N，图像分辨率为几公里。 通常可以使用长达30年或更长时间的长时间序列。 使用卫星数据的缺点是必须使用许多相当复杂的数学算法来计算地面水平的太阳辐射，这些算法不仅使用卫星数据，而且还使用大气水蒸气，气溶胶（粉尘，颗粒）和臭氧的数据。某些情况可能导致计算失去准确性，例如： 可能被误认为云的雪 在卫星图像中很难检测到的沙尘暴 对地静止卫星还具有不覆盖极地地区的局限性。尽管如此，基于卫星的太阳辐射数据的准确性现在通常非常好。因此，PVGIS中使用的大多数太阳辐射都基于卫星算法。 太阳辐射估计值的另一个来源来自气候再分析数据。使用数值天气预报模型计算再分析数据，重新运行过去的模型并使用已知的气象测量值进行更正。这些模型的输出是大量的气象数据，通常包括地面的太阳辐照度。其中一些数据集具有全球覆盖范围，包括卫星方法没有数据的极地地区。这些数据集的缺点是，它们大多具有较低的空间分辨率（每30 km或更高一次一个值），并且在覆盖范围内，太阳辐射值的准确性通常不如基于卫星的太阳辐射数据好两种类型的数据集。 在发布PVGIS 5时，我们使用了两个基于重新分析的太阳辐射数据集： ECMWF ERA-5，由欧洲中型天气预报中心（ECMWF）生产。该数据集的全球覆盖范围约为30 km，包括全球和直接太阳辐照度。在撰写本文时，仅发布了2010-2016年的时间段，而在2018年还有更长的时间段。 COSMO-REA是一个区域性再分析产品，覆盖欧洲和北非[ Bollmeyer等人，2015 ]。空间分辨率约为6公里（在PVGIS中我们使用3弧分），并且以1995-2015年期间的小时时间分辨率获得数据，尽管在PVGIS中目前仅使用2005-2015年的间隔。 COSMO-REA在地理范围上仅限于欧洲和北非部分地区。相反，ERA-5具有全球覆盖范围。但是，对于PVGIS 5版本，我们将以相同的程度提供这两个数据库，仅覆盖欧洲。 有关基于重新分析的新太阳辐射数据的更多信息，请参见此处。 卫星太阳辐射的计算 使用卫星图像估算云对太阳辐射的影响 使用大气中的辐射传递理论以及大气中有多少气溶胶（灰尘，颗粒等）的数据，计算晴朗天空条件下（即无云）的太阳辐射 根据云的反照率和晴空辐照度计算总辐射 使用卫星数据的缺点是必须使用许多相当复杂的数学算法来计算地面水平的太阳辐射，这些算法不仅使用卫星数据，而且还使用大气水蒸气，气溶胶（粉尘，颗粒）和臭氧的数据。某些情况可能导致计算失去准确性，例如： 可能被误认为云的雪 在卫星图像中很难检测到的沙尘暴 在许多科学论文中已经描述了用于计算来自卫星的太阳辐射的方法（Mueller等，2009； Mueller等，2012； Gracia Amillo等，2014）。在这里，我们仅简要介绍这些方法。本说明用于计算欧亚大陆和非洲的太阳辐射（PVGIS-CMSAF和PVGIS-SARAH数据库）。来自NSRDB数据集的数据已使用不同的方法进行了计算（Habte et al。，2017）。 计算的第一步是使用卫星图像估算云对太阳辐射的影响。云层倾向于反射入射的阳光，因此较少的辐射到达地面。 通过每月一个月的每天相同时间查看相同的卫星图像像素，可以计算出云的反射率。然后，该方法假定该月中最暗的像素是与晴朗的天空（无云）相对应的像素。对于所有其他日子，然后相对于晴朗的日子来计算云层反射率。这是一天中所有小时的工作。这样，可以计算出有效的云反照率。下图显示了原始卫星图像和根据该图像计算出的有效云反射率的示例。请注意，在第一个图像中陆地表面是如何可见的，但是在第二个图像中仅留下了云层。 来自印度洋METEOSAT-7的原始卫星图像 © PVGIS©欧洲共同体，2001-2017 根据2015年1月1日09:00 UTC拍摄的卫星图像计算出的有效云反射率。 © PVGIS©欧洲共同体，2001-2017 第二步，该方法使用大气中的辐射传递理论以及大气中有多少气溶胶（灰尘，颗粒等）的数据，计算晴朗天空条件下（即无云）的太阳辐射。浓度较高的水蒸气和臭氧，它们都倾向于吸收特定波长的辐射。然后根据云的反照率和晴空辐照度计算总辐射。下图显示了使用上图所示的云反照率计算的总体水平辐照度。 根据METEOSAT-7图像计算的2015年8月1日09:00的全球水平辐照度（W / m2） © PVGIS©欧洲共同体，2001-2017 该方法通常效果很好，但在某些情况下可能会失败。例如，如果地面上有雪，则该方法可能会将其视为云，然后计算出太低的辐照度。而且，用于计算的气溶胶信息包括多年平均值，因此该方法无法很好地捕获气溶胶的短期变化，例如由于沙尘暴或火山喷发而引起的变化。 对于当前版本的PVGIS，用于太阳辐射估算的卫星数据来自覆盖欧洲，非洲和亚洲大部分地区的METEOSAT卫星。根据卫星的类型，每15分钟或30分钟捕获一次图像。对于PVGIS，我们每小时使用一幅图像。卫星图像的分辨率各不相同，在卫星图像（最低点）以下最高，而向图像边缘移动时则降低。在最低点，分辨率约为4公里。 在CM SAF合作中已开发出PVGIS中用于基于卫星的太阳辐射数据的算法。PVGIS中使用的太阳辐射数据也可以通过Web用户界面直接从CM SAF获得。 最近，我们与国家可再生能源实验室合作，将NSRDB数据纳入PVGIS。这将覆盖范围扩展到北美和中美洲。 验证基于卫星的太阳辐射数据 必须对照在地面上的测量值来检查从卫星图像产生的太阳辐射数据，以了解基于卫星的太阳辐射数据有多大的不确定性。这称为数据验证。 通过与地面站测量结果进行比较，许多科学论文已经给出了PVGIS中使用的卫星太阳辐射数据的验证结果（Mueller等，2009； Mueller等，2012； Huld等，2012； Gracia Amillo等。 。，2014）。在这里，我们仅介绍验证的基本结果。地面站的大多数测量值来自“基线表面辐射网络”（BSRN），该网络为世界各地的站提供了高质量的太阳辐射测量值。 位置 纬度 经度 卫星与电台之间的百分比差异 参考 地理信息系统 地理信息系统 Lindenberg（德国） 52.22牛 14.12E -3.4 -3.2 [1,3] 卡博（NL） 51.97N 4.93E +0.4 -0.4 [1,3] 卡庞特拉（FR） 44.05N 5.03E +2.1 +5.5 [1,3] Payerne（CH） 46.81N 6.94E -3.0 +0.6 [1,3] 贝尔斯克（PL） 51.70牛 20.8E -5.5 不适用 [1] 坎伯伯恩（英国） 50.22牛 5.32瓦 +3.0 -1.9 [4,3] 托拉韦（EE） 58.27N 26.47E +5.1 -4.1 [4,3] 斯德·博克（IL） 30.87N 34.77E -3.3 +3.4 [4,3] 阿尔梅里亚（ES） 37.50N 2.2瓦 -0.9 不适用 [4] 日内瓦（CH） 46.12N 6.01E +2.6 不适用 [4] 南特（法国） 47.25牛 1.55瓦 +3.8 不适用 [4] 沃克斯昂维林（FR） 45.78N 4.93E +3.9 不适用 [4] 基希涅夫（MO） 47.00N 28.82E +0.4 +1.4 [4,3] 利耶帕亚（LV） 56.48牛 21.02E +2.5 不适用 [4] Sonnblick（AT） 47.05N 12.95E -14.0 不适用 [4] 塞萨洛尼基（GR） 40.63牛 22.97E +5.9 +3.6 [4,3] 维也纳·荷·瓦特（AT） 48.25牛 16.35E -1.5 不适用 [4] 伊斯普拉（IT） 45.81N 8.64E +8.4 +9.0 [4] 米兰（IT） 45.48牛 9.26E -0.5 不适用 [4] 罗马（IT） 41.86N 12.62E +4.1 不适用 [4] Sarreguren（ES） 42.82牛 1.60瓦 +1.6 不适用 [4] 拉科鲁尼亚（ES） 43.37N 8.42瓦 +11.0 不适用 [4] 莱里达（ES） 41.62N 0.60瓦 +2.4 不适用 [4] 马德里（ES） 40.45牛 3.72瓦 -0.3 不适用 [4] 塔曼拉塞特（DZ） 22.78牛 5.51E -6.0 +2.6 [4,3] 德阿（ZA） 30.67秒 23.99E +2.2 +0.6 [4,3] 太阳村（SA） 24.91N 46.41E +3.2 -0.2 [4,3] 弗洛里亚诺波利斯（BR） 27.53秒 48.52瓦 不适用 +0.3 [3] 科科斯岛（澳大利亚） 12.19秒 96.84E 不适用 +0.6 [3] 香河（CN） 39.75牛 116.96E 不适用 +0.8 [3] 斜面上太阳辐射的计算 上述基于卫星的计算会产生水平面上的整体和束辐照度值，宽带和光谱解析辐照度值。 然而，模块和PV系统通常相对于水平面或在跟踪系统上以倾斜角度安装，以使接收到的平面内辐照度最大化。因此，卫星检索的辐照度值不能代表模块表面可用的太阳辐射，因此有必要估算平面内辐照度。 科学参考书目中有几种模型，这些模型使用整体和漫反射和/或光束辐照度分量的水平面上的辐照度值作为输入数据，以估计倾斜表面上的光束和漫射分量的值。这些总和就是倾斜表面上的平面内全局辐照度。光束辐照度直接来自太阳圆盘，因此，只要知道天空中的太阳位置以及倾斜表面的倾斜度和方向，就可以轻松地从水平面的值计算出倾斜表面的值。相反，对倾斜表面上的散射分量的估计不是那么简单，因为它已被大气成分散射，因此可以描述为来自整个天空穹顶。 定义弥散分量的方式是各种估算模型之间的主要区别。可以在Gracia Amillo和Huld，2013年找到这些模型的比较。模型可以分为两大类，各向同性和各向异性。第一组认为漫射辐射在天穹上是均匀分布的（各向同性），类似于在阴天情况下观察到的情况。在此假设下，倾斜表面上的漫射辐照度是水平面上的值，其缩放系数仅取决于表面的倾斜度，并说明了从该平面的表面可见的天空穹顶部分。 但是，漫射辐射几乎不可能是各向同性的。改变云层，但即使在无云的情况下，也很容易区分亮度不同的区域。除了各向同性的背景外，太阳周围的明亮区域也很容易注意到。并且，根据云量的不同，天顶或地平线周围可能会有明亮的区域。在各向异性模型之间，如何估计和考虑这些区域是不同的。根据在各向同性背景旁边使用了多少个区域，可以将它们分为两组。他们是否考虑了绕地带和/或视界带。 PVGIS中实现的估计模型是Muneer T.（1990）开发的模型，可以将其分为两个组成部分的各向异性。它的表现与其他更复杂的模型（例如由Perez或Reindl开发的三个组件的各向异性模型）相似。实际上，在ESRA（2000）进行的研究中，Muneer模型证明了最佳性能。它可以区分晴朗和阴暗的天空条件，以及阳光直射和阴影的表面。 地形阴影的影响 意大利阿尔卑斯山某个位置的地平线高度图（以度为单位）。 © PVGIS©欧洲共同体，2001-2017 如果您靠近丘陵或山脉，有时太阳会落在丘陵后面，太阳辐射会减少到来自天空或云层的辐射。PVGIS使用有关地形高程的信息，分辨率为3弧秒（约90m）。这意味着对于每90m，我们都有一个地面标高值。根据这些数据，我们计算了每个地理位置周围的地平线高度。这些数据然后用于计算太阳被丘陵或山脉遮挡的时间。当发生这种情况时，仅使用辐射的扩散部分即可计算出太阳辐射。PVGIS中完成的计算都可以利用此信息。 下图显示了意大利阿尔卑斯山（Macugnaga）某个位置周围的地平线高度的示例。地平线高，除了向东，这是从那个地方向下谷的方向。 分辨率约为90m，PVGIS中的计算无法考虑附近物体（例如房屋或树木）的阴影影响。但是，PVGIS可以让用户上载要使用的地平线高度而不是内置地平线信息的数据文件。 光伏发电量的计算 当然，对于光伏系统的能量输出而言，最重要的因素是到达光伏模块的太阳辐射量。但是还有其他一些重要的因素。本章介绍了影响PV输出的不同影响以及如何在PVGIS中对其进行计算。 在实验室或工厂中测量光伏模块的功率时，这是在称为标准测试条件（STC）的标准化条件下完成的。这些标准条件由国际标准IEC-60904-1确定。这些条件是： 模块整个表面的光强度（辐照度）应为1000W /m²。这个值是关于 当模块正对着阳光时，在晴天的中午时分，尽管在实际条件下，辐照度有时可能更高。 模块温度应为25°C。 光的光谱应等于IEC 60904-3中给出的全局光谱。该光谱与您在晴天看到的光谱相对应，其中太阳比地平线高约40°，并且模块相对于面向太阳的水平面倾斜约40°。 在STC处测得的功率称为标称功率或峰值功率。 Angstrom公式实现 克里金插值 网址：克里金插值 确定性插值方法：IDW(反距离加权法) 样条函数插值法，直接基于周围的测量值生成表面的平滑度的数学公式 地统计方法：克里金法，基于包含自相关（测量点之间的统计关系）的统计模型，因此，地统计方法不仅具有产生预测表面的功能，而且能够对预测的准确性提供某种度量 克里金法假定采样点之间的距离或者方向可以反映表面的变化，克里金法可以将数学函数或指定数量的点或者半径内的所有点进行拟合以确定每个位置的输出值，克里金法是一个多步过程：数据的探索性统计分析、变异函数建模和创建表面 在反距离权重法中，权重仅取决于预测位置的距离，但是，使用克里金方法时，权重不仅取决于测量点之间的距离、预测位置，还取决于基于测量点的整体空间排列，要在权重中使用空间排列，必须量化空间自相关 要使用克里金插值法进行预测，有两个任务是必需的： 找到空间自相关的关系 进行预测 要实现这两个任务，克里金法需要经历一个两步过程： 创建变异函数和协方差函数以估算取决于自相关模型（拟合模型）的统计相关性（空间自相关的）值 预测未知值 "},"gis/遥感技术解决地理问题.html":{"url":"gis/遥感技术解决地理问题.html","title":"遥感技术解决地理问题","keywords":"","body":"遥感技术在土地利用中的应用 工业革命以来，人类生产方式的改变深刻的影响着全球的发展，工业化、城市化正深刻影响着全球土地利用空间格局并影响到区域和国家生态与环境状况[1]，人类对于土地的改造是前所未有的巨大，这些巨大的改变急需一种能定量的统计和观测手段，由此诞生了一个新兴的领域——遥感。遥感通过对地观测短时间内能获取了大范围的海量数据，通过这些海量数据科学家们建立起了完整的土地利用/覆盖变化遥感监测与数据分析技术路线,以及独特的分类体系和动态区划体系。遥感是一种地理空间技术，它对地球陆地、大气和水生生态系统发出和反射的电磁 (EM) 辐射进行采样，以便在不进行物理接触的情况下检测和监测区域的物理特征。这种数据收集方法通常涉及基于飞机和基于卫星的传感器技术，这些技术分为无源传感器或有源传感器。遥感技术的蓬勃发展支撑起了土地利用研究的半边天。比如：中国科学院组织开展了全国范围以遥感手段为主的土地资源调查，建立了全国1:10万多时相土地利用数据库、针对全球尺度，美国地质调查局为国际地圈与生物圈计划建立 IGBP DISCover 数据集[2] ，美国马里兰大 学开发了全球土地覆盖数据UMD数据集[3] ，欧盟联合研究中心制作了GLC数据集[4] ，美国波士顿大学基于MODIS影像生产了MCD12Q1数据集[5]，欧洲空间局制备了GlobCover数据集[6] 和CCI-LC数据集[7] ，中国清华大学研制了 FROM-GLC 数据集[8] 。遥感使从危险或无法进入的地区收集数据成为可能，这在现代社会中越来越重要。它取代了速度较慢、成本高昂的地面数据收集，为日常应用提供了对极大区域的快速和重复覆盖，从天气预报到自然灾害或气候变化的报告。 遥感也是一种无障碍的方法，允许用户在不干扰目标区域或对象的情况下，在异地收集数据并进行数据处理和GIS分析。遥感领域的知识浩如烟海，本文重点回顾了遥感技术在土地利用遥感制图和土地利用快速分类方面的应用，列举了近期比较经典的实际应用。 土地利用遥感制图 遥感制图是指通过对遥感图像目视判读或利用图像处理系统对各种遥感信息进行增强与几何纠正并加以识别、分类和制图的过程。遥感图像有航空遥感图像和卫星遥感图像，制图方式有计算机制图与常规制图。目前应用最多及着重研究的是利用Landsat的MSS图像制图。由于多波段的卫星图像具有信息量丰富、现势性强，利用它编图周期短等优点，在制图方面得到了广泛的应用。 土地利用遥感制图结果是支撑全球气候变化和区域可持续发展等领域科学研究不可或缺的重要基础数据，而制图精度 方面的评价信息则决定土地利用遥感制图结果的完整性、可靠性、可用性、可控性和可传播性[9]。比如侯西勇在中国海岸带土地利用遥感制图及精度评价一文中描述的：以时间序列的 Landsat 多波段卫星影像为主要数据源，采用目视判读、图斑勾绘与编码以及时序动态更新的技术途径进行多时相中国海岸带土地利用遥感制图，这一技术方案能够获得精度较优的多时相土地利用分类数据产品，在支持中国海 岸带土地利用变化监测和研究方面是行之有效的[9]。在中国湿地初步遥感制图及相关地理特征分析一文中，作者通过1999～2002年累积的597幅Landsat ETM+遥感影像为数据源,采用人工目视解译为主,同时结合全国高程、土壤、土地利用和Google Earth数据,对全国9ha以上的水面、沼泽等湿地进行了初步遥感制图.在此基础上,利用1km分辨率的全国地形高程数据,1:100万土壤数据、植被数据和1:400万的气候区划数据对湿地分布进行了相关地理特征分析[10]。雷海梅、张晓楠等人在2套30 m分辨率土地覆被遥感数据类别精度及空间一致性特征研究中以中国研发的2套30米分辨率全球尺 度土地覆被数据Globeland30和FROM-GLC-Hierarchy数据为研究对象，以国际组织发布的验证数据为参考，从国家、区域及类别尺度进行了比较和评价，探索了空间一致性随地形的变化特征。结果表明： 2套数据的林地、耕地、水体三种类别均具有较高的分类精度，Globeland30的草地具有较高的用户精度和制图精度，林业、农业及水资源领域研究可以选择二者作为基础数据源，草地科学研究可以选择 Globeland30作为基础数据源。2套数据的类别空间不一致性与高程具有典型的正相关，其不一致比例随着高程的增加明显增大，在1500 m以上区域，二者的类别不一致性比例最大，达到了42.91%；二者类 别不一致性区域主要位于2~15度之间，其面积接近占60%，2度以下区域不一致性最低，约占7.09%。 研究表明地形条件是影响大尺度土地覆被制图的重要因素，因此，未来应进一步加强高海拔及景观异质 性区域土地覆被分类算法的研发[11]。 土地覆被数据是自然资源管理、城市规划、气候模拟、环境保护建模等领域的重要信息，对其进行精度评价并揭示其类别混淆特征对于众多科学领域具有重要意义。土地利用多功能具有多层次性和区域性，应针对不同的区域背 景和研究尺度建立相应的分类与评价指标体系。将土地利用功能与土地利用结构相联系,，并将评价尺度延伸至地块这一微观尺度， 拓展和丰富了土地利用多功能研究的范围与内容，为土地利用多功能研究提供新的思路和途径。 土地利用快速分类 现代遥感技术快速发展，推动了遥感技术在水土保持监测中的广 泛应用。土地利用 / 覆盖变化是针对地表各种地物动态变化的反映，对 水土流失动态监测具有重要意义[12]。遥感数据源的丰富也对数据源的快 速应用提出了挑战，目视解译精度虽高，但是效率低下，监督分类方法可以实现快速的土地利用分类，为后续的水土保持动 态监测提供基础数据，但是现有的监督分类方法主要是以传统 的模式识别技术为基础，如最大似然分类器、K －近邻法等， 这些方法的分类精度均建立在趋于无穷大的样本基础上，否则难以取得较为理想的效果[12]。 快速分类对遥感技术的要求更高，对遥感图像的精度和分类的算法有着严格的要求。高分辨率卫星，数据分辨率可达米级或亚米级，它提供的影像精度就很高。国产高分辨率卫星经过十多年的快速发展，已形成庞大的观测体系，主要包括高分一号、高分二号、高分三号（雷达卫星）、高分四号（静止轨道卫星）、高分五号（高光谱卫星）、高分六号、资源系列卫星、环境系列卫星、高景一号、天绘卫星、实践9号等。国外高分辨率卫星起步早，体系更为庞大，观测能力也更强，目前常用的包括Worldview系列、GeoEye系列、Quickbird卫星、Ikonos卫星、Planet系列卫星等。李恒凯针对东江流域地物斑块破碎、湖泊河流众多等因素影响其地物分类精度的问题，以 GF-1 遥感影像为数据源， 采用面向对象的分类方法，结合模糊分类和 CART 决策树分类法获取研究区土地利用分类信息[13]。山区地物类型复杂多样,传统计算机分类难以有效克服“同物异谱”或“同谱异物”等现象,分类后“椒盐现象”严重，陈波以川西南攀枝花市的部分山区为实验区,使用IKONOS高分辨率遥感影像，采用面向对象分类方法，在ERDAS9.2、ENVI4.8和eCognition8.0等软件平台支持下，以多尺度分割后的对象为单元,辅以纹理特征、形状因子、地形因子等特征参与分类过程,实现了对实验区土地利用信息的提取[14]。胡龙飞以提高土地覆盖分类制图的质量为出发点，充分利用多源遥感数据，构建了全面的特征空间,包括空间特征(如纹理、形状等)、时间特征(时间序列特征)和光谱特征;在时间、空间和光谱三个维度较全面的考虑了多源遥感数据优势、建立了丰富的特征信息。并在建立特征空间的过程中,利用现有工具对多光谱数据与合成孔径雷达数据进行了必要的预处理,以减弱遥感数据受到的天气、大气散射和传感器灵敏度等问题的影响[15]。快速、准确获取耕地数量及其分布信息是研究耕地时空格局和生态效应的基础，也是及时制定应对粮食问题对策的迫切需求。近年来，随着卫星遥感技术的迅猛发展，遥感以其宏观性、实时性以及经济性为耕地信息快速获取提供了可能性。随着传感器数量不断增加，遥感影像时间分辨率、空间分辨率及光谱分辨率不断提高，分类算法的不断涌现，基于多源遥感数据，集成智能分类算法识别耕地将成为必然的发展趋势[16]。森林在生态系统服务中起着重要作用，例如提供清洁空气、保护生物栖息地以及减少全球温室气体的排放等。全球森林变化数据集（Global Forest Change，GFC）每年以30 m的高空间分辨率绘制森林覆盖变化图，成为监测森林覆盖时空变化特征的有效工具。王淑静利用谷歌地球引擎（Google Earth Engine，GEE），基于GFC产品，结合线性回归方法和空间自相关理论对西南地区2001~2019年森林变化情况进行研究表明：政策因素在土地利用方式转变过程中发挥着重要作用，林业活动和农业扩张是影响损失现象发生的主要驱动因素，今后制定森林保护和管理战略时应充分考虑多方面因素造成的森林损失现象，研究结果可以为森林监测和保护提供更科学的指导[18]。为有效地监测复杂区域生态环境治理成效，,研究大范围复杂地区土地利用遥感自动、快速提取方法，应构建适于研究区土地利用变化分析的分类系统；其次，采用地理分区综合遥感分类法对青海高原东部农业区进行土地利用遥感分类制图[19]。 土地利用/土地覆被变化是全球变化研究中的一个重要内容，而土地利用/土地覆被分类又是研究土 地覆被变化的重要前提，它既影响着分类结果的表达，也决定着分类数据的应用领域[20]。土地覆盖/土地利用已成为开展土地利用变化预测、自然灾害防治、土地利用管理与规划、环境保护等一系列重要工作的关键而又基本的任务之一。随着遥感技术和地理分析模型的发展，利用遥感数据监测土地覆盖/土地利用的状态和动态变化已成为最快速、最可靠、最有效的方法之一。 [1] 刘纪远, 张增祥, 张树文, 颜长珍, 吴世新, 李仁东, 匡文慧, 史文娇, 黄麟, 宁佳, 董金玮. 中国土地利用变化遥感研究的回顾与展望——基于陈述彭学术思想的引领[J]. 地球信息科学学报, 2020, 22(4): 680-687.DOI:10.12082/dqxxkx.2020.200052 [ 2 ] Loveland T R, Reed B C, Brown J F, et al. Development of a global land cover characteristics database and IGBP DIS Cover from 1 km AVHRR data[J]. International Journal of Remote Sensing, 2000,21(6-7):1303-1330. [ 3] Hansen M C, Reed B. A comparison of the IGBP DISCover and University of Maryland 1 km global land cover products[J]. International Journal of Remote Sensing, 2000,21(6-7):1365-1373. [ 4 ] Bartholomé E, Belward A S. GLC2000: A new approach to global land cover mapping from Earth observation data [J]. International Journal of Remote Sensing, 2005,26(9): 1959-1977. [ 5 ] Friedl M A, McIver D K, Hodges J C F, et al. Global land cover mapping from MODIS: Algorithms and early results [J]. Remote Sensing of Environment, 2002,83:287-302. [ 6 ] 宁佳,张树文,蔡红艳,等. MODIS 和 GLOBCOVER 全球 土地覆盖数据集对比分析——以黑龙江流域为例[J].地 球信息科学学报,2012,14(2):240-249. [ Ning J, Zhang S W, Cai H Y, et al. A comparative analysis of the MODIS land cover data sets and Globcover land cover data sets in Heilongjiang Basin[J]. Journal of Geo- information Science, 2012,14(2):240-249. ] [7] Li W, Ciais P, MacBean N, et al. Major forest changes and land cover transitions based on plant functional typesderived from the ESA CCI Land Cover product[J]. International Journal of Applied Earth Observation and Geoinformation, 2016,47:30-39. [8] 宫鹏,张伟,俞乐,等.全球地表覆盖制图研究新范式[J].遥 感学报,2016,20(5):1002-1016. [ Gong P, Zhang W, Yu L, et al. New research paradigm for global land cover mapping [J]. Journal of Remote Sensing, 2016,20(5):1002-1016. ] [9] 侯西勇, 邸向红, 侯婉, 等. 中国海岸带土地利用遥感制图及精度评价[J]. 2018. [10] 邸向红, 侯西勇, 吴莉. 中国海岸带土地利用遥感分类系统研究[J]. 2014. [11] Lei H, Zhang X, Sun Q, et al. The Category Accuracy and Spatial Consistence Characteristic Analysis for Two 30 m Resolution Land Cover Products in China[J]. 2020. [12] 黄超, 史超, 李书, 等. 高分辨率影像在水土保持土地利用快速分类中的应用[J]. 中国科技信息, 2019, 8. [13] 李恒凯, 吴娇, 王秀丽. 基于 GF-1 影像的东江流域面向对象土地利用分类[J]. 农业工程学报, 2018, 34(10): 245-252. [14] 陈波, 胡玉福, 喻攀, 等. 基于纹理和地形辅助的山区土地利用信息提取研究[J]. 地理与地理信息科学, 2017, 33(1): 1-7. [15] 胡龙飞. 基于多源遥感数据的土地覆盖分类方法研究[D]. 重庆邮电大学, 2019. [16] 熊曦柳, 胡月明, 文宁, 等. 耕地遥感识别研究进展与展望[J]. 农业资源与环境学报, 2020, 37(6): 856-865. [17] 张帅华. 基于 Landsat 影像的郑州市土地利用时空演变及驱动力分析[D]. 东华理工大学, 2017. [18] 王淑静, 赖佩玉, 郝斌飞, 等. 西南地区 2001~ 2019 年森林损失特征遥感监测与时空分析[J]. 遥感技术与应用, 2021, 36(3): 552-563. [19] 曾永年, 靳文凭, 何丽丽, 等. 青海高原东部农业区土地利用遥感分类制图[J]. 农业工程学报, 2012, 28(16): 225-231. [20] 张景华, 封志明, 姜鲁光. 土地利用/土地覆被分类系统研究进展[J]. 资源科学, 2011, 6. "},"gis/最小二乘法.html":{"url":"gis/最小二乘法.html","title":"最小二乘法","keywords":"","body":"基于最小二乘法拟合曲线 摘要 最小二乘法不应该只是简单的线性参数估计 1 最小二乘法简介 1.1 最小二乘法的历史背景 最小二乘法发展于天文学和大地测量学领域，科学家和数学家尝试为大航海探索时期的海洋航行挑战提供解决方案。准确描述天体的行为是船舰在大海洋上航行的关键，水手不能再依靠陆上目标导航作航行。1801年，意大利天文学家朱塞普·皮亚齐发现了第一颗小行星谷神星。经过40天的追踪观测后，由于谷神星运行至太阳背后，使得皮亚齐失去了谷神星的位置。随后全世界的科学家利用皮亚齐的观测数据开始寻找谷神星，但是根据大多数人计算的结果来寻找谷神星都没有结果。当年24岁的高斯也计算了谷神星的轨道。奥地利天文学家海因里希·奥伯斯根据高斯计算出来的轨道重新发现了谷神星。高斯使用的最小二乘法的方法发表于1809年他的著作《天体运动论》中，而法国科学家勒让德于1806年独立发现“最小二乘法”，但因不为世人所知而没没无闻。两人曾为谁最早创立最小二乘法原理发生争执。1829年，高斯提供了最小二乘法的优化效果强于其他方法的证明，见高斯-马尔可夫定理。 相关回归分析、方差分析和线性模型理论等数理统计学的几大分支都以最小二乘法为理论基础[1]。作为其进一步发展或纠正其不足而采取的对策，不少近现代的数理统计学分支也是在最小二乘法基础上衍生出来的[1]。正如美国统计学家斯蒂格勒 (s．M．Stigler)所说，“最小二乘法之于数理统计学犹如微积分之于数学”[2]。最小二乘法创立的历史过程充满着丰富的科学思想，这些对今 日的数学创造仍有着重要的启示意义。 1.2 最小二乘法原理 最小二乘法（least squares method）是一种数学优化建模方法，它通过最小化误差的平方和来寻求数据的最佳函数匹配，通过最小二乘法可以简便的求得未知数据，并使得所求值和实际数据之间的误差的平方和最小。 假设我们对某一变量$x$或多个变量$x_1,x_2...x_n$构成的相关变量$y$感兴趣，我们用$q$个独立变量或则$p$个系数拟合出如下的函数模型（参数b是为了使所选择的函数模型同观测值y相匹配），一般情况下，观测值多于选择参数： $$ y_m = f(x_1,x_2,...,x_q;b_1,b_2,...,b_p) $$ 然后最重要的是怎么判断不用拟合的质量。高斯和勒让德的给出的解决方案是：假设测量误差的平均值为0，令每一个测量误差对应一个变量并与其它测量误差不相关（随机无关），假设在测量误差中绝对不含系统误差，即它们都是是纯偶然误差(有固定的方差)，误差围绕真值波动。除此之外，测量误差符合正态分布，这保证了偏差值在最后的结果$y$上忽略不计。确定拟合的标准应该被重视，并小心选择，较大误差的测量值应被赋予较小的权[1]。并建立如下规则：被选择的参数，应该使算出的函数曲线与观测值之差的平方和最小。用函数表示为： $$ min\\sum_{i=0}^n(y_m-y_i)^2 $$ 2 最小二乘法在拟合中的应用 最小二乘法是从误差拟合角度对回归模型进行参数估计或 系统辨识，并在参数估计、系统辨识以及预测、预报等众多领域中得到极为广泛的应用[3]。然而大多同学对最小二乘法的认识都比较模糊，仅仅把最小二乘法理解为简单的线性参数估计[2]。在一般情况下，最小二乘法通常用于求解使用一阶泰勒级数展开线性化的一组非线性方程。求解非线性方程是一个使用牛顿法的迭代过程。收敛速度取决于解的初始猜测的质量。非线性最小二乘法通常称为束调整，因为解的初始估计值的所有值都一起修改（在束中调整）。这种技术有时也称为高斯-牛顿法。一般最小二乘法可用于求解一组未知数的一组方程。唯一的要求是方程的数量至少与未知数一样多。如果方程是线性的，最小二乘法将产生未知数的直接解。如果方程不是线性的，则需要对未知数进行初始猜测，结果是 对初始参数的调整。重复此操作直到结果收敛（调整变得非常接近于零）。线性的最小二乘问题发生在统计回归分析中；它有一个封闭形式的解决方案。非线性的问题通常经由迭代细致化来解决；在每次迭代中，系统由线性近似，因此在这两种情况下核心演算是相同的。 2.1 线性拟合 对于线性方程组，最小二乘法将产生未知数的直接解。线性情况在数学上与使用零作为所有参数的初始猜测来执行调整的一般情况相同。收敛只需要一次迭代。 方程必须是以下形式： $$ F_i(x_1, x_2,...,x_n)=a_1x_1+a_2x_2+...+a_nx_n=k_i $$ 因此雅可比矩阵$J$是 变量$y$与$n$个变量$x_1,x_2,...x_n$的内在联系是线性的，即： $$ y=a0+\\sum{i=0}^n(a_ix_i) $$ 设$xi$的第$i$次观测值为$x{ij}$，对应的函数值为$y_i(i=1,2,...,m)$，则函数的偏差平方和为： $$ s=\\sum{i=1}^m(y_i-y_i^1)=\\sum{i=1}^m(y_i-a_0-a_1x)^2 $$ 将实验数据$(x_{ij}, y_j)$代入上式可得$a_0,a_1,a_2,...,a_3$。 2.2非线性拟合 但是实际的科学实验得到的数据$(x_i,y_i)$的因变量$x$与自变量$y$之间可能根本不存在线性关系，此时可以考虑用一个$n$次多项式来拟合$y$与$x$之间的函数关系[4]。对于$n$次多项式来说，我们需要将它化为我们前面已经已经介绍的线性形式。如果方程个数$n$大于未知量个数$m$的方程组成为超定方程组，如果数学模型是最常用的代数多项式，则称为代数多项式拟合[5]。但是更多的曲线拟合均不能通过变量变换转换为线性拟合问题，如： $$ y = a+bln(x/c) $$ $$ y=a+bx^c $$ $$ y=a+b2^x $$ 关于非线性拟合问题 ，可以利用Taylor展开，逐次线性化 ，亦即对拟合参数逐次逼近，以得到问题的解答[6]。然而，非线性问题这样处理的难点，远不是需要大量的反复计算，而是迭代过程发散，也就是说 ，当迭代初值选择得不好时，Taylor展 开完全失真 ，致使迭代值不是逼近真值，而是远离真值 [7]。 通常我们选择的是迭代法： (1) 给定某个初始值$x_0$； (2) 对于第$k$次迭代，寻求一个增量$\\Delta x_k$，使得$||f(x_k+\\Delta x_k)||_2^2$达到最小值； (3) 若$\\Delta x_k$足够小，则停止； (4) 否则，另 $x_(k+1)=x_k+\\Delta x_k$，返回第2步 这让求解导函数为零的问题变成了一个不断寻找下降增量 ∆xk 的问题。以下就是寻找增量的方法。 考虑第k次迭代，想要寻找∆xk，最直接的方法是将目标函数F(x)在xk附近进行泰勒展开： $$ F(x_k+\\Delta x_k) = F(x_k) + J(x_k)^T\\Delta x_k + 1/2\\Delta x_k^TH(x_k)\\Delta x_k $$ 其中$J(x_k)$是关于$F(x)$的一阶导数(梯度、雅可比(Jacobian)矩阵)，$H(x_k)$则是二阶导数(海塞(Hessian)矩阵)。如果上式中只保留一阶项，则称为一阶梯度法或最快下降法，取$\\Delta x=-J(x_k)$，即增量的方向为梯度的反方向，通常还设置一个步长$\\lambda$。如果保留二阶项，则成为二阶梯度法或牛顿法。 一阶梯度法过于贪心，容易走出锯齿路线，反而增加了迭代次数；而二阶梯度法则需要计算目标函数的 H 矩阵，这在问题规模较大时非常困难，我们通常倾向于避免 H 的计算[8] [9]。在最小二乘法的线性拟合的方法中，高斯牛顿法和列文伯格—马夸尔特方法是两种比较经典的方法 2.3 拟合模型 我们知道多项式曲线拟合是一种较常用的数据处理方法,但当数据点较多时,只采用一种多项式曲线函数拟合所有数据点难以取得较好的拟合效果。但是数据拟合方法有很多，例如对数曲线拟合，反函数曲线拟合，二次曲线拟合，三次曲线拟合 ，幂函数曲线拟合 ，指数曲线拟合等。一般先观察散点图来确定曲线 的类型，不过散点图都是相关关系的粗略表示，有时候散点图可能与几种曲线都很接近，这时建立相应的经验函数可能都是合理的，但由于选择不同的曲线 ，得到同一个问题的多不同经验函数，一般我们需要确定怎样从这些经验函数中选择最优的一个[10] 。吴宗敏提出用几种函数进行拟合，计算历史数据点实测值和拟合值的误差平方和最小的为最优经验函数[11]。但是该方法存在一定问题：误差平方和最小，但误差波动较大，即一些点误差很小 ，一些点误差相对较大 。以该问题作为出发点，刘霞提出了一种新的确定经验函数的方法，用几种不同的函数进行拟合 ，从中选取最优的经验函数 ，最优经验函数确定的条件如下[10]：(1) 历史数据点误差为正和误差为负的个数之差小于适应性参数；(2) 计算误差的方差，方差最小的为最优的拟合函数。杨岚通过动态优化方法确定主成分数可提高所建立数学模型的预测效果，与交互验证方法选择主成分数方法相比较，动态优化方法确定的主成分数能够得到更好的预测结果，该方法能有效提高偏最小二乘数学模型的预测效果，是建立具有更好适应性数学模型的有效方法[12]。在最小二乘曲线拟合中,自变量的误差常常被略而不计，丁克良提出采用正交最小二乘法拟合曲线，该方法以正交距离残差平方和极小为准则，同时顾及了因变量和自变量的误差；基于间接平差原理详细推导了相关模型和算法，计算表明采用正交最小二乘法拟合曲线,拟合效果整体上优于普通最小二乘法[13]。 常见的曲线拟合模型有：对数函数、指数函数、幂函数、逻辑回归、多项式、Holt-Winters预测。其中Holt-Winters 预测使用 TIBCO Spotfire Enterprise Runtime for R 来计算对时间序列或可强制为时间序列的任何事物的 Holt-Winters 筛选。这是以指数方式对时间序列的级别、趋势和季节分量进行加权移动平均值筛选。所选的平滑参数用于最小化一步向前预测误差平方和。但是如何能得到一个更好的拟合模型还有待研究。 3 基于最小二乘法拟合曲线的简单实践 1、拟合多项式为：$y = a_0 + a_1x + a_2x^2 + ... + a_kx^k$ 2、求每个点到曲线的距离之和：$Loss = ∑(yi - (a_0 + a_1x + a_2x^2 + ... + a_kx^k))^2$ 3、最优化Loss函数，即求Loss对a0,a1,...ak的偏导数为0 3.1、数学解法——求解线性方程组： 整理最优化的偏导数矩阵为：X：含有xi的系数矩阵，A：含有ai的系数矩阵，Y：含有yi的系数矩阵 求解：XA=Y中的A矩阵 3.2、迭代解法——梯度下降法： 计算每个系数矩阵A[k]的梯度，并迭代更新A[k]的梯度 A[k] = A[k] - (learn_rate * gradient) 简单线性拟合 多项式拟合 实现方法为最小二乘法和求解线性方程组，误差下降为：0.6290094844905918 参考文献 [1] 贾小勇, 徐传胜, 白欣. 最小二乘法的创立及其思想方法[J]. 西北大学学报: 自然科学版, 2006, 36(3): 507-511. [2] LANCASTER H 0．Encyclopediaofstatisticalscience [J]．NewYork：Wiley，1988． [3] 邹乐强. 最小二乘法原理及其简单应用[J]. 科技信息, 2010 (23): 282-283. [4] 陆健. 最小二乘法及其应用[J]. 中国西部科技, 2007 (9): 19-21. [5] 王新和, 程世洲. 曲线拟合的最小二乘法[D]. , 2004. [6] 概率统计计算．科学出版社，2009． [7] 邢书珍, 邢天奇. 非线性最小二乘拟合的计算方法[J]. 中国铁道科学, 1995, 16(3): 64-71. [8] 高翔.视觉SLAM14讲 [9] 皮皮蒋.线性最小二乘和非线性最小二乘. https://www.jianshu.com/p/bf6ec56e26bd [10] 刘霞, 王运锋. 基于最小二乘法的自动分段多项式曲线拟合方法研究[J]. 科学技术与工程, 2014 (3): 55-58. [11] 吴宗敏.散乱数 据拟合的模 型、方法和理论．北京：科学出版社，2007 [12] 杨岚, 冯新泸. 动态优化偏最小二乘模型的建立与应用[J]. 后勤工程学院学报, 2008, 24(2): 75-77. [13] 丁克良, 欧吉坤, 赵春梅. 正交最小二乘曲线拟合法[J]. 测绘科学, 2007, 32(3): 18-19. "},"gis/人文地理学_第一次作业.html":{"url":"gis/人文地理学_第一次作业.html","title":"地理学思想","keywords":"","body":"人文地理学——第一次作业 [toc] 1.阅读 1.1. 地理学思想史阅读 1.1.1 述评 詹姆斯把地理学发展分为三个主要时期：即古典时期（诞生~1859）、近代时期（19世纪下半叶~20世纪50年代）与现代时期（20世纪60年代以来） “要使地理研究为年轻一代所吸引，一个强有力的方法就在于清楚的表明它对于解决重要问题时能做出什么样的贡献。抽象的概念需要结合实际的应用；不掌握这一点，就会使地理哦工作陷入无足轻重的境地” 1.1.2 序言、第一章——一门被称为地理的学科 人们发现并描述了许多不同的世界，但是人的观察能力和对所观察到的事物的概括能力是有很大的限度的 地球表层的所有事物和事件，在复杂的联合与相互的连接中存在着，组成一个巨大的人类-环境系统 地理思想史是人们试图获得他们在地球上居住和散步方面更为合理更为有用的知识的记录 它是哪里的：经纬度 它是什么样的：螺旋上升的地理认知 它意味着什么：宇宙的秩序？ 地理学的研究：数学传统和文学传统，地理大发现与传统的斗争，知识的分立门户，地理学还留下了一些知识方面，特别是社会科学，各种过程的发生从来不是真正相互孤立的，地理学应该研究综合性的问题 多种多样的新世界：多种多样的工作方法与范式 至少有 5 类问题可以进行研究的： 与地球空间有关的一般问题，但这些问题如果没有以一种概念结构作指导，来把有关的事物与大量无关的复杂事物区别开来，就不能获得有效的回答 与事态的先后顺序有关的问题，即从过去情况通过地理变迁知道目前情况的发生学问题，这些是用历史地理的方法研究的 与探讨经验的概括或一般法则的形成有关的理论问题，甚至还探讨基本理论以及引向逻辑推论的方法 应用地理概念和技能去研究实际的经济、社会或政治问题的有关一些补救性问题 与新的研究法实验、新的观察和分析技术或新的制图学有关的方法论问题 1.1.3 第十八章——创新与系统 数据模式的优越性并不意味着应该轻视用语言来阐述的模式 创新的新应该新在哪里，技术的进步带来了更多的资料，地理学者根据这些资料提出来哪些问题？地理研究有了新的方向？地理学是一个创新和传统的复合体 传统的回顾：地学传统、人地关系传统、区域研究传统、空间传统 系统：新地理学必须和空间系统联系起来，地理学者必须探索许多互不相同却相互依赖的变量 普通系统论：普通系统论致力于说明为许多种不同系统所共有的特性 空间系统：任何一个系统，凡其中一个或一个以上函数上的重要变量是属于空间方面的，这就是一个空间系统 1.2. 地理科学的战略方向阅读 由美国国家科学院研究机构组织的一项研究成果向世人展示了21世纪初期为应对地球面临的重要挑战，地理科学家能做出越来越重要贡献的具有前途的研究方向，集中讨论了与地理学相关的生态环境、发展、空间重组等11个议题 1.2.1 如何理解和应对环境变化 我们如何改变地球表面的自然环境 我们如何更好地保持生物多样性与保护濒危的生态系统 气候和其他环境变化将如何影响人与环境耦合系统的脆弱性 1.2.2 如何促进可持续发展 100亿人在地球上如何生存和分布 我们如何在未来10年和更长时间内可持续地养活每一个人 人口居住地是如何影响人类健康的 1.2.3 如何认识和应对经济社会快速的空间重组 人口流动、物资交流及思想传播如何改造世界 经济全球化如何影响不平等 地缘政治变化如何影响和平与稳定 1.2.4 如何促使技术革新更好地改善社会和环境 我们如何更好地观察、分析和可视化这个不断变化的世界 公民制图和绘制公民地图的社会影响是什么 1.3 当代 地理学要义第一篇阅读 1.3.1 地理学史 这一章追溯了地理学的起源及其在不同时间与地点同自然科学、社会科学与人文科学传统相互作用的方式 地理学是一个十分古老、格外复杂、饱受争议的科目 1.3.2 地理学与自然科学系统 这一章从考察自然科学与地理学的某些相似性和差异性的骄傲都，探究二者的原理和方法之间的关系 自然科学赖以立足的所谓科学方法本身其实只不过是一种模式，随着知识与理解力的增进，那些科学方法程序的平衡已经改变，而且还可能变成一种特别的研究成果 一旦揭示了某些规律性，就需要通过提出其背后机制的理论对其进行解释 为了评估机制相匹敌的理论的优劣，必须有一套理论与实践的程序 1.3.3 地理学与社会科学传统 越来越多的把自己视为社会科学家的地理学家向社会科学提出挑战，并接近更多样化的理论和方法领域 许多地理毕业生进入规划行业，但是多数人停留在数据收集者和展示者的水平 城市区域是内在的空间面貌或规划所必依的社会地理结构 地理学家关心科学的严密性，采用定量方法分析空间格局，并开发了空间组织模式 1.3.4 地理学与人文科学传统 人文科学包含对人的创造性、知识、信仰、思想和经验的研究 基于人本主义的地理学工作的例子包括历史与文化的研究以及对文学、视觉艺术和其他文化形式的研究与实践 在人本主义传统下工作的地理学家提出来有关空间的生产、表征的政治政策以及知识形象化与身份的关键性问题 1.4 重新发现地理学 地理学家致力于从环境变化到社会冲突等许多有价值问题的研究和教学，这些活动的价值来自本学科着重研究地球表面特征和组织的发展；研究具有独特自然与社会特征的具体地去自然与人文现象之间的互动方式；研究那些地方对各种自然与人文现象之间的互动方式；研究那些地方对各种自然与人文事件和过程的影响 地理学中的关键问题：经济健康、环境退化、民族矛盾、医疗卫生、全球气候变化、教育 自然气候系统 地理学的视角 通过地方、空间和尺度的透镜观察世界的地理学方法 地理学的综合领域：环境-社会动态把人类活动与自然环境、环境动态与自然系统、人类社会动态与经济、社会和政治系统联系起来 应用图像的、语言的、数学的、数字的和认知的 动态观察世界的方法 地理学技术：观测、野外观察/勘察、遥感、采样与观测的选择、展示与分析、地图学、地理信息系统、地理可视化、空间统计学 1.5 当代地理学 哲学原理部分覆盖了大量哲学及理论观点,包括实证主义、人文主义、女性主义、马克思主义、实在论、现代性理论、后结构主义、后殖民主义、结构化理论、行动者–网络理论等 作者或通过简单的例子阐述各自的观点,或通过逻辑来论证其观点,这些学科大人物为各自独特的认知方式提供了充分的论证,“强调各种认知方式之间的矛盾和冲突 1.6 中国国家地理 秦岭不知分南北：秦岭不是岭；淮河找不到自己的家：淮河是一条丢失了下游的河流；那秦岭淮河为何会成为分界线呢？对此最好的解释是秦岭淮河正好处于自然带的边缘地，从南到北的变化累积在此到达了临界状态，因此突变就此产生。把一些自然地理的等值线图画出来，会发现淮河所处的位置非常神奇，许多事关大自然神奇变化的临界点汇聚于此。 丝绸之路居然是由德国学者李希普芬提出，我一直以为就是中国自古就有的名词 楼兰的发现揭开了西域探险史 中国农业区划：东七西二一海洋 一个著名地理学家说过：地理学者的主要贡献在于划出有用的自然区域和地区。中国自然区划应有助于广义的农业生产和建设。其实广州既可以是亚热带，也可以是热带，这全是人为的。正如一位地理学家所说：选择什么样的标准来决定区域，这个问题在自然界找不到答案。做什么样的选择，必须由地理学家按照他对其重要性的主观判断而定 2. 思考问题 2.1 西方地理学思想经历了那些历史性的变化：概念、内容 答：詹姆斯把地理学发展分为三个主要时期：即古典时期（诞生~1859）、近代时期（19世纪下半叶~20世纪50年代）与现代时期（20世纪60年代以来），其中我认为重要的历史性变化有： 古希腊发展了天体位置对人的活动有重要影响：希腊人发展了天文科学，比如收集了大量有关恒星和行星的资料了、创立演绎法的柏拉图、创立归纳法的亚里士多德 十六世纪~十九世纪确立“学术自由”的原则：对抗宗教的势力，各个学者做出了巨大的努力：比如达芬奇和哥白尼 实现科学的崛起 信息革命带给地理学新的动力 2.2 地理学的传统是什么 空间传统 地区研究传统 人地传统 地球科学传统 2.3 重新发现地理学的价值在哪里 答：地理学是一门内容非常广泛的学科，牵涉到自然科学、社会经济和人文科学的许多方面。 地理学的研究、方法论、地理技术、地理信息系统、地理表述方法等多方面都在被越来越多的研究人员接受和使用，它的价值在于处理广泛的科学问题和社会需求，对于处于交叉学科的学者，地理学的思想和方法更有发挥的空间。 此外，地理学家因其技能与宽广的基础与多学科背景想结合和备受重视。地理学家应该也需要带来从环境方面与从空间方面解决问题的专长。 地理学家致力于从环境变化到社会冲突等许多有价值问题的研究和教学，这些活动的价值来自本学科着重研究地球表面特征和组织的发展；研究具有独特自然与社会特征的具体地去自然与人文现象之间的互动方式；研究那些地方对各种自然与人文现象之间的互动方式；研究那些地方对各种自然与人文事件和过程的影响 地理学中的关键问题：经济健康、环境退化、民族矛盾、医疗卫生、全球气候变化、教育 2.4 如何理解正在变化的星球 答：斯坦福大学的生态学家哈尔·穆尼认为我们生活在“地理学家的时代”——地理科学长期关注的不断变化着的地球表面的重要特征和空间结构，以及人类与环境之间的交互关系，正逐渐成为科学和社会的核心内容。近几十年来，随着人类对自然系统影响的程度和节奏的加大，地球表层处于持续的快速变化之中，这为地理科学战略方向的研究提供了一个逻辑起点。该书对地理科学研究的性质及其在当代的重要性进行了评述，同时，选取了十一个具有特别意义的重大科学问题进行了说明。 如何理解和应对环境变化 我们如何改变地球表面的自然环境 我们如何更好地保持生物多样性与保护濒危的生态系统 气候和其他环境变化将如何影响人与环境耦合系统的脆弱性 如何促进可持续发展 100亿人在地球上如何生存和分布 我们如何在未来10年和更长时间内可持续地养活每一个人 人口居住地是如何影响人类健康的 如何认识和应对经济社会快速的空间重组 人口流动、物资交流及思想传播如何改造世界 经济全球化如何影响不平等 地缘政治变化如何影响和平与稳定 如何促使技术革新更好地改善社会和环境 我们如何更好地观察、分析和可视化这个不断变化的世界 公民制图和绘制公民地图的社会影响是什么 2.5 中国地理学家的贡献主要集中在哪些方面 答：中国地理学家的贡献主要表现在科研方向的突破、对国家建设的贡献、研究手段的革新、对科学和教育的贡献、对社会的贡献等方面： 全国地理机构的布局 新中国成立以后，地理学领域有许多明确的、国家急需解决的重大科技问题，这些重大任务为地理学的发展、尤其是填补地理研究的空白领域，提供了广阔的空间。中国地理学空白领域的创建和学科体系的完善，大多是在各种国家任务的推动下、在国家强有力的经费支持和组织保障下发展起来的。 开拓新的方向，为地理学体制化奠定基础 中国地理学家不但注重地理研究机构的地域布局、推动新兴研究领域，而且从中国的国情出发，促进学科的合理布局。因此除了支持建立研究机构外，还努力推动地理学研究中的一些重要方向，为其后的体制化建设奠定了基础。 自然区划的研究 中国是幅员辽阔的国家，产生了无数关于自然区划的研究。比如黑河—腾冲线、秦岭淮河一线、中国主要的的农业区划等等 研究手段的革新 中国的遥感事业就一直蒸蒸日上，空间分析方法在各种预报、预测和发展研究领域中得到了广泛应用，成立了特别多的遥感和地理信息系统公司 3. 结合自己的专业（GIS），阐述对地理学思想的认识 地理信息科学应作为新时代地理学的出风口 ​ “要使地理研究为年轻一代所吸引，一个强有力的方法就在于清楚的表明它对于解决重要问题时能做出什么样的贡献。抽象的概念需要结合实际的应用；不掌握这一点，就会使地理工作陷入无足轻重的境地” —— 地理学思想史 ​ 地理信息科学(Geographical Information Science, GIScience)是信息地理学的重要分支之一，在技术和工具层面, 地理信息系统(Geographical Information System, GIS)是地理信息科学研究成果的具体实现, 它在信息技术支持下, 对地理空间数据进行采集、管理、 分析、表达. 地理信息系统遵循数据、信息、知识、 智慧的递进层次体系, 构建了地理空间模拟、预测、 优化等一系列方法。这些方法有助于研究揭示地理现 象和要素的分布形态、相互作用、动态演化和驱动机 理, 从而服务于空间决策支持。但是在地理学严重空心化的大环境下，地理学处于一个很尴尬的地位，地理信息科学在新时代的地理学中处于什么样的地位？地理信息科学到底是地理学的核心还是外缘？信息时代的地理学又该何去何从？ 尴尬的GIS ​ 从Goodchild（1992）提出了地理信息科学的概念，到现在已经有人称地理信息技术（GIS）是20世纪最伟大的地理技术发明。在地理学的历史上，没有任何其他技术发明能够像GIS这样产生如此深远的社会影响。GIS（及其他信息技术）对地理学的影响非常大。随着时间的推移，GIS技术还将以新的创新方式和发展模式继续发展，带来新的应用模式。这将使得GIS走进千家万户，在社会产生巨大影响。GIS是地理学与信息技术（IT）的交叉学科。它既是地理学不可分割的一部分，也是IT技术的重要分支。GIS的两大基础是地理学和信息技术。地理学为GIS提供地理信息的挖掘应用，从表面上看地理学对GIS的发展作用很小，GIS推动地理学发展。信息技术促进GIS的发展，信息技术的每一个进步都影响着GIS技术的变革。然而事实真是如此吗？ ​ 刚学GIS的时候，看到有人说GIS是个朝阳产业，但是它永远都到不了正午。这自然是一句调侃，但也无不包含着GISer的心酸，因为GIS的定义，很多在学校和行业里学习摸爬了很多年的人也未必说得上来，进而它的作用自然也就变得模糊了起来。GIS在发达国家亦不算是一门成熟的学科，更不用提在国内，很多学校甚至将测绘、地质等很多内容也放在GIS专业的课程设置之中，过于宽泛的学习反而丢失了对深度探索的可能。 ​ GIS 的应用可以说已经融入到了各行各业，我们也在和各种部门，比如国土局、水利局、林业局、环保局等等各种部门在合作。然而尴尬的是看一看这些各种单位历年事业单位招聘却发现，国土局更愿意招学土地的，水利局更愿意招学水利的，林业局更愿意招学林业的，环保局更愿意招学环保的。唯一点名要gis的事业单位是国家测绘与地理信息局。而一般的社会公司需求最多的是 GIS 开发人员，引用百度百科的一句话，目前GIS软件开发工程师是稀缺人才。目前国内GIS大公司比如百度、腾讯、高德，国际大公司比如谷歌和ESRI。但是这些公司的所谓GIS也是仅仅停留在地图与导航阶段，外加一些“附近”服务。也许“ESRI的地理信息系统”为美国政府决策起了一些作用，但是在中国尚未听说过。近两年数字城市、智慧城市、物联网非常火，其中少不了GIS的身影。 正确的理解地理学和地理信息 ​ 其实大多数人对地理这门学科的认知是有局限的，认为地理只是研究山川湖泊地形地貌，甚至分不清地质学和地理学的区别，认为地理学家整日需要风吹日晒地研究石头的成分。当然更多的人是一听说你学地理，就找个偏门的国家问问你首都是哪个城市。这种认知局限也限制了地理学潜在的可能性。其实，地图、区划等是地理学的基础，所有的信息都依靠这些基础建立联系，这种联系得以建立的原则就是——每一个事物都影响其他的事物，但是对距离近的事物影响更大。位置影响自然环境和人文环境，进而影响人类的活动。所以地理这门学科本身，虽然听上去是一个学科，但其内容却涉及社会学（城市化、人口、住房、种族）、政治（国际关系）、环境科学（水资源利用与保护、野生动物保护）甚至是医疗和法律。地理学以位置为基础，将与我们生活息息相关的所有部分串联起来，找到其中的关联，再用这种关联去解决问题。因此，地理信息并不只是某座山的海拔或是某条河的冰期，而是所有带有位置标签的信息。 ​ 拿美国管理得比较出色的普查数据（Census Data）作为例子，普查会将美国划分为小的普查区（Census Tracks）或者街区群（Block Groups），这里的普查区和街区群就是地理标签，对于每个地理标签，数据库中会详细记录该标签下的实际信息，比如收入的中位数等。 ​ 所以，做一个合格的GISer的基础，不是扎实的编程功底，也不是丰富的统计知识，而是对于地理信息的深刻理解和对空间的思考能力。习惯性地将信息和数据中所包含的地理标签带进思考过程之中，并利用地理上的关联来解决问题，是一个GISer与软件工程师、统计师、历史学家或是社会学家最大的区别。GIS的重点不在开发，也不是统计，更不是简单的制图和可视化，这些只是达成GIS的工具，而是空间思维、空间数据和空间分析才是GIS真正的核心。个人觉得GIS最大的价值在于将地理学的价值运用于商业、生产与流通、日常生活、政策实践等行业中，让社会与个人更好地认知地理信息所带来的决策与理解价值，由此进一步激发传统地理学发展动力。 地理学的“经世致用” ​ 目前, 地理信息科学已经和自然地理学、人文地理学一起, 成为地理学三大二级学科之一。在学科体系中, 地理信息科学具有独特的、不可或缺的地位, 主要体现在以下三个方面：1. 它为部门地理学研究提供数据整合和分析的方法和工具, 从而强调地理学作为观测性学科的性质；2. 为了达成上述目标, 需要研究地理学基础概念和规律的形式化, 通过体现“空间思维(spatial thinking)”, 强化地理学作为一个统一学科的理论基础; 3. 借助于信息系统的开发, 将地理学研究成果输出到其他领域, 产生知识溢出, 体现了地理学“经世致用”的特点。 图1. 地理信息科学在地理学中的学科地位 ​ 回顾地理学四大传统, 即空间分析传统、区域研究传统、人地关系传统和地球科学传统，地理信息科学研究更多传承了空间分析传统, 即关注地理现象的空间配置和相互作用的分布模式, 模式背后的一般性规律, 以及规律的空间可泛化性。地理信息科学是多学科交叉的产物, 它扮演了地理学与其他学科之间联系桥梁的角色。这种角色主要体现在数据和方法两个层面上。在数据上, 地理信息科学研究不同地理空间数据的生产、传输、表达机理, 构建数据质量和不确定性评估模型, 解决地理学研究中数据使用的问题. 因此, 它和测绘科学等学科存在着密切的联系, 后者通过研究地理空间数据的精确获取技术, 解决地理信息科学 的数据源问题。其中遥感、全球卫星导航系统等技术 的迅猛发展, 极大丰富了地理信息科学分析和研究的数据类型(如全球土地覆被数据、城市和建筑三维数据、个体粒度的轨迹数据等)。目前, 地理研究已经进入到大数据时代. 大数据不仅包含了人类大量地理知 识的长期累积, 同时也是新的技术手段支持下大范围地理现象和要素的存储和表达。. 在方法上, 地理信息科学也得益于信息科学与技术的快速发展. 后者已经改变了, 并且必将更为深刻地改变几乎所有学科的面貌。例如, 人工智能已经可以帮助科学家自动发现科学规律, 提取科学知识。纵观历史, 从单机到互联网, 再到移动互联网, 地理信息应用的形态在不断演化。如今, 信息科学与技术的发展等为地理信 息系统带来了新的机遇, 同时为地理信息科学提供了新的研究议题. 高性能计算提供了强大的分析模拟能力, 人工智能则提升了对复杂时空模式的理解能力。 结论 ​ 正如地理学思想史在80年代所说，要使地理研究为年轻一代所吸引，一个强有力的方法就在于清楚的表明它对于解决重要问题时能做出什么样的贡献。抽象的概念需要结合实际的应用；不掌握这一点，就会使地理工作陷入无足轻重的境地！然而这句话放到现在依然不过时，地理学从曾经到显学到现在“尴尬”的地位，GIS也一直是一个升不起的朝阳，这些事实不经让人唏嘘。但是面向未来，面向这个信息时代，地理信息科学作为地理学和信息技术结合最为紧密的方向，应该肩负起地理学复兴的重任，一方面要注重信息技术在向地理学迁移过程中的“本地化”, 另一方面, 也要促进地理信息科学成果向其他学科的溢出, 提升其普适性和影响力，真正的从经世致用的角度为社会，为国家服务。 "},"gis/人文地理学第二次作业_读书报告.html":{"url":"gis/人文地理学第二次作业_读书报告.html","title":"地理学方法论","keywords":"","body":"人文地理学第二次作业_读书报告 [toc] 1. 100 Years of Human Geography in the Annals 1.1 Abstract 人文地理学文章经历的阶段：环保方针、文化地理、“空间”科学，所有三种方法都采用区域的角度 20世纪70年代主要采用人道主义和马克思主义，区域和定量方法比较强劲 20世纪80年代，后结构主义出现 在过去二十年里，女权主义和反种族主义开始成为主体，以及经济和政治理论的加强 1.2 Content 1999年，人们选择了“人、地方、地域”三个概念来概括事物 从环境保护到区域，到空间系统，到人与人之间的相互作用，这是一个迂回前进的过程 二十世纪地理学的标志是“从世纪活动到强调认知需求，例如除了理解‘什么’ 和 ‘哪里’ 之外，还要研究‘为什么’和‘怎么样’。” 地理学家对经济、政治、社会和文化的过程的理解越来越复杂，这有助于解释世界上许多不同地区的人与地方之间的关系 2. 地理学的例外论 方法应该是在变化和进化中茁壮成长，但是地理学的方法有点墨守成规 包括人类在内的自然现象在空间的分布方式是地理学的主要关注点（区域地理学、系统地理学？），一个地区包含了一种特殊的但在某些方面却是统一的各类现象的组合，这些都是研究两类或两类以上选定现象之间的空间关系，但是目前对区域地理学和系统地理学的相对作用和重要性缺乏明确性，最主要的区别可能是系统地理学视图制定应用于区域地理学的区域和规律 历史和地理本质上都是对一个地方的记录，历史是记录时间上的现象，地理是记录空间上的现象，它们都是描述性的 从技术上讲，地理学的形态特征表现在其特有的工具——地图和制图的相关性上。 地图不是简单的一个描述 借助艺术符号制作的图画有意表现我们感兴趣的点，忽略不重要的差异 地图不仅描绘了空间上的各种特征，表达了它们之间的联系 制图相关性涉及比较地理学和类型学 地理规律可以分为三类 大多数的自然地理定律 经济地理定律 综合性系统性的定律 地理学应该更加强调系统性 3. 作为空间科学的地理学 空间科学包括天文学和地理学，我们现在可以加上地球物理学，这三组之间没有明显或绝对的界线，因为在许多的情况下，研究是重叠的，但在每个案例中，观点基本上是不同的 地理系统是所有有机体的总和，我们用自然系统的名称来命名它们 地理学的两位创始人都背弃了这位哲学家的地理著作，他们的思维都受经验主义知识观的支配，不信任自然哲学的演绎思维 新一代的地理学家从他们所受训练的领域中带来了这些概念，产生了地理二元论的双重形式。自然地理是一门构建和应用科学规律的自然科学，人文地理远离了物理基础 当地理学家用其他科学转移来的科学观念来考虑他们的主题时，都会忽略这个概念，只有当地理学家根据其自身的内在特征来考虑他们的课题时，它才会得到积极的回应 地理学的内在特征是人类努力认识和理解现象的产物，因为它们存在于人类师姐的区域相互关系中 地理没有一个特定类别的对象或现象作为它的具体研究对象，而是研究许多不同种类的事物作为区域的整体；地理学既不能呗归类为自然科学，也不能被简单的归类为社会科学 4. 人文地理学期刊分析 人文地理学是依托地理学基础发展起来与经济、社会发展有紧密联系的学科，是研究人类活动空间组织以及人类与环境关系的科学，主要研究各种认为现象的地理分布、扩散和变化，以及人类社会活动的地域结构的形成和发展规律 该 44 种人文地理学期刊的可以分为四个较为明显的聚类： 综合性期刊、文化地理学期刊和政治地理学期刊 经济地理学期刊和工业地理学期刊 环境地理学期刊 地理信息系统期刊 5. 人文地理学方法（第一部分） 第七章 结构化理论：能动性、结构与日常生活 走的人多了，也便成了路 结构化是为分析个人能动性与社会的构成提供了感性概念 吉登斯所发展的结构化理论,本质上认为社会既非脱离人类活动而独立存在,也不只是人类活动的产物。相反﹐结构化理论指出了社会生活内在的空间性。对于吉登斯来说,对秩序这一当时社会学核心问题的研究,并不是要发现社会生活的基本模式,而是关注社会系统如何在时间与空间中联系在一起，他认为宏观与微观、个人与社会、行动与结构、主观与客观双方都是相互包含的的 吉登斯将“结构”理解为不断卷入到社会关系的再生产过程之中的规则和资源，并且结构具有二重性，即社会结构不仅对人的行动具有制约作用，而且也是行动得以进行的前提和中介，它使行动成为可能。行动者的行动既维持着结构，也改变着结构。行动与结构之间中这种相互依赖、互为辩证的关系反映在处于时空之中的社会实践中 马克思曾说过：“人们自己创造自己的历史，但是他们并不是随心所欲的创造，并不是他们自己选定的条件下创造，而是再直接碰到的、既定的、从过去继承下来的条件创造”。吉登斯的结构化理论正是对马克思这句名言的深刻反思，并且做出了思考和发挥。但是吉登斯夸大了实践主体的能动性，否认了物质生产实践在社会构成中的重要地位和作用，因此吉登斯的实践观存在根本的缺陷 人是能动性，路是结构，人和路构成了社会实践，路的可能存在是人行动的前提，人也因此可以走出更为捷径的路 第八章 实在论作为认识世界的基础 文章本天成，妙手偶得之 实在论要求用一种“实在的”眼光来看待这个世界。实在论哲学最基本的理念是,世界无论是什么样子,很大程度上都不依赖特定的观察者对它的看法,它不是简单地来自于人类的思维。人们过去习惯于认为地球是的,但是当他们开始意识到它是圆的时候,我们不会认为地球在这一过程中也发生着变化。地球的形状不受我们对它的看法的影响。同时,我们关于世界的思想往往以很多种不同的看题的方式被建构起来——感知图式,概念和理论。我们不能超越这些来直接且如实地看待个世界,因为我们需要诸如图式一类的东西来观察、来思考。所以,这个世界的存在很大程度上不依赖于我们对于这个世界的知识的掌握程度,但是我们对于世界的描述显然也依靠了们可用的知识。我们往往通过可用的话语来解释世界,但是,就像各种关于地球形状的论述-样，这些话语在理解地球形状的程度上存在很大差异。 长城啊，真他妈的长；不到长城非好汉 第九章 后现代地理学和现代性的毁灭 无厘头（九品芝麻官，把歪的水管骂直了） 后现代主义（Postmodernism）是一场发生于欧美60年代，并于70与80年代流行于西方的艺术、社会文化与哲学思潮。其要旨在于放弃现代性的基本前提及其规范内容。在后现代主义艺术中，这种放弃表现在拒绝现代主义艺术作为一个分化了文化领域的自主价值，并且拒绝现代主义的形式限定原则与党派原则。其本质是一种知性上的反理性主义、道德上的犬儒主义和感性上的快乐主义。 后现代主义是一个处于不断变动的难以把握的概念，渗透到当代社会的方方面面。后现代主义对人文地理学发展产生了深刻的影响，对科学技术与理性的反动导致非理性主义的泛滥 崇尚天马行空的想象力，但是科学应该是真实的 第十章 后结构主义者的理论 盲人摸象 摸到大象腿的盲人说：“大象就像一根大柱子！” 摸到大象鼻子的忙说：“不对， 不对，大象又粗又长，就像一条巨大的蟒蛇。” 摸到大象耳朵的人急急地打断，忙着说：“ 你们说的都不对，大象又光又滑，就像一把扇子。” 摸到大象身体的人也说：“大象明明又厚又大， 就像一堵墙嘛。” 最后，抓到象尾巴的人慢条斯理地说：“你们都错了！依我看，大象又细又长，活像一根绳子。” 后结构主义是 20 世纪一系列关于语言和表征的思潮，并且极大地影响了人文学科，尤其在文学批评领域，后结构领域的核心就是 “意义链” 后结构主义是对于简明主义的怀疑，为何要对证实、表达和真理设定特定的假设条件，其本质是什么。在阅读抽象的哲学文本时，当我们强行的插入了我们称之为具体的实例时，我们会感到一种解脱，这时候我们以为我们终于明白了，但是实际上，我们却是离理解更远了，就好比盲人摸象 人类对历史上的“象”又真正了解多少呢，化石的新发现会不会又促发一种新的理解 第十一章 行动者——网络理论、网络和关系方法在人文地理学中的应用 一个人拿一把枪杀了人，那么是“枪杀人”，还是“人杀人”呢？ 行动者——网络理论起源于研究科学和技术的社会学，它旨在揭示和最终诸多人类、非人类、具体、抽象行动者之间的联系和关系，而正是这些行动者使得特定的行为、事件和过程能够顺利进行。 行动者——网络理论把行动者和能动性区分开来，行动者描述为行动元，它利用关系网络中行动元的无数联系来解释世界 地理学家将行动者——网络理论引入他们的研究中，使它成为今天的相关性思想中最为复杂的理论之一，它突破地理学中的二元思维具有重要意义。地理学者对行动者——网络理论主要围绕社会解释与网络解释、传统批判的合法性、人与非人对称的真实性与有效性等方面展开 当一个人手上有一把枪，并用它来杀人时，人变成“凶手”，枪变成了“凶器”，受害者从人变成“尸体”，这便是角色的转译（translation），有被动也有主动。“杀人”行为，既不只是枪手意图的结果，也不只是枪开火的结果，而是两者联结成的行动网络的作用结果，人和枪都是行动者。 第十二章 后殖民主义：空间、文本性和权力 美国的空气更加新鲜 后殖民主义是1970至1980年代产生的一种思潮和学术理论，主要目的是反思殖民主义，特别强调文化、知识领域内对殖民主义、新殖民主义、西方中心主义等现象的反思与批判。后殖民主义者认为，因为殖民主义等历史原因，现代文化被西方文化所垄断。非西方文化想要被世界接纳、现代化，就必须采用西方的语言、文化、思想，因此依然深受殖民主义的压迫。后殖民主义强调殖民不仅仅包含经济剥削和政治服从，还包含对被殖民人口施以文化的力量，这种力量被殖民势力用来贬低非西方文化传统，同时赞颂西方文化观点独特的优越性。 那么怎么精确地描述不熟悉的文化和社会？特别要强调的是,后殖民主义不能被简单地理解为是对现代人文文化普遍愿景的简单的全盘否定。就大部分而言,如赛义德和斯皮瓦克等学者批判了西方传统没有能够用恰当,和谐的交流方式去发展真正的多元普遍主义(pluralist universalism),这些交流的方式中会包括一种理念,即去借鉴理解世界的其他方式,包容其他的认知手段。 认为说了对方就能明白，这是一种傲慢。从纬度的角度上来说，美国的月亮的确更大更圆 "},"languages/Go.html":{"url":"languages/Go.html","title":"Go","keywords":"","body":"Go [toc] 菜鸟 基础 go 语言特色： 内存管理、数组安全、编译迅速 go 语言被设计成一门应用于搭载 Web 服务器，存储集群或类似用途的巨型中央服务器的系统编程语言 对于高性能分布式系统领域而言， go 语言有着更高的开发效率，它提供了海量并行的支持 go 语言结构： 包声明 引入包 函数 变量 语句&表达式 注释 当标识符（包括常量、变量、类型、函数名、结构字段等等）以一个大写字母开头，那么使用这种形式的标识符的对象就可以被外部包的代码所使用，如果该标识符是以小写字母开头，则对包外是不可见的 fmt.Sprintf 格式化字符串并赋值给新串 声明变量的一般形式是使用 var 关键字 变量没有初始化就会设置为 0 值 fmt.Println 和 fmt.Printf 是不一样的 := 是一个声明变量 intVal := 1 声明一个局部变量必须要使用， 声明的全局变量可以不使用 常量的定义格式 const b = \"abc\" or const b string = \"abc\" 常量可以做枚举： const( Unknown = 0 Fmale = 1 Male = 2 ) 常量可以用 len(), cap(), unsafe.Sizeof() 函数计算表达式 iota，特殊常量，可以认为是一个可以被编译器修改的常量 "},"languages/Java.html":{"url":"languages/Java.html","title":"Java","keywords":"","body":"[toc] java_temp temp java 中String直接赋值字符串和new String的区别， == 为false，equals结果为true，如果放在同一个hash中只能放一个 String A = \"abc\" 会在常量池子中找是否已经有了，如果没有它就会重新开辟一片空间，然后所有这么赋值的地址其实都是相同的 String str = new String(\"abc\") 这么赋值的是再次构造一个String对象，从堆中重新new一块内存，再把指针赋给栈，==是判断地址，则明显会不相同的 data method 现在的编辑的bug：打开编辑页面没有把数据读出来，detail框有问题 http 错误 2xx 成功 200 正常；请求已完成。 201 正常；紧接 POST 命令。 202 正常；已接受用于处理，但处理尚未完成。 203 正常；部分信息 — 返回的信息只是一部分。 204 正常；无响应 — 已接收请求，但不存在要回送的信息。 3xx 重定向 301 已移动 — 请求的数据具有新的位置且更改是永久的。 302 已找到 — 请求的数据临时具有不同 URI。 303 请参阅其它 — 可在另一 URI 下找到对请求的响应，且应使用 GET 方法检索此响应。 304 未修改 — 未按预期修改文档。 305 使用代理 — 必须通过位置字段中提供的代理来访问请求的资源。 306 未使用 — 不再使用；保留此代码以便将来使用。 4xx 客户机中出现的错误 400 错误请求 — 请求中有语法问题，或不能满足请求。 401 未授权 — 未授权客户机访问数据。 402 需要付款 — 表示计费系统已有效。 403 禁止 — 即使有授权也不需要访问。 404 找不到 — 服务器找不到给定的资源；文档不存在。 407 代理认证请求 — 客户机首先必须使用代理认证自身。 415 介质类型不受支持 — 服务器拒绝服务请求，因为不支持请求实体的格式。 5xx 服务器中出现的错误 500 内部错误 — 因为意外情况，服务器不能完成请求。 501 未执行 — 服务器不支持请求的工具。 502 错误网关 — 服务器接收到来自上游服务器的无效响应。 503 无法获得服务 — 由于临时过载或维护，服务器无法处理请求。 Tomcat 简单概念网址：Tomcat Tomcat 简单的说是一个运行 Java 的网络服务器，底层是 Socket 的一个程序，它也是 JSP 和 Serlvet 的一个容器 axios axios 是一个基于 promise 的 HTTP库，简单的讲就是可以发送get、post请求，因为Vue等框架，不需要操作Dom了，所以不需要引入Jquery.js 了？所以一些轻量级库的就跟着出现了 mongo导出与备份 mongo4.4 版本之后，mongodb数据库工具与现在的mongodb服务分开发布，需要单独安装 快速导出接口文档 怎么用Java快速生成接口文档 方案： 使用 japidocs swagger + knife4j 开源接口文档生成工具 前言 常常在项目收尾阶段，客户需要项目的接口文档，或则是一个大的sass平台，各个产品之间互相调用的时候，需要对方提供接口文档。通常来说，接口文档属于产品的技术沉淀，是一个长期积累的过程，然后开发阶段并不会想这么多，结果到了需要接口文档的时候总是疲于应付，情急之下，往往采用最笨拙的方法，就是对照着项目代码一个一个拷贝 该文提供了几种方法的策略 JapiDocs 这是一种最简单也最高效的快速生成接口文档的方式，也是对既有项目改造代价最小的方式 可用于生成spring boot api文档 读取JAVA DOC注释，无需额外的代码改造 使用步骤原文已经很清楚了 添加依赖 添加一个类，并写一些代码，运行 swagger + knife4j swagger 很出名的一个插件，用以快速进行接口调试，但是单纯使用swagger的效果并不理想（如导出文档这一块），这时候都会配合 knife4j 使用 步骤： 导入依赖 添加 swagger 配置类 访问接口页面 开源方案 japi ApiPost 工具 Java 版本 JDK的版本号解惑 Java 与 jdk 的区别： 在用户眼中，Java 是 Java 应用，在程序员眼中，jdk 是Java 开发工具，所以 jdk 等价于 Java jdk 8 与 jdk 1.8 的区别和联系：jdk 8 或者 jdk 1.8 是由于自从 jdk1.5/jdk5 命名方式改变后遗留的新旧命名方式问题，所以 jdk 8 或者 jdk 1.8 也是同一个东西 "},"languages/JavaScript.html":{"url":"languages/JavaScript.html","title":"JavaScript","keywords":"","body":"JavaScript_temp [toc] 如果在数学表达式中有一个NaN，那么它会一直传播下去 脚本永远不会因为一个致命错误就停止，大不了一个NaN alert prompt confirm 显示的转为字符串 String(value) 隐式的转为字符串 alert(value) 对undefined进行数字转换时候，结果为NaN，而不是0 比较的时候注意是否发生了类型转换 除了严格相等 === 外，其他但凡是有 undefined/null 参与的比较，我们都需要格外小心。 除非你非常清楚自己在做什么，否则永远不要使用 >= > 去比较一个可能为 null/undefined 的变量。对于取值可能是 null/undefined 的变量，请按需要分别检查它的取值情况。 '2' > '12' true js 的 || 能够返回第一个真值或者最后一个假值 两个非运算 !! 有时候用来将某个值转化为布尔类型 labelName 空值的 return 或没有 return 的函数返回值为 undefined 一个函数应该简短且只有一个功能 在其他编程语言中，只要提到函数的名称都会导致函数的调用执行，但 JavaScript 可不是这样。 回调其实就是传递了一个函数变量？ 一个函数是表示一个“行为”的值 一个函数代表一个行为，我们可以在变量之间传递它 函数声明是在js准备脚本阶段创建的，所以可以在任何位置使用它 箭头函数对于简单行为来说很方便 自动分号插入，有些时候它并不自动插入，代码块之后不需要分号 自描述型代码 $event 计算属性 方括号[] 属性名简写 对象能够访问任何属性，即使该属性不存在也不会报错 一般用in 来判断一个属性是否存在一个对象中，而不是undefined 赋值了对象的变量存储的不是对象本身，而是该对象'在内存中的地址'，换句话说就是对该对象的引用 仅当两个对象为同一对象的时候，它们才叫相等 Object.assign(dest, [src1, src2, src3...]) 深层克隆指的是对象里面的对象也拷贝过去 垃圾回收机制，可达性 对象属性的函数称为方法 在js中，this关键字和其它多数编程语言不同，js中的this可以用于任何函数，即使他不是对象的方法，this的值是在代码运行时计算出来的 this的并不取决于方法声明的位置，而是取决于点符号前的是什么对象（this的重要性就是c里面的指针 箭头函数没有自己的this，它取决于外部的正常函数 this通过函数调用才有意义 理解 this： this 永远指向一个对象 this的指向完全取决于函数调用的位置 js 中一切都是对象，运行环境也是一个对象，所以函数实在某个对象下运行，而this就是函数运行时的所在的对象（环境），但是js支持环境的动态切换，简单的说就是 this 的指向是动态的，很难事先确定到底指向哪里 事件绑定：行内绑定，动态绑定，事件监听 构造函数以大写字母开头，只能有'new' 操作符来执行 当一个函数使用new操作符执行时，它按照步骤为：一个新的对象被创建并分配给this；函数体执行，通常它会修改this，为其添加新的属性；返回this的值。隐式创建，隐式返回 可选链 ？. 使用在一些属性可以不存在的地方 symbol 类型 symbol不会被自动转为字符串 对象的属性键只能是字符串类型或则symbol类型，symbol类型可以防止被重写 symbol属性不参与for...in循环 除null 和 undefined 以外的原始类型都提供了许多有用的方法，从形式来说这些方法通过临时对象工作 Math.floor Math.ceil Math.round 编写一个随机整数的函数，容易边缘值的概率会低两倍 js中字符串不可更改 str.indexOf() 更现代的方法是 str.includes(substr, pos) str.startsWith(str) str.endsWith(str) str.slice(start [,end]) str.substr(start, [, length]) 对象能够存储键值集合，但是有些时候我们需要存储有序集合，这时候就到了数组了 数组可以存储任何类型的元素 pop push shift unshift 从本质上来说，数组仍然是一个对象 将数组视为有序数据的特殊结构 for... in 循环会遍历所有数组所有属性，不仅仅是这些数字属性 类数组对象 不应该用 for ... in 处理数组 我们修改数组的时候，length 属性会自动更新 数组通常都是使用方括号 数组有自己的 toString 实现，返回已逗号隔开的元素列表 不要使用 == 比较数组 仅当两个对象引用的是同一个对象的时候，它们才相等，如果==左右两个参数中有一个参数是对象，另一个参数是原始类型，那么该对象就会转换为原始类型 === 不会进行类型转换 如果我们使用 == 比较数组，除非它们两个引用了统一数组的变量，否则它们永远不相等，要用迭代的方法逐项的比较它们 遍历数组的元素： for( let i=0; i for ( let item of arr) 现代语法，只能访问items for (let i in arr) 永远不要用这个 传入call 和 apply 的第一个参数都会被看作函数上下文，不同之处在于后续的参数 箭头函数的this与声明所在的上下文相同 调用箭头函数时，不会隐式的传入this参数，而是从定义时的函数继承上下文 所有函数都可以访问bind方法， 可以创建并返回一个新函数，并绑定到传入的对象上，调用bind不会修改原函数，而是创建了一个全新的函数 this 表示函数上下文， 即与函数调用相关联的对象，函数的定义方式和调用方式决定了this的取值 函数的调用方式有四种： 作为函数调用 skulk() 作为方法调用 ele.skulk() 作为构造函数调用 new Skulk() 通过apply 和 call方法调用 skulk.apply(ele) skulk.call(ele) 函数调用方式影响this的取值： 如果作为函数调用，非严格模式下指向window对象， 严格模式下指向undefined 作为方法调用，this通常指向调用的对象 作为构造函数调用，this指向新创建的值 通过call 或 apply 调用，this 指向 call 或 apply 的第一个参数 箭头函数和bind某些时候都是绑定的感觉 闭包允许函数访问并操作函数外部的变量，只要函数或变量存在于声明函数时的作用域内，闭包即可使函数能够访问这些变量和函数 function getMaxSubSum(arr) { let maxSum = 0; let partialSum = 0; for (let item of arr) { partialSum += item maxSum = Math.max(maxSum, partialSum) if(partialSum arr.splice 方法可以说是处理数组的瑞士军刀 arr.slice 复制一部分值 arr.concat 连接多个数组 arr.forEach 方法允许为数组的每一个元素都运行一个函数 arr.indexOf、arr.lastIndexOf 和 arr.includes 方法与字符串操作具有相同的语法，并且作用基本上也与字符串的方法相同 如果是一个对象数组，可以用 arr.find() 方法找到具有特定条件的对象 同理有 arr.findIndex 和 arr.filter arr.map 方法对数组中的每个元素都调用函数，并返回结果数组，该方法和forEach 很像，但是forEach 并不返回结果数组，这两个应该是最常用的方法了 arr.sort() 方法对数组进行 原位(in-place) 排序，更改元素的顺序，但是默认情况下是按字符串进行排序了，所以一般要使用我们自己的函数进行排序 对于字符串比较算法，最好是使用 str.localeCompare 方法正确的对字母进行排序 arr.split 与 arr.join 恰好相反 arr.reduce 根据数组计算单个值 Array.isArray thisArg 也可以采用箭头函数 sort，reverse 和 splice 方法修改的是数组本身。 let prices = { banana: 1, orange: 2, meat: 4, }; let doublePrices = Object.fromEntries( // 转换为数组，之后使用 map 方法，然后通过 fromEntries 再转回到对象 Object.entries(prices).map(([key, value]) => [key, value * 2]) ); 可以通过这种方式建立强大的转换链, Object.keys, values, entries function count(obj) { return Object.keys(obj).length; } JS中最常用的两种数据结构是Object 和 Array， 对象能让我们创建键来存储数据项的单个实体， 数组则让我们能够将数据收集到一个有序的集合中，但是，当我们把它们传递给函数时， 函数可能只需要单个块 let [firstName, surname] = \"Ilya Kantor\".split(' '); 解构并不意味着破坏 let user = { name: \"John\", age: 30 }; // 循环遍历键—值对 for (let [key, value] of Object.entries(user)) { alert(`${key}:${value}`); // name:John, then age:30 } 内建对象： 日期（Date），该对象提供了日期/时间的管理方法 JS 提供了如下方法 JSON.stringify 将对象转换为JSON, JSON.parse 将 JSON 转换回对象 一些特定于 JS 的对象属性会被JSON.stringify 跳过，即：函数属性、 Symbol类型的属性、存储undefined的属性 JSON.stringify(user, null, 2) // 首行缩进 2 个字符 let str = '{\"title\":\"Conference\",\"date\":\"2017-11-30T12:00:00.000Z\"}'; let meetup = JSON.parse(str, function(key, value) { if (key == 'date') return new Date(value); return value; }); alert( meetup.date.getDate() ); // 现在正常运行了！ 函数进阶内容 所有函数的处理都是这样的： 当前上下文被记录在堆栈的顶部 为子调用创建一个新的上下文 当子调用结束后，前一个的上下文从堆栈中弹出，并继续执行 递归使用的时候要考虑堆栈的深度 Rest 参数必须放到参数列表的末尾 arguments是一个类数组 箭头函数是没有arguments的 spread语法可以传递多个可迭代对象，可以用来合并数组，和Array.from() 很像，但是后者还可以用来操作类数组 在 JS 中，每个运行的函数，代码块以及整个脚本都有一个成为词法环境(Lexical Environment) 的内部隐藏的关联对象 词法环境由两部分组成： 环境记录(Environment Record)：一个存储所有局部变量作为其属性的对象 对外部词法环境的引用，与外部代码相关联 变量是特殊内部对象的属性，与当前正在执行的块/函数/脚本有关，操作变量实际上是操作该对象的属性 当代码要访问一个变量是，首先回搜索内部词法环境，然后搜索外部环境，然后搜索更外部的环境，直到全局词法环境 在JS中，所有函数都是天生闭包的，闭包就是指内部函数总是可以访问所在的外部函数中声明的变量和参数 词法环境仅在可达时才会保留在内存中 debugger 理论上当函数可达时，它外部变量也都将存在，但在时间中，JS引擎会试图优化它，如果从代码中可以明显看出所有未使用的外部变量，那么就会将它删除，此类变量在调试中将不可用 从程序进入代码块的那一刻开始，变量就开始进入“未初始化”状态，它一直保持未初始化状态，直至程序执行到相应的let语句 var 没有块级作用域，用var声明的变量，不是函数作用域就是全局作用域，var 的变量可以重新声明，可以在声明前被使用，声明会提升，但是赋值不会 (function{...})，立即调用函数声明，但是如今没有理由这么来编写代码 全局对象，浏览器中是 'window' ， 对 Node.js 而言，它的名字是 'global' ，最近 globalThis 被作为全局对象的标准名称加入了JS 全局对象的所有属性都可以直接访问 在浏览器中，使用var 声明的全局函数和变量会变成全局对象的属性 把函数想成一个可被调用的行为对象，我们不仅可以调用它们，还能把它当作对象来处理，函数对象包含一些便于使用的属性 name length 函数也可以添加属性，然后用于闭包 给函数表达式添加名字，可以在局部词法环境中添加一个函数，这样可以以防外面的被更改掉，当我们需要一个可靠的内部名时，就可以吧函数声明写成函数表达式 函数名后面跟着多个括号，为了函数能够正常工作，需要是函数的结果也是一个函数 function makeCounter() { let count = 0; function counter() { return count++; } counter.set = value => count = value; counter.decrease = () => count--; return counter; } function sum(a) { let currentSum = a; function f(b) { currentSum += b; return f; } f.toString = function() { return currentSum; }; return f; } js的函数变量是真的好用啊 \"new Function\" 很少被使用，但是有些时候只能选择它，它允许我们将任意字符串变为函数，这样我们就可以从服务器接受一个新的函数并执行它，只有这种从服务器动态的创建函数的情况可能才会使用到这个语法 通常，闭包是指使用一个特殊的属性 [[Environment]] 来记录函数自身创建时的环境的函数，它具体指向了函数创建时的词法环境 setTimeout 允许我们将函数推迟到一段时间间隔之后再执行 setInterval 允许我们重复运行一个函数，从一段时间间隔之后开始运行，之后以一个时间间隔重复运行 clearTimeout clearInterval let delay = 5000 let timerId = setTimeout(function request(){ ... if(request failen due to server overload){ delay *= 2 } timerId = setTimeout(request, delay); // 感觉这就是递归了 }, delay) 嵌套的setTimeout 能够精确的设置两次执行之间的延时， 而 setInterval 却不能 function slow(x) { // 这里可能会有重负载的 CPU 密集型工作 alert(`Called with ${x}`); return x; } function cachingDecorator(func) { let cache = new Map(); return function(x) { if (cache.has(x)) { // 如果缓存中有对应的结果 return cache.get(x); // 从缓存中读取结果 } let result = func(x); // 否则就调用 func cache.set(x, result); // 然后将结果缓存（记住）下来 return result; }; } 一旦方法被传递到与对象分开的某个地方，this就丢失 setTimeout 方法的函数调用设定了 this = window 这个需求很典型：我们想将一个对象方法传递到别的地方，然后再该位置调用它，如何确保在正确的上下文中调用它 setTimeout(user.sayHi, 1000); // Hello, undefined! setTimeout(() => user.sayHi(), 1000); // Hello, John! 最简单的解决方案是使用一个包装函数，看起来不错，如果在setTimeout触发前一秒user的值有改变的话就错误了 第二种解决方案是内建方法 bind, 它可以绑定this let boundFunc = func.bind(context) func.bind(context) 的结果是一个特殊的类似于函数的\"外来对象\"，它可以像函数一样被调用，并且透明地将调用传递给func并将this=context 如果一个函数有多个方法，可以使用bindAll 我们不仅可以绑定this，还可以绑定参数（arguments），但是很少这么做 一个函数不能重绑定 bind之后，函数会丢失原来的函数属性 bind 和 包装都可以解决一样的问题，但是包装可能在一些复杂的场景下失效 function askPassword(ok, fail) { let password = prompt(\"Password?\", ''); if (password == \"rockstar\") ok(); else fail(); } let user = { name: 'John', login(result) { alert( this.name + (result ? ' logged in' : ' failed to log in') ); } }; askPassword(()=>user.login(true), ()=>user.login(false)) askPassword(user.login.bind(user, true), user.login.bind(user, false)) 箭头函数不仅是简洁代码，它还具有一些特性 JS 的精髓在于创建一个函数并将其传递到某个地方，在这样的函数中，我们通常不想离开当前上下文，这就是i箭头函数的主战场 .bind(this) 会创建一个该函数的\"绑定版本\"，箭头函数没有创建任何绑定，箭头函数只是没有this，this的查找与常规变量的搜索方式完全相同：在外部词法环境中查找 对象可以存储属性，但是目前的属性对我来说只是简单的\"键值对\"，但是实际上属性是更灵活和强大的东西 对象属性除了value，还有三个特殊的特性：writable、 enumerable、 configurable getOwnPropertyDescriptor defindeProperty defineProperties 除了数据属性，还有访问器属性，它们本质上是用于获取和设置值的函数 let user = { name: \"John\", surname: \"Smith\", get fullName() { return `${this.name} ${this.surname}`; } }; alert(user.fullName); // John Smith 从外表看，访问器属性看起来就是普通属性，这就是访问器属性的设计思想 let user = { name: \"John\", surname: \"Smith\", get fullName() { return `${this.name} ${this.surname}`; }, set fullName(value) { [this.name, this.surname] = value.split(\" \"); } }; // set fullName 将以给定值执行 user.fullName = \"Alice Cooper\"; alert(user.name); // Alice alert(user.surname); // Cooper 现在我们有了一个虚拟属性，而且他是可读可写的 访问器属性没有 value 和 writable， 但是有 get 和 set 函数 Getter/Setter 可以用作”真实“属性值的包装其，以便进行更多的控制，如我们可以设置命名的时候判断name是不是太短 function User(name, birthday) { this.name = name; this.birthday = birthday; // 年龄是根据当前日期和生日计算得出的 Object.defineProperty(this, \"age\", { get() { let todayYear = new Date().getFullYear(); return todayYear - this.birthday.getFullYear(); } }); } let john = new User(\"John\", new Date(1992, 6, 1)); alert( john.birthday ); // birthday 是可访问的 alert( john.age ); // ……age 也是可访问的 在编程中我们经常会像获取并扩展一些东西，原型继承(Prototypal inheritance) 这个语言特性能够帮助我们实现这一个需求 在 JS中，对象有一个特殊的隐藏属性 [[Prototype]] ，它要么为 null，要么就是对另一个对象的引用，该对象被称为原型 当我们从 object中读取一个缺失的属性时，JS会自动从原型中获取该属性，在编程中，这种行为被称为原型继承 rabbit.__proto__ = animal 这种感觉和闭包有点像啊，都是继承的关系 原型继承有两个限制 引用不能形成闭环 __proto__的值可以是对象，也可以是 null ，而其它类型会被忽略 __proto__ 是 [[Prototype]]不一样 写入不适用原型，原型仅用于读取属性，访问器属性是一个例外，因为分配操作是由setter函数处理的，因此，写入此类属性实际上与调用函数相同 无论在哪里找到方法，在一个对象还是在原型中，在一个方法调用中，this始终是 . 前面的对象 for ... in 循环也会迭代继承的属性 属性查找和执行是两回事，先从原型中找到属性，然后给当前的this 执行 所有描述特定对象状态的属性，都应该被写入改对象中，这样可以避免一些问题 Obejct.create(proto, [descriptors]) Object.getPrototypeOf(obj) Object.setPrototypeOf(obj, proto) 类的方法之间没有逗号，在JavaScript中，类也是一种函数，准确的说是构造方法 有些人说class是一种语法糖，但是仍有一些区别，首先通过从class创建的函数具有特殊的内部属性标记，类的方法不能枚举，类定义将“prototype”中的所有方法的enumerable标志设置为false，类里面总是使用 use strict 静态方法不是某个特定的方法，而是整个class的方法，可用于搜索/保存/删除，静态属性同理 静态属性和方法是可被继承的 在面向对象中，属性和方法分为两组： 内部接口：可以通过该类的其它方法访问，但不能从外部访问的方法和属性 外部接口：可以从类的外部访问的属性和方法 受保护的属性通常以下划线_作为前缀 内建的方法也是返回的扩展内建类 类检查 instanceof 操作符用于检查一个对象是否属于某个特定的class 要使 try ... catch 能工作，代码必须是可执行的 try ... catch 同步工作，如setTimeout 如果我们不需要 error 的详细信息， catch 可以忽略它 throw 操作符会生成一个 error 对象 try ... catch ... finally function loadScript(src, callback){ let script = document.createElement('script') script.src = src script.onload = () => callback(script) document.head.append(script) } loadScript('/my/test.js', function(){newFunction()}) 这被称为”基于回调“的异步编程风格，异步执行某项功能的函数应该提供一个callback 参数用于在相应事件完成是调用 let promise = new Promise(function(resolve, reject){ // executer }) promise 我感觉和 setTimeOut 的区别就是区分的了成功和失败，成功了就 resolve， 失败了就 reject let promise = new Promise(function(resolve, reject) { setTimeout(() => reject(new Error(\"Whoops!\")), 1000); }); // reject 运行 .then 中的第二个函数 promise.then( result => alert(result), // 不运行 error => alert(error) // 1 秒后显示 \"Error: Whoops!\" ); promise.then(alert); // 只对成功感兴趣 promise.catch(alert); // 只对失败感兴趣 promise 基于回调的模式的一些好处： promise 允许我们按照自然顺序进行编码，首先允许函数然后利用 .then 来处理结果，我们可以根据需要多次 .then ，称之为 Promise链 第二个对resolve的调用会被忽略，只有第一次对 reject/resolve 的调用才会被处理 cnew Promise(function(resolve, reject) { setTimeout(() => resolve(1), 1000); // (*) }).then(function(result) { // (**) alert(result); // 1 return result * 2; }).then(function(result) { // (***) alert(result); // 2 return result * 2; }).then(function(result) { alert(result); // 4 return result * 2; }); 从技术上我们可以将多个 .then 添加到一个promise上，但这并不是promise链 在前端编程中， promise通常被用于网络请求，也可使用 fetch 方法从远程服务器加载用户信息 Fetch JS 可以将网络请求发送到服务器，并在需要时加载新信息，对于来自 JS 的网络请求，有一个总称术语 AJAX（Asynchronous JavaScript and XML），但是我们一般不必使用XML，这个是一起的了 let promise = fetch(url, [options]) url 要访问的url options 可选参数：method，header 如果没有options，那就是一个简单的 get 请求，下载url 的内容，浏览器立即启动请求，并返回一个该调用代码用来获取结果的promise 获取响应通常需要经历两个阶段： 第一阶段，当服务器发送了响应头（response header），fetch 返回的 promise 就使用内建的 Response class 对象来对响应头进行解析 这个阶段，我们通过检查响应头来检查HTTP状态以确定请求是否成功，如果没有响应体（response body），那么promise就会reject，异常的HTTP状态，不会出现error，我们可以从response中看到http状态： status、ok let res = await fetch(url) if(res.ok){} 第二阶段，为了获取response body，我们需要使用一个其它方法调用 response提供了很多基于promise的方法，以不同的格式来访问body：response.text(), response.json(), response.formData(), response.blob(), 我们只能选择一种读取body的方法，因为第二次的是已经被处理过的 response header 位于 response.headers 中的一个类似于 Map 的header 对象 let user = { name: 'John', surname: 'Smith' } let res = await fetch('/article/fetch',{ method: 'POST', headers: { 'Content-Type': 'application/json;charset=utf-8' }, body: JSON.stringify(user) }) let result = await res.json() alert(res.message) 同样我们可以使用 Blob 或 BufferSource 对象通过 fetch 提交二进制数据，如图片 canvasElem.onmousemove = function(e){ let ctx = canvasElem.getContext('2d') ctx.lineTo(e.lientX, e.e.clientY) ctx.stroke() } async function submit(){ let blob = await new Promise(resolve=>canvasElem.toBlob(resolve, 'image/png')) let res = await fetch('/article/fetch/post/image',{ method:'POST', body: blog }) let result = await res.json() alert(result.message) } 典型的fetch 请求由两个 await 组成 let res = await fetch(url, [options]) let result = await res.json() // 或者是 fetch(url, options) .then(res => res.json()) .then(result => /* ... */) 下面这段代码有意思，promise和fetch一起联合写的： // 发送一个对 user.json 的请求 fetch('/article/promise-chaining/user.json') // 将其加载为 JSON .then(response => response.json()) // 发送一个到 GitHub 的请求 .then(user => fetch(`https://api.github.com/users/${user.name}`)) // 将响应加载为 JSON .then(response => response.json()) // 显示头像图片（githubUser.avatar_url）3 秒（也可以加上动画效果） .then(githubUser => { let img = document.createElement('img'); img.src = githubUser.avatar_url; img.className = \"promise-avatar-example\"; document.body.append(img); setTimeout(() => img.remove(), 3000); // (*) }); 这段代码可以工作，但是有个为题， * 行头像显示结束后如果我们还想显示一个编辑的表单是做不到的，为了使得链可以扩展，我们需要显示一个在头像结束时进行 resolve 的 promise 作为一个好的做法，异步行为应该始终返回一个promise promise 的 executor 周围存在隐式的 try...catch 自动获取了 error， 并将其变为 rejected promise promise.all 并行执行多个 promise let names = ['iliakan', 'remy', 'jeresig']; let requests = names.map(name => fetch(`https://api.github.com/users/${name}`)); Promise.all(requests) .then(responses => { // 所有响应都被成功 resolved for(let response of responses) { alert(`${response.url}: ${response.status}`); // 对应每个 url 都显示 200 } return responses; }) // 将响应数组映射（map）到 response.json() 数组中以读取它们的内容 .then(responses => Promise.all(responses.map(r => r.json()))) // 所有 JSON 结果都被解析：\"users\" 是它们的数组 .then(users => users.forEach(user => alert(user.name))); Async/await 是以更舒适的方式使用promise的一种特殊语法，同时它非常易于理解和使用 async 这个单词表达了一个简单的事情，即这个函数总是返回一个promise， 其它值将自动被包装在一个resolved的promise中 await 只在async 中工作，关键字await 让JS引擎等待直到 promise 完成（settle）并返回结果，await 实际上会暂停函数的执行，知道promise的状态变为settled，然后以promise的结果继续执行，这个行为不会耗费任何CPU资源，因为 JS引擎可以同时处理其它脚本 await 不能在顶层代码中运行，但我们可以将其包裹在一个匿名 async 函数中 (async()=>{ let res = await fetch(/*...*/) })() async/await 可以和 promise.all 一起使用 常规函数只会返回单一值或者直接不返回任何值，但generator 可以按需一个接一个的返回（“yeild”）多个值，他们可以与iterable完美配合使用，从而可以轻松的创建数据流 要创建一个generator，我们需要一个特殊的语法结构：function* 异步迭代允许我们对按需通过异步请求而得到的数据进行迭代，例如，我们通过网络分段（chunk-by-chunk）下载数据的时候，异步生成器（generator）是这一步骤更加方便 随着我们的应用越来越大，我们想要将其拆分成多个文件，即所谓的模板（module），一个模板可以用户包含用于特定目的的类和函数库 模块可以相互加载，并可以使用特殊的指令export和import来交换功能，从一个模块调用一个模块的函数 import 指令通过相当于当前文件的路径加载模块，并将导入的函数分配给相应的变量 模块始终默认使用 use strict 每个模块都有自己的顶级作用域，一个模块中的顶级作用域变量和函数在其它脚本中是不可见的 如果我们真的需要创建一个 window-level 的全局变量，我们可以明确的赋值给 window 如果同一个模块被导入到多个其它位置，那么它的代码仅会在第一次导入的时候执行， 在一个模块中，this 是 undefined 模块脚本总是延迟的，模块脚本回等到HTML文档完全准备就绪，然后才会运行，保持脚本的相对顺序，在文档中排在前面的脚本先执行 如果内联脚本具有 async 特种，它就不会等待任何东西 标签 --> import {counter} from './analytics.js'; counter.count(); import 必须给出相对或绝对的 url 路径，没有任何路径的模块被成为裸模块，在import中是不允许这种模块的 在实际开发中，浏览器模块很少被以”原始“形式进行使用，通常我们会使用一些特殊工具，如Webpack将它们打包在一起，然后部署到生产环境的服务器中，使用打包工具的一个好处是它们可以更好的控制模块的解析方式，允许我们使用裸模块和更多功能，例如css/html 模块等 构建工具做以下这些事： 从一个打算放在 HTML 中的 ` ”主“模块开始 分析它的依赖，它的导入，它的导入的导入等 使用所有模块构建一个文件或者多个文件，并用打包函数（bundler function）替代原生的import调用，以使其正常工作，还支持像 html/css 模块等特殊的模块类型 在处理过程中进行一些优化 我们可以通过在声明之前防止export来标记任意声明为导出，在类或者函数前的export不会让它们变成函数表达式，尽管被导出了，但它仍然是一个函数声明，不建议在函数和类声明后使用分号 通通导入一般不可取，如果明确列出我们需要的导入的内容，优化器（optimizer）就会检测到它，从而是构建更小，这就是所谓的”摇树（tree-shaking）“ import as 可以让导入具有不同的名字 eval 执行代码字符串，代码字符串可能会比较长，eval的结果是最后一条语句的结果 A re-introduction to JavaScript A re-introduction to JavaScript Numbers console.log(3/2) // 1.5, not 1​ an apparent integer is fact implicitly a float parseInt parseInt('123', 10); // 123 parseInt('010', 10); // 10 parseInt('11', 2); // 3 parseInt('0x10'); // 16 parseFloat() always uses base 10. You can also use the unary + operator to convert values to numbers: + '42'; // 42 + '010'; // 10 + '0x10'; // 16 A special value called NaN(not a number) is returned if the string is non-numeric: parseInt('hello') NaN is toxic: if you provide it as an operand to any mathematical operation, the result will also be NaN +'10.2abc' // NaN parseFloat('10.2abc') // 10.2 String Strings are sequences of Unicode characters. 'hello'.charAt(0); // \"h\" 'hello, world'.replace('world', 'mars'); // \"hello, mars\" 'hello'.toUpperCase(); // \"HELLO\" null: only accessible through the null keyword. undefined: a value hasn't even been assigned yet. undefined is actually a constant You can perform this conversion explicitly using the Boolean() function: Boolean(''); // false Boolean(234); // true false, 0, empty strings (\"\"), NaN, null, and undefined all become false. All other values become true. Variables let, const or var let allows you to declare block-level variables, the declared variable is available from the block it is enclosed in. // myLetVariable is *not* visible out here for (let myLetVariable = 0; myLetVariable const allows you to declare variables whose values are never intended to change. The variable is available from the blcok. var does not have the restrictions, a variable declared with the var keyword is available from the function it is declared in. // myVarVariable *is* visible out here for (var myVarVariable = 0; myVarVariable An important difference between JavaScript and other languages like Java is that in JavaScript, blocks do not have scope, only functions have a scope. Operators The + operator also does string concatenation: 'hello' + 'world' Adding an empty string to something is a useful way of converting it to a string itself: ' ' + 5 ==: the double-equals operator performs type coercion if you tive it different types. 123 == '123'; // true 1 == true; // true to avoid type coercion, user the triple-equals operator: === Control structures The && and || operators use short-circuit logic, which means whether they will execute their second operand is dependent on the first. Objects JavaScript objects can be thought of as simple collections of name-value pairs. The 'name' part is a JavaScript string, while the value can be any JavaScript value -- including more objects. Attribute access can be chained together: obj.details.color obj['details']['size'] The following example creates an object prototype and an instance of that prototype: function Person(name, age) { this.name = name; this.age = age; } // Define an object var you = new Person('You', 24); // We are creating a new person named \"You\" aged 24. obj.for = 'Simon'; // Syntax error, because 'for' is a reserved word obj['for'] = 'Simon'; // works fine Array Arrays in JavaScripts are actually a special type of object. The work very much like regular objects but they have one magic property called 'length'. Note that array.length isn't necessarily the number of items of the array.Consider the following: var a = ['dog'] a[100] = 'fox' a.length; // 101 Remember -- the length of the array is one more than the highest index If you query a non-existent array index, you'll get a value of undefined in return: typeof a[90]; // undefined ES2.15 introduced the more concise for...of loop for iterable objects such as array. for..in this does not iterate over the array elements, but the array indeces. Futhermore, if someone added new properties to Array.prototype, they would also be iterated overby such a loop. forEach(): ['dog', 'cat', 'hen'].forEach(function(currentValue, index, array)) { } Functions If no return statement is used(or an empty return with no value), JavaScript returns undefined. Functions have access to an additional variable inside their body called arguments. ...variable will include within that variable the entire list of uncaptured arguments that the function was called with. JavaScript let you call a function with an arbitrary of arguments, using the apply() method of any function object. Anonymous functions Anonymous functions are typically used as arguments to other functions or are made callable by immediately assigning them to a variable that can be used to invoke the function. (function() { // … })(); Recursive functions Custom objects JavaScript uses functions as classes function makePerson(first, last) { return { first: first, last: last }; } function personFullName(person) { return person.first + ' ' + person.last; } function personFullNameReversed(person) { return person.last + ', ' + person.first; } var s = makePerson('Simon', 'Willison'); personFullName(s); // \"Simon Willison\" personFullNameReversed(s); // \"Willison, Simon\" This works, but it's pretty ugly. What we really need is a way to attach a function to an object. Since functions are objects, this is easy: function makePerson(first, last) { return { first: first, last: last, fullName: function() { return this.first + ' ' + this.last; }, fullNameReversed: function() { return this.last + ', ' + this.first; } }; } var s = makePerson('Simon', 'Willison'); s.fullName(); // \"Simon Willison\" s.fullNameReversed(); // \"Willison, Simon\" We can take advantage of the this keyword to imporove our function: function Person(first, last) { this.first = first; this.last = last; this.fullName = function() { return this.first + ' ' + this.last; }; this.fullNameReversed = function() { return this.last + ', ' + this.first; }; } var s = new Person('Simon', 'Willison'); new is strongly related to this. It creates a brand new empty object, and then calls the function specified, with this set to that new object. Functions that are designed to be called by new are called constructor functions. function personFullName() { return this.first + ' ' + this.last; } function personFullNameReversed() { return this.last + ', ' + this.first; } function Person(first, last) { this.first = first; this.last = last; this.fullName = personFullName; this.fullNameReversed = personFullNameReversed; } That's better: we are creating the method functions only once, and assigning references to them inside the constructor. Can we do any better than that? The answer is yes: function Person(first, last) { this.first = first; this.last = last; } Person.prototype.fullName = function() { return this.first + ' ' + this.last; }; Person.prototype.fullNameReversed = function() { return this.last + ', ' + this.first; }; Person.prototype is an object shared by all instances of Person. The first argument to apply() is the object that should be treated as 'this'. apply() has a sister function named call, which again lets you set this but takes an expanded argument list as opposed to an array. An important detail of nested functions in JavaScript is that they can access variables in their parent function's scope. Closures function makeAdder(a) { return function(b) { return a + b; }; } var add5 = makeAdder(5); var add20 = makeAdder(20); add5(6); // ? add20(7); // ? This allow you to write many similar functions. 课外 JS_轮询 思否 轮询其实就是一个循环了 轮询的坑 function getData() { return new Promise((resolve,reject) => { setTimeout(() => { resolve({data:666}) },500) }) } // 轮询 async function start () { const { data } = await getData() // 模拟请求 console.log(data) timerId = setTimeout(start, 1000) } start () 想暂停，就是清除 timeId 了，继续就是重新轮询 轮询的坑 暂停 let timerId = null function getData() { return new Promise((resolve,reject) => { setTimeout(() => { resolve({data:666}) },500) }) } // 轮询 async function start () { const { data } = await getData() // 模拟请求 console.log(data) timerId = setTimeout(start, 1000) } // 暂停 function stop () { clearTimeout(timerId) } start () const botton = document.querySelector(\"#button\") let isPlay = true botton.addEventListener(\"click\", function(){ isPlay = !isPlay botton.innerHTML = isPlay ? '暂停' : '播放' isPlay ? start() : stop() }, false) 有bug，因为js是单线程，如果快速点击或则异步的运行很久的话，就会有几个轮询的情况出现，所以应该有个标记，但是一个变量的 true false 不满足快速点击的情况 轮询的坑 暂停 let timerId = 1 // 模拟计时器id，唯一性 let timerObj = {} // 计时器存储器 function getData() { return new Promise((resolve,reject) => { setTimeout(() => { resolve({data:666}) },500) }) } // 轮询 function start () { const id = timerId++ timerObj[id] = true async function timerFn () { if (!timerObj[id]) return const { data } = await getData() // 模拟请求 console.log(data) setTimeout(timerFn, 1000) } timerFn() } // 暂停 function stop () { timerObj = {} } start () const botton = document.querySelector(\"#button\") let isPlay = true botton.addEventListener(\"click\", function(){ isPlay = !isPlay botton.innerHTML = isPlay ? '暂停' : '播放' isPlay ? start() : stop() }, false) Promise 现代JavaScript教程 Promise 这部分知识挺有用的，仔细看一遍，当时是 Promise 链没有看熟悉，回头重新看看 简介：回调 什么是回调 JavaScript 主机（host）环境提供了许多函数，这些函数允许我们计划异步行为（action），现在看是执行的行为，但是在稍后才完成。eg：setTimeout 函数 例如加载脚本的一个函数： function loadScript(src) { let script = document.createElement('script') script.src = src document.head.append(script) } loadScript('/my/test1.js') console.log('test1') 在执行loadScript 的函数的时候是异步，函数会在异步执行这个函数的时候接着往下走，如果我们想用这个脚本中的函数，我们其实并不知道什么时候这个异步行为能结束，虽然我们不知道这个异步行为什么时候结束，但是我们可以传递一个函数作为参数，只要它一结束就可以执行这个传递的函数，这就是回调 function loadScript(src, callback) { let script = document.createElement('script') script.src = src document.head.append(script) script.onload = () => callback() // 脚本加载完之后执行 } loadScript('my/test1.js', () => {console.log('append test1.js')}) 回调中回调 如何在第一个回调后结束第二个回调，自然的想法就是第一个执行的回调中有第二个回调 loadScript('/my/test1.js', () => { console.log('append test1.js') loadScrit('my/test2.js', () => {console.log('append test2.js')}) }) 每一个新的行为（action）都在回调的内部，如果只是几个行为还好，如果行为多了，就会出现回调地狱 处理Error 在上述的例子当中，我们都没有考虑出现error的情况，如果脚本加载失败怎么办？回调需要能对此做出反应 function loadScript(src, callback) { script = document.createElement('script') script.src = src script.onload = () => callback(src) script.onerror = () => callback(new Error(`append error for ${src}`)) document.head.append(script) } loadScript('my/test1.js', (err, src) => { if(err) { console.error('error: ', err) return } console.log(`${src} append success.`) }) Error 优先回调（error-first callback）风格，约定是： callback的第一个参数是为 error 而保留的，一点出现 error，callback(err) 就会被调用 第二个参数及以后的参数用于成功的结果，此时 callback(null, result1, result2, ...) 就会被调用 厄运金字塔 看起来这是一种可行的异步编程方式，的确对于一个或两个嵌套的调用看起来还不错，但是对于一个接一个的多个异步行为，代码会变成这样： loadScript('1.js', function(error, script) { if (error) { handleError(error); } else { // ... loadScript('2.js', function(error, script) { if (error) { handleError(error); } else { // ... loadScript('3.js', function(error, script) { if (error) { handleError(error); } else { // ...加载完所有脚本后继续 (*) } }); } }); } }); 嵌套调用的“金字塔”随着每个异步行为会向右增长，很快它就失控了，解决方法是独立函数，但是这些函数都是一次性使用的，代码看起来就像是撕裂的表格，可读性很差，在阅读的时候需要在各个代码块之间跳转。解决方法最好的办法之一就是 “promise” Promise e.g: 想象一下，你是一个顶尖的歌手，粉丝没日没夜的问你什么时候发新歌，终于你忍受不了了，然后想了一个解决方案：你发了一个订阅列表，愿意的粉丝在上面填上自己的邮箱，你承诺一首歌出来（或者出了事故不能发歌）的时候立马向这个列表的邮箱发送消息。 Promise 与这个例子的类比： “生产者代码（producing code）”：做事情，但是需要一段时间 “消费者代码（consuming code）”：想要在“生产者代码（producing code）”出现的第一时间获得结果 Promise 是将“生产者代码”和“消费者代码”连接在一起的的一个特殊的 JavaScript 对象，就好比前面说的订阅列表 Promise 对象的构造器（constructor）语法如下： let promise = new Promise((resolve, reject) => { // executor 生产者代码 }) 传递给 new Promise 的代码被称为 executor，当 new Promise 被创建，executor 会自动运行，它包含最终应产出结果的生产者代码 当 executor 获得了结果，无论或早或晚都可以，它应该调用以下回调之一： resolve(value)：如果任务成功完成并带有结果 value reject(err)：如果出现了error Promise 对象具有以下内部属性： state：最初是 pending，然后再 resolve 被调用的时候变成 fulfilled，或者在 reject 被调用时变成 rejected result：最初是 undefined，然后在 resolve 被调用的时候变为 value，或者在 reject 被调用的时候变成 error promise 状态变化 小提示： 与最初的 \"pending\" promise 相反，一个 resolved 或 rejected 都会被称为 \"settled\"，任何状态的更改都是最终的，也就是只能调用一个 resolve 或者 一个 reject 如果什么出了问题，exector 应该调用 reject，这可以使用任何类型的参数来完成，但是建议使用 Error 对象 state 和 result 是内部的，Promise 对象的 state 和 result 属性都是内部的，我们无法直接访问它们，但我们可以对它们使用 .then / .catch / .finally 方法 消费者：then，catch，finally promise 对象充当的是 executor 和消费者代码之间的连接，后者将接收结果或者 error，通过使用 .then / .catch / .finally 来为消费者函数注册 踩了一个坑，如果executor中有异常，则promise 必须要有 catch 的错误回调函数，否则会报错，所以说写promise随手写 catch 是一个好习惯 最重要最基础的就是 then， then 的第二个参数可以是执行失败的回调函数： let promise = new Promise((resolve, reject) => { setTimeout(resolve('done'), 1000) }) promise.then( value => console.log('value: ', value), // 执行 err => console.error('error: ', err) // 不执行 ) let promise2 = new Promise((resolve, reject) => { setTimeout(() => reject(new Error('not'))) }) promise2.then( value => console.log('value: ', value), // 不执行 err => console.error('error: ', err) // 执行 ) 如果我们只对成功的完成感兴趣，那么可以只为 .then 提供一个函数参数： let promise = new Promise((resolve, reject) => { setTimeout(resolve('done'), 1000) }) promise.then(console.log) 如果我们只对 error 感兴趣，那么我们可以使用 null 作为 .then 的第一个参数或者使用 .catch，这两者是一样的： let promise = new Promise((resolve, reject) => { setTimeout(() => reject(new Error('not done')), 1000) }) promise.catch(console.log) .finally(f) 调用和 .then(f, f)，类似，在某种意义上，f 总是在 promise 被 settled 时执行，finally 是执行清理（cleanup）的很好的程序（handler），它们之间有一些细微的区别： finally 处理程序时没有参数，也不知道 promise 是否成功 finally 处理程序将结果和 error 传递给力下一个处理程序 JavaScript 不具有 sleep() 函数，但是可以尝试使用 setTImeout 和 promise 来共同实现它，也可以使用 Date.now 直接阻塞主线程（但是一般不考虑这个），一个同步一个异步 // 用 promise 模拟 sleep 函数 let delay = (time = 0) => {return new Promise((resolve, reject) => setTimeout(resolve, time))} console.log('delay time: ', new Date().toLocaleTimeString()) delay(3000).then(() => console.log('runs after 3 seconds first at ', new Date().toLocaleTimeString())) // 使用 Date.now() 阻塞主线程 let delay2 = (time = 0) => { let record = Date.now() while(Date.now() - record Promise 链 回调我们提过，有一系列的异步任务要一个接一个地执行，加载脚本，利用 Promise 链我们可以写出更好的代码，它看起来就像这样： new Promise((resolve, reject) => { setTimeout(() => resolve(1), 1000) }).then(value =>{ console.log('value: ', value) return 2 }).then(value => { console.log('value: ', value) return 3 }).then(value => { console.log('value: ', value) console.log('finished.') }) 它的理念是将 result 通过 .then 处理程序（handler）链进行传递 Promise 链 新手常犯的一个经典错误：将多个 .then 添加到一个 promise 上，但这并不是 promise 链（chaining）： let promise = new Promise(function(resolve, reject) { setTimeout(() => resolve(1), 1000); }); promise.then(function(result) { alert(result); // 1 return result * 2; }); promise.then(function(result) { alert(result); // 1 return result * 2; }); promise.then(function(result) { alert(result); // 1 return result * 2; }); Promise 多处理程序情况 同一个 promise 上的所有 .then 获得的结果都相同，实际上我们极少遇到一个 promise 需要多处理程序（handler）的情况 返回Promise .then（handler）中所使用的处理程序（handler）可以创建并返回一个 Promise，在这种情况下，其它的处理程序（handler）将等待它 settled 后再获得其结果（result） new Promise((resolve, reject) => { setTimeout(() => resolve(1), 1000) }).then(value => { console.log('value: ', value) return new Promise((resolve, reject) => { setTimeout(() => resolve(99), 1000) }) }).then(value => { console.log('value: ', value) return new Promise((resolve, reject) => { setTimeout(() => resolve(8), 1000) }) }).then(value => { console.log('value: ', value, '\\nfinished.') }) 返回 promise 让我们能够构建异步行为链 更复杂的示例：fetch 一个好的做法，异步行为应该始终返回一个 promise，这样就可以使得我们计划后续的行为成为可能，即使我们现在不打算对链进行扩展，但我们之后可能会需要 function loadJson(url) { return fetch(url) .then(response => response.json()) } function loadGithubUser(name) { return fetch(`https://api.github.com/users/${name}`) .then(response => response.json()) } function showAvatar(githubUser) { return new Promise((resolve, reject) => { let img = document.createElement('img') img.src = githubUser.avatar_url img.className = 'promise-avatar-examle' document.body.append(img) setTimeout(() => { img.remove() resolve(githubUser) }, 3000) }) } loadJson('/user.json') .then(user => loadGithubUser(user.name)) .then(showAvatar) .then(githubUser => alert(`Finished showing ${githubUer.name}`)) 如果 .then （或 catch/finally 都可以）处理程序（handler）返回一个promise，那么链的其余部分将会等待，知道它的状态变为 settled。当它被 settled 后，其 result（或 error）将被进一步传递下去 Promise chain flow chart 使用 promise 进行错误处理 Promise 链在错误（error）处理中十分强大。当一个 promise 被 reject 时，控制权将移交给最近的 rejection 处理程序。 fetch('/article/promise-chaining/user.json') .then(response => response.json()) .then(user => fetch(`https://api.github.com/users/${user.name}`)) .then(response => response.json()) .then(githubUser => new Promise((resolve, reject) => { let img = document.createElement('img'); img.src = githubUser.avatar_url; img.className = \"promise-avatar-example\"; document.body.append(img); setTimeout(() => { img.remove(); resolve(githubUser); }, 3000); })) .catch(error => alert(error.message)); .catch 不必是立即的，它可能在一个或多个 .then 之后出现，捕获所有 error 最简单的方法是，将 .catch 附加到链的末尾 Promise 的执行者（executor） 和 promise 的处理程序（handler）周围有一个“隐式”的 try...catch 。如果发生异常，它就会被捕获，并被视为 rejection 进行处理，一下这两段代码是等价的 new Promise((resolve, reject) => { throw new Error('error') }).catch(console.log) new Promise((resolve, reject) => { reject(new Error('error')) }).catch(console.log) 再次抛出（rethrowing） 正如我们所注意到的，链尾端的 .catch 的表现有点像 try...catch，我们可能由许多个 .then 处理程序（handler），然后在尾端使用一个 .catch 处理上面所有的 error 在常规的 try...catch 中，我们可以分析错误（error），如果我们无法处理它，可以将其再次抛出，对于promise来说，这样也是可以的 如果我们在 .catch 中 throw，那么控制权就会被移交到下一个最近的 error 处理程序，如果我们处理该 error 并正常完成，那么它将继续到最近的成功的 .then 处理程序 new Promise((resolve, reject) => { reject(new Error('err')) }) .catch(console.log) .then(() => console.log('finish')) catch 立马继续 throw，忽略 then 处理程序，传给下一个 catch 处理程序 new Promise((resolve, reject) => { reject(new Error('err')) }) .catch(err => { if(err instanceof URIError) { // handle it } else { throw err } }) .then(() => console.log('no handle')) .catch(err => console.log('unknown err: ', err)) 未处理的 rejection 当一个 error 没有被处理，未被 try...catch 捕获，那么脚本就死了，并在控制台留下来一个信息，同理在 promise 中未被处理的rejection 也会发生类似的事 JavaScript 引擎会跟踪此类 rejection，在这种情况下会生成一个全局的 error，在浏览器中我们可以使用 unhandledrejection 事件来捕获这类 error： window.addEventListener('unhandledrejection', (event) => { console.log(event.promise) console.log(event.reason) }) 通常此类 error 是无法恢复的，所以我们最好的解决方案是将问题告知用户，并且可以将事件报告给服务器，在 Node.js 等非浏览器环境中，有其他用于跟踪未处理的 error 的方法 Fetch 错误处理示例 当请求无法发出时，fetch reject 会返回 promise，但是如果远程服务器返回错误响应 404 或者是 500，这些都被认为是合法的响应，但是这应该当作错误来处理，并且无论是 404 或者 500 的响应，它的response都会被当成 json 处理，都会报 SyntaxError ，但是实际上并不是这个错误，错误只是落在了链上，并没有相关细节信息 fetch('test.json') .then(response => response.json()) .catch(console.log) // SyntaxError: Unexpected token 所以我们可以为 HTTP 错误 创建一个自定义类用来区分 HTTP 错误和其它类型错误，这个新类有一个 constructor，它接受response 对象，并将其保存到 error 中 然后我们将请求和错误处理代码包装进一个函数，它能 fetch url 并将所有状态码不是 200 的视为错误，我们通常需要这样的逻辑 // fetch 请求 github 用户 function printOneGithubUser() { let name = prompt('Enter your name', 'name') fetch(`https://api.github.com/users/${name}`) .then(response => { if(response.status == 200) { return response.json() } else { throw new HttpError(response) } }) .then(user => console.log('user: ', user)) .catch(err =>{ if(err instanceof HttpError && err.response.status != 200) { console.log('no such user') return printOneGithubUser() } else { console.log('other error: ', err) } }) } printOneGithubUser() 如果我们有加载指示（load-indication），finally 就是一个很好的处理程序，在 fetch 完成时停止。try...catch 结构只能抓捕同步的错误。 Promise API 在 Promise 类中，有 5 中静态方法 Promise.all 假设我们需要并行执行多个 promise，并等待所有 promise 都准备就绪，比如并行下载交给 URL，并等到所有内容都下载完毕后再对它们进行处理。 // promise.all 简单使用 Promise.all([ new Promise(resolve => setTimeout(() => resolve(1), 1000)), new Promise(resolve => setTimeout(() => resolve(2), 2000)), new Promise(resolve => setTimeout(() => resolve(3), 3000))]) .then(console.log) let urls = ['https://api.github.com/users/Ting-xin', 'https://api.github.com/users/Ting-xin'] Promise.all(urls.map(url => fetch(url))) .then(responses => responses.forEach(response => { console.log('response: ', response) })) 一个更加实际的例子是 response.json()，应该有一个 promise.all 专门来处理这个，踩了一个坑，第二个Promise.all 使用 {} 会有问题，暂时我也不知道为啥： let urls = ['https://api.github.com/users/Ting-xin', 'https://api.github.com/users/Ting-xin'] Promise.all(urls.map(url => fetch(url))) .then(responses => Promise.all(responses.map(response => response.json()))) .then(resultArr => resultArr.forEach(result => console.log('name: ', result.name))) 如果任意一个 promise 被 reject，由 Promise.all 返回的 promise 就会立即 reject，并且带有这个error，其它的 promise 将被忽略，其中一个失败，但是其余的 fetch 操作仍然会继续执行，但是结果还是会被忽略，promise 中没有取消的概念，只能通过 AbortController 来取消 Promise.all(iterable) 允许在 iterable 中使用 non-promise 的“常规”值 Promise.allSettled 在 Promise.all 中，如果任意的 promise reject，整个都会 reject，当我们需要所有的结果，无论结果是啥的时候，就可以用 Promise.allSettled 例如，我们想要获取多个用户的信息，即使其中一个请求失败，我们仍然对其它的感兴趣，就可以使用 Promise.allSettled let urls = [ 'https://api.github.com/users/iliakan', 'https://api.github.com/users/remy', 'https://no-such-url' ]; Promise.allSettled(urls.map(url => fetch(url))) .then(results => { // (*) results.forEach((result, num) => { if (result.status == \"fulfilled\") { alert(`${urls[num]}: ${result.value.status}`); } if (result.status == \"rejected\") { alert(`${urls[num]}: ${result.reason}`); } }); }); Promise.race 与 Promise.all 类似，但只等待一个 settled 的 promise 并获取其结果 Promise.race([ new Promise((resolve, reject) => setTimeout(() => resolve(1), 1000)), new Promise((resolve, reject) => setTimeout(() => reject(new Error(\"Whoops!\")), 2000)), new Promise((resolve, reject) => setTimeout(() => resolve(3), 3000)) ]).then(alert); // 1 Promise.resolve、Promise.reject 已经过时了，因为 async/await 语法 Promisification Promisification 是指将一个接收回调的函数转换为一个返回promise的函数。由于许多函数和库都是基于回调的，因此在实际开发中经常会需要进行这种转换，因为使用 promise 更加方便，所以将基于回调的函数和库 promisfy 是有意义的 function loadScript(src, callback) { let script = document.createElement('script') } await 处理 promise 返回 reject 报错的问题 blog promise 用 async，awati 优化，不仅是为了更优雅的书写和阅读，通过优化把异步代码写成同步，也是为了更加符合人正常的思维方式 ES5的异常捕获 try{ throw new Error(3) } catch(e) { console.log(e) } 这是ok的，但是如果try中出现了异步的代码呢 try{ setTimeout(() => { throw new Error(3) }, 1000) } catch(e) { console.log(e) } try-catch 是同步的，setTimeout 是在异步任务队列中的，同步任务执行完再从任务队列中的回调函数拿来执行就出错了 改正 setTimeout(() => { try{ throw new Error(3) } catch(e) { console.log(e) } }, 0) ES6 promise 方式的错误捕获 异步任务完成调用 resolve 的做法： function fn() { return new Promise((resolve, reject) => { setTimeout(() => { resolve('ok') }, 1000) }) } fn().then(res => { console.log(res) }) 异步任务失败的，调用reject的捕获异常方法： function fn() { return new Promise((resolve, reject) => { setTimeout(() => { reject(3) }, 1000) }) } fn().catch(err => console.log(err)) ES6 通过 async， await优化promise时的异常捕获 问题，通过 async，await的方式去优化promise，只能接收到成功 resolve() 的结果，对与 reject() 的记过是回报错的 // resolve情况，正常 function fn1() { return new Promise((resolve, reject) => { setTimeout(() => { resolve('ok') }, 0) }) } async function test1() { let res = await fn1() console.log(res) } test1() // reject情况，异常 function fn2() { return new Promise((resolve, reject) => { setTimeout(() => { reject('error') }, 0) }) } async function test2() { let res = await fn2() console.log(res) } test2() 解决async/await 的promise 返回错误 reject 的问题及错误捕获 方式一：async/await 已经把异步代码优化成了同步代码，同步代码可以通过 try, catch捕获异常 function fn() { return new Promise((resolve, reject) => { setTimeout(() => { reject('error') }, 0) }) } async function test() { try{ let test = await fn() } catch (e) { console.log(e) } } test() 方式2：通过返回一个pending 状态的结果，中断promise链的方式处理错误 function fn() { return new Promise((resolve, reject) => { setTimeout(() => { // reject('error') return new Promise(() => {}) // 中断 promise 链 }) }) } async function test() { let res = await fn() console.log(res) } test() 方法2不会出现多余且不好看的代码，但是根本不能拿到错误了呀 正则表达式 为什么要学习字符串 处理 为什么学习字符串处理 传统的统计学教育几乎没有告诉过我们如何进行文本的统计建模分析。然而我们日常生活中接触到的大部分数据都是以文本的形式存在，文本分析与挖掘在业界有着非常广泛的应用。 由于文本数据大多数属于非结构化数据，要想对文本数据进行传统的统计模型分析，必须要经过层层的数据清洗和整理，正则表达式就用来干这个的。 和建立酷炫的模型比起来，数据的清洗与整理似乎是一种低档次的工作。如果吧建模比作高级厨师的工作，那么数据清洗就类似于切菜洗碗打扫卫生的活儿。然而想要成为资深的“数据玩家”，这种看似低档次的工作是必不可少的，并且这种工作极有可能占据整个建模流程的 80% 的时间。如果我们能掌握高效的数据清洗工作，那么我们将拥有更多的时间来选择模型和参数选择。 教程 以前一直都是草草了事，这次一定要把这个好好看懂 教程 模式（Paterns）和修饰符（flags） 正则表达式是搜索和替换字符串的一种强大方式，在JavaScript中，正则表达式通过内置的“RegExp”类的对象实现，并与字符串集成 创建正则表达式有两种语法 // 较长的语法 regexp = new RegExp(\"pattern\", \"flags\") // 较短的语法 regexp = /pattern/; // 没有修饰符 regexp = /pattern/gmi; // 伴随修饰符 g m i 如果要在字符串种进行搜索，可以使用search 方法 let str = 'I love JavaScript' let regexp = /love/ alert(str.search(regexp)) // 2 // 上面这段代码等价于 let str = 'I love JavaScript' let substr = 'love' alert(str.search(substr)) // 2 str.search 方法会查找模式 /love/ ，然后返回匹配项在字符串中的位置 通常我们使用的都是简短语法 /../ 。但是它不接受任何变量的插入，new RegExp 允许从字符串中动态的构造模式 let search = prompt('What you want to search?', 'love') let regexp = new RegExp(search) alert('I love JavaScript'.search(regexp)) 正则表达式的修饰符可能会影响搜索结果，在JavaScript中有5个修饰符 i 不区分大小写 g 查找所有的匹配项，而不只是第一个 m 多行模式 u 开启完整的 unicode 支持，能修正对于代理对的处理 y 粘滞模式 alert('love'.search(/LOVE/)) // -1，没找到 alert('love'.search(/LOVE/i)) // 0 如果不使用我们后面将会学到的修饰符和特殊标志，正则表达式的搜索就等同于字符串查找了 字符类 字符类（character classes）是一个特殊的符号，匹配特定集合中的任何符号 str.match(regexp) 方法在字符串中 str 中找到匹配 regexp 的字符 // 考虑一个实际的例子，只保留字符中的所有数字 console.log('+1,3,5,,,,'.match(/\\d/g).join('')); // 135 常用的字符类有： \\d d 来自 digit，从 0 到 9 的字符 \\s s 来自 space，空格符号，包括空格，制表符\\t，换行符\\n，及其他稀有字符，如 \\v，\\f 和 \\r \\w w 来自 word，拉丁字符或数字或下划线 正则表达式可能同时包含常规符号和字符类，匹配项（每个正则表达式字符类都有对应的结果字符） 对于每个字符类，都有一个反向类，用相同的字符表示，但是要大写，反向代表它与所有其它字符匹配 \\D 非数字，匹配除 \\d 以外的所有字符 \\S 非空格字符，匹配除 \\s 以外的所有字符 \\W 非单字字符，匹配除 \\w 以外的所有字符 // 考虑一个实际的例子，只保留字符中的所有数字 console.log('+1,3,5,,,,'.match(/\\d/g).join('')); // 135 // 另一种快捷的方式是将所有的非数字字符找到，并直接删除 console.log('+1,3,5,,,'.replace(/\\D/g, '')); // 135 点（.）是一种特殊的字符类，匹配任何字符，点表示任何字符，而不是缺少字符，必须有一个与之匹配的字符 默认情况下，点与换行符 \\n 不匹配，但在很多情况下，当我们希望用点来表示任何字符（包括换行符\\n时），就要用到标识符 s console.log('a\\nb'.match(/a.b/)) // null console.log('a\\nb'.match(/a.b/s)) // a\\nb 的 object 但是 \\s 的方式不是所有的浏览器都适用，有一种替代方法在任何地方都适用，可以使用 [\\s\\S] 之类的正则表达式来匹配任何字符 alert(\"a\\nb\".match(/a[\\s\\S]b)/) // a\\nb 在正则表达式中，所有字符都很重要，空格也很重要 Unicode：修饰符 'u' 和 class \\n{...} 很久以前，当JavaScript被发明出来的时候，Unicode的编码要更加简单：当时并没有 4 个字节长的字符，所以一部分语言特性在现在仍旧无法队Unicode进行正确的处理 与字符串有所不同的是，正则表达式有一个修饰符 u 被用以解决这类问题，但一个正则表达式使用了这个修饰符后，4个字节长的字符将被正确的处理 我们可以查找具有某种属性的字符，写作 \\p{...} ，为了顺利使用 \\p{...}，一个正则表达式必须使用修饰符u \\p{Letter} 表示任何语言中的一个字母，可以使用 \\p{L} 代替 let str = \"A ბ ㄱ\" // 英语，格鲁吉亚语，韩语字母 console.log(str.match(/\\p{L}/gu)) // ['A', 'ბ', 'ㄱ'] console.log(str.match(/\\p{L}/g)) // null 一个 16 进制数字可以表示为 \\p{Hex_Digit}： let regexp = /x\\p{Hex_Digit}\\p{Hex_Digit}/u; alert(\"number: xAF\".match(regexp)); // xAF 有一个 unicode 属性 Script （一个书写系统），这个属性可以有一个值：Cyrillic，Greek，Arabic，Han （中文）等等 let regexp = /\\p{sc=Han}/gu; // 返回中文 console.log(`Hello Привет 你好 123_456`.match(regexp).join('')) // 你好 接着是一个数字”的价格文本： let regexp = /\\p{Sc}\\d/gu; let str = `Prices: $2, €1, ¥9`; alert( str.match(regexp) ); // $2,€1,¥9 修饰符 u 在正则表达式中提供对 Unicode 的支持。 这意味着两件事： 4 个字节长的字符被以正确的方式处理：被看成单个的字符，而不是 2 个 2 字节长的字符。 Unicode 属性可以被用于查找中 \\p{…}。 有了 unicode 属性我们可以查找给定语言中的词，特殊字符（引用，货币）等等。 锚点（anchors）： 字符串开始^和末尾$ 插入符号 ^匹配文本开头，而美元符号 $ 匹配文本末尾 测试完全匹配，这两个锚点放在一起常常被用于测试一个字符串是否完全匹配一个模式 // 测试字符是否属于 12:34 的格式 let goodInput = '12:34' let errInput = '12:345' let regexp = /^\\d\\d:\\d\\d$/ console.log(regexp.test(goodInput)) // true console.log(regexp.test(errInput)) // false 锚点 ^ 和 $ 属于测试。它们的宽度为零。 换句话来说，它们并不匹配一个具体的字符，而是让正则引擎测试所表示的条件（文本开头/文本末尾） 多行模式Flag \"m\" 通过flag /.../m 可以开启多行模式，这仅仅影响 ^ 和 $ 锚符的行为，在多行模式下，它们不仅仅匹配文本的开始和结束，还匹配每一行的开始和结束 let str = `1st place: Winnie 2nd place: Piglet 33rd place: Eeyore`; console.log(str.match(/^\\d+/gm)) // ['1', '2', '33'] 词边界 \\b 词边界 \\b 是一种检查，就像 ^ 和 $ 一样，match 返回的应该是一个类数组 console.log('hello, java'.match(/\\bjava\\b/)) // ['java'] console.log('hello, javascript'.match(/\\bjava\\b/)) // null \\b 既可以用于单词，也可以用于数字 例如，模式 \\b\\d\\d\\b 查找独立的两位数。换句话说，它查找的是两位数，其周围是与 \\w 不同的字符，例如空格或标点符号（或文本开头/结尾）。 转义，特殊字符 所有特殊字符的列表：[ \\ ^ $ . | ? * + ( ) 如果要把特殊字符作为常规字符来使用，只需要在它的前面加一个反斜杠 斜杠符号 / 并不是一个特殊符号，他被用于在 JavaScript 中开启和关闭正则匹配 console.log('/'.match(/\\//)) // '/' console.log('/'.match(new RegExp('/'))) // '/' 在字符串中的反斜杠表示转义或者类似 \\n 这种只能在字符串中使用的特殊字符。这个引用会“消费”并且解释这些字符，所以调用 new RegExp 会获得一个灭有反斜杠的字符串，如果要修复这个，需要双斜杠 要在字面（意义）上搜索特殊字符 [ \\ ^ $ . | ? * + ( )，我们需要在它们前面加上反斜杠 \\（“转义它们”）。 如果我们在 /.../ 内部（但不在 new RegExp 内部），还需要转义 /。 传递一个字符串（参数）给 new RegExp 时，我们需要双倍反斜杠 \\\\，因为字符串引号会消费其中的一个。 集合和范围 [...] 在方括号 [...] 中的几个字符或者字符类意味着”搜索给定的字符中的任意一个\" console.log('Mop top'.match(/[tm]op/gi)) // ['Mop', 'top'] 请注意尽管在集合中有多个字符，但它们只会对应其中一个 方括号可以包含字符范围，比如说 [a-z]， [0-5] [0-8A-F] 表示两个范围：它搜索一个字符，满足其中一个条件，如果我们还想查找小写字母，则可以添加范围 a-f：[0-9A-Fa-f]。或添加标志 i。 由于字符类 \\w 是简写的 [a-zA-Z0-9_]，因此无法找到中文象形文字 除了普通的范围匹配，还有类似 [^...] 的排除范围匹配 通过在匹配查询的开头添加插入符号 ^ 来表示，它会匹配所有除了给定的字符之外的任意字符 [^aeyo] 匹配任何除了 a, e, y, o 之外的字符 在 [...] 中不转义， [-().^+] 会查找 -().^+ 的其中任意一个字符： 范围和标志 'u' alert( '𝒳'.match(/[𝒳𝒴]/u) ); // 𝒳 量词 +, *, ?, {n} 数量 {n} \\d{5} 表示 5 位的数字 某个范围的位数： {3, 5} 大多数量词都可以有缩写 + 代表一个或者多个，相当于 {1,} ? 代表一个或者0个，相当于{0, 1} * 代表零个或者多个，相当于 {0,} 正则表达式越精确，它就越长且越复杂 贪婪量词和惰性量词 量词看上去很简单，但实际上它可能会很棘手，如果我们打算寻找比 /\\d+/ 更加复杂的工作，就需要理解搜索工作是如何进行的 eg：有一个文本，我们需要用书名号： 《...》 来代理所有的 引号 “...”，第一想法是不是采用 /\".+\"/g 的正则去寻找，但是实际情况并不是这样的 str = '\"str\" is \"test\" str' console.log(str.match(/\".+\"/g)) // ['\"str\" is \"test\"'], 返回了一整个，而不是两个 贪婪搜索 为了查找到一个匹配项，正则表达式采用了以下算法：对于字符串中的每一个字符，用这个模式来匹配此字符，若无匹配，则移至下一个字符（回溯），在贪婪模式下（默认情况），量词都会尽可能的重复多次 懒惰模式 懒惰模式中的量词与贪婪模式中的是相反的，我们通过在量词后添加一个问好 ？ 来启用它，？它本身就是一个量词（0 或 1） 上例子中，正则表达式 /\".+?\"/g 就会如预期工作了 str = '\"str\" is \"test\" str' console.log(str.match(/\".+\"/g)) // ['\"str\"', '\"test\"'], 返回了两个 懒惰模式只能通过带 ？ 的量词启用 alert( \"123 456\".match(/\\d+ \\d+?/g) ); // 123 4 总结：量词有两种工作模式，贪婪模式和懒惰模式 捕获组 模式的一部分可以用括号括起来，这称为捕获组，它有两个影响： 它允许将匹配的一部分作为结果数组中的单独项 如果我们将量词放在括号后，则它将括号视为一个整体 eg： gogogo 'Gogogo now'.match(/(go)+/i) // 'Gogogo' eg：域名 let regexp = /(\\w+\\.)+\\w+/g \"site.com my.site.com\".match(regexp) //site.com my.site.com eg: email 名称可以是任何单词，可以使用连字符和点，在正则表达式是 [-.\\w]+ let regexp = /[-.\\w]+@([\\w-]+\\.)+[\\w-]+/g \"my@mail.com @ his@site.com.uk\".match(regexp) // ['my@mail.com', 'his@site.com'] eg： 匹配括号中的内容 括号可以嵌套，在这种情况下，编号从左往右 let str = ''; let regexp = /]*))>/; let result = str.match(regexp); alert(result[0]); // alert(result[1]); // span class=\"my\" alert(result[2]); // span alert(result[3]); // class=\"my\" 可选组，即使组是可选的并且在匹配项中不存在，也存在相应的 result 数组项，并且等于 undefined let match = 'a'.match(/a(z)?(c)?/); alert( match.length ); // 3 alert( match[0] ); // a（完全匹配） alert( match[1] ); // undefined alert( match[2] ); // undefined 搜索所有具有组的匹配项：matchAll，由 matchAll 所返回的每个匹配，其格式与不带标志 g 的 match 所返回的格式相同：它是一个具有额外的 index（字符串中的匹配索引）属性和 input（源字符串）的数组 命名组：用数字记录组很困难。对于简单模式，它是可行的，但对于更复杂的模式，计算括号很不方便。我们有一个更好的选择：给括号起个名字。 let dateRegexp = /(?[0-9]{4})-(?[0-9]{2})-(?[0-9]{2})/; let str = \"2019-04-30\"; let groups = str.match(dateRegexp).groups; alert(groups.year); // 2019 alert(groups.month); // 04 alert(groups.day); // 30 替换捕获组：方法 str.replace(regexp, replacement) 用 replacement 替换 str 中匹配 regexp 的所有捕获组。这使用 $n 来完成，其中 n 是组号 模式中的反向引用： \\N 和 \\k 我们可以将两种引号放在方括号中：['\"](.*?)['\"]，但它会找到带有混合引号的字符串，例如 \"...' 和 '...\"。当一种引号出现在另一种引号内，比如在字符串 \"She's the one!\" 中时，便会导致不正确的匹配： let str = `He said: \"She's the one!\".`; let regexp = /['\"](.*?)['\"]/g; // 不是我们想要的结果 alert( str.match(regexp) ); // \"She' 如我们所见，该模式找到了一个开头的引号 \"，然后文本被匹配，直到另一个引号 '，该匹配结束。 为了确保模式查找的结束引号与开始的引号完全相同，我们可以将其包装到捕获组中并对其进行反向引用：(['\"])(.*?)\\1。 这是正确的代码： let str = `He said: \"She's the one!\".`; let regexp = /(['\"])(.*?)\\1/g; alert( str.match(regexp) ); // \"She's the one!\" 选择 | gr(a|e)y 严格等同 gr[ae]y。 gra|ey 匹配 “gra” or “ey”。 时间正则表达式 // 错误版本 let reg = /[01]\\d|2[0-3]:[0-5]\\d/g; alert(\"12\".match(reg)); // 12 (matched [01]\\d) // 正确版本 let reg = /([01]\\d|2[0-3]):[0-5]\\d/g; alert(\"00:00 10:10 23:59 25:99 1:2\".match(reg)); // 00:00,10:10,23:59 正则表达式引擎查找选择模式的时是挨个查找的。意思是：它先匹配是否存在 Java，否则 —— 接着匹配 JavaScript 及其后的字符串。 变更匹配顺序，长的字符串优先匹配：JavaScript|Java|C\\+\\+|C|PHP。 合并相同前缀：Java(Script)?|C(\\+\\+)?|PHP。 运行代码如下： let reg = /Java(Script)?|C(\\+\\+)?|PHP/g; let str = \"Java, JavaScript, PHP, C, C++\"; alert( str.match(reg) ); // Java,JavaScript,PHP,C,C++ 前瞻断言与后瞻断言 有时候我们需要匹配后面跟着特定模式的一段模式。比如，我们要从 1 turkey costs 30€ 这段字符中匹配价格数值。 我们需要获取 € 符号前面的数值（假设价格是整数）。 那就是前瞻断言要做的事情。 前瞻断言 语法为：x(?=y)，它表示 “匹配 x, 仅在后面是 y 的情况\"” 语法为：x(?!y)，意思是 “查找 x, 但是仅在不被 y 跟随的情况下匹配成功”。 后瞻断言 前瞻断言允许添加一个“后面要跟着什么”的条件判断。 后瞻断言也是类似的，只不过它是在相反的方向上进行条件判断。也就是说，它只允许匹配前面有特定字符串的模式。 语法为: 后瞻肯定断言：(?, 匹配 x, 仅在前面是 y 的情况。 后瞻否定断言：(?, 匹配 x, 仅在前面不是 y 的情况。 灾难性回溯 有些正则表达式看上去很简单，但是执行起来耗时非常非常非常长，甚至会导致 JavaScript 引擎「挂起」。 开发者们很容易一不小心就写出这类正则表达式，所以我们迟早会面对这种意外问题。 典型的症状就是 —— 一个正则表达式有时能正常工作，但对于某些特定的字符串就会消耗 100% 的 CPU 算力，出现“挂起”现象。 在这种情况下，Web 浏览器会建议杀死脚本并重新载入页面。这显然不是我们愿意看到的。 在服务器端 JavaScript 中，在使用这种正则表达式处理用户数据时可能会引发程序漏洞。 搭建一个图床 利用Minio搭建私有图床 简介 图片存储服务，也叫图床，是博客需要具备的基础服务。过往我们采用的是公共免费的图床，但是这些服务有一些缺点： 存储容量受限 稳定性，可能突然对方不提供服务了 安全性，没在自己这始终不放心 因此，大家开始自建私有图床，参考的博客的采用的存储服务是Minio AWS S3 一文读懂 AWS S3 S3 的全名是 simple storage service，简单的存储服务。它的作用有： 提供了同一的接口 REST/SOAP 来统一访问任何数据 对 S3 来说，存在里面的就是对象名和数据 不限量，单个文件最高可达 5 TB 高速，每个 bucket 下每秒可达 3500 put/copy/post/delete 或 5500 get/head 请求 具备版本、权限控制能力 具备数据生命周期管理能力 每个对象最多指定 10 个标签（其实数据标签真的很有用） 防盗链 传说中防盗链的爱恨情仇 盗链是指自己的页面上展示一些并不在自己服务器上的内容。通常的做法是通过技术手段获得它人服务器上的资源地址，绕过别人的资源展示页面，直接在自己的页面上向最终用户提供此内容，比较常见的是一些小站盗用大站的资源 防盗链的原理：在HTTP协议中，如果从一个页面调到另一个页面，header字段里面会带个Referer，图片服务器通过检测Referer是否来自规定的域名来进行防盗链 前端常用功能集合 掘金 这位大佬自己动手做了前端的一些无依赖，精简高效的东西，然后按需应用到实际项目中，小白也想要一个一个的试试，就当练手了 http请求 前端必备技能，也是使用最多的技能。 基础知识 XMLHttpRequest (XHR) 对象用于与服务器交互，通过 XMLHttpRequest 可以在不刷新页面的情况下请求特定 URL，获取数据。这允许页面在不影响用户操作的情况下更行页面的局部内容，XMLHttpRequest 在 AJAX 编程中被大量使用。 AJAX(Asynchronous JavaScript And XML) 是一种使用 XMLHttpRequest 技术构建更复杂，动态的网页的编程实践。AJAX 允许只更新一个 HTML 页面的部分 DOM，而无须重新加载整个页面。AJAX 还允许异步工作，这意味着当网页的一部分正试图重新加载时，代码可以继续运行 AJAX 发送请求 为了使用 JavaScript 向服务器发送一个 http 请求，所以需要一个包含必要函数功能的对象实例，这就是为什么会有 XMLHttpRequest 的原因 创建一个 XMLHttpRequest 实例： // Old compatibility code, no longer needed. if (window.XMLHttpRequest) { // Mozilla, Safari, IE7+... httpRequest = new XMLHttpRequest() } else { httpRequest = new ActiveXObject(\"Microsoft.XMLHTTP\") } 发送一个请求后会收到响应，在这个阶段，需要告诉 XMLHttp 请求对象应该由哪一个 JavaScript 函数处理响应 httpRequest.onreadystatechange = nameofTheFunction; // 这个只是应用赋值，为了真正的调用，应该用个匿名函数 httpRequest.onreadystatechange = () => { // process the server response here. } 接下来，通过调用 HTTP 请求对象的 open() 和 send() 方法： httpRequest.open('GET', 'http://www.example.org/some.file', true) httpRequest.send() open 的第一个参数是 HTTP 请求，由 GET, POST, HEAD 以及服务器支持的其它方法，这些方法都是大写 第二个参数是你要发送的URL。由于安全原因，默认不能调用第三方 URL 域名。确保使用正确的域名，否则调用时会有\"permission denied\" 错误提示 第三个参数是设置请求是否异步，如果是 true 即代表是异步 send() 方法的参数可以是任何你想发送给服务器的内容，如果是 POST 请求的话，发送表单数据应该用服务器可以解析的格式 处理服务器响应 在发送请求时，我们提供的JavaScript函数负责处理响应，这个函数首先检查请求的状态，如果状态值是 XMLHttpRequest.DONE(对应的值是4)，意味着服务器响应收到了并且是没有问题的，然后可以继续执行 httpRequest.onreadystatechange = () => { if(httpRequest.readyState = XMLHttpRequest.DONE) { // everythin is good, the response is received. } else { // not ready yet. } } 接下来通过检查 200 OK 判断AJAX有没有成功 if (httpRequest.status === 200) { // perfect! } else { } 一个简单的例子 make a request (function() { var httpRequest; document.getElementById('test').addEventListener('click', makeRequest) function makeRequest() { httpRequest = new XMLHttpRequest() if(!httpRequest) { alert('Browser don\\'t support XMLHttpRequest.') return } httpRequest.onreadystatechange = handleRequest httpRequest.open('GET', 'www.test.com/test.html') httpRequest.send() } function handleRequest() { if(httpRequest.readystate = XMLHttpRequest.DONE) { if(httpRequest.status = 200) { alert(httpRequest.responseText) } else { alert('Something wrong.') } } } }) 在这个例子中： 用户点击“make a request” 按钮 事件处理调用 makeRequest() 函数 请求通过 onreadystatechange 传给 handleRequest 函数 handleRequest 函数首先进行判断，然后处理 提示： 如果你向一个代码片段发送请求，将返回 XML，而不是静态 XML 文件，在 IE 浏览器上则必须要设置响应头才能正常工作。如果不设置响应头 Content-Type: application/xml，IE 浏览器会在访问你的 XML 元素的时候抛出 “Object Expected” 错误 如果不设置响应头 Cache-Control: no-cache，那么浏览器会把响应缓存下来而且再也无法重新提交请求。还有一种做法是添加一个总是不同的 GET 参数，比如时间戳或者随机数 如果变量 httpRequest 在全局范围内使用，那么它会在 makeRequest() 函数中被相互覆盖，从而导致资源竞争，为了避免这个情况，请求包含 AJAX 函数的闭包中声明 httpRequest 变量 在通信错误的事件中（例如服务器宕机），在访问响应状态 onreadystatechange 方法中会掏出一个例外 exception，为了缓和这种情况，则可以使用 try...catch... function handleRequest() { try{ if(httpRequest.onreadystate === XMLHttpRequest.DONE) { if(httpRequest.status === 200) { // do something with httpRequest.responseText } else { alert('something wrong') } } } catch(e) { alert('Caught Exception: ' + e.description) } } XMLHttpRequest.readyState: 0 未初始化 或 请求还未初始化 1 正在加载 或 已建立服务器链接 2 加载成功 或 请求已接收 3 交互 或 正在处理请求 4 完成 或 请求已完成并且响应已准备好 XMLHttpRequest.status: 100-199 信息响应 200-299 成功响应 300-399 重定向消息 400-499 客户端错误响应 500-599 服务端错误响应 处理 XML 响应 在上一个例子中，在收到 HTTP 请求的响应后我们会使用对象的 responseText 属性，包含 test.html 文件的内容。现在我们试试 responseXML 属性 有效的 xml 文档： test 将 test.html 改为 test.xml ，然后再把 httpRequest.responseText 改为： let xmlDoc = httpRequest.responseXML; let rootNode = xmlDoc.getElementByTagName('root').item(0) alert(rootNode.firstChild.data) Fetch API Fetch API 提供了一个获取资源的接口（包括跨域请求）。任何使用过 XMLHttpRequest 的人都能轻松上手，新的 API 提供了更强大和灵活的功能集。Fetch 提供了对 Request 和 Response （以及其他与网络请求有关的）对象的通用定义。使之今后可以被使用到更多的应用场景中：无论是service worker、cache api、又或者是其它处理请求和响应的方式、甚至是任何一种需要再自己程序中生成响应的方式 fetch() 必须接受一个参数：资源的路径。无论请求成功与否，它都返回一个 Promise 对象，resolve 对应请求的 Response 简单使用： fetch('http://example.com/movies.json').then(response => response.json()).then(data => console.log(data)) fetch() 接收第二个可选参数，一个可以控制不同配置的 init 对象： // example of post method implementation by fetch api async function postData(url = '', data = {}) { const response = await fetch(url, { // default option are marked with * method: 'POST', // *GET, POST, PUT, DELETE, etc. mode: 'cors', // no-cors, *cors, same-origin cache： 'no-cache', // *default, no-cache, reload, force-cache, only-if-cached credentials: 'same-origin', // include, *same-cache, omit headers: { 'Content-Type': 'application/json' //'Content-Type': 'application/x-www-form-urlencoded' }, redirect: 'follow', //manual, *follow, error referrerPolicy: 'no-referrer', // no-referrer, *no-refer-when-downgrade, etc. body: JSON.stringfy(data) // body data type must match \"Content-Type\" header }) return response.json() // parses JSON response into native JavaScript objects } 使用 fetch() 发送 json 数据： // Post json data by fetch api fetch(url, { method: 'Post', headers: { 'Content-Type': 'application/json' }, body: JSON.stringfy(data) }) .then(res => res.json()) .then(data => console.log('success: ',data)) .catch((e) => { console.error('error: ', e) }) 通过 HTML 元素，FormData() 和 fetch() 上传文件： // Put file by fetch api const formData = new FormData() const fileField = document.querySelector('input[type=\"file\"]') formData.append('name', 'test') formData.append('file', fileField.files[0]) fetch(url, { method: 'PUT', body: formData }) .then(res => res.json()) .then(data => console.log('success: ', data)) .catch((e) => { console.error('error: ', e) }) 通过 HTML 元素，FormData() 和 fetch() 上传文件： // Post files by fetch api const filesField = document.querySelector('input[type=\"file\"][multiple]') const formData2 = new FormData() formData2.append('name', 'multiple files') for(let i = 0; i response.json()) .then(data => console.log('success: ', data)) .catch(e => console.error('error: ', e)) 从响应中读取的分块并不是按行分割的，并且是 Uint8Array 数组类型（不是字符串类型）。如果通过 fetch() 获取一个文本文件并逐行处理它，那需要自行处理这些复杂的情况： // Processing text files line by line async function* makeTextFileLineIterator(fileURL) { const utf8Decoder = new TextDecoder('utf-8') const response = new fetch(fileURL) const reader = response.body.getReader() let { value: chunk, done: readerDone} = await reader.read() chunk = chunk ? utf8Decoder.decode(chunk): '' const re = /\\n|\\r|\\r\\n/gm; let startIndex = 0 let result for(;;) { let result = re.exec(chunk) if(!result) { if(readerDone) { break } let remainder = chunk.substr(startIndex) ({ vlaue: chunk, done: readerDone} = await reader.read()); chunk = remainder + (chunk ? utf8Decoder.decode(chunk): '') startIndex = re.lastIndex = 0 continue } yield chunk.substring(startIndex, result.index) startIndex = re.lastIndex } if(startIndex 如果遇到网络故障或者服务端的 CORS 配置错误时， fetch() promise 将会 reject，带上一个 TypeError 对象 // Detecting the success of a request fetch('test.jpg') .then(response => { if(!response.ok) { throw new Error(\"Network response was not ok\") } return response.blob() }) .then(myBlob => { myImage.src = URL.createObjectURL(myBlob) }) .catch(err => console.error('error: ', error)) 除了传给 fetch() 一个资源的地址，还可以通过 Request() 构造函数来创建一个 request 对象，然后在作为参数传给 fetch()： // Customizing the request object const myHeader = new Headers() const request = new Request('test.jpg', { method: 'GET', headers: myHeader, mode: 'cors', cache: 'default' }) fetch(request) .then(response => response.blob()) .then(myBlob => myImage.src = URL.createObjectURL(myBlob)) 提示： 当请求使用 credentials: 'include' 时，响应的 Access-Control-Allow-Origin 不能使用通配符 *，在这种情况下， Access-Control-Allow-Origin 必须是当前请求的源 function 是定义一个生成器函数（generator function），它返回一个 generator 对象，generator 函数在执行时能暂停，后面又能从暂停出继续执行。调用一个 generator 函数并不会马上执行它里面的语句，而是返回一个这个生成器的迭代器（iterator）对象。当这个迭代器的 next() 方法被首次（后续）调用时，其内的语句会执行到一个出现 yield 的位置为止，yield 后紧跟迭代器要返回的值，如果使用的是 yield 则表示执行权移交给另一个生成器函数（当前生成器暂停执行）。当在生成器函数中显示 return 时，会导致生成器立即变成完成状态 Request() 构造器创建一个新的 Request 对象，语法： let myRequest = new Request(input[, init]) 不管是请求还是响应都能够包含 body 对象，body 也可以是以下任意类型的实例： ArrayBuffer ArrayBufferView(Uint8Array 等) Blob/File string URLSearchParams FormData Body 类定义了以下方法以获取 body 内容，这些方法都会返回一个别解析后的 Promise 对象和数据，相比于 XHR，这些方法让非文本化数据的使用更加简单： Request.arrayBuffer() Request.blob() Request.formData() Request.json() Request.text() JSDoc 使用JSDoc提高代码的可读性 讲的很好，脑容量要用到改用的地方，写出别人看不懂的代码不是什么能力，写出所有人能看懂的代码才是真的厉害 RESTful 理解 RESTful 架构 理解RESTful架构 越来越多的人意识到，网络即软件，而且是一种新型的软件，这种“互联网软件”采用客户端/服务端模式，建立在分布式体系上，通过互联网通信，具有高延时（hige latency），高并发等特点。网站开发，完全可以采用软件开发的模式，但是传统上，软件和网络是两个不同的领域，软件开发主要针对单机环境，网络则主要研究系统之间的通信。互联网的兴起，这两个领域开始融合，现在我们必须考虑，如何开发在互联网环境中使用的软件。 RESTful 架构是目前流行的一种互联网软件架构，它结构清晰、符合标准、易于理解、扩展方便，被多个网站所采用 起源 Fielding 在 2000 年的博士论文中提出，作者目的是在符合架构原理的前提下，理解和评估以网络为基础的应用软件的架构设计，得到一个功能强，性能好，适宜通信的架构。Fielding 将他对互联网软件的架构原则，定名为 REST，即 Representational State Transfer 的缩写，即 表现层状态变化。要理解 RESTful 架构，最好的方法就是去理解 Representational State Transfer 这个词组的意思。 资源（Resources) REST 的名称“表现层状态转化”中，省略了主语，表现层其实指的是资源（Resorces）的表现层 所谓资源，就是网络上的一个实体，或者说是网络上的一个具体的信息，可以用一个URI（统一资源定位符）指向它，每种资源对应一个特定的 URI，要获取这个资源，访问相应的 URI 即可。上网其实就是与互联网上的一系列资源的互动，调用它的URI 表现层（Representation） 资源是一种信息实体，它可以有很多种外在表现形式。我们把资源具体呈现出来的形式，叫做它的表现层（Representation）。比如，文本可以用txt格式表现，也可以用 HTML 格式、 XML 格式、 JSON 格式呈现；图片可以用 JPG 格式表现，PNG 格式表现。URI 只代表资源的实体，不代表它的具体形式，它的具体表现形式应该在 HTTP 请求的头信息中用 Accept 和 Content-Type 字段指定。 状态转化（State Transfer） 访问一个网站，就代表了客户端和服务端的一个互动过程，在这个过程中，势必涉及到数据和状态的变化。互联网通信协议 HTTP 协议是一个无状态协议，这意味着所有的状态都保存在服务器端，如果客户端想要操作服务器，必须通过某种手段让服务器端发生“状态转化”（State Transfer），而这种状态变化是建立在表现层之上的，所以就是“表现层状态转化” 客户端用到的手段只能是 HTTP 协议，具体来说就是 HTTP 协议中四个表示操作方式的动词：GET、POST、POST、PUT、 DELETE。它们分别对应四种基本操作：GET 用来获取资源，POST 用来新建资源（也可以用来更新资源），PUT 用来更新资源，DELETE 用来删除资源。 综述 综上，我们总结一下什么是RESTful 架构： 资源（Resource）：每一种 URI 表示一种资源 表现层（Representation）：客户端与服务器端传递这种资源的某种表现层 状态转化（State Transfer）：客户端通过 HTTP 四个动词对服务端资源进行操作，实现“表现层状态转化” RESTful 架构中不应该有动词 深入理解浏览器 原文：Inside look at modern web browse 翻译：深入了解现代浏览器 精读 分层结构 模块之间需要合理分工，一般称之为 renderer process 而不是 renderer thread，因为 process（进程）相比 thread（线程），之间的数据是被操作系统隔离的，为了网页间无法相互读取数据，浏览器必须为每个 tab 创建一个独立的进程，甚至每个 iframe 都必须是独立进程（但是我查询的 vue 中 tab 和 iframe 存在数据交互） UI thread 处理浏览器 UI 的展现与用户交互，比如当前加载的状态变化，历史前进后退，浏览器地址的输入、校验与监听按下 Enter 等事件，但不会涉及诸如发送请求、解析网页内容、渲染等内容 network thread 仅处理网络相关的事情，它主要关心通信协议、安全协议，目标就是快速准确的找到网站服务器，并读取其内容。network thread 会读取内容头做一些前置判断，读取内容和 renderer process 做的事情是有一定重合，但是 network thread 读取内容头仅为了判断内容类型，以便交给渲染引擎或者下载管理器（content-type 等设置），所以为了不让渲染引擎知道下载管理器的存在，读取内容头必须交给 network thread 来做 browser process 做与 renderer process 的通信， 也就是 UI thread、network thread 一旦要创建或与 renderer process 通信，都会交由它们所在的 browser process 处理 renderer process 仅处理渲染逻辑，它不关心从哪来的，比如是网络请求来的，还是 service worker 拦截后修改的，也不关心当前浏览器的状态是什么，它只管按照约定的接口规范，在指定的节点抛出回调，而修改应用状态由其它关心的模块复杂，比如 onload 回调触发后，browser process 处理浏览器的状态就是一个例子 假如 renderer process 里点击了一个新的跳转链接，这个事情是发生在 renderer process，但会交给 browser process 处理，因为每个模块解耦的非常彻底，所以任何复杂工作都能找到一个能响应它的模块，而这个模块也只要处理这个复杂工作的一部分，其余部分交给其它模块就好了，这就是大型应用维护的秘诀（类比 GFS 中的一个 master 节点，这些不就是设计的一些思想吗，说起来设计模式也只是看了一个开头） 提到加速优化，Chrome 惯用技巧就是用资源换时间（其实硬盘现在都不值钱，都是资源换时间，分布式也是想要通过空间换取其它东西）。即宁可浪费潜在资源，也要让事物尽可能的并发，这些从提前创建 renderer process、提前发起 network proces 都能看出来 从渲染分层看性能优化 渲染有 5 个重要环节：解析、样式、布局、绘图、合成，这是前端开发者日常工作中对浏览器体感最深的部分，也是优化最常发生的部分 从性能优化角度来看，解析环节可以被替代为 JS 环节，因为现代 JS 框架往往没有什么 HTML 模板内容要解析，几乎全是 JS 操作 DOM，所以可以看作 5 个新的环节：JS、样式、布局、绘图、合成 几乎每层的计算都依赖上层的结果，但并不是每层都一定会重复计算，尤其是以下几点： 修改元素的几何属性（位置、宽高等）会触发所有层的重新计算，因为这是一个非常重量级的修改 修改某个元素绘图属性（颜色、背景色），并不影响位置，则会跳过布局层 修改比如 transform 属性会跳过布局与绘图层，transform 的内容会提升到合成层并交由 GPU 渲染 隐式合成层、层爆炸、层自动合并 除了 transform、will-change 属性外，还有很多种情况元素会提升到合成层，比如 video、canvas、iframe、fixed 元素，这些都有明确的规则，所以属于显式合成 而隐式合成是指元素没有被特别标记，但也被提升到合成层的情况，这种情况常见发生在 z-index 元素产生重叠时，下方的元素显式申明提升到合成层，则浏览器为了保证 z-index 覆盖关系，就要隐式把上方的元素提升到合成层 层爆炸是指隐式合成的原因，当 css 出现一些复杂行为时（比如轨迹动画），浏览器无法实时捕捉到哪些元素位于当前元素上方，所以只好把所有元素都提升到合成层，当合成层数量过多，主线程与 GPU 的通信可能会成为瓶颈，反而影响性能 浏览器也会支持层自动合并，比如隐式提升到合成层时，多个元素会自动合并到一个合成层里。但这种方式不总是靠谱的，自动处理毕竟猜不到开发者的意图，所以最好的优化方式就是开发自己主动干预 浏览器规范由于是逐步迭代的，因此看似都在描述位置的 css 属性其实背后实现原理都是不同的，虽然这个规则体现在 W3C 规范上，但如果仅从属性名是很难看出端倪的，因此想要做极致性能优化就必须了解浏览器实现原理 深入理解浏览器一 CPU、GPU、操作系统、应用的关系 cpu：可以处理几乎所有计算，现在的cpu是多核的 gpu：开始专门为图像处理设计，现在拥有大量并行处理简单事物的能力，非常适合矩阵运算，矩阵运算又是图形学的基础，所以大量用在可视化领域 这些硬件各自都提供了一些接口供汇编语言使用，而操作系统基于它们之上用 c 语言（如Linux）将硬件管理了起来，包括进程调度、内存分配、用户内核态切换等 运行在操作系统之上的就是应用程序了，应用程序不直接和硬件打交道，而是通过操作系统间接操作硬件 为什么应用程序不能直接操作硬件呢？这样做有巨大的安全隐患，因为硬件是没有任何抽象与安全措施的，这意味着理论上一个网页可以通过 js 程序，在你打开网页时直接访问你的任意内存地址，读取你的聊天记录，甚至读取历史输入的银行卡密码进行转账操作。 进程与线程 为了让程序运行的更安全，操作系统创造了进程与线程的概念（Linux对进程与线程的实现是同一套），进程可以分配独立的内存空间，进程内可以创建多个线程进行工作，这些线程共享内存空间 因为线程间共享内存空间，因此不需通信就能交流，但内存地址相互隔离的进程间也有通信需求，需通过IPC（inter process communication）进行通信 进程之间相互独立，即一个进程挂了不会影响到其它进程，而在一个进程中可以创建一个新进程，并与之通信，所以浏览器就采用了这种策略，将UI、网络、渲染、插件、存储等模块进程独立，并且任意挂掉之后都可以被重新唤起 浏览器架构 浏览器可以拆分为许多独立的模块，比如 浏览器模块（Browser）：负责整个浏览器内行为协调，调用各个模块 网络模块（Network）：负责网络 I/O 存储模块（Storage）：负责本地 I/O 用户界面模块（UI）：负责浏览器提供给用户的界面模块 GPU模块：负责绘图 渲染模块（Rencderer）：负责渲染网页 设备模块（Device）：负责与各种本地设备交互 插件模块（Plugin）：负责处理各类浏览器插件 基于这些模块，浏览器有两种可用的架构设计：一种是少进程，一种是多进程 Chrome 多进程架构的优势 Chrome 尽量为每个 tab 单独创建一个进程，所以我们才能在某个tab未响应时，从容的关闭它，而其它tab不会受影响。不仅是tab间，一个tab内的iframe也会创建一个单独的进程 Chrome 并不满足于采用一种架构，而是在不同环境下切换不同的架构。Chrome 将各功能模块化后，就可以自由决定当前将哪些模块放在一个进程中，将哪些模块启动独立的进程，即可以在运行时决定采用哪套进程架构 浏览器的主从架构 类似应用模式的主从模式，浏览器的 Browser 模块可以看作是主模块，它本身用于协调其它模块的运行，并维持其它各模块的正常工作，在其它模块失去响应时等待或重新唤起，在模块销毁时进行内存回收 各从模块也分工明确，比如在浏览器敲击URL地址时，会先通过 UI 模块响应用户的输入，并判断输入是否是 URL 地址，若校验通过之后，会通知 Network 网络模块发送请求，UI 模块就不再关心请求是如何处理了。Network模块也是相对独立的，仅处理请求的发送与接收，如果接收到的是 HTML 网页，则交给 Render 模块进行渲染 有了这些相对独立且分工明确的模块划分后，将这些模块作为线程或进程管理就都不会影响他们的业务逻辑了，唯一影响的就是内存是否共享，以及某个模块 crash 后是否会影响其它模块了。 深入理解浏览器二 概述 重点介绍了浏览器路由跳转后发生了什么，上一篇介绍了，browser process 包含了 UI thread，network thread 和 storage thread，当我们在浏览器菜单栏输入网址并敲击回车时，这套动作均由 browser process 的 UI thread 响应 普通的跳转 UI thread 响应输入，并判断是否是合法的网址，如果是搜索协议，导致分发到另外的服务处理 如果第一步输入的是合法地址，则 UI thread 会通知 network thread 获取网页内容，network thread 会寻找合适的协议处理网络请求，一般会通过 DNS协议 寻址，通过 TLS 协议 建立安全链接。如果服务器返回了比如 301 重定向信息，network thread 会通知 UI thread 这个信息，再启动一遍第二步 读取响应内容，在这一步 network thread 会首先读取首部一些字节，即我们常说的响应头，其中包含 Content-Type 告知返回内容是什么，如果返回内容是 HTML，则 network thread 会将数据传送给 renderer process。这一步还会校验安全性，比如 CORB 或 cross-site 问题 寻找 renderer process，一旦所有检查都完成，network thread 会通知 UI thread 已经准备好跳转了（注意此时并没有加载完所有数据，第三步只是检查了首字节），UI thread 会通知 renderer process 进行渲染。为了提升性能， UI thread 在通知 network thread 的同时会实例化一个 renderer process 等着，一旦 network thread 完毕后就可以立即进入渲染阶段 确认导航。第四步后，browser process 通过 IPC 向 renderer process 传送 stream 数据，此时导航会被确认，浏览器的各个状态将会被修改，同时为了方便 tab 关闭后快速恢复，会话记录会被存储在硬盘 跳转到别的网站 如果是跳转到别的网站，在执行普通跳转流程前，还会响应 beforeunload 事件，这个事件注册在 renderer process，所以 browser process 需要检查 renderer process 是否注册了这个响应，如无必要，请勿注册。 如果跳转是 js 发出的，那么执行跳转就由 renderer process 触发，browser process 来执行，后续流程就是普通的跳转流程。需要注意的是，执行跳转时，会触发原网站 upload 等事件，这个由旧的 renderer process 响应，而新网站会创建一个新的 render process 处理，当旧网页全部关闭时，才会销毁旧的 renderer process Service Worker Service Worker 可以在页面加载前执行一些逻辑，甚至改变网页的内容，但是浏览器仍然把 Service Worker 实现在了 renderer process 中 深入理解现代浏览器三 概述 宏观介绍 renderer process 做了哪些事情。浏览器 tab 内 html、css、JavaScript 内容基本上都由 renderer process 的主线程处理，除了一些 js 代码会放在 web worker 或 service worker 内，所以浏览器主线程的核心工作就是解析 web 三件套并生成可交互的用户界面 解析阶段 首先 renderer process 主线程会解析 HTML 文本为 DOM（Document Object Model，文档对象模型），要把文本结构化才能继续处理。 对于 HTML 的 link、script、img 需要加载远程资源的，浏览器会调用 network thread 优先并行处理，但遇到 script 标签就必须停下来优先执行，因为 js 代码可能会改变任意 DOM 对象，这可能导致浏览器重新解析。如果 js 代码中没有修改 DOM 的副作用，可以添加 async， defer 标签，或则弄成 js 模块的方式，这样浏览器不必等待 js 的执行 样式计算 只有 DOM 是不够的，style 标签申明的样式需要作用在 DOM 上，所以基于 DOM，浏览器要生成 CSSOM，这个 CSSOM 主要基于 css 选择器（selector）确定作用节点的 布局 有了 DOM、CSSOM 仍然不足以绘制网页，因为仅知道结构和样式，但不知道元素的位置，这就需要生成 LayoutTree 以描述布局的结构。LayoutTree 和 DOM 结构很像，但比如 display:none 的元素不会出现在 LayoutTree 上，所以 LayoutTree 仅考虑渲染结构，而 DOM 是一个综合性描述结构，它不适合用来渲染 原文特别提到，Layout Tree 有个很大的技术难点：排版，Chrome 专门有一整个团队在攻克这个技术难题。为什么排版难：盒模型之间的碰撞、字体撑开内容导致换行，引发更大区域的的重新排版、一个盒模型撑开挤压另外一个盒模型... 布局最难的地方在于，需要对所有奇奇怪怪的布局做一个尽量合理的处理，而很多时候布局定式间的规则是相互冲突的。而且这还不考虑布局引擎的修改在数亿网页上引发 bug 的风险 绘图 最后一环 PaintRecord，绘图记录。它会记录元素的层级关系，以决定元素绘制的顺序。因为 LayoutTree 仅决定了物理结构，但不决定元素的上下空间结构 有了 DOM、CSSOM、LayoutTree、PaintRecord 之后，终于可以绘图了。然后当 HTML 变化时，重绘的代价是巨大的，因为上面的任何一步的计算结果都依赖前面一步，HTML 改变时，需要对 DOM、CSSOM、LayoutTree、PaintRecord 重新计算。 大部分时候浏览器都可以在 16 ms 内完成，使 FPS 保持在 60 左右，但当页面结构过于复杂，这些计算本身超过了 16 ms，或其中遇到了 js 代码的阻塞，都会导致用户感到卡顿。对于 js 卡顿可以通过 requestAnimationFrame 把逻辑运算分散在各帧空闲时进行，也可以独立到 web worker 里。 合成 绘图的步骤称为 rasterizing（光栅化）。在 Chrome 最早发布时，采用了一种较为简单的光栅化方案，即仅渲染可视区域内的像素点，当滚动后，再补充渲染当前滚动位置的像素点。这样做会导致渲染永远滞后于滚动 现在一般采用较为成熟的合成技术（compositing），即将渲染内容分层绘制与渲染，这可以大大提升性能，并可通过 CSS 属性 will-change 手动申明一个新层（不要滥用） 浏览器会根据 LayoutTree 分析后得到 LayerTree（层树），并根据它逐层渲染，合成层会将绘图内容切分为多个栅格并交由 GPU 渲染，因此性能会非常好 "},"languages/Node.html":{"url":"languages/Node.html","title":"Node","keywords":"","body":"Node.js [toc] 作为一个异步事件驱动的 js 运行时，node.js 被设计用来构建可扩建的可扩展的网络应用 现在看的是 一起学node.js 知识点讲解 require require 可以用来加载一个文件的代码，可加载 js、json、 和 .node 后缀的文件，require的过程是i同步的 require 的目录机制是：如果目录下有 package.json 并指定了main字段，则用它，如果不存在，则一次加载 index.js 和 index.node 判断是否是程序的入口文件： require.main === module 不在最外层 require，在用到的时候 require exports 和 module.exports require 用来加载代码，而 exports 和 module.exports 用来导出代码，exports 是指向 module.exports 的引用 express express 路由 和 模板引擎 ejs，express的精髓在于中间件（middleware）的设计理念 express 中的中间件（middleware）就是用来处理请求的，当一个中间件处理完，可以通过调用 next() 传递给下一个中间件，如果没有调用 next()，则请求不会往下传递，如内置的 res.render 其实就是渲染完 html 直接返回给客户端，没有调用 next()，从而没有传递给下一个中间件。看个小例子，修改 index.js 如下： 从 GitHub 安装 express-formidable 最新版，v1.0.0 有 bug example myblog restful 是一种 api 设计风格，提出了一组api 的设计原则和约束条件 如上面删除文章的路由设计： GET /posts/:postId/remove Restful 风格的设计： DELETE /posts/:postId cookie 和 session 由于http 协议是一种无状态协议，所以服务端需要记录用户状态时，就需要session 他俩的区别： cookie是浏览器的，有大小限制，session是服务端的，没有大小限制 通常 session 的实现是基于 cookie 的， session的 id 存储于 cookie 中 session更安全，cookie 可以直接在浏览器中查看并编辑 组件的概念 上面的 ejs 模板中我们用到了 blog、user、success、error 变量，我们将 blog 变量挂载到 app.locals 下，将 user、success、error 挂载到 res.locals 下。为什么要这么做呢？app.locals 和 res.locals 是什么？它们有什么区别？ express 中有两个对象可用于模板的渲染，app.locals 和 res.locals 可以看出：在调用 res.render 的时候，express 合并（merge）了 3 处的结果后传入要渲染的模板，优先级：res.render 传入的对象> res.locals 对象 > app.locals 对象，所以 app.locals 和 res.locals 几乎没有区别，都用来渲染模板，使用上的区别在于：app.locals 上通常挂载常量信息（如博客名、描述、作者这种不会变的信息），res.locals 上通常挂载变量信息，即每次请求可能的值都不一样（如请求者信息，res.locals.user = req.session.user）。 node-mongodb-native 与 mongoose，前者是官方库，但是不支持文档校验，mongoose 通过 schema 支持文档校验 mongolass 保持了与 mongodb 一样的api，又借鉴了许多 mongoose 的优点，同时又保持了精简 Node入门 绪论 应用本身并没有什么了不起的，相比为了实现该功能书写的代码本身，我们更关注的事如何创建一个框架类对我们应用的不同模块进行干净的剥离 本书三部分结构： node.js 中进行JavaScript 开发和在浏览器中进行 js 开发的差异 node.js 应用 如何设计一个完整的应用，剖析不同的模块 JavaScript 与 node.js 现在还是一个 JavaScript 用户，而非 JavaScript 开发者，写Node.js应用是一件事情；理解为什么它们要以它们书写的这种方式来书写则意味着——你要懂JavaScript。这次是玩真的了。 要实现在后台运行 JavaScript 代码，代码需要先被解释然后正确的执行，node.js 的原理正是如此，它使用了 Google 的 V8虚拟机来解释和执行 JavaScript 代码，此外 node.js 还有许多有用的模块，node.js 事实上既是一个运行时环境，也是一个库 简单应用 目标： 用户可以通过浏览器使用我们的应用。 当用户请求http://domain/start时，可以看到一个欢迎页面，页面上有一个文件上传的表单。 用户可以选择一个图片并提交表单，随后文件将被上传到http://domain/upload，该页面完成上传后会把图片显示在页面上。 分析： 我们需要提供Web页面，因此需要一个HTTP服务器 对于不同的请求，根据请求的URL，我们的服务器需要给予不同的响应，因此我们需要一个路由，用于把请求对应到请求处理程序（request handler） 当请求被服务器接收并通过路由传递之后，需要可以对其进行处理，因此我们需要最终的请求处理程序 路由还应该能处理POST数据，并且把数据封装成更友好的格式传递给请求处理入程序，因此需要请求数据处理功能 我们不仅仅要处理URL对应的请求，还要把内容显示出来，这意味着我们需要一些视图逻辑供请求处理程序使用，以便将内容发送给用户的浏览器 最后，用户需要上传图片，所以我们需要上传处理功能来处理这方面的细节 对于node.js来说，使用 node.js，我们不仅仅事在实现一个应用，同时还实现了整个 http 服务器 构建应用的模块 server.js let http = require('http') http.createServer(function(req,res) { res.writeHeader(200, {'Content-Type': 'text/plain'}) res.write('hello, world') res.end() }).listen(8888) 我们请求了 node.js 自带的http模块，调用http模块的 createServer函数，该函数会返回一个对象，这个对象有个listen的方法，该方法有个一个数值的参数，用来指定这个http服务器监听的端口号 在 JavaScript 中，函数和其他变量一样都是可以被传递的 为什么要用函数传递的方式呢？ node.js 是基于事件驱动的回调，当我们使用 http.createServer 方法的时候，我们当然不只是想要一个侦听某个端口的服务器，我们还想它在服务器收到一个 http 请求的时候做点什么，问题是，这是异步的：请求任何时候都可能到达，但是我们的服务器却跑在一个单进程里面 写 php 应用的时候，任何时候有请求进入的时候，网页服务器（apache）就为这个请求新建一个进程，并开始执行脚本 那么在node.js 程序中，当一个新的请求到达时，我们怎么控制流程呢？ 我们创建了服务器，并且向创建它的方法传递了一个函数，无论何时我们的服务器收到一个请求，该函数就会被调用，这个就是回调，我们给某个地方传递了一个函数，这个方法在有相应事件发生的时候调用这个函数来进行回调 大部分浏览器都会在你访问 http://localhost:8888/ 时尝试读取 http://localhost:8888/favicon.ico 服务器是如何处理请求的 在函数中有两个参数：request 和 response，它们是对象，你可以使用它们的方法来处理HTTP请求的细节，并且响应请求 当收到请求时，使用 res.writeHead() 函数发送一个 http 状态 200 和 http头的内容类型，使用res.write() 函数在HTTP相应主体中发送文本，最后调用 res.end() 完成响应 把某段代码变成模块意味着我们希望提供其功能的部分，并导出到请求这个模块的脚本 我们现在可以把我们应用的不同部分放入不同的文件里，并且通过模块的方式把它们连接在一起 url 和 querystring 我们的服务器应当知道路由的存在并加以有效利用。我们当然可以通过硬编码的方式将这一依赖项绑定到服务器上，但是其它语言的编程经验告诉我们这会是一件非常痛苦的事，因此我们将使用依赖注入的方式较松散地添加路由模块（你可以读读Martin Fowlers关于依赖注入的大作来作为背景知识）。 依赖注入不应该仅仅为使用而使用，使用依赖注入可以让路由和请求处理程序之间的耦合更加松散，重用性更高 在C++或C#中，当我们谈到对象，指的是类或者结构体的实例。对象根据他们实例化的模板（就是所谓的类），会拥有不同的属性和方法。但在JavaScript里对象不是这个概念。在JavaScript中，对象就是一个键/值对的集合 -- 你可以把JavaScript的对象想象成一个键为字符串类型的字典。 此就有了简洁流畅的形如handlepathname;的表达式 server，route，requestHandlers 三个模块都有了，浏览器传给了server，再传给了route，再传给了 requestHanlders，现在需要requestHandlers做出回应了 如果回应是直接 return，当未来有请求处理程序是进行非阻塞的操作的时候，我们的应用就挂了 阻塞操作：一个工作阻塞了所有其它的处理工作 node.js 可以再不新增额外线程的情况下，依然对任务进行并行处理 child_process 可以用来执行 shell命令 然而，要用非阻塞操作，我们需要使用回调，通过将函数作为参数传递给其他需要花时间做处理的函数（比方说，休眠10秒，或者查询数据库，又或者是进行大量的计算）。 对于Node.js来说，它是这样处理的：“嘿，probablyExpensiveFunction()（译者注：这里指的就是需要花时间处理的函数），你继续处理你的事情，我（Node.js线程）先不等你了，我继续去处理你后面的代码，请你提供一个callbackFunction()，等你处理完之后我会去调用该回调函数的，谢谢！” 现在我们能够异步的运行一些命令了，模块也分开了，但是我们的应用并没有实际的用途 添加一个交互：用户选择一个文件，上传该文件，然后再浏览器中看到上传的文件 用node.js 来处理文件上传（multipart post 请求） 是比较复杂的 post请求一般都比较重，用户可能输入大量内容，用阻塞的方式处理大数据量的请求必然会导致用户操作的阻塞，为了使整个过程非阻塞，node.js会将post数据拆分成很多个小的数据块，然后通过促发特定的事件，将这些小数据块传递给回调函数，这里的特定事件就是有data事件（表示新的小数据块到达了）以及end事件（表示所有的数据都已经接收完毕） 我们需要告诉 node.js 当这些事件触发的时候，回调哪些函数，怎么告诉呢，我们通过在 request 对象上注册监听器（listener）。这里的request对象是每次接收到 http请求时候，都会把该对象传递给 onRequest 回调函数 request.addListener(\"data\", function(chunk) { // called when a new chunk of data was received }); request.addListener(\"end\", function() { // called when all chunks of data have been received }); 问题来了，这部分逻辑写在哪里呢？我们现在只是在服务器中获取到了request对象，我们并没有像之前 response 对象那样，把 request对象传递给请求路由和请求处理程序 在我看来，获取所有来自请求的数据，然后将这些数据交给应用层处理应该是http服务器要做的事，因此我们直接在服务器中处理 post 数据，然后将最终的数据传递给请求路由和请求处理器 上述代码做了三件事：首先设置了接收数据的编码格式为 utf-8 ， 然后注册了'data' 事件的监听器，用于收集每次接收到的新数据块，最后将路由的调用放到了end事件处理程序中 当前我们是把请求的整个消息体都传递给了请求路由和请求处理程序，我们应该只把 post数据中我们感兴趣的部分传递给请求路由和请求处理程序 formidable模块对解析上传的文件数据做了很好的抽象，其实说白了，处理文件上传就是处理post数据，但是，麻烦的就是在具体的处理细节 我们需要将文件读取到我们的服务器中，使用一个叫fs的模块 supervisor express 使用了 path-to-regexp 模块实现的路由匹配 const app = express() app.get('/users/:name', function(req, res) { res.send('hello, ' + req.params.name) }) 模板引擎有很多种， ejs 是其中一种 app.set('views', path.join(__dirname, 'views')) app.set('view engine', 'ejs') express 理论上基于 connect 实现的中间件 second time 我们将 / 和 /user/:name 的路由分别放到了 routes/index.js 和 routes/users.js 中，每个路由文件通过生成一个 express.Router 实例并导出，通过 app.use 挂载到不同的路径，在实际开发中推荐使用 express.Router 将不同的路由分离到不同的路由文件中 通过 app.use 加载中间件，在中间件中通过next 将请求传递到下一个中间件， next 可接受一个参数接收错误信息 fs (文件系统) fs 模块可用于与文件系统进行交互，所有的文件系统操作都具有同步的、回调的、以及基于 promise 的形式 const fs = require('fs') // 同步的示例 try { fs.unlinkSync('文件') console.log('已成功删除文件') } catch (err) { } // 回调的示例 fs.unlink('文件'， (err) => { if (err) throw err; console.log('已成功删除文件') }) // promise 的示例 (async function(path) { try { await fs.unlink(path); console.log('已成功删除文件') } catch { } })('文件') err 感觉都在第一个参数 err 优先回调风格 readFile open writeFile access stat mkdir readdir rmdir unlink 回调与基于 promise 的操作的顺序，当使用异步的方法，无法发保证顺序 fs.rename('旧文件'， '新文件'， (err) => { if(err) throw err; console.log('重命名完成') }) fs.stat('新文件', (err, stats) => { if (err) throw err: console.log(`文件属性： ${JSON.stringify(stats)}`) }) 若要正确的排序这些操作，则移动 fs.stat() 调用到 fs.rename() 操作的回调中： fs.rename('旧文件', '新文件'， (err) => { if(err) throw err; fs.stat('新文件'， (err, stats) => { if(err) throw err; console.log(`文件属性： ${JSON.stringify(stats)}`) }) }) // 或者使用 promise (async function(from, to) { try { await fs.rename(from, to); const stats = await fs.stat(to); console.log(`文件属性： $({JSON.stringigy(stats)}`) } catch (err) { console.log('出错： '， err.message) } })('旧文件'， '新文件') 回调 因为函数能够作为变量，所以可以有回调这种写法？，函数不作为变量也可以有回调这种写法吧，但是函数作为变量的话看着要清楚一点 回调应该要考虑如果出现错误的情况，error优先回调风格，约定是： callback 的第一个参数是为了 error 而保留的，一旦出现 error， callback(err) 就会被调用 第二个参数及以后的参数用于成功的结果，此时是 callback(null, res1, res2) 就会被调用 promise 对象的构造器（constructor）语法如下： let promise = new Promise(function(resolve, reject) { // executor }) 当 executor 获得了结果，无论是早还是晚都没关系，它应该调用以下回调之一： resolve(value) — 如果任务成功完成并带有结果 value。 reject(error) — 如果出现了 error，error 即为 error 对象。 由 new Promise 构造器返回的 promise 对象具有以下内部属性： state — 最初是 \"pending\"，然后在 resolve 被调用时变为 \"fulfilled\"，或者在 reject 被调用时变为 \"rejected\"。 result — 最初是 undefined，然后在 resolve(value) 被调用时变为 value，或者在 reject(error) 被调用时变为 error。 promise 只能有一个结果或者一个error promise 做出承诺之后，后者通过 then, catch, finally 接收结果或者 error pormise.then(function(result) {},function(err) {}) .then 的第一个参数是一个函数，该函数在 promise resolved 后运行并接收结果，第二个参数也是一个函数，该函数在promise rejected后运行并接收结果 let promise = new Promise(function(resolve, reject) { setTimeout(() => resolve('done!'), 1000); }) promise.then(res=>{alert(res)}, err=>{alert(err)}) let promise = new Promise(function(resolve, reject) { setTimeout(() => reject(new Error('err')), 1000) }) promise.then(res =>{alert(res)}, err => {alert(err)}) 如果我们只对成功完成的情况感兴趣，则可以只为 .then 提供一个函数，如果我们只对失败的情况感兴趣，则可以 .then(null, err) 或者 使用 catch promise 中的 .finally(f) 并不意味着要处理 promise 的结构，所以它将结果传递了下去 // 基于回调的函数 function loadScript(src, callback) { let script = document. } nodejs: 浅析高并发和分布式集群 nodejs的几个特性 单线程 异步I/O 事务驱动 分布式Node架构 event loop normal stack $\\Rightarrow$ setTimeout({}, 0) (process.nextTick、 setImmediate) $\\Rightarrow$ message Queue $\\Rightarrow$ job queue error-first callbacks promise: a proxy for a value that will eventually become available $\\Rightarrow$ async await promise: remain in a pending state \\ promisifying \\ util.promisify chaining promises: return Promise.resolve(), Promise.reject() response: status, statusText, json()(return a promise) promise.all() promise.race() prepending the async keyword to any function means that the function will return a promise const getFirstUserData = () => { return fetch('/usres.json') // get users list .then(response => respongse.json()) // parse json .then(usres => users[0]) // pick first user .then(user => fetch(`/user/${user.name}`)) // get user data .then(userResponse => userResponse.json()) // parse json } getFirstUserData() const getFirstUserData = async () => { const response = await fetch('/user.json') // get users list const users = await response.json() // parse json const user = users[0] // pick first user const userResponse = await fetch(`/users/${user.name}`) // get user data const userData = await userResponse.json // parse json return userData } getFirstUserData() Debugging promises is hard because debugger will not stop over asynchronous code. Async/await makes this very easy because to the compiler it's just like synchronous code. EventEmitter const EventEmitter = require('event') const eventEmitter = new EventEmitter() const http = require('http') const port = process.env.PORT const server = http.createServer((req, res) => { res.statusCode = 200 res.setHeader('Content-Type', 'text/html') res.end('Hello, world!') }) server.listen(port, () => { console.log(`Server running at port ${port}`) }) request http.IncomingMessage request headers and request data response http.ServerResponse perform a get request const https = request('https') const options = { hostname: 'example.com', port: 443, path: '/todos', method: 'GET' } const req = https.request(options, res => { res.on('data', d => { process.stdout.write(d) }) req.on('error', error => { console.log(error) }) }) req.end() perform a post request const https = require('https') const data = new TextEncoder().encode( JSON.stringify({ todo: 'Buy thie milk 🍼' }) ) const optoins = { hostname: 'whatever.com', por: 443, path: '/todos', method: 'POST', headers: { 'Content-Type': 'application/json', 'Content-Length': data.length } } const req = http.request(options, res => { res.on('data', d => { process.stdout.write(d) }) }) req.on('error', err => console.log(err)) req.write(data) req.end() const axios = require('axios') axios.post('https://watever.com/todos', { todo: 'but the milk' }) .then(res => { console.log(`statusCode: ${res.status}`) console.log(res) }) .catch(error => { console.log(error) }) path dirname basename extname path.basename(notes, path.extname(notes)) join resolve normalize fs.writeFile('/test.txt', content, {flag: 'a+'}, err => {}) const isFile = fileName => { return fs.lstatSync(fileName).isFile() } fs.readdirSync(folderPath).map(fileName => { return path.join(folderPath, fileName) }).filter(isFile) fs.rmdir(dir, {recursive: true}, (err) => { if(err) { throw err } console.log(`${dir} is deleted.`) }) fs-extra buffer deal with binary data why streams: 1. memory efficiency 2. time efficiency const http require('http') const fs = require('fs') const server = http.createServer((req, res) => { fs.readFile(__dirname + '/data.txt', (err, data) => { res.end(data) }) }) server.listen(3000) const http = require('http') const fs = require('fs') const server = http.createServer((req, res) => { const stream = fs.createReadStream(__dirname + '/data.txt') stream.pipe(res) }) server.listen(3000) src.pipe(dest1).pipe(dest2) MongoDB 操作 blog {$lt: } {$lte: } {$gte: } {$ne: } {$in: []} ··· mongoose spawn 的坑 使用node子进程 spawn, exec 踩过的坑 使用 spawn 的时候，子进程有太多的日志输出，导致该子进程卡在那里，没有正常或者异常的退出，文件也被占用着，最坑的是一点提示都没有 child_process 介绍 nodejs 是单线程单进程的，但是有了 child_process 模块，可以在程序中直接创建子进程，并在主进程和子进程之间实现通信 exec与spawn的区别与陷阱 exec与spawn方法的区别与陷阱 2011年的文章了，，，好老 exec 和 spawn 都是通过生成一个子进程，去执行指定的命令，但是在命令的指定上，exec 更加灵活，等于一个 shell 的命令行，他俩都有参数的 spawn 的 options 默认为： { cwd: undefined, env: process.env, setsid: false } exec 的 option 默认为： { encoding: 'utf8', timeout: 0, /*子进程最长执行时间 */ maxBuffer: 200*1024, /*stdout和stderr的最大长度*/ killSignal: 'SIGTERM', cwd: null, env: null } 注意 maxBuffer 这个参数，如果 stdout 的值超过 200 k 的时候就会杀死进程，其实spawn 表现的更差，当 spawn 的子进程的 stdout 更多的时候会出现我前文说过的问题，文章中说 spawn 没有 maxBuffer 限制，但是我个人感觉还是有 maxBuffer 的类似限制。exec 在使用便捷上要超过 spawn，且执行速度上也相差无几，但是这种便携性要付出一定的代价。在exec的options中，有一项是 maxBuffer，如果执行的 command 输出超出了这个长度，不管是采用回调函数的方式，还是emit data 事件方式传递结果，都会抛出 maxBuffer exceeded异常，并且杀死子进程 "},"languages/Python.html":{"url":"languages/Python.html","title":"Python","keywords":"","body":"python 利用python进行数据分析第二版 python-offer python解决剑指offer和一些算法 "},"languages/TypeScript.html":{"url":"languages/TypeScript.html","title":"TypeScript","keywords":"","body":"TypeScript 接口是一系列抽象方法的声明，是一些方法特征的集合，这些方法应该都是抽象的，需要由具体的类去实现，然后第三方就可以通过这组抽象方法调用 interface IPerson{ firstName: string, lastName: string, sayHi: () => string } let customer: IPerson = { firstName: 'Tian', lastName: 'Wu', sayHi: ():string => {return 'hello, world'} } console.log('customer: ', customer) let test: IPerson = { firstName: 'testFirst', lastName: 'testLast', sayHi: ():string => {return 'hey, I\\'m testing'} } console.log('test: ', test) interface Person { age: number } interface Musician extends Person { instrument: string } let drummer = {} drummer.age = 27 drummer.instrument = 'Drums' console.log('drummer: ', drummer) TypeScript 是面向对象的 JavaScript。 类描述了所创建的对象共同的属性和方法。 TypeScript 支持面向对象的所有特性，比如 类、接口等。 定义类的关键字为 class，后面紧跟类名，类可以包含以下几个模块（类的数据成员）： 字段 − 字段是类里面声明的变量。字段表示对象的有关数据。 构造函数 − 类实例化时调用，可以为类的对象分配内存。 方法 − 方法为对象要执行的操作。 TypeScript 支持继承类，即我们可以在创建类的时候继承一个已存在的类，这个已存在的类称为父类，继承它的类称为子类。 类继承使用关键字 extends，子类除了不能继承父类的私有成员(方法和属性)和构造函数，其他的都可以继承。 TypeScript 一次只能继承一个类，不支持继承多个类，但 TypeScript 支持多重继承（A 继承 B，B 继承 C）。 子类只能继承一个父类，typescript 不支持继承多个类，但支持多重继承 类继承后，子类可以对父类的方法重新定义，这个过程称之为方法的重写 其中super关键字是对父类的直接引用，该关键字可以直接引用父类的属性和方法 instanceof 运算符用于判断对象是否是指定的类型，如果是返回true， 否则返回false，父类包括了子类 static 关键字用于定义类的数据成员（属性和方法）为静态的，静态成员可以直接通过类名调用。（没有初始化就可以调用） 访问控制修饰符 public: 公有，可以在任何地方被访问 protected: 保护，可以被其自身及其子类和父类访问 private： 私有，只能在被其定义所在的类访问 类和接口 类可以实现接口，是有关键字implements(interface)，并将interest作为类的属性使用 鸭子类型（duck typing） （还不懂） 鸭子类型（英语：duck typing）是动态类型的一种风格，是多态(polymorphism)的一种形式。 在这种风格中，一个对象有效的语义，不是由继承自特定的类或实现特定的接口，而是由\"当前方法和属性的集合\"决定。 可以这样表述： \"当看到一只鸟走起来像鸭子、游泳起来像鸭子、叫起来也像鸭子，那么这只鸟就可以被称为鸭子。\" 在鸭子类型中，关注点在于对象的行为，能作什么；而不是关注对象所属的类型。例如，在不使用鸭子类型的语言中，我们可以编写一个函数，它接受一个类型为\"鸭子\"的对象，并调用它的\"走\"和\"叫\"方法。在使用鸭子类型的语言中，这样的一个函数可以接受一个任意类型的对象，并调用它的\"走\"和\"叫\"方法。如果这些需要被调用的方法不存在，那么将引发一个运行时错误 typescript命名空间 命名空间一个最明确的目的就是解决重名问题 如果一个命名空间在一个单独的typeScript文件忠，则应该使用三斜杠 /// 引用它 我可以认为模块就是一个文件级别的命名空间吗，这种不需要写namespace了（但是实际上不是这样的，编译的结果不一样） typescript 声明文件 TypeScript 作为 JavaScript 的超集，在开发过程忠不可避免要引用第三方的JavaScript的库，虽然可以直接通过调用库的类和方法，但是却无法使用 typeScript 诸如类型检查等特性功能。为了解决这个问题，需要将这些库里的函数和方法体去掉后只保留导出类型声明，而产生了一个描述JavaScript库和模块信息的声明文件，通过引用这个声明文件，就可以借用 typescript 的各种特性来使用库文件了 声明文件以 .d.ts 为后缀 Jest 作为 typescript 的单元测试 /** * 判断一个value是不是 NaN、null、undefined * @param value */ export function isNull(value): boolean { return String(value) ==== 'NaN' || value === null || value === void 0 } 正则表达式 （元字符感觉还行，但是简写字符集、断言自己有i点会懵） 元字符 . 匹配除换行符以外的任意字符。 [ ] 字符类，匹配方括号中包含的任意字符。 否定字符类。匹配方括号中不包含的任意字符 * 匹配前面的子表达式零次或多次 + 匹配前面的子表达式一次或多次 ? 匹配前面的子表达式零次或一次，或指明一个非贪婪限定符。 {n,m} 花括号，匹配前面字符至少 n 次，但是不超过 m 次。 (xyz) 字符组，按照确切的顺序匹配字符 xyz。 \\ 分支结构，匹配符号之前的字符或后面的字符。 \\ 转义符，它可以还原元字符原来的含义，允许你匹配保留字符 `[ ] ( ) { } . * + ? ^ $ \\ ` ^ 匹配行的开始 $ 匹配行的结束 简写字符集 . 匹配除换行符以外的任意字符 \\w 匹配所有字母和数字的字符：[a-zA-Z0-9_] \\W 匹配非字母和数字的字符：[^\\w] \\d 匹配数字：[0-9] \\D 匹配非数字：[^\\d] \\s 匹配空格符：[\\t\\n\\f\\r\\p{Z}] \\S 匹配非空格符：[^\\s] 断言 ?= 正向先行断言 ?! 负向先行断言 ? 正向后行断言 ? 负向后行断言 标记 i 不区分大小写：将匹配设置为不区分大小写。 g 全局搜索：搜索整个输入字符串中的所有匹配。 m 多行匹配：会匹配输入字符串每一行。 TypeScript 教程 入门教程 [toc] 简介 大部分JavaScript代码都只需要少量的修改就变成typescript，这得益于typescript强大的[类型推论] []，即使不去手动声明变量的类型，typescript也可以自动推论出它的类型 console.log(1 + '1'); // 打印字符串 print(1 + '1'); // python代码，报错 typescript是完全兼容JavaScript的，它不会修改JavaScript运行时的特性，所以它们完全是弱类型的，作为对比，python是强类型的 基础 原始数据类型 JavaScript的类型分为两种：原始数据类型和对象类型 原始数据类型：布尔值、数值、字符串、null、undefined、ES6中的新类型symbol，ES10中的bigint boolean 使用构造函数Boolean 创造的对象不是布尔值，布尔值boolean和布尔对象Boolean不是一个东西 let isDone:boolean = false let createByNewBoolean:Boolean = new Boolean(1) 数值 0b1010 和 0o744 是 ES6 中的二进制和八进制表示法，它们会被编译为十进制数字。 字符串 其中`用来定义定义ES6中的模板字符串，${expr}用来在模板字符串中嵌入表达式 let myName:string = 'Tom' let myAge:number = 25 //模板字符串 let sentence:string = `Hello, ${myName} will be ${myAge + 1} nest year.` 空值 JavaScript中没有空值（void）的概念，在typescript中，可以用void表示没有任何返回值的函数： function alertName(myName:string):void { alert(`my name is ${myName}.`) } 声明一个void类型的变量没有什么用，因为你只能将它复制为undefined和null let unusable:void = undefined Null 和 Undefined 在typescript中，可以用null和undefined来定义这两个原始数据类型： let u:undefined = undefined let n:null = null 于void 的区别是，undefined和null是所有类型的子类型，也就是说undefined类型的变量可以赋值给number类型的变量： let num:number = undefined // 不会报错 let u:undefined let num:number = u // 这样也不会报错 void类型不能赋值给number类型的变量 任意值 任意值（Any）用来表示允许赋值为任意类型 什么是任意类型 如果是一个普通类型，在赋值过程中改变类型是不允许的，但是如果是any类型的，则允许被赋值为任意类型 let myFavoriteNumber:string = 'seven' myFavoriteNumber = 7 // error let myFavoriteNumber:any = 'seven' myFavoriteNumber = 7 //正常 任意值的属性和方法 在任意值上访问任何属性都是允许的，也允许调用任何方法，可以认为声明一个变量是任意值之后，对它的任何操作，返回的类型都是任意值 let anyThing:any = 'hello' console.log(anyThing.myName) console.log(anThing.myName.firstName) anyThing.setName('Jerry') anyThing.setName('Jerry').sayHello() 未声明类型的变量 变量如果在声明的时候，为指定其类型，那么它会被识别为任意值类型： let something somthing = 'seven' somthing = 7 something.setName('Tom') 等价于 let something:Any somthing = 'seven' somthing = 7 something.setName('Tom') 类型推论 如果没有明确的指定类型，那么typescript会按照类型推论（Type Inference）的规则推断出一个类型 什么是类型推论 一下代码虽然没有指定类型，但是会在编译的时候报错 let myFavoriteNumber = 'seven' myFavoriteNumber = 7 // error 事实上，它等价于 let myFavoriteNumber:string = 'seven' myFavoriteNumber = 7 // error typescript会在没有明确的指定类型的时候推测出一个类型，这就是类型推论 let myFavoriteNumber myFavoriteNumber = 'seven' myFavoriteNumber = 7 如果定义的时候没有赋值，不管之后有没有赋值，都会被推断成any类型而完全不被类型检查 联合类型 联合类型（union types）表示取值可以为多种类型的一种 简单例子 let myFavoriteNumber:string|number myFavoriteNumber = 'seven' myFavoriteNumber = 7 myFavoriteNumber = true // error 联合类型使用 | 分隔每一个类型 这里 let myFavoriteNumber:string|number 的含义是 myFavorite 的类型可以是 string 或者 number， 但是不可以是其它类型 访问联合类型的属性或方法 当typescript不确定一个联合类型的变量到底是哪个类型的时候，我们只能访问此两盒类型的所有类型里共有的属性或方法 function getLength(something:string|number):number{ return something.length } // error, something 不确定类型，length只是string的属性 function getString(something:string|number):string{ return something.toString() // 正确，这是共有属性 } 联合类型的变量在赋值的时候，会根据类型推论的规则推断出一个类型： let myFavoriteNumber:string|number myFavoriteNumber = 'seven' console.log(myFavoriteNumber.length) // 正确 myFavoriteNumber = 7 console.log(myFavoriteNumber.length) // 编译时报错 对象的类型——接口 在typescript中，我们使用接口（interfaces）来定义对象的类型 什么是接口 在面向对象语言中，接口是一个很重要的概念，它是对行为的抽象，而具体如何行动需要类去实现 typescript中的接口是要给非常灵活的概念，处理可用于类的一部分行为进行抽象意外，也常对对象的形状（形状）进行描述 interface Person{ name: string; age: number; } let tom: Person = { name: 'Tom', age: 25 } 在这个例子中，我们定义了一个接口 Person，接着定义了一个变量 tom，它的类型是Person，这样我们就约束了tom的形状必须和接口Person一致 接口一般首字母大写，有些编程语言会建议接口的名称前加一个 I 定义的变量比接口少了一些属性是不允许的 interface Person { name: string; age: number; } let tom: Person = { name: 'tom' } // Propertyp 'age' is missing in type '{name: string}' 多一些属性也是不允许的： let tom: Person = { name: 'tom', age: 25, gender: 'male' } // 'gender' does not exist in type 'Person' 可见，赋值的时候，变量的形状必须和接口的形状保持一致 可选属性 有时我们希望不要完全匹配一个形状，那么可以用可选属性： interface Person { name: string; age?: number } let tom: Person = { name: 'Tom' } 但是仍然不允许添加未定义的属性 let tom: Person = { name: 'tom', age: 25, gender: 'male' } // 'gender' does not exist in type 'Person' 任意属性 有时候我们希望一个接口允许有任意的属性，可以使用如下方式： interface Person { name: string; age?: number; [propName: string]: any; } let tom: Person = { name: 'tom', gender: 'male' } 使用 [propName: string] 定义了任意属性取string类型的值 需要注意的是，一旦定义了任意属性，那么确定属性和可选属性的类型必须都是它的类型的子集 interface Person { name: string; age?: number; [propName: string]: strnig; } let tom: Person = { name: 'tom', age: 25, gender: 'male' } // error, type 'number' is not assignable to type 'string' 上例中，任意属性的值允许是 string，但是可选属性age的值确实number，number不是string的子属性，所以报错了 一个接口中只能定义一个任意属性，如果接口中有多个类型的属性，则可以在任意属性中使用联合类型 只读属性 有时候我们希望对象中的一些字段只能在创建的时候赋值，那么可以使用readonly定义只读属性： interface Person { readonly id: number; name: string; age?: number; [propName: string]: any; } let tom: Person = { id: 1, name: 'tom', gender: 'male' } tom.id = 2 // error, id is read-only 注意，只读的约束存在于第一次给对象赋值的时候，而不是第一次给只读属性赋值的时候 let tom: Person = { name: 'tom' } tom.id = 1 // error 两个错误，第一次初始化没有给id赋值，重新给id赋值的时候已经晚了 数组的类型 在typescript中，数组类型有多种定义方式，比较灵活 [类型+方括号]表示法 最简单的方法是使用[类型+方括号]来表示数组： let fibonacci: number[] = [1, 1, 2, 3] 数组的项中不允许出现其它的类型，数组的一些方法的参数也会根据数组在定义时按约定的类型进行限制 let fabonacci: number[] = [1, '1', 2, 3] // error, 类型不对 let fibonacci.push('5') // error, 方法也被类型限制了 上例中，push 方法只允许传入number类型的参数 数组泛型 我们也可以使用数组泛型（array generic）Array 来表示数组： let fibonacci: Array = [1, 1, 2, 3, 5] 用接口表示数组 interface NumberArray { [index: number]: number; } NumberArray 表示： 只要索引的类型是数字时，那么值的类型必须是数字 虽然接口也可以用来描述数组，但是我们一般不会这么做，因为这种方式比前两种复杂多了 有一种情况例外： 类数组 类数组 类数组（Array-like Object）不是数组类型，比如arguments： function sum() { let args: number [] = arguments } // error, 类数组不能用普通的数组的方式描述，而应该用接口 function sum() { let args: { [index: number]: number; length: number; callee: Function; } = arguments } 事实上常用的类数组都有自己的接口定义，如 IArguments， NodeList， HTMLCollectoin等： function sum() { let args: IArguments = arguments } any 在数组中的应用 一个比较常见的做法是，用 any 表示数组中允许出现任意类型： let list: any[] = ['xcatliu', 25, { website: 'http://xcatliu.com' }]; 函数类型 函数是JavaScript中的一等公民 函数声明 在JavaScript中，有两种常见的定义函数的方式：函数声明和函数表达式 // 函数声明（Function Declaration） function sum(x, y) { return x + y } // 函数表达式（Function Expression) let mySum = function(x, y) { return x + y } 一个函数有输入输出，要在typescript中对其进行约束，需要把输入和输出都考虑到，其中函数声明的类型定义较为简单： function sum(x: number, y: number): number { return x + y } 输入多余的（或者少于要求的）参数，都是不允许的 函数表达式在typescript中的定义： let mySum = function(x: number, y: number): number { return x + y } 事实上，我们只对右侧的匿名函数进行了类型定义，而等号左边的可以通过赋值操作进行类型推论而推断出来，如果我们需要手动给mySum添加对象，则应该是这样： let mySum:(x: number, y: number) => number = function(x: number, y: number): number { return x + y } 注意不要混淆了typescript中的 => 和ES6 中的 => 在typescript中，=> 用来表示函数的定义，左边是输入类型，需要用括号，右边是输出类型，es6 中这个是箭头函数 用接口定义函数的形状 我们也可以使用接口的方式来定义一个函数需要符合的形状： interface SearchFunc { {source: string, subString: string}: boolean } let mySearch: SearchFunc mySearch = function(source: string, subString: string) { return source.search(sbString) != -1 } 采用函数表达式|接口定义函数的方式时，对等号左侧进行类型限制，可以在以后对函数名赋值时保证参数个数、参数类型、函数值返回不变 可选参数 前面提到，输入多余的（或者少于要求的）参数，是不被允许的，那么如何定义可选参数呢，与接口类似，我们用 ？ 表示可选的参数 function buildName(firstName: string, lastName?: string) { if(lastName) { return firstName + ' ' + lastName } else { return firstName } } 可选参数后面不允许再出现必需参数了 参数默认值 在 ES6 中，我们允许给函数的参数添加默认值，typescript会将添加量默认值的参数识别为可选参数，这时候就可以不受顺序影响 剩余参数 ES6中，可以使用 ...rest 的方式获取函数中的剩余参数 function push(array, ..items) { items.forEach(function(item) { array.push(item) }) } 事实上items是一个数组，我们可以用数组的类型来定义它 function push(array: any[], ...items: any[]) { items.forEach(function(item) { array.push(item) }) } rest参数只能是最后一个参数 重载 重载允许一个函数接受不同数量或类型的参数时，做出不同的处理 function reverse(x: number | string): number | string | void { if(typeof x === 'number') { return Number(x.toString().split('').reverse().join('')) } else if(typeof x === 'string') { return x.split('').reverse().join('') } } 然而这样有一个缺点，就是不够精确的表达，输入数字的时候，输出也应该是数字，输入是字符串的时候，输出也应该是字符串 function reverse(x: number): number; function reverse(x: string): string; function reverse(x: number | string): number | string | void { if(typeof x === 'number') { return Number(x.tostring().split('').reverse().join('')) } else if(typeof x === 'string') { return x.split('').reverse().join('') } } typescript会优先从最前面的函数定义开始匹配，所以多个函数定义如果有包含关系，需要优先把精确的定义写在前面 类型断言 类型断言（type assertion）可以用来手动指定一个值的类型 语法 值 as 类型 或者 值 tsx语法必须使用前者，建议在使用类型断言时，统一使用 值 as 类型 这样的语法 将一个联合类型断言为其中一个类型 interface Cat { name: string; run(): void; } interface Fish { name: string; run(): void; } function isFish(animal: Cat | Fish) { if(typeof animal.swim === 'function') { return true } return false } // Error, Property 'swim' does not exit on type 'Cat' function isFish(animal: Cat | Fish) { if (typeof (animal as Fish).swim === 'function') return true return false } 这样就可以解决访问 animal.swim 报错的问题，但是类型断言只能够欺骗typescript编译器，无法避免运行时的错误，滥用类型断言可能会导致运行时错误 将一个父类断言为具体的子类 当类之间有继承关系时，类型断言也很常见 class ApiError extends Error { code: number = 0 } class HttpError extends Error { statusCode: number = 200 } function isApiError(error: Error) { if(typeof (error as ApiError).code === 'number') { // instanceof 也是一个办法，如果判断的是类的话 return true } return false } 将任何一个类型断言成any 在any类型的变量上，访问任何属性都是允许的，但是将一个变量断言成any可以说是解决typescript中类型问题的最后一个手段 它极有可能掩盖了真正的类型错误，所以如果不是非常确定，不要使用 as any (window as any).foo = 1 上面例子中最好的解决办法是扩展window 的类型，但是使用 as any 更加方便 我们需要在类型的严格性和开发的便利性之间掌握平衡 将any断言成一个具体的类型 遇到 any 类型的变量时，我们可以选择无视它，任由它滋生更多的 any。 我们也可以选择改进它，通过类型断言及时的把 any 断言为精确的类型，亡羊补牢，使我们的代码向着高可维护性的目标发展。 类型断言的限制 联合类型可以被断言为其中一个类型 父类可以被断言为子类 任何类型都可以被断言为 any any 可以被断言为任何类型 要使得 A 能够被断言为 B，只需要 A 兼容 B 或 B 兼容 A 即可 前四种情况都是最后一个的特例 双重断言 既然任何类型都可以被断言成any，any可以被断言成任何类型，双重断言基本就可以断言成想要的类型，但是这样做的大部分都是错误的 类型断言 vs 类型转换 vs 类型声明 类型断言只会影响 typescript编译时的类型，类型断言语句会在编译结果中被删除 function toBoolean(something: any): boolean { return something as boolean } toBoolean(1) // 返回值 1 // 编译结果 function toBoolean(something: any): boolean { return something } toBoolean(1) 类型转换就是一句允许的语句了 animal 断言为 Cat，只需要满足 Animal 兼容 Cat 或 Cat 兼容 Animal 即可 animal 赋值给 tom，需要满足 Cat 兼容 Animal 才行 我们还有第三种方式可以解决这个问题，那就是泛型 声明文件 当使用第三方库时，我们需要引用它的声明文件，才能获得对应的代码补全、接口提示等功能。 declare var 声明全局变量 declare function 声明全局方法 declare class 声明全局类 declare enum 声明全局枚举类型 declare namespace 声明（含有子属性的）全局对象 interface 和 type 声明全局类型 export 导出变量 export namespace 导出（含有子属性的）对象 export default ES6 默认导出 export = commonjs 导出模块 export as namespace UMD 库声明全局变量 declare global 扩展全局变量 declare module 扩展模块 /// 三斜线指令 暴露在最外层的interface 或 type 会作为全局类型作用于整个项目中，我们应该尽可能的减少全局变量或全局类型的变量，故最好将它们放到namespace下 注意只有function、class和interface可以直接默认导出，其它的变量需要先定义出来，在默认导出 进阶 类型别名 类型别用来给一个类型起一个新的名字 type Name = string type NameResolver = () => string type NameOrResolver = Name | NameResolver function getName(n: NameOrResolver) : Name { if(typeof n === 'string') return n return n() } 字符串字面量类型 字符串字面量类型用来约束取值只能是某几个字符串中的一个(枚举？) type EventNames = 'click' | 'scroll' | 'mousemove' function handleEvent(ele: Element, event: EventNames) { } handleEvent(document.getElementById('hello'), 'scroll') // 没问题 handleEvent(document.getElementById('hello'), 'dbclick') // error 没有这个类型 我们使用type定义了一个字符串字面量类型，它只能取这几个字符串中的一个 类型别名与字符串字面量类型都使用 type 进行定义 元组 数组合并了相同类型的对象，而元组（tuple）合并了不同类型的对象 简单例子 let tom: [string, number] = ['Tom', 25] tom[0] = 'Tom' // 可以只赋值其中一项 tom = ['Tom', 25] // 直接对元组类型的变量进行初始化，需要提供所有元组类型中指定的项 枚举 枚举（Enum）类型用于取值被限定在一定范围内的场景，比如一周内只有七天 简单的例子 枚举成员会被赋值为从0开始递增的数字，同时也会对枚举值到枚举名进行反向映射 enum Days {Sun, Mon, Tue, Wed,Thu, Fri, Sat} console.log(Days[\"Sun\"] === 0); // true console.log(Days[\"Mon\"] === 1); // true console.log(Days[\"Tue\"] === 2); // true console.log(Days[\"Sat\"] === 6); // true console.log(Days[0] === \"Sun\"); // true console.log(Days[1] === \"Mon\"); // true console.log(Days[2] === \"Tue\"); // true console.log(Days[6] === \"Sat\"); // true // 事实上，上面会被编译成 var Days; (function (Days) { Days[Days[\"Sun\"] = 0] = \"Sun\"; Days[Days[\"Mon\"] = 1] = \"Mon\"; Days[Days[\"Tue\"] = 2] = \"Tue\"; Days[Days[\"Wed\"] = 3] = \"Wed\"; Days[Days[\"Thu\"] = 4] = \"Thu\"; Days[Days[\"Fri\"] = 5] = \"Fri\"; Days[Days[\"Sat\"] = 6] = \"Sat\"; })(Days || (Days = {})); 手动赋值 enum Days {Sun = 7, Mon = 1, Tue, Wed, Thu, Fri, Sat}; console.log(Days[\"Sun\"] === 7); // true console.log(Days[\"Mon\"] === 1); // true console.log(Days[\"Tue\"] === 2); // true console.log(Days[\"Sat\"] === 6); // true 未手动赋值的枚举项会接着上一个枚举项递增。 类 在传统方法中，JavaScript通过构造函数实现类的概念，通过原型链实现继承，而在es6中，我们终于迎来的class 类的概念 类（Class）：定义了一件事物的抽象特点，包含它的属性和方法 对象（Object）：类的实例，通过 new 生成 面向对象（OOP）的三大特性：封装、继承、多态 封装（Encapsulation）：将对数据的操作细节隐藏起来，只暴露对外的接口。外界调用端不需要（也不可能）知道细节，就能通过对外提供的接口来访问该对象，同时也保证了外界无法任意更改对象内部的数据 继承（Inheritance）：子类继承父类，子类除了拥有父类的所有特性外，还有一些更具体的特性 多态（Polymorphism）：由继承而产生了相关的不同的类，对同一个方法可以有不同的响应。比如 Cat 和 Dog 都继承自 Animal，但是分别实现了自己的 eat 方法。此时针对某一个实例，我们无需了解它是 Cat 还是 Dog，就可以直接调用 eat 方法，程序会自动判断出来应该如何执行 eat 存取器（getter & setter）：用以改变属性的读取和赋值行为 修饰符（Modifiers）：修饰符是一些关键字，用于限定成员或类型的性质。比如 public 表示公有属性或方法 抽象类（Abstract Class）：抽象类是供其他类继承的基类，抽象类不允许被实例化。抽象类中的抽象方法必须在子类中被实现 接口（Interfaces）：不同类之间公有的属性或方法，可以抽象成一个接口。接口可以被类实现（implements）。一个类只能继承自另一个类，但是可以实现多个接口 es6 中类的用法 属性和方法 使用class定义类，使用constructor定义构造函数 通过new生成新实例的时候，会自动调用构造函数 class Animal { public name; constructor(name) { this.name = name } sayHi() { return `my name is ${this.name}` } } let tian = new Animal('Tian') console.log(tian.sayHi()) // my name Tian 类的继承 使用extends关键字实现继承，子类中使用super关键字来调用分类的构造函数和方法 class Cat extends Animal { constructor(name) { super(name); // 调用父类的构造方法 console.log(this.name) } sayHi() { return 'Meow,' + super.sayHi() } } let mango = new Cat('Mongo') console.log(mongo.sayHi()) // Meow, my name is Mongo 存取器 使用getter和setter可以改变属性的赋值和读取行为 class Animal { constructor(name) { this.name = name } get name() { return 'Jack' } set name(value) { console.log('setter: ' + value) } } let test = new Animal('Kitty') test.name = 'Tom' // setter： Tom console.log(test.name) // Jack 静态方法 使用 static 修饰符修饰的方法称为静态方法，他们不需要实例化，而是直接通过类来调用 class Animal { static isAnimal(a) { return a instanceof Animal } } lat a = new Animal('Jack') Animal.isAnimal(a) // true a.isAnimal(a) // error, a.isAnimal is not a function es7 中类的用法 ES6 中实例的属性只能通过构造函数中的 this.xxx 来定义，ES7 提案中可以直接在类里面定义 ES7 提案中，可以使用 static 定义一个静态属性 typescript 中类的用法 public private 和 protected TypeScript 可以使用三种访问修饰符（Access Modifiers），分别是 public、private 和 protected。 public 修饰的属性或方法是公有的，可以在任何地方被访问到，默认所有的属性和方法都是 public 的 private 修饰的属性或方法是私有的，不能在声明它的类的外部访问 protected 修饰的属性或方法是受保护的，它和 private 类似，区别是它在子类中也是允许被访问的 当构造函数修饰为private，该类不允许被继承或者实例化，当构造函数修饰为protected时，该类只允许被继承，不能用super来调用 参数属性 修饰符和readonly还可以使用在构造函数参数中，等同于类中定义该属性同时给该属性赋值，使代码更简洁。 只读属性关键字 readonly，只允许出现在属性声明或索引签名或构造函数中。 抽象类 abstract 用于定义抽象类和其中的抽象方法 抽象类是不允许被实例化的 abstract class Animal { public name; public constructor(name) { this.name = name } public abstract sayHi() } let a = new Animal('Jack') // error， cannot create an instance of the abstract class 其次，抽象类中的抽象方法必须被子类实现： abstract class Animal { public name; public constructor(name) { this.name = name } public abstract sayHi() } // 子类实现 class Cat extends Animal { public sayHi() { console.log(`Meow, My name is ${this.name}`); } } 类的类型 给类加上typescript中的类型很简单，与接口类似： class Animal { name: string; constructor(name: string) { this.name = name } sayHi(): string { return `my name is ${this.name}` } } let a:Animal = new Animal('Jack') console.log(a.sayHi()) 类与接口 接口可以用于对对象的形状进行描述，也可以对类的一部分行为进行抽象 类实现接口 实现（implements）是面向对象中的一个重要概念，一般来说，一个类只能继承自另一个类，有时候不同了类之间可以有一些共有的特性，这时候就可以把特性提取成接口（interfaces），用 implements 关键字来实现，这个特性大大提高了面向对象的灵活性 举例来说，门是一个类，防盗门是门的子类。如果防盗门有一个报警器的功能，我们可以简单的给防盗门添加一个报警方法。这时候如果有另一个类，车，也有报警器的功能，就可以考虑把报警器提取出来，作为一个接口，防盗门和车都去实现它 interface Alarm { alert(): void } class Door {} class SecurityDoor extends Door implements Alarm { alert() { console.log('SecurityDoor alert') } } class Car implements Alarm { alert() { console.log('Car alert') } } 一个类可以实现多个接口 interface Alarm { alert(): void } interface Light { lightOn(): void; lightOff(): void; } class Car implements Alarm, Light { alert() { console.log('Car alert') } lightOn() { console.log('Car light on') } lightOff() { console.log('Car light off') } } 接口继承接口 接口与接口之间可以是继承关系： interface Alarm { alert(): void; } interface LightableAlarm extends Alarm { lightOn(): void; lightOff(): void; } 接口继承类 常见的面向对象语言中，接口是不能继承类的，但是在 TypeScript 中却是可以的： class Point { x: number; y: number; constructor(x: number, y: number) { this.x = x; this.y = y; } } interface Point3d extends Point { z: number; } let point3d: Point3d = {x: 1, y: 2, z: 3}; 当我们在声明 class Point 时，除了会创建一个名为 Point 的类之外，同时也创建了一个名为 Point 的类型 「接口继承类」和「接口继承接口」没有什么本质的区别 泛型 泛型（Generics）是指在定义函数、接口或类的时候，不预先指定具体的类型，而在使用的时候再指定类型的一种特性 简单的例子 首先，我们来实现一个函数 createArray，它可以创建一个指定长度的数组，同时将每一项都填充一个默认值： function createArray(length: number, value: any): Array { let result = []; for (let i = 0; i 这个函数使用了数组泛型来定义返回值的类型，这段代码有一个缺陷，它并没有准确的定义返回值的类型： Array允许数组的每一项都是任意类型，但是实际上我们希望每一项都是 value 的类型 function createArray(length: number, value: T): Array { let result: T[] = []; for(let i = 0; i (3, 'x') // ['x', 'x', 'x'] 调用的时候可以不指定 T 的具体类型，而让类型推论自动推论出来 多个类型参数 定义泛型的时候，可以一次定义多个类型参数： function swap(tuple: [T, U]): [U, T] { return [tuple[1], tuple[0]] } swap([7, 'seven']) // ['seven', 7] 泛型约束 再函数内部使用泛型变量的时候，由于事先不指定它是那种类型，所以不能随意的操作它的属性 function loggingIdentity(arg: T): T{ console.log(arg.length) return arg } // error, Property 'length' does not exist on type 'T' 泛型 T 不一定包含属性 length，所以编译的时候报错了，这时候我们可以对泛型进行约束，只允许这个函数传入那些包含length属性的变量，这就是泛型约束： interface Lengthwise { length: number } function loggingIdentity(arg: T): T{ console.log(arg.length) return arg } 我们使用了 extends 约束了泛型 T 必须符合接口 Lengthwise 的形状，也就是必须包含 length 属性 此时如果调用 loggingIdentity 的时候，传入的 arg 不包含 length，那么在编译阶段就会报错了 多个类型参数之间也可以互相约束： function copyFields(target: T, source: U): T { for (let id in source) { target[id] = (source)[id]; } return target; } let x = { a: 1, b: 2, c: 3, d: 4 }; copyFields(x, { b: 10, d: 20 }); 上例中，我们使用了两个类型参数，其中要求 T 继承 U，这样就保证了 U 上不会出现 T 中不存在的字段。 泛型接口 可以使用接口的方式来定义一个函数需要符合的形状： interface SearchFunc { (source: string, subString: string): boolean; } let mySearch: SearchFunc; mySearch = function(source: string, subString: string) { return source.search(subString) !== -1; } 当然也可以使用含有泛型的接口来定义函数的形状： interface CreateArrayFunc { (length: number, value: T):Array } 泛型类 与泛型接口类似，泛型也可以用于类的类型定义汇总： class GenericNumber { zeorValue: T; add: (x: T, y:T) => T } let myGenericNumber = new GentericNumber(); myGenericNumber.zeroValue = 0 myGenericNumber.add = function(x, y) {return x + y}; 泛型参数的默认类型 在 TypeScript 2.3 以后，我们可以为泛型中的类型参数指定默认类型。当使用泛型时没有在代码中直接指定类型参数，从实际值参数中也无法推测出时，这个默认类型就会起作用。 function createArray(length: number, value: T): Array { let result: T[] = []; for (let i = 0; i 声明合并 如果定义了两个相同名字的函数、接口或类，它们会合并成一个类型 合并的属性的类型必须是唯一的 工程 掌握了typescript的语法就像是学会了砌墙的工艺 代码检查 代码检查主要是用来发现代码错误，同意代码风格，eslint 用的比较多 编译选项 TypeScript 提供了非常多的编译选项，但是官方文档对每一项的解释很抽象，这一章会详细介绍每一个选项的作用，并给出对应的示例。 "},"skills/Docker.html":{"url":"skills/Docker.html","title":"Docker","keywords":"","body":"Docker [gitbook](https://yeasy.gitbo [ok.io/docker_practice/) [toc] 前言 Docker是个划时代的开源项目，它彻底释放了计算虚拟化的威力，极大的提高了应用的维护效率，降低了云计算应用开发的成本，使用Docker，可以让应用的部署、测试和分发都变得前所未有的高效和轻松 Docker 简介 Docker 在容器的基础上，进行了进一步的封装，从文件系统、网络互联到进程隔离等等，极大的简化了容器的创建和维护，使得Docker技术比虚拟机技术更为轻便、快捷 更高效的利用系统资源 快速的启动时间 一直的运行环境 持续交付和部署 更轻松的迁移 更轻松的维护和扩展 基本概念 Docker 包括三个基本概念：镜像（Image）、容器（Container）、仓库（Repository） 镜像 们都知道，操作系统分为 内核 和 用户空间。对于 Linux 而言，内核启动后，会挂载 root 文件系统为其提供用户空间支持。而 Docker 镜像（Image），就相当于是一个 root 文件系统。 Docker 镜像 是一个特殊的文件系统，除了提供容器运行时所需的程序、库、资源、配置等文件外，还包含了一些为运行时准备的一些配置参数（如匿名卷、环境变量、用户等）。镜像 不包含 任何动态数据，其内容在构建之后也不会被改变。 容器 镜像（Image）和容器（Container）的关系就像是面向对象程序设计中的类和实例一眼，镜像是静态的定义，容器是镜像运行时的实体，容器可以被创建、启动、停止、删除、暂停等 容器的实质是进程，但与直接在宿主执行的进行不同，容器进程运行于属于自己的独立的命名空间，因此容器可以拥有自己的root文件系统，自己的网络配置、自己的进程空间，容器的进程是运行在一个隔离的环境里。容器不应该向其存储层中写入任何数据、容器存储层要保持无状态化。所有的文件写入操作，都应该使用数据卷（Volume）或者绑定宿主目录 仓库 镜像构建完成后，可以很容易在当前宿主机上运行，但是，如果需要在其它服务器上使用这个镜像，我们就需要一个几种的存储、分发镜像的服务，Docker Registry 就是这样的服务 一个 Docker Registry 中可以包含多个仓库（Repository），每个仓库可以包含多个标签，每个标签对应一个镜像 安装Docker Docker分为 stable test 和 nightly 三个更新频道 "},"skills/Git.html":{"url":"skills/Git.html","title":"Git","keywords":"","body":"Git ProGit 起步 版本控制是一种记录一个或若干文件内容变化，以便将来查阅特定版本修订情况的系统（可以对任何文件进行版本控制） 本地版本控制系统 许多人习惯用复制整个项目目录的方式来保存不同的版本，或许还会改名加上备份时间以示区别。 这么做唯一的好处就是简单，但是特别容易犯错。 有时候会混淆所在的工作目录，一不小心会写错文件或者覆盖意想外的文件。 为了解决这个问题，人们很久以前就开发了许多种本地版本控制系统，大多都是采用某种简单的数据库来记录文件的历次更新差异。 Git learn Git Branching Introduction to Git Commits(branching, merging, rebasing, etc) commit: records a snapshot of all files(even better) branch early, and branch often(branches are pointers to a specific commit) Git rebase: second way of combining work hash $\\Rightarrow$ relative refs git branch -f main HEAD~1 git reset / git revert I want this work here and that work there git cherry-pick git rebase -i juggling commits Git Remotes You can typically talk to this other computer through the Internet, which allows you to transfer commits back and forth. git pull $\\rightleftarrows$ git fetch; git merge o/main The difficulty comes in when the history of the repository diverges. git fetch $\\Rightarrow$ git rebase o/main $\\Rightarrow$ git push $\\rightleftarrows$ git pull git fetch $\\Rightarrow$ git merge o/main $\\Rightarrow$ git push $\\rightleftarrows$ git pull --rebase "},"skills/Linux.html":{"url":"skills/Linux.html","title":"Linux","keywords":"","body":"Linux "},"skills/画图.html":{"url":"skills/画图.html","title":"画图","keywords":"","body":"[toc] 架构图 思否 思否 前言 程序代码本身就是一种数学逻辑的具体体现，如果没有一些图表配合文字的阐述，很难让所有人都能在共同的共识下进行交流。 而我们画的架构图、流程图、结构图、功能图、逻辑图等，都需要好看、好懂、好用、好搞，因为： 好看是为了提升沟通效率， 好懂是为了提升交流共识， 好用是为了提升交付质量， 好搞是为了提升实施速度。 架构分类 业务架构：需求初期业务的结果和过程描述一般比较模糊，可能来自于某个老板、运营或用户的反馈。客户说海尔洗衣机洗土豆会堵，海尔立马设计专门的土豆洗衣机 业务方向往往是定方向和结果的叫战略，主要包括业务规划、业务模块和流程以及问题域的列表等。 应用架构：服务复用、跨组协同，简单、灵活、整合是应用架构必须考虑的点，就像你要上线一个聊天功能，那么聊天内容的输入法、文字识别、舆情监控以及视频服务、支付服务等，它们都是在应用架构分层下沉淀到平台的产物，在供各个方使用。 产品架构：业务提需求，产品定方案，相对于业务的粗放流程，产品架构会更加细腻以及考虑各个模块的分层和边界。 数据架构：数据的获取、数据的存放和数据的使用是数据架构要解决的三个问题，数据库存放、大数据汇总、数据分析等。 技术架构：是离程序员最近的架构设计，它不仅是系统搭建的架构图设计，还包括了结构、功能、流程、逻辑等内容。它的具体描述就是整个系统如何落地的具体实现方案。 业务架构 应用架构 产品架构 数据架构 技术架构 技术文章配图指南 draveness 无论是使用Photoshop还是 OmniGraffle 甚至是其它工作都能达到完全相同的效果，更加重要的是我们对于制图规则的思考并形成一套自洽的体系。 概述 作者的画图准则： 图片必须足够美观并且清晰地传达想要表现的内容； 是技术博客中出现图片的意义； 图片必须能够在短时间内实现量产，不影响写作的效率； 博客中的全部图片都是在写作的过程中一一绘制的，而不是最后统一完成的，所以会希望画图的时间可以尽量短，一旦画图的时间超过过长，那么整个思路就会被打断； 博客的内容和逻辑相比于图片更加重要，作者不希望在上面花费过长的时间； 图片需要保证风格上的一致性，不会显得非常突兀； 图片的风格和配色对于作者来说就是签名，形成统一的风格之后会给读者留下比较深的印象； 作者推荐： Sketch（明年筹钱买一个mac） 画图 为技术文章绘制图片和使用PS修改图片或者为App绘制UI设计图是完全不同的，技术文章的配图主要作用还是为了辅助说明内容，相比于图片的样式，我们应该更加关注图片的内容是否清晰和简单。 图片的内容是配图时至关重要的，作者在一个问题太过复杂或者连续文字太多时，就会选择为文章插入适合的图片。作者将博客中的图片简单分成了一下三类： 用于展示多个平等的概念时 用于描述模块以及概念之间的关系时 用于描述特定场景下概念的特性 在需要展示某个问题的多个方面、多个原因或者阶段等处于相同层次的概念时就会使用如下所示的图片： 这张图片介绍了选择版本控制系统时应该关注的三个特性：分布式、性能和可靠性，使用列表的方式也是没有问题的，这只是作者的配图习惯，而你在这篇文章稍微靠前的部分中也会看到用于展示绘图工具的插图，这些图片的内容类型都是相似的。 除了展示概念的配图之外，作者还会使用如下所示的图片来展示不同概念或者模块之间的关系，流程图、架构图等类型的图片都会被作者归到这一类中： 上述图片展示了在分布式的版本控制系统中，各个仓库之间的树形结构，图中使用不同的颜色将不同仓库在树中的高度做出了区分，这种图片能够很好地帮助读者理解各个模块之间的关系，我们在 LucidChart 一节中分享的图片其实也属于这种类型的图片，只是使用的工具不同： 除了这两种比较常见的插图类型之外，作者在遇到一些特殊问题时也会选择通过图片帮助读者理解问题，例如 为什么 DNS 使用 UDP 协议 中就使用了如下所示的图片： 这张巨型图片的主要作用就是帮助读者理解 DNS 协议使用 TCP 或者 UDP 获取域名解析时所需要传输数据的大小，通过这张图片我们能够比较直观的了解不同协议在处理 DNS 协议时在数据方面的差别。 样式 图片的内容是它的核心价值所在，而图片的样式是决定图片是否『优雅』的关键，内容和样式之间的关系，就是 Web 前端中 HTML 和 CSS 的关系一样，我们在这一节中就详细介绍作者对于博客中图片样式的一些约定。 调色： Coolors 长宽： 宽度 1200px，长度不宜太长 字号：标题 30px，非标题字号：20 px 圆角：能用圆角就用圆角，显得柔和 "},"temp/TestForS.html":{"url":"temp/TestForS.html","title":"TestForS","keywords":"","body":"写了加深记忆的 前后端分离的意思是通过RESTful API 传递JSON数据进行交流，后端不交涉页面内容。 前端用前端的服务器(Nginx)，后端用后端的服务器（Tomcat），通过前端的服务器将前端的请求发送给后端的服务器，这就成为反向代理，反向代理可以不暴露服务器的真实地址 真实的项目中，直接将账号密码写上去太危险了了，一般的做法是存储密码等信息的hash值 使用数据库验证的逻辑和前面类似，大致如下： 获得前端发送过来的用户名和密码信息 查询数据库中是否存在相同的一对用户名和密码 如果存在返回200，否则返回失败代码400 对UserDAO进行了二次封装，我们再DAO中定义了基础的增删改查操作，而具体的操作应该是再Service里面进行完成 这个项目将会很长的时间都会采用这种简单的三层架构：DAO + Servic + Controller DAO用于与数据库交互，定义增删改查操作 Service负责业务逻辑，跟功能有关的代码一般都写在这里，编写、调用各种方法对DAO取得的数据进行操作 Controller 负责数据交互，即接受前端发送的数据，通过调用Service获得处理后的数据并返回 在实践中我们一般倾向于让Controller清凉一些，以方便代码的阅读者快速找到分析功能的入口 在这个看脸的时代，代码写的烂，界面写的也不好，就真的没救了，所以所我们需要element等组件，为什么我的element总是没有引用进去啊 登录的页面似乎较为完善了，但是我们这个登录页面其实没有用，因为别人直接输入首页的网址就可以进去了，为了防止别人绕过登录页面，我们需要做一个拦截器。 登录界面做完，我们差不多就理解了项目的构成，之后的开发就可以直接集中在业务功能的实现上面了，之后的基本模式就是前端开发组件，后端开发控制器，调试功能 URL中的#号是什么意思呢？#号可以认为是一个锚点，里哦那个AJAX，我们就可以不重载页面就刷新数据，如果我们加上#号的特性（即改变URL但是不请求后端），我们就可以在前端实现页面的整体变化而不用每次都去请求后端。为了实现前端路由，我们就可以监听#号后面内容的变化（hashchange），从而动态的改变页面的内容，URL的#号后面的地址成为hash，这种实现模式我们称之为hash模式，是非常典型的前端路由方式。 另一种常用的模式叫history模式，这种方式使用了History API，该API是针对历史记录的API，这种模式的原理是把原来页面的状态保存到一个对象（state）里面，当页面的URL变化时找到对应的对象，从而还原了这个页面。 Vue已经实现了这两种前端路由 回顾一下单页面应用的概念，在项目中其实只有index.html这一个页面，所有其他的内容都是在这一个页面中渲染的，当我们直接在后端方位/login路径的时候，后端中并未有该内容，为了获取到我们需要的页面，我们需要想办法触发前端路由，即在后端添加处理内容，把通过这个URL渲染出的index.html返回到浏览器中。 后端访问登录页面还是没跳转过去啊 后端拦截器的开发： 用户访问URL，检测是否为登录页面 如果用户访问的不是登录页面，检测用户是否已经登录，否则转到登录界面 为了保存登录的状态，我们需要把用户信息保存在Session中（当用户在web页面之间进行跳转的时候，存储在Session中的对象的变量不会丢失） 我们在拦截器 LoginInterceptor 中配置的路径，即index，触发的时机在拦截器生效以后。我们访问一个URL，先通过Configurer判断是否需要拦截，如果需要，才会触发拦截器，根据我们的自定义的规则再次判断。拦截器这里没咋看懂 前端拦截器需要一个全局属性，不应该写在单一的组件里面，所以引入了一个新的工具Vuex（专门为vue开发的状态管理方案），该工具可以把需要在各个组件中传递使用的变量、方法定义在这里。 项目虽然本质上是一个单页面应用，但是表面上有多个功能页面 在一个组件中通过导入引用了其它组件，可以称之为父子组件，如果想要通过控制子组件的显示，则需要相关的路由的配置 Books.Vue的修改：添加搜索框，添加增加，删除按钮，完善分页功能，构造增、删、改、查功能 pojo包中读数据库中的表 dao包中提供接口 service包中根据接口写服务 controller中继续写需要的API 项目中需要查询的地方主要有三处： 打开页面，默认查询出所有图书并显示(页面初始化) 点击左侧分类栏，按照分类显示图书 在搜索栏中输入作者或者书名，可以模糊的查询出相关书籍 页面初始化：使用了Vue的钩子函数-mounted，钩子函数就是在某个特定条件下被触发的函数，钩子函数一般与生命周期对应，mounted翻译为已挂载，所谓挂载，就是我们写的Vue代码被转换为HTML并替换为相应的DOM这个过程，这个过程完事的时候，就会执行mounted里面的代码。 中途隔了几天了，review一下： 简介 安装Vue Cli npm 安装 ， npm install -g vue-cli 安装脚手架，vue init webpack [name] 构建前端项目 components中创建组件，然后设置反向代理（就是再src/main.js)里面配置axios，eg： // 设置反向代理，前端请求默认发送到 http://localhost:8443/api var axios = require('axios') //我个人写的是 import axios from 'axios' axios.defaults.baseURL = 'http://localhost:8443/api' // 全局注册，之后可在其他组件中通过 this.$axios 发送数据 Vue.prototype.$axios = axios Vue.config.productionTip = false 配置页面路由： //格式如下 routes: [ // 下面都是固定的写法 { path: '/login', name: 'Login', component: Login }, { path: '/index', name: 'AppIndex', component: AppIndex } ] 在 config\\index.js 中配置跨域支持： proxyTable: { '/api': { //我也不知道为啥要api，可能是配置反向代理的时候用了api吧 target: 'http://localhost:8443', changeOrigin: true, pathRewrite: { '^/api': '' } } } 运行项目 npm run dev 后端项目创建 spring initializer，输入项目元数据，选择web，finish pojo包中创建自己要使用的类 result包中创建Result类，构造response，主要是响应码： package com.evan.wj.result; public class Result { //响应码 private int code; //这里code应该使用枚举，响应码是确定的 public Result(int code) { this.code = code; } public int getCode() { return code; } public void setCode(int code) { this.code = code; } } controller包中新建一个类，用来对响应进行处理，eg：LoginController package com.evan.wj.controller; import com.evan.wj.result.Result; //引进了响应码 import org.springframework.stereotype.Controller; import org.springframework.web.bind.annotation.*; import org.springframework.web.util.HtmlUtils; import com.evan.wj.pojo.User; //引进了类 import java.util.Objects; @Controller public class LoginController { @CrossOrigin @PostMapping(value = \"api/login\") //我写的是 @RequestMapping(value = \"api/login\") @ResponseBody public Result login(@RequestBody User requestUser) { //RequestBody就是前端传来的数据 // 对 html 标签进行转义，防止 XSS 攻击 String username = requestUser.getUsername(); username = HtmlUtils.htmlEscape(username); if (!Objects.equals(\"admin\", username) || !Objects.equals(\"123456\", requestUser.getPassword())) { String message = \"账号密码错误\"; System.out.println(\"test\"); return new Result(400); } else { return new Result(200); } } } 引入数据库：MySQL，工具Navicat，创建数据库，表，导入数据 项目相关配置：修改 pom.xml(配置完之后要在maven中重新导入一遍) 把pojo包中的类重新改一遍，因为数据是从数据库里面拿了，要建立对数据库的映射 eg： package com.evan.wj.pojo; import com.fasterxml.jackson.annotation.JsonIgnoreProperties; import javax.persistence.*; @Entity //表示一个实体 @Table(name = \"user\") //表名 @JsonIgnoreProperties({\"handler\",\"hibernateLazyInitializer\"}) public class User { @Id @GeneratedValue(strategy = GenerationType.IDENTITY) @Column(name = \"id\") int id; String username; String password; public int getId() { return id; } public void setId(int id) { this.id = id; } public String getUsername() { return username; } public void setUsername(String username) { this.username = username; } public String getPassword() { return password; } public void setPassword(String password) { this.password = password; } } 在dao包中创建一个类来操作数据库对象，但是这里是创建一个接口，eg： package com.evan.wj.dao; import com.evan.wj.pojo.User; import org.springframework.data.jpa.repository.JpaRepository; public interface UserDAO extends JpaRepository { User findByUsername(String username); User getByUsernameAndPassword(String username,String password); } 这里关键的地方在于方法的名字。由于使用了 JPA，无需手动构建 SQL 语句，而只需要按照规范提供方法的名字即可实现对数据库的增删改查。 在service包中创建一个类，提供相关服务，这里实际上是对 UserDAO 进行了二次封装，一般来讲，我们在 DAO 中只定义基础的增删改查操作，而具体的操作，需要由 Service 来完成。eg： package com.evan.wj.service; import com.evan.wj.dao.UserDAO; import com.evan.wj.pojo.User; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.stereotype.Service; @Service public class UserService { @Autowired UserDAO userDAO; public boolean isExist(String username) { User user = getByName(username); return null!=user; } public User getByName(String username) { return userDAO.findByUsername(username); } public User get(String username, String password){ return userDAO.getByUsernameAndPassword(username, password); } public void add(User user) { userDAO.save(user); } } controller包里面写一个类，引入pojo，result，service，dao，处理前端发回来的数据和后端的数据，完成业务逻辑 package com.evan.wj.controller; import com.evan.wj.pojo.User; import com.evan.wj.result.Result; import com.evan.wj.service.UserService; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.stereotype.Controller; import org.springframework.web.bind.annotation.*; import org.springframework.web.util.HtmlUtils; @Controller public class LoginController { @Autowired UserService userService; @CrossOrigin @PostMapping(value = \"/api/login\") @ResponseBody public Result login(@RequestBody User requestUser) { String username = requestUser.getUsername(); username = HtmlUtils.htmlEscape(username); User user = userService.get(username, requestUser.getPassword()); if (null == user) { return new Result(400); } else { return new Result(200); } } } 简单的三层架构（DAO + Service + Controller） DAO 用于与数据库的直接交互，定义增删改查等操作 Service 负责业务逻辑，跟功能相关的代码一般写在这里，编写、调用各种方法对 DAO 取得的数据进行操作 Controller 负责数据交互，即接收前端发送的数据，通过调用 Service 获得处理后的数据并返回 前端使用element 安装：npm i element-ui -S ，引入import Element-UI from 'element-ui' , import 'element-ui/lib/theme-chalk/index.css' , 接下来就是根据例子改自己组件的部分了 前端路由 前端路由：作用改变前端的URL却不用的请求后端，在前端实现页面的整体变化 后面的地址成为hash，有#号成为hash模式，另一种常用的前端模式是history模式，模式的原理是先把页面的状态保存到一个对象（state）里，当页面的 URL 变化时找到对应的对象，从而还原这个页面 使用history模式：修改 router\\index.js，加入 mode: 'history 前端打包部署到后端（不推荐的做法）：先npm run build，这时在项目的 dist 文件夹下生成了 static 文件夹和 index.html 文件，把这两个文件，拷贝到我们后端项目的 wj\\src\\main\\resources\\static 文件夹下 为什么要这里做呢，因为我们实际上只有index.html，后端想要方位其它路径是没有的，所以使用这种build之后copy的方式 后端拦截器 使用session来判断用户是否已经登录，加一条语句 session.setAttribute(\"user\", user); 新建一个拦截器的包 interceptor,然后新建类，在 Springboot 我们可以直接继承拦截器的接口，然后实现 preHandle 方法。preHandle 方法里的代码会在访问需要拦截的页面时执行。eg： package com.evan.wj.interceptor; import com.evan.wj.pojo.User; import org.apache.commons.lang.StringUtils; import org.springframework.web.servlet.HandlerInterceptor; import javax.servlet.http.HttpServletRequest; import javax.servlet.http.HttpServletResponse; import javax.servlet.http.HttpSession; public class LoginInterceptor implements HandlerInterceptor{ @Override public boolean preHandle (HttpServletRequest httpServletRequest, HttpServletResponse httpServletResponse, Object o) throws Exception { HttpSession session = httpServletRequest.getSession(); String contextPath=session.getServletContext().getContextPath(); String[] requireAuthPages = new String[]{ \"index\", }; String uri = httpServletRequest.getRequestURI(); uri = StringUtils.remove(uri, contextPath+\"/\"); String page = uri; if(begingWith(page, requireAuthPages)){ User user = (User) session.getAttribute(\"user\"); if(user==null) { httpServletResponse.sendRedirect(\"login\"); return false; } } return true; } private boolean begingWith(String page, String[] requiredAuthPages) { boolean result = false; for (String requiredAuthPage : requiredAuthPages) { if(StringUtils.startsWith(page, requiredAuthPage)) { result = true; break; } } return result; } } 写完拦截器之后要将它配置到项目中： 新建config包，再新建类： package com.evan.wj.config; import com.evan.wj.interceptor.LoginInterceptor; import org.springframework.boot.SpringBootConfiguration; import org.springframework.context.annotation.Bean; import org.springframework.web.servlet.config.annotation.*; @SpringBootConfiguration public class MyWebConfigurer implements WebMvcConfigurer { @Bean public LoginInterceptor getLoginIntercepter() { return new LoginInterceptor(); } @Override public void addInterceptors(InterceptorRegistry registry){ // 这条语句是关键 registry.addInterceptor(getLoginIntercepter()).addPathPatterns(\"/**\").excludePathPatterns(\"/index.html\"); } } 前端还要进行相应的设置，感觉我现在用不上，就不看了 数据库 review到此结束 上传文件的逻辑很简单：前端向后端发送post请求，后端对接受到的数据进行处理（压缩、格式转换、重命名等），并保存再服务器中的指定位置，再把该位置对应的url返回给前端即可 "},"temp/文件系统的设计原理.html":{"url":"temp/文件系统的设计原理.html","title":"文件系统的设计原理","keywords":"","body":"文件系统的设计原理 [toc] 摘要 这次又是要写文件的上传下载，又是需要对文件进行管理，文件的元数据信息，目录结构，文件夹和文件的管理，我感觉这是一个很重要的东西，想要把文件系统搞懂一点。参考文章：文件系统的设计原理，这篇写的很好，绝大部分都copy的，但是我还想要了解具体设计的方面的东西，比如有哪些元数据信息，Inode 或则 NameNode 怎么抽象的，目录是啥样的，然后怎么管理的 文件及硬盘管理是计算机操作系统的重要组成部分。让微软走上成功之路的正是微软最早推出的个人电脑 PC 操作系统，这个操作系统叫做 DOS，即 Disk Operating System，硬盘操作系统。我们每天使用电脑都离不开硬盘，硬盘既有大小的限制，通常大一点的硬盘也只是几T，又有速度的限制，快一点的硬盘也不过每秒几百M（现在局域网下的带宽都可以达到几千M，分布式文件系统的重要原因） 文件是存储在硬盘上的，文件的读写速度必然受到硬盘的物理限制，那么如何才能 1 分钟内完成一个 100 T 大文件的遍历呢？ 想要知道这个问题的答案，我们就必须知道文件系统的原理。做软件开发的时候，我们经常要和文件系统打交道，而文件系统也是一个软件，了解文件系统的设计原理，可以帮助我们更好的使用文件系统，另外设计文件系统的各种考量，也对我们自己软件设计有诸多简介意义 硬盘 硬盘是一种可持久保存、多次读写数据的存储介质。硬盘的形式主要有两种：机械式硬盘、固态硬盘 机械式硬盘的结构，主要包含盘片、主轴、次投币，主轴带动盘片高速旋转，当需要读写盘上的数据的时候，磁头臂会移动磁头到盘片所在的磁道上，磁头读取磁道上的数据。读写数据需要移动磁头，这样一个机械的动作，至少需要花费数毫秒的时间，这是机械式硬盘访问延迟的主要原因。 固态硬盘的读写速度快得多，但是成本也要高得多，因此在生产环境中，最主要的存储介质依然是机械式硬盘。如果一个场景对数据访问速度、存储容量、成本都有较高的要求，那么可以采用固态硬盘和机械式硬盘混合部署的方式 文件系统 我们一般不需要直接操作硬盘，而是通过操作系统，以文件的方式对硬盘上的数据进行读写。文件系统将硬盘空间以块为单位进行划分，每个文件占据若干个块，然后通过文件控制块 FCB 记录每个文件占据的硬盘数据块 文件系统分块 文件控制块在 Linux 中的角色是 inode，要想访问文件，就必须获得文件的 inode 信息，在 inode 中查找文件数据块索引表，根据索引表中记录的硬盘地址信息访问硬盘，读写数据 inode 中记录着文件权限、所有者、修改时间和文件大小等文件属性信息，以及文件数据块硬盘地址索引。inode 是固定结构的，能够记录的硬盘地址索引数也是固定的，只有 15 个索引。其中前 12 个索引直接记录数据块地址，第 13 个索引记录索引地址，也就是说，索引块指向的硬盘数据块并不直接记录文件数据，而是记录文件数据块的索引表，每个索引表可以记录 256 个索引；第 14 个索引记录二级索引地址，第 15 个索引记录三级索引地址，如下图： Inode 文件控制块 每个 inode 最多可以存储 12+256+256256+256256*256 个数据块，如果每个数据块的大小为 4k，也就是单个文件最大不超过 70G，而且即使可以扩大数据块大小，文件大小也要受单个硬盘容量的限制。这样的话，对于我们开头提出的一分钟完成 100T 大文件的遍历，Linux 文件系统是无法完成的。 Inode 理解Inode inode 的内容、大小和号码 文件存储在硬盘上，硬盘的最小存储单位是扇区（Sector），每个扇区存储 512 字节，但是操作系统读取硬盘的时候，不会一个一个扇区的读取，这样效率太低了，而是一次性读取多个扇区，我们将这多个扇区称为一个块（Block）， 常见大小是 4 kb，也就是 8 个扇区 文件数据都存储在块中了，但是我们必须找到一个地方存储文件的元信息，比如文件的创建者、创建日期、文件的大小等等，这种存储文件元信息的区域就叫做 inode（索引节点） inode 包含的信息： 文件的字节数 文件的拥有者 User ID 文件的 Group ID 文件的读、写、执行权限 文件的时间戳：ctime， inode 上一次变动的事件；mtime，文件内容上一次变动的事件；atime，文件上一次打开的时间 链接数，既有多少文件名指向这个 inode 文件数据 block 的位置 inode 也会消耗硬盘空间，所以硬盘格式化的时候，操作系统自动将硬盘分为两个区域，一个是数据区，存放文件数据；另一个是 inode 区，存放 inode 包含的信息。每个inode节点的大小，一般是128字节或256字节。inode节点的总数，在格式化时就给定，一般是每1KB或每2KB就设置一个inode。假定在一块1GB的硬盘中，每个inode节点的大小为128字节，每1KB就设置一个inode，那么inode table的大小就会达到128MB，占整块硬盘的12.8%。由于每个文件都必须有一个inode，因此有可能发生inode已经用光，但是硬盘还未存满的情况。这时，就无法在硬盘上创建新文件。 每个 inode 都有一个号码，操作系统用 inode 号码来识别不同的文件。Linux 系统内部不适用文件名，而使用 inode 号码来识别文件。对于系统来说，文件名只是 inode 号码便于识别的别称或者绰号。表面上，用户通过文件名打开文件，实际上，系统内部这个过程分为三步：首先，系统找到这个文件名对应的 inode 号码；其次，通过 inode 号码获取 inode 信息；最后，根据 inode 信息，找到文件数据所在的 block，读取数据 由于inode号码与文件名分离，这种机制导致了一些Unix/Linux系统特有的现象。 　　1. 有时，文件名包含特殊字符，无法正常删除。这时，直接删除inode节点，就能起到删除文件的作用。 　　2. 移动文件或重命名文件，只是改变文件名，不影响inode号码。 　　3. 打开一个文件以后，系统就以inode号码来识别这个文件，不再考虑文件名。因此，通常来说，系统无法从inode号码得知文件名。 第3点使得软件更新变得简单，可以在不关闭软件的情况下进行更新，不需要重启。因为系统通过inode号码，识别运行中的文件，不通过文件名。更新的时候，新版文件以同样的文件名，生成一个新的inode，不会影响到运行中的文件。等到下一次运行这个软件的时候，文件名就自动指向新版文件，旧版文件的inode则被回收。 目录文件 在 Unix/Linux 系统中，目录（directory）也是一种文件。打开目录，实际上就是打开目录文件。目录文件的结构非常简单，就是一系列目录项（dirent）的列表。每个目录项，有两部分组成：所包含文件的文件名，文件名对应的 inode 号码。ls命令只列出目录文件中的所有文件，ls -i命令列出整个目录文件，即文件名和inode号码。如果要查看文件的详细信息，就必须根据 inode 号码，访问 inode 节点，读取信息。ls -l命令列出文件的详细信息。 理解了上面这些知识，就能理解目录的权限。目录文件的读权限（r）和写权限（w），都是针对目录文件本身。由于目录文件内只有文件名和inode号码，所以如果只有读权限，只能获取文件名，无法获取其他信息，因为其他信息都储存在inode节点中，而读取inode节点内的信息需要目录文件的执行权限（x）。 stat 查看详细信息 df -i 查看inode总数和使用数量 ls命令只列出目录文件中的所有文件名，ls -i命令列出整个目录文件，即文件名和inode号码，ls -i命令列出整个目录文件，即文件名和inode号码（需要目录文件有 x 执行权限） 硬、软链接 一般情况下，文件名和 inode 号码是一一对应的关系，但是 Linux 系统允许多个文件名指向同一个 inode。这意味着，可以用不同的文件名访问同样的内容；对文件内容进行修改，回影响到所有文件名；但是删除一个文件名，不影响另一个文件名的访问。这种情况称为硬链接（hard link），ln命令可以创建硬链接 ln 创建硬链接 运行上面这条命令以后，源文件与目标文件的inode号码相同，都指向同一个inode。inode信息中有一项叫做\"链接数\"，记录指向该inode的文件名总数，这时就会增加1。反过来，删除一个文件名，就会使得inode节点中的\"链接数\"减1。当这个值减到0，表明没有文件名指向这个inode，系统就会回收这个inode号码，以及其所对应block区域。 目录文件的链接数：创建目录时，默认回生成两个目录项：'.' 和 '..'，前者的 inode 号码就是当前目录的 inode 号码，等同于当前目录的硬链接，后者的 inode 号码就是当前目录的父目录的 inode 号码，等同于父目录的硬链接。 除了硬链接之外，还有一种特殊情况。文件 A 和 文件 B 的 inode 号码虽然不一样，但是文件 A 的内容是文件 B 的路径，读取文件 A 时，系统会自动将访问者导向文件 B（好比是window 中的快捷方式）。因此，无论打开哪一个文件，最终读取的都是文件 B。这时，文件 A 就称为文件 B 的软连接 这意味着，文件A依赖于文件B而存在，如果删除了文件B，打开文件A就会报错：\"No such file or directory\"。这是软链接与硬链接最大的不同：文件A指向文件B的文件名，而不是文件B的inode号码，文件B的inode\"链接数\"不会因此发生变化。 ln -s 创建软链接 RAID RAID(Redundant Array of Independent Disks, 独立硬盘冗余阵列)：利用虚拟化存储技术把多个硬盘组合起来，称为一个或多个硬盘阵列组，目的是提升性能或减少冗余，或者是两者同时提升。 RAID 的核心思路其实是利用文件系统将数据写入硬盘中不同数据块的特性，将多块硬盘上的空闲空间看作一个整体，进行数据写入，也就是说，一个文件的多个数据块可能写入多个硬盘。根据硬盘组织和使用方式不同，常用 RAID 有五种，分别是 RAID 0、RAID 1、RAID 10、RAID 5 和 RAID 6。we RAID 0 将一个文件的数据分成 N 片，同时向 N 个硬盘写入，这样单个文件可以存储在 N 个硬盘上，文件容量可以扩大 N 倍，（理论上）读写速度也可以扩大 N 倍。但是使用 RAID 0 的最大问题是文件数据分散在 N 块硬盘上，任何一块硬盘损坏，就会导致数据不完整，整个文件系统全部损坏，文件的可用性极大地降低了。 RAID 1 则是利用两块硬盘进行数据备份，文件同时向两块硬盘写入，这样任何一块硬盘损坏都不会出现文件数据丢失的情况，文件的可用性得到提升。 RAID 10 结合 RAID 0 和 RAID 1，将多块硬盘进行两两分组，文件数据分成 N 片，每个分组写入一片，每个分组内的两块硬盘再进行数据备份。这样既扩大了文件的容量，又提高了文件的可用性。但是这种方式硬盘的利用率只有 50%，有一半的硬盘被用来做数据备份。 RAID 5 针对 RAID 10 硬盘浪费的情况，将数据分成 N-1 片，再利用这 N-1 片数据进行位运算，计算一片校验数据，然后将这 N 片数据写入 N 个硬盘。这样任何一块硬盘损坏，都可以利用校验片的数据和其他数据进行计算得到这片丢失的数据，而硬盘的利用率也提高到 N-1/N。 校验数据这一块建议去了解汉明码，然后 3Blue1Brown 的两个视频讲的特别好，地址：B站 RAID 5 可以解决一块硬盘损坏后文件不可用的问题，那么如果两块文件损坏？RAID 6 的解决方案是，用两种位运算校验算法计算两片校验数据，这样两块硬盘损坏还是可以计算得到丢失的数据片。 实践中，使用最多的是 RAID 5，数据被分成 N-1 片并发写入 N-1 块硬盘，这样既可以得到较好的硬盘利用率，也能得到很好的读写速度，同时还能保证较好的数据可用性。使用 RAID 5 的文件系统比简单的文件系统文件容量和读写速度都提高了 N-1 倍，但是一台服务器上能插入的硬盘数量是有限的，通常是 8 块，也就是文件读写速度和存储容量提高了 7 倍，这远远达不到 1 分钟完成 100T 文件的遍历要求。 分布式文件系统 我们再回过头看下 Linux 的文件系统：文件的基本信息，也就是文件元信息记录在文件控制块 inode 中，文件的数据记录在硬盘的数据块中，inode 通过索引记录数据块的地址，读写文件的时候，查询 inode 中的索引记录得到数据块的硬盘地址，然后访问数据。 如果将数据块的地址改成分布式服务器的地址？也就是查询得到的数据块地址不只是本机的硬盘容量，还可以是其他服务器的地址，那么文件的存储容量就将是整个分布式服务器集群的硬盘容量，这样还可以在不同的服务器上同时并行读取文件的数据块，文件访问速度也将极大的加快。 这样的文件系统就是分布式文件系统，分布式文件系统的思路其实和 RAID 是一脉相承的，就是将数据分成很多片，同时向 N 台服务器上进行数据写入。针对一片数据丢失就导致整个文件损坏的情况，分布式文件系统也是采取数据备份的方式，将多个备份数据片写入多个服务器，以保证文件的可用性。当然，也可以采用 RAID 5 的方式通过计算校验数据片的方式提高文件可用性。 我们以 Hadoop 分布式文件系统 HDFS 为例，看下分布式文件系统的具体架构设计。 HDFS 的关键组件有两个，一个是 DataNode，一个是 NameNode。 DataNode 负责文件数据的存储和读写操作，HDFS 将文件数据分隔成若干数据块（Block），每个 DataNode 存储一部分数据块，这样文件就分部存储在整个 HDFS 服务器集群中。应用程序客户端（Client）可以并行对这些数据块进行访问，从而使得 HDFS 可以在服务器集群规模上实现数据并行访问，极大地提高了访问速度。在实践中，HDFS 集群的 DataNode 服务器会有很多台，一般在几百台到几千台这样的规模，每台服务器配有数块硬盘，整个集群的存储容量大概在几 PB 到数百 PB。 NameNode 负责整个分布式文件系统的元数据（MetaData）管理，也就是文件路径名、访问权限、数据块的 ID 以及存储位置等信息，相当于 Linux 系统中 inode 的角色。HDFS 为了保证数据的高可用，会将一个数据块复制为多分（缺省情况下为 3 份），并将多份相同的数据块存储在不同的服务器上，甚至不同的机架上。这样当有硬盘损坏，或者某个 DataNode 服务器宕机，甚至某个交换机宕机，导致其存储的数据块不能访问的时候，客户端会查找其备份的数据块进行访问。 有了 HDFS，可以实现单一文件存储几百 T 的数据，再配合大数据计算框架 MapReduce 或者 Spark，可以对这个文件的数据块进行并发计算。也可以使用 Impala 这样的 SQL 引擎对这个文件进行结构化查询，在数千台服务器上并发遍历 100T 的数据，1 分钟都是绰绰有余的。 小结 文件系统从简单操作系统文件，到 RAID 再到分布式文件系统，其设计思路其实是具有统一性的。这种统一性方面体现在文件数据如何管理，也就是如何通过文件控制块管理文件的数据，这个文件控制块在 Linux 系统中就是 inode，在 HDFS 中就是 NameNode。 另一方面体现在如何利用更多的硬盘实现越来越大的文件存储需求和越来越快的读写速度需求，也就是将数据分片后同时写入多块硬盘。单服务器我们可以通过 RAID 来实现，多服务器则可以将这些服务器组成一个文件系统集群，共同对外提供文件服务，这时候，数千台服务器的数万块硬盘以单一存储资源的方式对文件使用提供服务，也就是一个文件可以存储数百 T 的数据，并在一分钟完成这样一个大文件的遍历。 "},"interview/前端_面试.html":{"url":"interview/前端_面试.html","title":"前端_面试","keywords":"","body":"面试——原理 [toc] HTML HTML 自定义元素 HTML 自定义元素教程 组件是 web 开发的方向，HTML 规范有一个令人感到兴奋的功能，自己可以自定义 HTML 元素，浏览器对待自定义元素，就像对待标准元素一样，只是没有默认的样式和行为。事实上，浏览器提供了一个 HTMLUnknownElement 对象，所有的自定义元素都是该对象的实例，有了自定义元素，就可以写出语义性非常好的 HTML 代码。HTML 5 规定了自定义元素是合法的，W3C 就为自定义元素制定了一个单独的 Custom Elements 标准，与其它三个标准：HTML Imports，HTML Template，Shadow DOM 统称为 Web Components 规范。Custom Elements 规定自定义元素的名字必须包含一个破折号，这样 HTML 解析器就可以分辨哪些是标准元素，哪些是自定义元素。一旦使用了破折号，自定义元素就不是 HTMLUnknownElement 的实例了。而且 Custom Elements 标准规定自定义元素可以使用 ES 6 的 class 语法，这样可以很容易的写出继承类 vue 组件和自定义元素很像，它们之间的主要不同是 Vue 组件的数据模型是作为框架的一部分而设计的，而框架为了构建复杂的应用提供了很多必要的附加功能，比如响应式模板和状态管理 行内元素、块状元素、行内块状元素 HTML 内行内元素、块状元素、行内块状元素的区别：display: inline; display: block; display: inline-block。一个行内元素只占据它对应标签的边框所包含的空间、块级元素占据父元素的整个空间、行内块状元素综合了行内元素和块状元素的特点，但是各有取舍 行内元素的特点： 设置宽和高无效 margin 和 padding 设置左右有效，上下无效 不会自动换行 块状元素的特点： 能够识别宽高 margin 和 padding 的上下左右都有效 可以自动换行 默认排列方式是从上到下 行内块状元素的特点： 不自动换行 能设置宽高 默认排列方式为从左到右 禁止用户缩放 将meta属性里面的 user-scalable 设置为 no script 标签，async，defer script标签上使用 defer和 async的区别（前端面试） script 是引入js 代码的，而 async、defer 可以优化加载第三方脚本 因此 script标签的使用分为三种情况： 没有 async 和 defer 属性，浏览器会立即加载并执行相应的脚本，不等待后续加载的文档元素，读到就开始加载和执行，此举会阻塞后续文档的加载 使用了async 属性，表示后续文档的加载和渲染与 js 脚本的加载和执行是并行进行的，即异步执行 使用了 defer 属性，表示加载后续文档的过程和 js 脚本的加载是并行进行的，此时的 js 脚本仅加载不执行，js 脚本的执行需要等到文档的所有元素解析完成之后 区别： 从图中我们可以明确一下几点： 1.defer和async在网络加载过程是一致的，都是异步执行的；(放在页面顶部,也不会阻塞页面的加 载,与页面加载同时进行) 2.两者的区别,脚本加载完成之后, async是立刻执行, defer会等一等 (等前面的defer脚本执行,等dom的加载) 所以, js脚本加上 async或 defer,放在头部可以减少网页的下载加载时间,如果不考虑兼容性,可以用于优化页面加载的性能 事件冒泡，事件捕获，事件流，事件代理，阻止冒泡 你真的理解 事件冒泡 和 事件捕获 吗？ 事件冒泡和事件捕获分别由微软和网景公司提出的，这两个概念都是为了解决页面各种事件流（事件发生顺序的）的问题 事件冒泡：从事件源朝父级一直到根元素（html），当某个元素的某类型事件被触发时，那么它的父元素同类型的事件也会被触发，一直触发到根源上，从具体元素到不确定元素 事件捕获：从根元素（html）到事件源，当某个元素的某类型被触发时，先触发根元素的同类型事件，朝子一级触发，一直触发到事件源，从不确定的元素到具体的元素 事件流：就是事件的流向，先捕获，再到事件源，然后在冒泡，一共分三个阶段：捕获阶段，目标阶段，冒泡阶段 在实际的开发中，利用事件流的特性，我们可以使用一种叫做事件代理的方法，使用事件代理的好处不仅在于将多个事件处理函数减为一个，而且对于不用的元素可以有不同的处理方法 阻止事件冒泡： 给子级加 event.stopPropagation() 在事件处理函数中返回 false 但是这两种方式是有区别的。return false 不仅阻止了事件往上冒泡，而且阻止了事件本身(默认事件)。event.stopPropagation()则只阻止事件往上冒泡，不阻止事件本身。 阻止默认行为 有一些html元素默认的行为，比如说a标签，点击后有跳转动作；form表单中的submit类型的input有一个默认提交跳转事件；reset类型的input有重置表单行为。 如果你想阻止这些浏览器默认行为：event.preventDefault() 或者 return false BOM 面试官：说说你对BOM的理解，常见的BOM对象你了解哪些？ BOM(Browser Object Model)，浏览器对象模型，提供了独立于内容与浏览器窗口进行交互的对象。其作用就是跟浏览器做一些交互兄效果，比如如何进行页面的前进、后退、刷新，浏览器的窗口发生变化，滚动条的滚动等 常见的 BOM 对象有： window：它表示浏览器的一个实例，在浏览器中，window对象有双重角色，即是浏览器窗口的一个接口，又是全局对象 location：url地址 history：history对象主要用来操作浏览器URL的历史记录，可以通过参数向前，向后 懒加载、预加载 前端面试题 - 懒加载实现原理 加载图片资源的优化方式经常使用的就是 懒加载 和 预加载的方式 懒加载就是延时加载，也称为按需加载，具体表现为，当我们访问页面时，先将 img 图片的路径替换成一张占位图的路径，这样就只需请求一次，而当图片进入可视区域时候，才把图片路径替换成真正的图片的路径，从而显示图片，达到懒加载的效果 技术原理是：先将img的src属性隐藏，而将其真正的地址存放在img标签自定义的属性中(eg：data-src)，当图片进入可视区域时，将真正的路径从data-src中取出替换回来，从而显示图片 预加载就是提前加载，用户需要图片的时候从缓存中获取 具体表现为，显然 img 显示其它图片，当真实图片缓存完成后，再显示真正的图片，最常用的方式是 new Image() 设置src属性来实现预加载，再使用onload回调预载完成事件。也可以使用 css 的 background 属性将图片加载了却不显示（但是不推荐，会影响页面的加载速度） css 样式单位 css 中自适应的单位有哪些 vw（相对于视口宽度的单位） vh vm（相对于视口宽度或者高度，取决于哪个小） em（相对于父元素字体大小的单位） rem（相对于根元素字体大小的单位） 伪类，伪元素 前端面试题-伪类和伪元素 css 引入伪类和伪元素的概念是为了格式化文档树以外的信息，也就是说，伪类和伪元素是用来修饰不在文档树种的部分，比如，一句话种的第一个字母 伪类用于当已有元素处于的某个状态时，为其添加对应的样式，这个状态是根据用户行为而动态变化的。当用户悬停在指定的元素时，我们可以通过 :hover 来描述这个元素的状态。虽然它和普通的 CSS 类相似，可以为已有的元素添加样式，但是它只有处于 DOM 树无法描述的状态下才能为元素添加样式，所以将其称为伪类。 伪元素用于创建一些不在文档中的元素，并为其添加样式。，比如我们可以用 ：before 来在一个元素前增加一些文本，并为这些文本添加样式，用户也可以看到这些文本，但是这些文本实际上不在文档树中 浮动与清除浮动 前端面试题-clearfix（清除浮动 浮动的概念 浮动的框可以向左或向右移动，直到它的外边缘碰到包含框或另一个浮动框的边框为止，由于浮动框不在文档的普通流种，所以文档的普通流种的块框表现得就像浮动框不存在一样 浮动的影响：浮动会导致父元素高度塌陷：如果父元素没有设置高度，子元素在父元素种浮动，结果必然是父元素的高度为 0，导致父元素高度塌陷的问题 浮动的清除 在浮动元素后添加一个空标签，并且在CSS中设置 clear{clear:both;}，即可清理浮动，添加一个空标签，父元素可以自动获取到高度，有点是简单，代码少且兼容，缺点是增加页面的标签，造成结构混乱，现在该方法已经过时 :after 伪元素，给浮动元素的容器添加一个clearfix的class，然后给这个class添加一个:after伪元素实现元素之后添加一个看不见的块元素（Block element）清理浮动 clearfix:after{ content: \"\\20\"; display: block; height: 0; clear: both} 定位 position 有哪些值及其作用 position有4个值，分别是static，relative, absolute, fixed. 一般元素的默认值是static。 relative 是相对定位，相对该元素本来应该在的位置偏移，偏移后可能和其它正常元素重叠 absolute 是绝对定位，相对于 static 定位以外（即relative，absolute和fixed）的第一个父元素进行定位，设置成absolute之后，元素将会脱离文档布局，即该元素在页面中并不占有位置，而是显示在正常元素的上层或者下层 fixed是相对浏览器视窗定位，页面滚动时，fixed定位的元素相对浏览器视窗的位置始终不变。设置成fixed之后，元素将会脱离文档布局，即该元素在页面中并不占有位置，而是显示在正常元素的上层或者下层。 文档流：块元素都是从上到下，行内元素都是从左到右，这些元素在文档中排列时候都会占用位置，称为文档流，一般设置了position: absolute， position: fixed, float: left, float: right的元素为脱离文档流 选择器，选择器优先级 面试官：说下CSS选择器优先级 样式类型：行内样式，内联样式，外部样式；选择器类型：id 选择器、class 选择器、属性选择器、*、伪类选择器、后代选择器、子类选择器、兄弟选择器 权重计算规则： 第一优先级：!important会覆盖页面内任何位置的元素样式 1.内联样式，如style=\"color: green\"，权值为1000 2.ID选择器，如#app，权值为0100 3.类、伪类、属性选择器，如.foo, :first-child, div[class=\"foo\"]，权值为0010 4.标签、伪元素选择器，如div::first-line，权值为0001 5.通配符、子类选择器、兄弟选择器，如*, >, +，权值为0000 6.继承的样式没有权值 比较规则 1.1000 > 0100，从左向右逐个比较，前一级相等才能往后比较 2.无论是行内样式、内部样式还是外部样式，都是按照以上提到的权重方式进行比较，面试的时候遇到优先级比较，答案往往是：行内>id>class>元素(标签)，我们以为给了能令面试官满意的答案，其实不然，比如对同一个元素操作，在权重相等的情况下，后面的样式会覆盖前面的，这样我们给出来的答案就不成立了 3.权重相同的情况下，位于后面的样式会覆盖前面的样式 4.通配符、子选择器、兄弟选择器，虽然权重为0000，但是优先于继承的样式 基本盒子模型 CSS基本盒子模型介绍 当对一个文档进行布局（lay out）的时候，浏览器的渲染引擎会根据标准之一的 CSS 基础框盒模型（CSS basic box model），将所有元素表示为一个个矩形的盒子（box）。CSS 决定这些盒子的大小、位置以及属性（例如颜色、背景、边框尺寸…）。每个盒子由四个部分组成，其效用由它们各自的边界（Edge）所定义。每个盒子由四个边界：内容边界 Content edge，内边距边界 Padding edge，边框边界 Border edge，外边框边界 Margin edge 传统布局 CSS 居中：完整指南 布局的传统解决方案，基于盒子模型，依赖 display 属性 + position 属性 + float 属性，它对于那些传统布局非常不方便，比如居中就不容易实现 水平居中 如果元素是一个 inline 或者 inline-block，在父元素中使用 text-align: center 如果元素是块元素，可以使用 margin: 0 auto 如果多个元素 .inline-block-center { text-align: center; } .inline-block-center div { display: inline-block; text-align: left } 垂直居中 如果是一个 inline 或者 inline-block，使用 padding-top 和 padding-bottom 将上下填充相同，或则将文本的 line-height 等于高度 如果是一个块级元素 如果知道高度 .parent {position: relative} .child {position: absolute; top: 50%; height: 100px; margin-top: -50px} 如果未知高度 parent {position: relative} .child {position: absolute; top: 50%; transform: translateY(-50%)} 可以做成一个表格 同时水平和垂直居中 固定宽度和高度的元素：.parent {position: relative} .child {width: 300px; height: 100px; position: absolute; top: 50%; left: 50%; margin: -70px 0 0 -170px} 未知宽度：.parent{position: relative} .child { position: relative; top: 50%; left: 50%; transform: translate(-50%, -50%)} css transform 属性允许你旋转，缩放，倾斜或平移给定元素，这是通过修改 css 视觉格式化模型的坐标空间来实现的 flex 布局 Flex 布局教程：语法篇 2009 年，提出的 Flex 布局，可以简便、完整、响应式地实现各种页面的布局。Flex 是 Flexible Box 的缩写，意为\"弹性布局\"，用来为盒状模型提供最大的灵活性。任何一个容器都可以指定为 Flex 布局： display: flex。采用 flex 布局的元素，称为 flex container，简称容器，它的所有子元素自动成为容器成员，称为欸flex item，简称 项目 容器默认存在两根轴，水平的主轴（main axis）和 垂直的交叉轴（cross axis），主轴开始位置叫 main start，结束位置叫 main end，交叉轴开始的位置叫 cross start，结束的位置叫 cross end。项目默认沿主轴排列，单个项目占据的主轴空间叫做 main size，占据的交叉轴空间叫做 cross size 容器的属性有： flex-direction，决定主轴的方向：row | row-reverse | column | column-reverse flex-wrap，决定换行：nowrap | wrap | wrap-reverse flex-flow，是 flex-direction 属性和 flex-wrap 属性的简写方式，flex-flow: | | justify-content 属性定义了项目在主轴上的对齐方式：flex-start | flex-end | center | space-between | space-around align-items，定义项目在交叉轴上如何对齐：flex-start | flext-end | center | baseline | stretch align-content，定义了多根轴线的对齐方式：flex-start | flex-end | center | space-between | space-around | stretch grid 布局 CSS Grid 网格布局教程 网格布局（grid）是最强大的css布局方案，它将网页划分成一个个网格，可以任意组合不同的网格，做出各种各样的布局。以前，只能通过复杂的 css 框架达到的效果，现在浏览器内置了。Grid 布局与 Flex 布局有一定的相似性，都可以指定容器内部多个项目的位置。但是，它们也存在重大区别。Flex 布局是轴线布局，只能指定项目针对轴线的位置，可以看成是一维的布局。grid 布局则是将容器划分成行和列，产生单元格，然后指定“项目所在”的单元格，可以看作是二维布局。 容器里面的水平区域称为 行（row），垂直区域称为 列（column），行和列的交叉区域，称为单元格（cell），划分网格的线，称为网格线（grid line），grid 布局的属性分为两类，一类定义在容器上面，称为容器属性；另一类定义在项目上，称为项目属性 容器属性： display：grid 指定一个容器采用网格布局，默认情况下容器元素都是块级元素，但也可以通过 display: inline-grid 设置成行内元素 容器指定网格布局后，接着就要划分行和列。grid-template-columns 属性定义每一列的列宽，grid-template-rows 定义每一行的行高，有时候，重复写很麻烦，可以用 repeat 函数 auto-fill，单元格大小确定，容器大小不确定，auto-fill 表示自动填充 fr：为了方便表示比例关系，网格布局提供了 fr 关键字，如果两列的宽度分别是 1 fr 和 2 fr，就表示后者是前者的两倍 justify-items属性设置单元格内容的水平位置（左中右），align-items属性设置单元格内容的垂直位置（上中下） justify-content属性是整个内容区域在容器里面的水平位置（左中右），align-content属性是整个内容区域的垂直位置（上中下）。 5 种 css 经典布局 只要一行代码，实现五种 CSS 经典布局 常用页面的布局其实就那么几个 空间居中布局：不管容器大小，项目总是占据中心点 .container { dispaly: grid; place-items: center} 并列式布局：多个项目并列 .container { display: flex; flex-warp: wrap; justify-content: center} .item:{flex: 0 1 150px; margin: 5px} 两栏式布局：边栏始终存在，主栏根据设备宽度，变宽或者变窄 .container{display: grid; grid-template-columns: minmax(150x, 25%) 1fr;} 三明治布局：页面在垂直方向，分成三部分（页眉、内容区、页脚） .container{ display: grid; grid-template-rows: auto 1fr auto} 圣杯布局：它将页面分成五个部分，除了页眉和页脚，内容区分成左边栏、主栏、右边栏 .container{ display: grid; grid-template-rows: auto 1fr auto / auto 1fr auto} bfc 面试官：谈谈你对BFC的理解 元素之间相互影响，可能导致意外的情况发生，这就涉及到了 BFC，BFC（Block Formatting Context），即块级格式化上下文，它是页面中的一块渲染区域，并且有一套属于自己的渲染规则： 内部的盒子会在垂直方向上一个接一个的放置 对于同一个BFC的俩个相邻的盒子的margin会发生重叠，与方向无关。 每个元素的左外边距与包含块的左边界相接触（从左到右），即使浮动元素也是如此 BFC的区域不会与float的元素区域重叠 计算BFC的高度时，浮动子元素也参与计算 BFC就是页面上的一个隔离的独立容器，容器里面的子元素不会影响到外面的元素，反之亦然 BFC目的是形成一个相对于外界完全独立的空间，让内部的子元素不会影响到外部的元素 JavaScript 基本类型 数值（number）：整数和小数（比如1和3.14）。 字符串（string）：文本（比如Hello World）。 布尔值（boolean）：表示真伪的两个特殊值，即true（真）和false（假）。 undefined：表示“未定义”或不存在，即由于目前没有定义，所以此处暂时没有任何值。 null：表示空值，即此处的值为空。 对象（object）：各种值组成的集合。 对象是最复杂的数据类型，又可以分成三个子类型： 侠义的对象（object） 数组（array） 函数（function） typeof null 的类型是 object，undefined == null 是 true，null 转为数字是 0，undefined 转为数字是 NaN typeof 和 instanceof typeof 操作符返回一个字符串，便是未经计算的操作数的类型，typeof null 为 object 是一个 bug，如果我们想要判断一个变量是否存在，可以使用 typeof a != 'undefined' instanceof 运算符用于检测构造函数的 prototype 属性是否出现在某个实例对象的原型链上 object instanceof constructor this JavaScript 的 this 原理 this 是 JavaScript 语言的一个关键字，由于函数可以在不同的运行环境中执行，所以需要一种机制，能够在函数体内获得当前的运行环境（context），所以，this 就出现了，它的设计目的就是在函数体的内部，指代函数当前运行环境。当函数运行时 this 在函数内部自动生成一个对象，只能在函数体内部使用。函数的不同使用场景，this 有不同的值。总的来说，this 就是函数运行时所在的环境对象，有四种情况： 纯粹的函数调用：这是函数的最通常用法，属于全局性调用，因此 this 就代表全局对象 作为对象的方法调用：函数还可以作为某个对象的方法调用，这时候 this 就是指这个上级对象 作为构造函数使用：对构造函数使用 new 运算符，就能够生成实例，并且 this 变量会绑定在实例对象上 apply、call、bind 调用：查看 this 的具体指向 call，apply，bind 深入浅出，妙用 apply、call、bind 在 JavaScript 中，call 和 apply 都是为了改变某个函数运行时的上下文（context）而存在的，换句话说，就是为了改变函数内部 this 的指向。JavaScript 的一大特点是，函数存在定义时上下文和运行时上下文以及上下文是可以改变的这样的概念 call 和 apply 都是为了动态改变 this 而存在的，当一个 object 没有某个方法，但是其它的有，我们就可以借助 call 或 apply 用其他对象的方法来操作 apply、call 的区别 call 需要把参数按顺序传递进去，而 apply 则是把参数放在数组里 bind() 方法与 apply 和 call 很相似，也是可以改变函数体内 this 的指向，MDN 的解释是，bind 方法会创建一个函数，称为绑定函数，当调用这个绑定函数时，绑定函数会以创建它时传入 bind 方法的第一个参数作为 this，传入 bind 方法的第二个以及以后的参数加上绑定运行时本身的参数按照顺序作为原函数的参数来调用原函数，bind 可以更加优雅的解决 _this 的问题。在 JavaScript 中，多次 bind 是无效的，bind 的实现，相当于使用函数在内部包了一个 call/apply apply、call、bind 三者都用来改变函数的 this 的指向的 apply、call、bind 三者第一个参数都是 this 要指向的对象，也就是向指定的上下文 apply、call、bind 三者都可以利用后续参数传参 bind 是返回对应函数，apply、call 是立即调用 原型与原型链 Javascript继承机制的设计思想 原型链关系图 在 es 6 还没有出来的时候，JavaScript 没有子类和父类的概念，也没有类和实例的区分，全靠一种很奇特的原型链（prototype chain）模式，来实现继承 JavaScript 是一种基于对象的语言，是需要封装的，设计 js 语言的时候，作者觉得不需要类，会太复杂了，所以只是弄了一个构造函数的模式。所谓构造函数，其实就是一个普通的函数，但是内部使用了 this 变量，对构造函数使用 new 运算符，就能够生成实例，并且 this 变量会绑定在实例对象上。每个实例对象都会自动含有一个 constructor 属性，指向它们的构造函数。 构造函数的方法很好用，但是存在一个浪费内存的问题，所以 JavaScript 规定，每个构造函数都有一个 prototype 属性，指向另一个对象，这个对象的所有属性和方法都会被构造函数的实例继承，现在称之为 Prototype 模式 prototype 模式的验证模式： isPrototypeof()：这个方法用来判断某个 prototype 对象和某个实例之间的关系 hasOwnProperty()：每个实例对象都有一个 hasOwnProperty() 方法，用来判断某一个属性到底是本地属性，还是继承的自 prototype 对象的属性 in：in 运算符可以用来判断，某个实例是否含有某个属性 对象之间的继承的五种方法： 构造函数绑定：使用 call 或 apply 方法，将父对象的构造函数绑定在子对象上，即在子对象构造函数中加一行： function Cat(name, color) { Animal.apply(this, arguments) this.name = name this.color = color } prototype 模式：如果目标的 prototype 对象，指向 Animal 的实例，那么所有目标的实例，都能继承 Animal 了。任何一个 prototype 对象都有一个 constructor 属性，指向它的构造函数，更重要的是每个实例也有一个 constructor 属性，默认调用 prototype 对象的 constructor 属性 Cat.prototype = new Animal(); Cat.prototype.constructor = Cat; 直接继承 prototype：这是对第二种方法的改进，由于 Animal 属性中，不变的属性都可以直接写入 Animal.prototype，所以我们也可以让 Cat 跳过 Animal，直接继承 Animal.prototype。与前一种方法相比，效率更高了（不用执行了建立 Animal 的实例了），缺点是现在 Cat.prototype 和 Animal.prototype 现在指向了同一对象，任何对 Cat.prototyp 的修改，都会反映在 Animal.prototype Cat.prototype = Animal.prototype Cat.prototype.constructor = Cat 利用空对象作为中介：由于直接继承 prototype 存在上述缺点，所以第四种方法利用一个空对象作为中介 let F = function() {} F.prototype = Animal.prototype Cat.prototype = new F() Cat.prototype.constructor = Cat 我们可以将上面的方法，封装成一个函数，便于使用 function extend(Child, Parent) { let F = function() {} F.prototype = Parent.prototype Child.prototype = new F() Child.prototype.constructor = Child Child.uber = Parent.prototype // uber，向上一层，纯属备用 } 拷贝继承：把父对象的所有属性和方法，拷贝进子对象，也能够实现继承 function extend2(Child, Parent) { let p = Parent.prototype let c = Child.prototype for(let i in p) { c[i] = p[i] } c.uber = p } 非构造函数的继承，如果两个对象都是普通对象，不是构造函数，怎么继承 object()方法：把子对象的 prototype 属性，指向父对象，从而使得子对象与父对象连在一起 function object(o) { function F() {} F.prototype = o return new F() } 浅拷贝：处理使用 “prototype链”以外，还有另外一种思路：把父对象的属性，全部拷贝给子对象，也能实现继承。但是这样会有一个问题，如果父对象的属性等于数组或另一个函数，那么实际上，子对象获得的只是一个内存地址 function extendCopy(p) { let c = {} for(let i in p) { c[i] = p[i] } c.uber = p return c } 深拷贝：就是能够实现真正意义上的数组和对象的拷贝，实现只要递归调用浅拷贝就行 function deepCopy(p, c) { let c = c || {} for(let i in p) { if(typeof p[i] === 'object') { c[i] = (p[i].constructor === Array) ? [] : {} deepCopy(p[i], c[i]) } else { c[i] = p[i] } } return c } 作用域和闭包 闭包（closure）是 JavaScript 语言的一个难点，也是他的特色，很多高级应用都要依靠闭包来实现，函数和对其周围状态（lexical environment，词法环境）的引用捆绑在一起构成闭包（closure）。也就是说，闭包可以让你从内部函数访问外部函数作用域。在 JavaScript 中，每当函数被创建，就会在函数生成时生成闭包。 阮一峰老师的说法就是，闭包就是能够读取其他函数内部变量的函数，由于在 JavaScript 语言中，只有函数内部的子函数才能读取局部变量，因此可以把闭包简单理解成“定义在一个函数内部的函数”，所以在本质上，闭包就是将函数内部和函数外部连接起来的一座桥梁 闭包可以用在很多地方，它的最大的用处有两个：一个是读取函数内部的变量，一个是让这些变量的值始终保持在内存中（把闭包赋值给一个全局变量，就导致父函数也始终在内存中，不会在调用结束后，被垃圾回收机制回收） 使用闭包的注意点： 由于闭包会使得函数中的变量都被保存在内存中，内存消耗很大，所以不能滥用闭包，否则会造成网页的性能问题，在 IE 中可能导致内存泄露。解决办法是，在退出函数之前，将不适用的局部变量全部删除 闭包会在父函数外部，改变父函数内部变量的值。所以，如果你把父函数当作对象（object）来使用把闭包当作它的公用方法，把内部变量当作它的私有属性，这是一定要小心，不要随便改变父函数内部变量的值 内存泄漏 js面试之闭包和内存泄漏 内存泄露是指不再使用的内存，没有及时释放。垃圾回收器定期扫描对象，并计算引用了每个对象的其它对象的数量。如果一个对象的引用数量为 0（没有其它对象引用过该对象），或该对象的唯一引用是循环的，那么该对象的内存即可回收 造成泄露额操作： 意外的全局变量：全局变量引用，变量未申明。当全局变量使用不当，没有及时回收（手动赋值为 null ），或者错误将某个变量挂载到了全局变量，也就发生了内存泄露了 被遗忘的计时器或回掉函数： DOM 元素的生命周期是取决于：是否挂载在 DOM 树上，当从 DOM 树上移除时，也就可以被销毁回收了，但如果某个 DOM 元素，在 js 中也持有它的引用时，那么它的生命周期就由 js 和 DOM 树两者一起决定了，需要两个地方都要清楚 setTimeout ，setInterval 也会有同样的问题，当有不需要的 interval 或者 timeout 时，最好调用 clearInterval 或者 clearTimeout 来清除 垃圾回收 垃圾回收的机制：找出不再使用的变量，然后释放掉其占用的内存，但是这个过程不是实时的，因为其开销比较大，所以垃圾回收器会按照固定的时间间隔周期性的执行 JS权威指南解释说：由于字符串、对象和对象没有固定大小，所有当他们的大小已知时，才能对他们进行动态的存储分配。JavaScript 程序每次创建字符串、数组或对象时，解释器都必须分配内存来存储哪个实体，只要像这样动态地分配了内存的，最终都要释放掉这些内存以便他们能够再用，否则JavaScript的解释器（执行JavaScript源码的）将会消耗掉系统中所有可用的内存，造成系统崩溃 全面了解浏览器 JS核心知识点梳理——异步，单线程，运行机制 浏览器有许多进程： Browser 进程：浏览器的主进程（负责协调、主控），只有一个 第三方插件：每种类型的插件对应一个进程 GPU 进程：最多一个，用于 3D 绘制 浏览器渲染进程（浏览器内核）：Renderer 进程，内部是多线程的 在浏览器渲染进程中有许多线程： 渲染引擎线程：顾名思义，该线程负责页面的渲染 JS 引擎线程：负责JS的解析和执行（主线程） 定时触发器线程：处理定时任务，比如 setTimeout，setInterval 事件触发线程：处理 DOM 事件 异步 http 请求线程：处理 http 请求 单线程与事件循环 单线程模型 单线程模型指的是 JavaScript 只在一个线程上执行，也就是说，JavaScript同时只能执行一个任务，其它任务都必须在后面排队等待。值得注意的是，JavaScript 脚本只在一个线程上运行，不代表 JavaScript 引擎有多个线程，单个脚本只能在一个线程上执行（称为主线程）但是其它线程都在后台配合。 JavaScript之所以采用单线程，而不是多线程，跟历史有关系。JavaScript 从诞生起就是单线程，原因是不想让浏览器变得太复杂，因为多线程有些时候需要共享资源，且有可能修改彼此的运行结果，还得上锁的机制。所以，为了避免复杂性，JavaScript 一开始就是单线程，这已经成为了这门语言的核心特征（Web Worker 标准可以利用多核CPU的计算能力，但是子线程完全受主线程控制且不得操作 DOM，并没有改变单线程的的本质） 事件循环是一种循环检查的机制 单线程模式的好处是实现起来简单，执行环境相对单纯；坏处是只要有一个任务耗时很长，后面的任务就必须排队等着（同步），常见的就是浏览器无响应。JavaScript 语言本身并不慢，慢的是读写外部数据，比如等待 Ajax 请求返回的结果。如果排队是因为计算量大，CPU忙不过来就算了，但是很多时候CPU是闲着的，主要是因为 IO 操作。因此，JavaScript 语言的设计者意识到，这时 CPU 完全可以不管 IO 操作，挂着处于等待的任务，先运行排在后面的任务。等到 IO 操作返回了结果，再回过头，把挂起的任务继续执行下去，这种机制就是 JavaScript 内部采用的“事件循环”机制（Event Loop） 同步和异步 程序里所有的任务，都可以分为两类：同步任务（synchronous）和异步任务（asynchronous） 同步任务是那些没有被引擎挂起、在主线程上排队执行的任务，只有前一个任务执行完毕，才能执行后一个任务。异步任务是那些被引擎放在一边，不进入主线程，而进入任务队列的任务。只有引擎认为某个异步任务可以执行了（比如从服务器得到了结果），该任务（采用回调函数的形式）才会进入主线程执行。排在异步任务后面的代码，不用等待异步任务就会马上执行，也就是说异步任务不具有“堵塞”效应 任务队列和事件循环 JavaScript 运行中，除了一个正在运行的主线程，引擎还提供一个任务队列（task queue），里面是各种需要当前程序处理的异步任务。（实际上，根据异步任务的类型，存在多个任务队列，未来方便了解，这里假设只存在一个队列） 首先，主线程会去执行所有的同步任务，等到所有同步任务全部执行完，就回去看任务队列里面的异步任务。如果满足条件，那么异步任务就重新进入主线程开始执行，这是它就变成同步任务了。等到执行完，下一个异步任务再进入主线程开始执行，一旦任务队列队列清空，程序就介绍执行了 异步任务的写法通常是回调函数。一旦异步重新进入主线程，就会执行对应的回调函数。如果一个异步任务没有回调函数，就不会进入任务队列，也就是不会重新进入主线程，因为没有用回调函数指定下一步的操作 JavaScript 引擎怎么知道异步任务有没有结果，能不能进入主线程呢？答案就是引擎在不停的检查，一遍又一遍，只要同步任务执行完了，引擎就会去检查那些挂起来的异步任务是不是可以进入主线程。这种循环检查的机制就是事件循环（Event Loop） 宏任务（macrotask）、微任务（microtask） 宏任务，微任务、练习 宏任务又称为 task，可以理解是每次执行栈执行的代码就是一个 task，task1 -> 渲染 -> task1，比如主代码块，setTime 微任务：可以理解是在当前 task 执行结束后立即执行的任务，所以 microtask 有归属性，只在对应的 task 执行完之后立即执行：task1 -> microtask1 -> 渲染 -> task2 -> micorotask2，比如 Promise，process.nextTick 回调函数 回调函数是异步操作最基本的方法，就是将函数作为参数传入另外一个函数，回调函数的优点是简单，容易理解和实现，缺点是不利于代码的阅读和维护，各个部分之间高度耦合 异步 Promise 前端面试必备——异步（Promise） Promise 对象是 CommonJS 工作组提出的一种规范，目的是为异步编程提供统一接口，简单的说，它的思想就是，每个异步任务返回一个 Promise 对象，该对象有一个 then 方法，允许指定回调函数，这样写的优点是，回调函数变成了链式写法，程序的流程可以看的很清楚。它还有一个好处是如果一个任务已经完成，再添加回调函数，该回调函数会立即执行。 基础特性： Promise 对象初始状态值为 pending 立即执行 Promise 里面的代码，在代码中通过 resolve，reject改变 promise 状态为 fulfilled 和 rejected 状态一旦改变就不能再改变 then 方法中的回调函数会在状态改变后执行，成功的调成功的回调，失败就调失败的回调，调用的值会传递到回调函数的参数中 异步 Async 前端面试必备——异步（async） 生成器（Generator）是一种返回迭代器的函数，通过function 关键字后的星号（*）来表示，函数中会用到新的关键字 yield，生成器的调用和普通函数相同，只是返回的是一个迭代器（Iterator）。Generator 函数是 ES6 提供的一种异步编程解决方案，语法行为与传统函数完全不同。Generator 函数是一个状态机，封装了多个内部状态。yield 相当于隔断点执行 Generator 函数会返回一个遍历器对象，通过调用 next 方法使状态不断改变。 function *read() { let age = yield readFile('./name.txt', 'utf8') let ageData = yield readFile('./${age}', 'utf8') return ageData } let it = read() let {value, done} = it.next() value.then(data => let {value, done} = it.next(data)) generator 是解决异步的另外一个方案，但是需要手动调用 next 方法，有一个 co 函数，代码就几行，但是能帮我们自动调用 next 方法 co(it){ return new Promise((resolve,reject)=>{ function next(val){ {value,done}=it.next(val) //手动next程序到第一个yield的地方 if(done){ //都已经成功了还有什么好说的，直接返回结果就行了 resolve(value) }else{ return Promise.resolve(value).then(next,rejext) //核心，看懂co的思想就会了 } } next(undefined) }) } co(read()).then(data => console.log(data)) // 调用变得超级简单 async、await 实际上就是 generator + co 函数的语法糖，就是 generator + 自动执行器，执行顺序是：第一个 await 前的都是同步代码，第一个 await 后面的代码可以看成在 promise.then 里面的，相当于是一个微任务，所以程序在主栈里面执行 async 函数，会先执行 await 前面的宏任务，然后遇到 await ，await 后面的会放在微任务队列里面，返回主栈去执行主栈里面的其它宏任务 比较官方的说法：async 函数返回一个 Promise 对象，当函数执行的时候，一旦遇到 await 就会先返回，等到触发的异步操作完成，再执行函数体内后面的语句。可以理解为，是让出了线程，跳出了 async 函数体。 防抖节流 函数防抖(debounce)与函数节流(throttle)%E4%B8%8E%E5%87%BD%E6%95%B0%E8%8A%82%E6%B5%81(throttle)/) 在前端开发中，有一部分的用户行为会频繁的触发事件执行，而对于 DOM 操作、资源加载等耗费性能的处理，很可能导致界面卡顿，甚至浏览器的崩溃。函数节流（throttle）和函数防抖（debounce）就是为此而生的。浏览器的 resize、scroll、keypress、mousemove 等事件的触发会不断的调用绑定在事件上的回调函数，极大浪费资源 函数防抖：当事件触发之后，必须等待一个时间（N）之后，回调回函才会执行，假如在等待的时间内，事件又触发了，则重新设置等待时间，直到在时间（N）内事件不被触发，则在最后一次触发事件后，执行事件。作用是在短时间内多次触发同一函数，只执行最后一次 function debounce(fn, delay) { var timer = null return function() { let context = this // 保存函数调用时的上下文和参数，传递给 fn let args = arguments if(timer) clearTimeout(timer) // 函数被调用，清楚定时器 timer = setTimeout(function () { // 当返回的额函数最后一次调用，等到 delay 毫秒就可以执行 fn.apply(context, args) }, delay) } } 函数节流（throttle）：节流函数允许一个函数在规定的时间内只执行一次，它和防抖最大的区别是，节流函数不管事件触发有多频繁，都会保证规定时间内执行一次 function throttle(func, delay) { var timer = null return function() { var context = this; var args = arguments; if(!timer) { timer = setTimeout(function() { func.apply(context, args) timer = null }, delay) } } } 正则 RegExp对象 正则表达式（regular expression）是一种表达文本模式（即字符串结构）的方法，有点像字符串的模板，常常用来按照“给定模式”匹配文本。比如，正则表达式给出一个 Email 地址的模式，然后用它来确定一个字符串是否为 Email 地址 修饰符 g 全局，m 多行，i 忽略大小写 实例方法：test 是否包含、exec 返回匹配结果，是一个数组，如果正则表达式包含圆括号，则返回的数组会包括多个成员，第一个成员是整个匹配成果的记过，后面的成员就是圆括号对应的匹配成果的组、match 类似与 exec、search、replace、split、 点字符（.）匹配除回车意外的的所有字符 位置字符 ^ 开始，$ 结束 选择符 | 或者 字符类 [] 脱字符 ^ 预定义模式 \\d \\D \\w \\W 重复类 {} 量词符 贪婪模式 + 一个或多个，* 零个或多个， ？ 可以将贪婪模式改为非贪婪模式 常见的正则表达式匹配 账号是否合法：^[a-zA-Z][a-zA-Z0-9_]{4,15}$ Email地址：^\\w+([-+.]\\w+)*@\\w+([-.]\\w+)*\\.\\w+([-.]\\w+)*$ url: ^[http|https]://([\\w-]+\\.)+[\\w-]+(/[\\w-./?%&=]*)?$ 前端的一些概念 模块化编程 JavaScript 模块化编程 随着网站逐渐变成“互联网应用程序”，嵌入网页的 JavaScript 代码越来越大，需要一个团队分工协作、进度管理、单元测试等...开发者不得不使用软件工程的方法来管理网页的逻辑 原始写法：只要把不同的函数以及记录状态的变量简单的放在一起，就算是一个模块，但是这种做法的缺点很明显：“污染”了全局变量，无法保证不与其它模块发生变量名冲突，而且模块成员之间看不出直接关系 对象写法：为了解决上述缺点，可以把模块写成一个对象，所有模块成员都放在这个对象里面，但是这也的写法会暴露所有模块成员，内部状态可以被外部改写 立即执行函数法，使用立即执行函数，可以达到不暴露成员的目的 nodejs 使用 CommonJS 的 require 语法 AMD（asynchronous module definition，异步模块定义），它采用异步方式记载模块，模块加载不影响后面语句的运行。所有依赖这个模块的语句，都定义在一个回调函数中，等到加载完成后，回调函数才运行 DOM 渲染是什么，为什么比较慢 为什么DOM渲染慢 DOM：Document Object Model，文档对象模型 所谓 DOM 渲染，就是浏览器将 HTML 字符串渲染成视图的过程： 首先，浏览器的 HTML 解析器，会对 HTML 字符串进行解析，并将它转换成 DOM 树，同时 CSS 解析器也会解析 HTML 使用到的 CSS 样式，生成一系列 CSS 规则 然后浏览器的渲染进程将 DOM 树和 CSS 规则进行整合，并生成一个可用于视图渲染的 DOM 渲染树 渲染进程开始对渲染树进行布局，生成布局树 渲染树对布局树进行绘制，生成绘制记录，然后对布局树进行分层，分别栅格化每一层，并得到合成帧，渲染进程将合成帧发送到 GPU 进程最后显示到页面中 为什么说 DOM 渲染比较慢呢，比如 HTML 解析器解析 HTML 的的例子，在 HTML 解析器中，有两个程序交替进行：分词程序和解析程序，分词程序负责将 HTML 字符串划分成合法的 DOM 标签字符串，然后将它们交给用于处理的解析器，解析器将它们添加到正在构建的 DOM 树中，当分词器解析所有字符串时候，就是构建完 DOM 树的时候。这个过程太复杂了，所以 DOM 呈现如此缓慢了。 在 web 页面中添加和删除 DOM 将大大降低视图呈现和交互的效率 虚拟 DOM 是什么，为什么要使用虚拟 DOM 为什么要使用虚拟 DOM 什么是虚拟 DOM？ Virtual dom，即虚拟 DOM 节点，它通过 JS 的 Object 对象模拟 DOM 中的节点，通过特定的 render 方法可以将其渲染成真实的 DOM 节点。如果存在多个相同的元素可能比浪费性能，所以React和Vue引用key值进行区分。 为什么我们要使用虚拟 DOM? 保证性能下限 框架的虚拟 DOM 需要适配任何上层 API 可能产生的操作，它的一些 DOM 操作的实现必须是普适的，所以它的性能并不是最优的；但是比起粗暴的 DOM 操作性能要好很多，因此框架的虚拟DOM可以保证在你不许有手动优化的情况下，依然可以提供还不错的性能，即保证性能下限，比较 innerHTML vs. Virtual DOM 的重绘性能消耗： innerHTML：render html string O + 重新创建所有 DOM 元素（DOM size） Virtual DOM：render Virtual DOM + diff O + 必要的 DOM 更新 inner HTML计算中，界面的大小改动，都会产生 js 计算和 DOM 操作，但是在 Virtual DOM 中，只有 js 计算和界面大小相关，DOM 操作是和数据的变动量相关的。和 DOM 操作比起来，js 计算是极其便宜的，这就是为什么要有 virtual DOM：他保证了不管你的数据变化多少，每次重绘的性能都可以接受，保证了性能的下限 不需要手动优化，依然可以得到一个过得去的性能 尤大大亲自在知乎里说过，在应用的每一个地方，都可以写出比任何框架更快的的手动优化，但是这个这个并没有多大的意义，因为在构建一个实际的应用的时候，不可能为每一个地方都去做手动优化。处于可维护性的考虑，这显然不可能的。所以我们使用框架，使用 virtual DOM + diff 算法的方式，在我们不需要手动优化的情况下，依然可以得到过得去的性能 跨平台 虚拟 DOM 本质上是一个 JavaScript 对象，而 DOM 与平台强相关，相比之下虚拟 DOM 可以进行更方便的跨平台操作 Dom-Diff 算法 虚拟DOM 及 DOM-Diff Dom-Diff 则是通过 js 层面的计算，返回一个 patch 对象，即补丁对象，再通过特定的操作解析 patch 对象，完成页面的重新渲染。Diff 算法规则：同层比较。Diff 算法有很多种情况，常见的情况有： 当节点类型相同时，判断属性是否相同，否则产生一个属性的补丁包 {type: 'ATTRS', attrs: {class: 'list-group'}} 新的 dom 节点不存在 {type: 'REMOVE', index: xxx} 节点类型不相同，直接采用替换模式 {type: 'REPLACE', newNode: newNode} 文本的变化 {type: 'TEXT', text: 1} 比较两棵虚拟 DOM 树的核心 diff 方法接受 oldTree 旧 DOM 树，newTree 新 DOM 树两个参数，根据两个虚拟对象创建出补丁，描述改变的内容，将这个补丁用来更新 DOM。该方法的核心在于 walk 递归树，该方法将比较后的差异节点放到补丁包中 整个 DOM-Diff 过程： 用 JS 对象模拟 DOM（虚拟 DOM） 把此虚拟 DOM 转换成真实 DOM 并插入页面中（render） 如果有事件发生修改了虚拟 DOM，比较两棵虚拟 DOM 树的差异，得到差异对象（diff） 把差异对象应用到真正的 DOM 树上（patch） SPA（单页应用）的理解 说说你对SPA（单页应用）的理解 什么是 SPA ？ SPA（single-page application)，翻译过来就是单页应用 SPA 是一种网络应用程序或网站的模型，它通过动态重写当前页面来与用户交互，这种方法避免了页面之间转换打断用户体验。在单页应用中，所有的必要的代码（html、JavaScript和css）都通过单个页面的加载而检索，或者根据需要（通常是为了响应用户操作）动态加载适当的资源并添加到页面。页面在任何时间点都不会重新加载，也不会讲控制转移到其它页面。常见的JS框架 react、vue、angular 都是 SPA SPA 和 MPA 的区别 多页应用MPA（MultiPage-page application），每个页面都是一个主页面，都是独立的。当我们在访问另一个页面的时候，都需要加载 html、css、js 文件，公共文件则按需加载 SPA MPA 组成 一个主页面和多个页面片段 多个主页面 刷新方式 局部刷新 整页刷新 url 模式 哈希模式 历史模式 SEO 搜索引擎优化 难实现，可使用 SSR 方式改善 容易实现 数据传递 容易 通过url、cookie、localStorage 等传递 页面切换 速度快，用户体验良好 切换加载资源，速度慢 维护成本 相对容易 相对复杂 SPA 的优缺点 优点： 具有桌面应用的即时性、网站的可移植性和可访问性 用户体验好、快，内容的改变不需要重新加载整个页面 良好的前后端分离，分工更明确 缺点： 不利于搜索引擎的抓取 首次渲染速度相对较慢 实现一个 SPA 原理 监听地址栏 hash 变化驱动界面变化 用 pushsate 记录浏览器的历史，驱动界面发送变化 如何给 SPA 做 SEO 基于 Vue 的 SPA 如何实现 SEO 的三种方式： SSR 服务端渲染：讲组件或页面通过服务器生成 html，在返回浏览器 静态化：1. 通过程序将动态页面抓取并保存为静态页面 2.通过web服务器内部模块按一定规则将外部的 url 请求转化为内部的文件地址 使用 Phantom.js 针对爬虫 服务端渲染，SSR 原理 彻底理解服务端渲染，SSR原理 什么是服务端渲染？ 页面的渲染其实就是浏览器将 HTML 文本转化为页面帧的过程。而如今我们大部分 Web 应用都是使用 JavaScript 框架（Vue、React、Angular）进行页面渲染的，也就是说，在执行 JavaScript 脚本的时候，HTML 页面已经开始解构并且构建 DOM 树了，JavaScript 脚本只是动态的改变 DOM 树的结构，使得页面称为希望成为的样子，这种渲染方式叫动态渲染，也可以叫客户端的渲染（CSR，Client Side Render） 服务端渲染（SSR，Server Side Render)就是在浏览器请求页面 URL 的时候，服务端将我们需要的 HTML 文本组装好，并返回给浏览器，这个 HTML 文本被浏览器解析之后，不需要经过 JavaScript 脚本的执行，即可直接构建出希望的 DOM 树并展示到页面中 服务端渲染的由来？ web1.0 在没有 AJAX 的时候，也就是 web1.0 时代，几乎所有的应用都是服务端渲染（非现在的服务端渲染），哪个时候的页面渲染大概是这样的（thymeleaf？ php、asp、jsp），浏览器请求页面 URL，然后服务端接收到请求之后，到数据库查询数据，将数据丢到后端的组件模板中，并渲染成 HTML 片段，接着服务器再组装这些 HTML，最后返回给浏览器，这个时候浏览器已经拿到一个完整的被服务器动态组装出来的 HTML 文本，然后将 HTML 渲染到页面中，过程没有任何 JavaScript 代码的参与 客户端渲染 在 Web1.0 时代，服务端渲染看起来是一个当时最好的渲染方式，但是随着业务的日益复杂和 AJAX 的出现，也暴露一些问题： 每次更新也买你的一个小的模块，都需要重新请求一次页面，重新查一次数据库，重新组装一次 HTML 前端 JavaScript 代码和后端（jsp、php、jsp）代码混杂在一起，使得日益复杂的 Web 应用难以维护 那个时候根本就没有前端工程师这个概念，前端 js 的话一般都由后端同学 JQuery 一把梭，但是前端页面渐渐复杂之后，后端发现 js 好麻烦，虽然简单，但是坑太多了，于是让公司招一些专门写 js 的人，也就是前端，这时候前后端鄙视链形成，后端觉得 js 太简单，无非就是写写页面特效（js），切切图（CSS），算不上真正的程序员 随之 nodejs 的出现，前端看到了翻身的契机，为了摆脱后端的指指点点，前端开启了一场前后端分离的运动，希望可以脱离后端独立发展。前后端分离，表面上看上去是代码分离，实际上是为了前后端人员分离，也就是前后端分家。前后端分离之后，页面开始被当成了独立的应用程序（SPA，Single Page Application），前端团队接管了所有页面渲染的事，后端团队只负责提供所有数据查询和处理的 API。 大体流程：首先浏览器请求 URL，前端服务器直接返回一个空的静态 HTML 文件，这个文件中加载了很多渲染页面需要的 JavaScript 脚本和 CSS 样式表，浏览器拿到 HTML 文件后开始加载脚本和样式表，并且执行脚本，这个时候脚本请求后端服务提供的 API，获取数据，获取完成后将数据通过 JavaScript 脚本动态的将数据渲染到页面中，完成页面显示 服务端渲染2.0 随着单页应用（SPA）的发展，程序员渐渐发现 SEO（Search Engine Optimazition，搜索引擎优化）出了问题，而且随着应用的复杂化，JavaScript 脚本也不断的臃肿起来，使得首屏渲染相比于 Web1.0 时候的服务端渲染也慢了不少 于是前端团队选择了使用 nodejs 在服务器进行页面的渲染，进而再次出现了服务器端渲染。大体流程和客户端渲染有些相似，首先是浏览器请求 URL，前端服务器接收到 URL 请求之后，根据不同的 URL，前端服务器向后端服务器请求数据，请求完成后，前端服务器会组装一个携带了具体数据的 HTML 文本，并且返回给浏览器。浏览器得到 HTML 之后开始渲染渲染页面，同时，浏览器加载并执行 JavaScript 脚本，给页面上的元素绑定事件，让页面变得可交互，当用户与浏览器界面进行交互，执行 JavaScript 脚本向后端请求数据并且渲染（我的理解即使首屏渲染是服务端，之后的和客户端渲染差不多） 服务端渲染的利弊 优点 有利于 SEO：也就是利于爬虫来爬取你的页面，然后别人使用搜索引擎搜索相关的内容时，你的网页排行能靠的更前 白屏时间更短：相对于客户端渲染，服务端渲染在浏览器请求 URL 之后已经得到了一个带有数据的 HTML 文本，浏览器只需要解析 HTML，直接构建 DOM 树就可以。而客户端渲染，需要先得到一个空的 HTML 页面，这个时候页面已经进入白屏，之后需要经过加载并执行 JavaScript、请求后端服务器获取数据、JavaScript 渲染页面几个过程才可以看到最后页面 缺点 代码复杂度增加：为了实现服务端渲染，应用代码中需要兼容服务器和客户端两种运行情况，而一部分依赖的外部扩展库却只能在客户端运行，需要对其进行特殊处理才能在服务器渲染应用程序中进行 需要更多的服务器负载均衡。由于服务器增加了渲染 HTML 的需求，使得原本只需要输出静态资源文件的 nodejs 服务器，新增了数据获取的 IO 和渲染 HTML的 CPU 占用，如果流量突然暴增，有可能导致服务器 down 机，因此需要使用响应的缓存策略和准备相应的服务器负载 涉及构建设置和部署的更多要求 所以在使用服务端渲染 SSR 之前，需要开发者考虑投入产出比，比如大部分应用系统都不需要 SEO，而且首屏时间并没有很慢，就不需要 SSR 了 同构 客户端和服务器渲染运行的环境是不一样的。所谓同构，就是让一份代码，既可以在服务端执行，也可以在客户端执行，并且执行的效果是一样的，都是完成了这个 html 的组装，正确的显示页面 为了实现同构，我们需要满足什么条件呢？首先，我们思考一个应用中一个页面的组成，加入我们使用的是 Vue.js，当我们打开一个页面时，首先是打开这个页面的 URL，这个 URL，可以通过应用的路由匹配，找到具体的应用，不同的页面有不同的视图，那么视图是什么，从应用的角度来看，视图 = 模板 + 数据。所以对于同构应用来说，我们必须实现客户端与服务端的路由、模型组件、数据模型的共享 Vue Vue 和 React 的区别 个人理解 Vue 和 React 相同 Vue 和 React 相同点非常多： 都使用 Virtural DOM 都使用组件化思想，流程基本一致 都是响应式，推崇单向数据流 都有成熟的社区，都支持服务端渲染 Vue 和 React 实现原理和流程基本一致，都是使用 Virtual DOM + Diff 算法。不管是 Vue 的 template 模板 + api 的写法 还是 React 的 Class 或 Function 的写法，底层最终都是为了生成 render 函数，render 函数执行返回 VNode（虚拟 DOM 的数据结构，本质上是一棵树）。当每一次 UI 更新时，总会根据 render 重新生成最新的 VNode，然后和缓存起来的老的 VNode 进行对比，在使用 Diff 算法（框架核心）去真正更新真实 DOM Vue和React通用流程：vue template/react jsx -> render函数 -> 生成VNode -> 当有变化时，新老VNode diff -> diff算法对比，并真正去更新真实DOM。 不同的地方 核心思想不同 Vue 早期定位是尽可能加功能的降低前端开发的门槛，所以 Vue 推崇灵活易用（渐进式开发体验），数据可变，双向数据绑定（依赖收集） React 早期口号是 Rething Best Practices，想要做的是用更好的方式去颠覆前端开发方式。所以 React推崇函数式编程（纯组件），数据不可变以及单向数据流。函数式编程的最大好处是其稳定性（无副作用）和可测试性（输入相同，输出相同），所以大家都说 React 适合大型应用 核心思想不同导致写法差异，vue推崇 template + option API，所以不可避免有比较多的概念和 api，比如 slot，watch，computed等概念。React 本质上只有一个 Virtual DOM + Diff 算法，所以 API 非常少，知道 setState 就能开始开发了 组件实现不同 Vue 源码实现是把 options 挂载到 Vue 核心类上，然后再 new Vue（{options}) 拿到实例（Vue 组件的 script 导出的是一个挂满 options 的纯对象而已）。所以需要文档去说明api。另外 Vue 插件都是基于 Vue 原型类基础之上的，确保第三方库的 Vue 和当前应用的 Vue 对象是同一个 React 内部实现比较简单，直接定义 render 函数以生成 VNode，而 React 内部使用了四大组件类包装 VNode，不同类型的 VNode 使用相应的组件类处理，职责划分清洗。React 类组件都是继承自 React.Component 类，其 this 指向用户自定义的类，对用户来说也是透明的 响应式原理不同 vue vue依赖收集，自动优化，数据可变 vue 递归监听 data 的所有属性，直接修改 当数据改变时，自动找到引用组件重新渲染 react react 基于状态机，手动优化，数据不可变，需要 setState 驱动新的 State 替换老的 State 当数据改变时，以组件为根目录，默认全部重新渲染 diff 算法不同 两者流程思维上是类似的，都是基于两个假设（使得算法复杂度降为O(n)）： 不同的组件产生不同的 DOM 结构。当type不相同时，对应DOM操作就是直接销毁老的DOM，创建新的DOM。 同一层次的一组子节点，可以通过唯一的 key 区分。 但两者源码实现上有区别： Vue基于snabbdom库，它有较好的速度以及模块机制。Vue Diff使用双向链表，边对比，边更新DOM。 React主要使用diff队列保存需要更新哪些DOM，得到patch树，再统一操作批量更新DOM。 事件机制不同 vue Vue 原生事件使用标准 Web 事件 Vue 组件自定义事件机制，是父子组件通信基础 react React原生事件被包装，所有事件都冒泡到顶层document监听，然后在这里合成事件下发。基于这套，可以跨端使用事件机制，而不是和Web DOM强绑定 React 组件上无事件，父子组件通信使用 props React 网络知识 localstorage、sessionStorage、indexDB 和 cookie 的区别？ 详说Cookie，LocalStorage与SessionStorage cookie 是存储在浏览器中的一小串数据，是 HTTP 协议的一部分，通常是由 Web 服务器使用响应字段 Set-Cookie 设置的。然后浏览器使用请求字段 Cookie 将它们自动添加到几乎每个对相同域的请求中。大小受限只有 4 kb，需要指定作用域，不可以跨域使用。比较常用的应用场景就是判断当前用户是否登录了，但是如今似乎使用 localStorage 更多了 sessionStorage 是本地会话级别的一个存储，在页面打开的时候创建，当用户关闭浏览器窗口后，数据会被删除。sessionStorage 与 localStorage 的接口类似，但保存数据的声明周期与 localStorage 不同，，它只是可以将一部分数据在当前会话保存下来。5 M 左右，在不同的浏览器窗口是不共享的，即使是同一个页面，localStorage 和 cookie 在所有同源窗口是共享的 localStorage 是一个持久化的本地存储，是 HTML 5 本地存储的 API，使用键值对的方式进行存储，存取的数据只能是字符串，存储的数据没有时间限制，除非强制删除，否则数据永远不过期。5 M 左右。localStorage 的好处是存储空间大一点，长时间保存，不好的地方是永久有效，除非手动清除。所有如果数据有时效性的需求，就需要自己来处理，一般可以和数据一起存一个 expires 时间戳 IndexDB 是一个浏览器内置的数据库，异步操作，存储空间大，一般不小于 250 m 安全性考虑：不是什么数据都适合放在Cookie、LocalStorage 和 sessionStorage 中的，使用它们的时候，需要时刻注意是否有 XSS 注入的风险。因为只要打开控制台，就可以随意修改它们的值，所以也不要存储敏感数据 Cookie 和 Session 的区别？ 你真的了解 Cookie 和 Session 吗 Session 是在无状态的 HTTP 协议下，服务端记录用户状态用于表示具体用户的机制。Session 代表着服务器和客户端一次会话的过程，Session 对象存储特定用户会话所需的属性及配置信息。它是在服务端保存的用来跟踪用户的状态的数据结构，可以保存在文件、数据库和文件中，Cookie 是保存用户信息的一种机制，用来记录用户的一些信息，也是实现 Session 的一种方式 不同 作用范围不同，Cookie 保存在客户端，Session 保存在服务器端 存取方式不同，Cookie 只能保存 ASCII，Session 可以存任意数据类型，一般情况下我们可以保存一些常用变量信息，比如 userId 有效期，Cookie 可设置为长时间保持，比如经常使用的默认登录功能，Session 一般失效时间较短，客户端关闭或者 Session 超时都会失效 安全性不同，Cookie 存储在客户端，比较容易遭到不法获取 存储大小不同 关联 用户第一次请求服务器的时候，服务器根据用户提交的相关信息，创建创建对应的 Session ，请求返回时将此 Session 的唯一标识信息 SessionID 返回给浏览器，浏览器接收到服务器返回的 SessionID 信息后，会将此信息存入到 Cookie 中，同时 Cookie 记录此 SessionID 属于哪个域名。 当用户第二次访问服务器的时候，请求会自动判断此域名下是否存在 Cookie 信息，如果存在自动将 Cookie 信息也发送给服务端，服务端会从 Cookie 中获取 SessionID，再根据 SessionID 查找对应的 Session 信息，如果没有找到说明用户没有登录或者登录失效，如果找到 Session 证明用户已经登录可执行后面操作。 根据以上流程可知，SessionID 是连接 Cookie 和 Session 的一道桥梁，大部分系统也是根据此原理来验证用户登录状态 如果浏览器中禁止了 Cookie，如何保障整个机制的正常运转? 每次请求中都携带一个 SessionID 的参数，也可以 Post 的方式提交，也可以在请求的地址后面拼接 Token机制，Token 的意思是“令牌”，是服务端生成的一串字符串，作为客户端进行请求的一个标识。 ajax ajax及常见面试题 概念 AJAX 即 Asynchronous Javascript And XML（异步JavaScript和XML），是一种异步请求数据的web开发技术，对于改善用户的体验和页面性能很有帮助。简单地说，在不需要重新刷新页面的情况下，Ajax 通过异步请求加载后台数据，并在网页上呈现出来。Ajax的目的是提高用户体验，较少网络数据的传输量。同时，由于AJAX请求获取的是数据而不是HTML文档，因此它也节省了网络带宽，让互联网用户的网络冲浪体验变得更加顺畅。 原理 Ajax相当于在用户和服务器之间加了一个中间层,使用户操作与服务器响应异步化。并不是所有的用户请求都提交给服务器，像一些数据验证和数据处理等都交给Ajax引擎自己来做，只有确定需要从服务器读取新数据时再由Ajax引擎代为向服务器提交请求。 Ajax的原理简单来说通过XmlHttpRequest对象来向服务器发送异步请求，从服务器获得数据，然后用JavaScript来操作DOM而更新页面。这其中最关键的一步就是从服务器获得请求数据。要清楚这个过程和原理，我们必须对 XMLHttpRequest有所了解。 过程 创建 XMLHttpRequest 对象(记得考虑兼容性) 向服务器发送请求 服务器响应处理（同步 顺序写下来、异步 回调，xhr.onreadystatechange） 跨域 前端面试总结之：js跨域问题 Access-Control-Allow-Origin 就是典型的跨域报错，跨域就是违反同源策略（协议、域名、端口必须相同）的一类请求场景。假如没有同源政策，我在一个网页上登录了，里面会存放相应cookie，再访问另外的网址，cookie 就可能泄露。 跨域的解决方案有： 通过 jsonp 跨域 CORS nginx 跨域 nodejs 中间件代理跨域 websocket 协议跨域 postMessage 跨域 document.domain + iframe 跨域（两个页面都通过js强制设置document.domain为基础主域，就实现了同域） location.hash + iframe 跨域 window.name + iframe 跨域 jsonp 通常为了减轻 web 服务器的负载，我们把 js、css、html 等静态资源分离到一台独立域名的服务器上，在HTML页面中通过相应的标签从不同的域名下加载静态资源，而被浏览器允许，基于此原理，我们可以通过动态创建 script，再请求一个带参网址实现跨域通信。jsonp 正是利用这个特性来实现的。jsonp 是服务器与客户端跨源通信的常用方法。最大特点是简单易用，老式浏览器全部支持，服务器改造非常小，但是它只能实现 get 一种请求，不安全，容易受到 xss 攻击 function addScriptTag(src) { var script = document.createElement('script') script.setAttribute(\"type\", \"text/javascript\") script.src = src document.body.appendChild(script) } CORS 跨域资源共享 CORS 详解 CORS 是一个 W3C 标准，全称是 跨域资源共享（Cross-origin resource sharing），它允许浏览器想跨源服务器，发出 XMLHttpRequest 请求，从而克服了 AJAX 只能同源使用的限制。CORS 需要浏览器和服务器同时支持，目前所有浏览器支持该功能，IE 浏览器不能低于 IE 10，整个 CORS 通信过程，都是浏览器自动完成，不需要用户参与。对于开发者来说，CORS 通信与同源的 AJAX 通信没有差别，代码完全一样。浏览器一旦发现 AJAX 请求跨源，就会自动添加一些附加的头信息，有时还会多出一次附加的请求，但是用户不会有感觉 浏览器将 CORS 请求分为两类：简单请求和非简单请求 简单请求 简单请求：请求方法是 HEAD、GET、POST 中的一种，HTTP 的头信息不超过 几个值，其中 Content-Type 只限于 application/x-www-form-urlencoded、multipart/form-data、text/plain 凡是不满足上面条件额，就是非简单请求，浏览器对于这两种请求的处理是不一样的 简单请求：对于简单请求，浏览器直接发送 CORS 请求，但是头信息中会增加一个 Origin 字段来说明这次请求来自哪个源，服务器根据这个值来决定是否同意这次请求。如果 Origin 指定的源不在许可范围内，服务器会返回一个正常的 HTTP 回应，浏览器发现这个回应的头信息中没有包含 Access-Control-Allow-Origin 字段，就知道出错了，从而抛出一个错误。如果 Origin 指定的域名在许可范围内，服务器返回的相应就会多出几个头信息段 Access-Control-Allow-Origin: 它的值要么是请求时 Origin 字段的值，要么是 * Access-Control-Allow-Credentials：布尔值，代表是否允许发送 Cookie Access-Control-Expose-Headers：可选字段，表明可以暴露的字段 CORS 请求默认不发送 Cookie 和 HTTP 认证信息，需要设置一些东西 非简单请求 非简单请求的 CORS 请求，会在正式通信前，增加一次 HTTP 查询请求，一般使用 OPTIONS，称为 “预检”请求（preflight），服务器会先询问浏览器，当前网页所在的域名是否在服务器的许可名单之中，以及可以使用哪些 HTTP 方法和头信息字段，只有得到肯定答复，浏览器才会发出正式的 XMLHttpRequest 请求。一旦服务器通过了“预检请求”，以后每次浏览器正常的 CORS 请求，就都跟简单请求一样了 Nginx 代理跨域 跨域原理：同源策略是浏览器的安全策略，不是 HTTP 协议的一部分，服务器段调用 HTTP 接口只是使用 HTTP 协议，不会执行 JS 脚本，不需要同源策略，也就不存在跨域问题，实现的思路是通过 niginx 配置一个代理服务器（域名与 domain 1 相同，端口不通）作跳板，反向代理 domain2 接口，并且可以顺便修改 cookie 中 domain 信息，方便当前域 cookie 写入，实现跨域登录 #proxy服务器 server { listen 81; server_name www.domain1.com; location / { proxy_pass http://www.domain2.com:8080; #反向代理 proxy_cookie_domain www.domain2.com www.domain1.com; #修改cookie里域名 index index.html index.htm; # 当用webpack-dev-server等中间件代理接口访问nignx时，此时无浏览器参与，故没有同源限制，下面的跨域配置可不启用 add_header Access-Control-Allow-Origin http://www.domain1.com; #当前端只跨域不带cookie时，可为* add_header Access-Control-Allow-Credentials true; } } WebSocket WebSocket protocol是HTML5一种新的协议。它实现了浏览器与服务器全双工通信，同时允许跨域通讯，是server push技术的一种很好的实现。WebSocket是一种通信协议，使用ws://（非加密）和wss://（加密）作为协议前缀。该协议不实行同源政策，只要服务器支持，就可以通过它进行跨源通信。WebSocket 有一个字段是Origin，表示该请求的请求源（origin），即发自哪个域名。正是因为有了Origin这个字段，所以WebSocket才没有实行同源政策。因为服务器可以根据这个字段，判断是否许可本次通信。如果该域名在白名单内，服务器就会做出如下回应。 HTTP/1.1 101 Switching Protocols Upgrade: websocket Connection: Upgrade Sec-WebSocket-Accept: HSmrc0sMlYUkAGmm5OPpG2HaGWk= Sec-WebSocket-Protocol: chat 输入域名到出现网页发生了什么 面试官：浏览器输入URL后发生了什么 合成 url 用户输入url，浏览器会根据用户输入的信息判断是搜索内容还是准确的 url，如果是搜索内容，就将 搜索内容 + 默认搜素引擎合成新的 url，如果是用户输入的是url且符合规则，浏览器就会根据 URL 协议，在这段内容上加上协议合成合法的 URL DNS 域名解析 我们一般输入是域名，但是协议需要的是 ip，因此需要 DNS 服务器进行域名查找ip，这是一个递归查找的过程，先从浏览器缓存中查找->再到本地的 hosts 文件查找 -> 找本地DNS解析器查找->本地的DNS服务器查找->转发到其它DNS服务器查找 建立 TCP 连接（三次握手） 首先判断是不是 https 协议，如果是，处理要复杂一点，如果不是就直接三次握手，建立 TCP 连接 第一次握手：建立连接。客户端发送连接请求报文段，将 syn 位置设置为 1，Sequence Number 为 x（随机的），然后客户端进入 SYN_SEND 状态，等待服务器的确认 第二次握手：服务器收到 SYN 报文段。服务器收到客户端的 SYN 报文段，需要对这个 SYN 报文段进行确认，设置 Acknowledge Number 为 x + 1，同时服务器发送 SYN 相应信息，将 SYN 位置设置为 1，Sequence Number 为 y，服务器段将上述所有信息放到一个报文段（SYN + ACK），然后发送响应的信息，服务器进入 SYN_RECV 状态 第三次握手：客户端收到服务器的 SYN + ACK报文段。然后将 Acknowledge Number 设置为 y + 1，向服务器发送 ACK 报文段，这个报文段发送完毕之后，客户端和服务器都进入 ESTABLISHED 状态，完成三次握手 如果是 HTTPS，HTTPS其实是HTTP + SSL / TLS 两部分组成，也就是在HTTP上又加了一层处理加密信息的模块。服务端和客户端的信息传输都会通过TLS进行加密，所以传输的数据都是加密后的数据。 ，就会多一个 SSL 握手的过程： 客户端请求建立 SSL 连接，并向服务器发送一个报文，内容包括 TSL 协议版本，用于生成对话密匙的随机数 1、支持的加密方法、支持的压缩方法 此时是明文传输 服务器响应客户端，内容包括确认使用的加密通信协议版本、用于生成对话密匙的随机数 2、确认加密方法、服务器证书 客户端验证证书，如果证书不是可信机构版本，或者证书过期，会显示警告，确认是否继续通信 客户端确认证书没问题，就会取出证书中的服务器公匙，然后生成新的随机数 3 并通过服务器发送的公匙及加密方法进行加密，发送给服务器 服务器端收到客户端的回复，利用一直的加解密方式进行解密，同时利用上面的 3 个随机数通过一定算法生成 HTTP 对称加密的钥匙，之后都可以安全的对称加密通信了 建立连接之后，浏览器就可以利用 HTTP/HTTPS 协议向服务器发送请求了，服务器接受请求，就解析请求并响应响应结果，但是可能直接就从缓存中读取结果了，这个过程涉及到一些缓存的机制 关闭 TCP 连接，四次挥手 第一次挥手：主机1（客户端或者服务器）设置 Sequence Number 和 AcknowledgeMent Number，向另外个主机2发送一个 FIN 报文段，此时主机1 进入 FIN_WAIT_1 的状态 第二次挥手：主机2接收到主机1发送的 FIN 报文段，向主机 1 返回 ACK 报文段，AcknowledgeMental Number 为 Sequence Number + 1，主机1 进入 FIN_WAIT_2 状态，也就是主机2 告诉主机 1 我同意关闭连接了 第三次挥手：主机 2 向主机 1 发送 FIN 报文段，请求关闭连接，同时主机 2 进入 LAST_ACK 状态 第四次挥手：主机 1 收到主机 2 发送的 FIN 报文段，向主机 2 发送 ACK 报文段，然后主机 1 进入 TIME_WAIT 状态。主机 2 收到 主机 1 的 ACK 报文段之后，就关闭连接。此时主机 1 等待 2 MSL 后依然没有收到恢复，主机1 就也可以关闭了 浏览器渲染，判断是不是 HTML文件，是的话就开始解析渲染（参考前面的） 缓存逻辑 一张图弄懂HTTP缓存及常见面试题 浏览器的缓存机制（HTTP 如何控制缓存的） 浏览器第一次向服务器发请求资源，服务器响应报文的状态是200，响应头会带上Cache-Control、Etag字段 。 浏览器收到响应后会把资源存到本地。 当浏览器再次发送请求获取该资源时，浏览器会先检查该资源是否过期（通过Cache-Control:max-age = 时间）。如果在时间内，就直接使用该资源。 如果时间过期，则发送请求询问该资源是否可以用。 请求头包含 If-None-Match，也就是之前响应报文中的 Etag。 服务器收到请求后通过 If-None-Match里的Etag和新计算的Etag做对比，如果匹配，则直接返回一个状态码 304 ，不包含任何响应体报文，告诉浏览器该资源可以用。 如果不匹配，则返回一个状态码为200再带上 Cache-Control、Etag和原始资源的新报文 如果不存在Etag，则用 Last-Modified 和 if-Modified-Since 做类似的判断 Last-Modified、If-Modified-Since Last-Modified 则是 是由服务器发送给客户端的HTTP请求头标签，If-Modified-Since 则是由客户端发送给服务器的HTTP请求头标签 etag Etag相当于给资源生成了一个独一无二的标识，当资源被修改了，Etag就会改变。 作用和 Last-Modified 类似。 get 和 post 面试官：说一下 GET 和 POST 的区别 GET和POST，两者是HTTP协议中发送请求的方法，GET方法请求一个指定资源的表示形式，使用GET的请求应该只被用于获取数据，POST方法用于将实体提交到指定的资源，通常导致在服务器上的状态变化或副作用，本质上都是TCP链接，并无差别，但是由于HTTP的规定和浏览器/服务器的限制，导致他们在应用过程中会体现出一些区别 从w3schools得到的标准答案的区别如下： GET在浏览器回退时是无害的，而POST会再次提交请求。 GET产生的URL地址可以被Bookmark，而POST不可以。 GET请求会被浏览器主动cache，而POST不会，除非手动设置。 GET请求只能进行url编码，而POST支持多种编码方式。 GET请求参数会被完整保留在浏览器历史记录里，而POST中的参数不会被保留。 GET请求在URL中传送的参数是有长度限制的，而POST没有。 对参数的数据类型，GET只接受ASCII字符，而POST没有限制。 GET比POST更不安全，因为参数直接暴露在URL上，所以不能用来传递敏感信息。 GET参数通过URL传递，POST放在Request body中 tcp 和 udp TCP 是面向连接的、可靠的流协议。流就是指不间断的数据结构，当应用程序采用 TCP 发送消息时，虽然可以保证发送的顺序，但还是犹如没有任何间隔的数据流发送给接收端。 TCP 为提供可靠性传输，实行“顺序控制”或“重发控制”机制。此外还具备“流控制（流量控制）”、“拥塞控制”、提高网络利用率等众多功能。 TCP有以下特点： TCP充分地实现了数据传输时各种控制功能，可以进行丢包时的重发控制，还可以对次序乱掉的分包进行顺序控制。而这些在 UDP 中都没有。 此外，TCP 作为一种面向有连接的协议，只有在确认通信对端存在时才会发送数据，从而可以控制通信流量的浪费。 根据 TCP 的这些机制，在 IP 这种无连接的网络上也能够实现高可靠性的通信（ 主要通过检验和、序列号、确认应答、重发控制、连接管理以及窗口控制等机制实现）。 UDP 是面向报文的，所谓面向报文，是指面向报文的传输方式是应用层交给UDP多长的报文，UDP就照样发送，即一次发送一个报文。因此，应用程序必须选择合适大小的报文。若报文太长，则IP层需要分片，降低效率。若太短，会是IP太小。 UDP 是不具有可靠性的数据报协议，细微的处理它会交给上层的应用去完成。在 UDP 的情况下，虽然可以确保发送消息的大小，却不能保证消息一定会到达。因此，应用有时会根据自己的需要进行重发处理。 UDP有以下特点： UDP 不提供复杂的控制机制，利用 IP 提供面向无连接的通信服务。 传输途中出现丢包，UDP 也不负责重发。 当包的到达顺序出现乱序时，UDP没有纠正的功能。 并且它是将应用程序发来的数据在收到的那一刻，立即按照原样发送到网络上的一种机制。即使是出现网络拥堵的情况，UDP 也无法进行流量控制等避免网络拥塞行为。 如果需要以上的细节控制，不得不交由采用 UDP 的应用程序去处理。 TCP 和 UDP 的优缺点无法简单地、绝对地去做比较：TCP 用于在传输层有必要实现可靠传输的情况； 而在一方面，UDP 主要用于那些对高速传输和实时性有较高要求的通信或广播通信。TCP 和 UDP 应该根据应用的目的按需使用。 http 状态码 HTTP状态码(status)由三个十进制数字组成，第一个十进制数字定义了状态码的类型，后两个数字没有分类的作用。HTTP状态码共分为5种类型： 1xx（临时响应）：表示临时响应并需要请求者继续执行操作的状态码。 2xx（成功）：表示成功处理了请求的状态码。 3xx（重定向）：表示要完成请求，需要进一步操作。通常，这些状态代码用来重定向。 4xx（请求错误）：这些状态码表示请求可能出错，妨碍了服务器的处理。 5xx（服务器错误）：这些状态码表示服务器在尝试处理请求时发生内部错误。这些错误可能是服务器本身的错误，而不是请求出错。 常见状态码： 200 表示从客户端发来的请求在服务器端被正常处理了。 204 表示请求处理成功，但没有资源返回。 301 表示永久性重定向。该状态码表示请求的资源已被分配了新的URI，以后应使用资源现在所指的URI。 302 表示临时性重定向。 304 表示客户端发送附带条件的请求时（指采用GET方法的请求报文中包含if-matched,if-modified-since,if-none-match,if-range,if-unmodified-since任一个首部）服务器端允许请求访问资源，但因发生请求未满足条件的情况后，直接返回304Modified（服务器端资源未改变，可直接使用客户端未过期的缓存） 400 表示请求报文中存在语法错误。当错误发生时，需修改请求的内容后再次发送请求。 401 表示未授权（Unauthorized)，当前请求需要用户验证 403 表示对请求资源的访问被服务器拒绝了 404 表示服务器上无法找到请求的资源。除此之外，也可以在服务器端拒绝请求且不想说明理由时使用。 500 表示服务器端在执行请求时发生了错误。也有可能是Web应用存在的bug或某些临时的故障。 503 表示服务器暂时处于超负载或正在进行停机维护，现在无法处理请求。 xss 和 csrf 运维 git Linux Docker Docker 入门教程 软件系统最大的麻烦事之一，就是环境配置。虚拟机（virtual "},"interview/前端_笔试.html":{"url":"interview/前端_笔试.html","title":"前端_笔试","keywords":"","body":"面试——编程题 方法库 flex 布局 Document .container{ width: 500px; height: 500px; border: 1 solid gray; display: flex; align-items: center; } .box{ width: 100px; height: 100px; border: 2px solid black; border-radius: 2px; } .box4{ align-self: flex-start; } 001 002 003 004 输出字符串中的个数 let str='helloworld'; let dict={}; for(let i=0;i 求一个字符串的字节长度 function GetBytes(str){ var len = str.length; var bytes = len; for(var i=0; i 255) bytes++; } return bytes; } 最多的字符和个数 let str = \"abcabcabcbbccccc\"; let num = 0; let char = ''; str = str.split('').sort().join(''); let re = /(\\w)\\1+/g; str.replace(re,($0,$1) => { if(num 数组去重 let dict={}, result=[], j=0; for(let i=0;i url 匹配 function fn(url, name) { let exp = /(?\\w+)=(?\\w+)/g let match = url.matchAll(exp) let res = [...match].find(item => item.groups.key === name) console.log(res.groups.val) return res.groups.val } fn(\"https://a.com/?a=1&b=2\", \"a\") 拷贝 // 浅拷贝 function extendCopy(p) { let c = {} for(let i in p) { c[i] = p[i] } c.uber = p return c } // 深拷贝 function deepCopy(p, c) { let c = c || {} for(let i in p) { if(typeof p[i] === 'object') { c[i] = (p[i].constructor === Array) ? [] : {} deepCopy(p[i], c[i]) } else { c[i] = p[i] } } return c } 深度遍历 /** * @fnName walk ... * @param {*} list ... */ function walk () { var arr = [] return function unlockTheArray(list) { list.forEach(item => { var o = {} let temp = Object.entries(item) for(let [k, v] of temp) { if(k === 'children' && Array.isArray(v)) { unlockTheArray(v) } else { o[k] = v } } arr.push(o) }) return arr } } console.log(walk()(list)) 迭代器实现 function createIterator(items) { var i = 0 return { next: function() { var done = (i => i>= items.length) var value = ~!done ? items[i++]: undefined return { done: done, value: value } } } } 懒加载实现 var imgs = document.getElementsByTagName('img');//获取img元素 function lazyLoad(){//监听页面滚动事件 var vHeight = window.innerHeight||document.documentElement.clientHeight||document.body.clientHeight;//可视区域距浏览器窗口的距离 var scrollHeight = window.pageYOffset||document.documentElement.scrollTop||document.body.scrollTop;//浏览器窗口与文档顶部的距离，即：垂直滚动高度 for(var i = 0; i 防抖 function debounce(fn, delay) { var timer = null return function() { let context = this // 保存函数调用时的上下文和参数，传递给 fn let args = arguments if(timer) clearTimeout(timer) // 函数被调用，清楚定时器 timer = setTimeout(function () { // 当返回的额函数最后一次调用，等到 delay 毫秒就可以执行 fn.apply(context, args) }, delay) } } 节流 function throttle(func, delay) { var timer = null return function() { var context = this; var args = arguments; if(!timer) { timer = setTimeout(function() { func.apply(context, args) timer = null }, delay) } } } Promise 实现 class Promise { constructor(executor) { this.status='pending' //三状态 this.value = undefined //参数 this.reason = undefined this.onFulfilled = [] //发布订阅中储存回调 this.onRejected = [] let resolve = (value)=>{ if(this.status==='pending'){ this.status = 'fulfilled' this.value = value this.onFulfilled.forEach(fn=>fn(this.value)) //发布订阅模式，异步一改变状态则立即执行回调 } } let reject = (reason)=>{ if(this.status==='pending'){ this.status = 'rejected' this.reason = reason this.onRejected.forEach(fn=>fn(this.reason)) } } try{ executor(resolve,reject) //executor同步执行 }catch (e) { reject(e) } } then(onFulfilled, onRejected) { // 如果then的时候 根据当前状态执行成功或者失败 if(this.status==='fulfilled'){ onFulfilled(this.value) } if(this.status==='rejected'){ onRejected(this.reason) } if(this.status==='pending'){ this.onFulfilled.push(onFulfilled) //发布订阅模式储存异步回调 this.onRejected.push(onRejected) } } } 虚拟 DOM 转换为真实 DOM // 创建 virtual DOM 实体类 class Element { constructor(type, props, children) { this.type = type this.props = props this.children = children } } // virtual DOM => inner DOM function render(eleObj) { if(!eleObj.type) return let node = eleObj.createElement(eleObj.type) for(let key of eleObj.props) { setAttr(node, key, eleObj.props.key) } eleObj.children.forEach(child => { child = (child instanceof Element) ? render(child) : document.createTextNode(child) el.appendChild(child) }) } // 真实 DOM 添加到浏览器上 function renderDom(el, target) { target.appendChild(el) } // 设置 elenment 属性 function setAttr(node, key, value) { switch(key) { case 'value': if(node.tagName.toUpperName() == 'INPUT' || node.tagName.toUpperName() == 'TEXTAREA') { node.value = value } else { node.setAttribute(key, value) } break; case 'style': node.style.cassText = value break; default: node.setAttribute(key, value) } } 实现 hash 模式，核心通过监听 url 的 hash 来实现跳转： class Router{ constructor() { this.routes = {} // 存放路由及回调 this.currentUrl = '' // 监听路由change，调用响应的回调函数 window.addEventListener('load', this.refresh, false) window,addEventListener('haschange', this.refresh, false) } route(path, callback) { this.routes[path] = callback } push(path) { this.routes[path] && this.routes[path]() } } // 使用 router window.miniRouter = new Router() miniRouter.route('/', () => {console.log('/')}) miniRouter.route('/page1', () => {console.log('/page1')}) miniRouter.push('/') miniRouter.push('/page1') history 模式核心借用 HTML history api，api 提供了丰富的 router 相关属性： history.pushState 浏览器历史记录添加记录 history.replaceState 修改浏览器历史记录中当前记录 history.popState 当 history 发生变化时触发 // 定义 Router class Router { constructor () { this.routes = {}; this.listerPopState() } init(path) { history.replaceState({path: path}, null, path); this.routes[path] && this.routes[path](); } route(path, callback){ this.routes[path] = callback; } push(path) { history.pushState({path: path}, null, path); this.routes[path] && this.routes[path](); } listerPopState () { window.addEventListener('popstate' , e => { const path = e.state && e.state.path; this.routers[path] && this.routers[path]() }) } } // 使用 Router window.miniRouter = new Router(); miniRouter.route('/', ()=> console.log('page1')) miniRouter.route('/page2', ()=> console.log('page2')) // 跳转 miniRouter.push('/page2') // page2 算法部分 吐血整理！！！2019最强前端面试合集(编程题) - SegmentFault function swap(A,i,j){ const t=A[i]; A[i]=A[j]; A[j]=t; } function buble_sort(A){ // |---未排序---|---已排序的最大值---| // 初始 |------未排序------|i| for(let i=A.length;i>0;i--){ for(let j=1;j 快排 // i指向最后一个小于支点的数字，j指向未确认的下一个数字 初始值 i=-1,j=0 function swap(A,i,j){ [A[i],A[j]]=[A[j],A[i]]; } function divide(A,p,r){ const x=A[r-1]; let i=p-1; for(let j=p;j 归并排序 const SENTINEL=Number.MAX_SAFE_INTEGER; function divide(p,r){ return Math.floor((p+r)/2) } function conquer(A,p,q,r){ const A1=A.slice(p,q); const A2=A.slice(q,r); A1.push(SENTINEL); A2.push(SENTINEL); for(let k=p,i=0,j=0;kA[r-1]){ [A[p],A[r-1]]=[A[r-1],A[p]] } return } const q=divide(p,r); console.log('divide:'+q); merge_sort(A,p,q) merge_sort(A,q,r) conquer(A,p,q,r) } 二分查找 function bsearch(A,x){ let l=0, r=A.length-1, guess; while(lx){ r=guess-1; }else{ l=guess+1 } } return -1; } 符号匹配 function match(n,c){ return ( c=='[' && n==']' ) || ( c=='(' && n==')' ) } function is_balance(str){ const [first,...others]=str; const stack=[first]; while(others.length>0){ const c=stack[stack.length-1]; const n=others.shift(); if(!match(n,c)){ stack.push(n) }else{ stack.pop() } } return stack.length === 0; } 深度、广度有限遍历 function depth_first_search(node){ let stack=[node]; while(stack.length>0){ const item=stack.pop(); for(let i=item.length-1;i>0;i--){ stack.push(item.children[i]) } } } function *breath_first_search(node){ let queue=[node]; while(queue.length>0){ const item=queue.pop(); yield item.tagName; for(let i=item.length-1;i>0;i--){ queue.unshift(item.children[i]) } } } 综合部分 吐血整理！！！2019最强前端面试合集(编程题) - SegmentFault 无缝轮播图 &lt; &gt; window.onload = function(){ var eleInners = document.getElementById('inner-list'), eleDots = document.getElementById('dot-list'), liImgs = eleInners.getElementsByTagName('li'), liDots = eleDots.children, elePrev = document.getElementById('btn-prev'), eleNext = document.getElementById('btn-next'), LI_WIDTH = liImgs[0].offsetWidth, TIME_DURATION = 3000, interval = null, index = 0, circle = 0; eleInners.appendChild(liImgs[0].cloneNode(true)); for(var i= 0,len = liImgs.length -1;i targetPlace ? -15:15; var result = targetPlace - obj.offsetLeft; if(Math.abs(result) > Math.abs(speed)){ obj.style.left = obj.offsetLeft + speed +'px' }else{ obj.style.left = targetPlace+'px'; clearInterval(obj.timer); } },10) } interval = setInterval(autoplay,3000) function autoplay(){ index++; if(index > liImgs.length -1){ eleInners.style.left = 0; index = 1; } animate(eleInners, -index * LI_WIDTH); circle++; if(circle >= liImgs.length -1){ circle = 0; } for(var i= 0,len = liDots.length;i 幻灯片 .myDiv{ width: 600px; height: 400px; margin: 20px auto; background-size: over; background-position: center; animation-name:loop; animation-duration: 20s; animation-iteration-count: infinite; } @keyframes loop{ 0% {background: url('图片1.jpg') no-repeat;} 25% {background: url('图片2.jpg') no-repeat;} 50% {background: url('图片3.jpg') no-repeat;} 75% {background: url('图片4.jpg') no-repeat;} 100% {background: url('图片5.jpg') no-repeat;} } 三栏布局 flex 布局 .container{ display:flex; justify-content: center; height: 200px; background: #eee; } .left { width: 200px; background-color: red; height: 100%; } .main { background-color: yellow; flex: 1; } .right { width: 200px; background-color: green; } 1 2 3 绝对定位布局 .container { position: relative; background:#eee; height:200px; } .main { height: 200px; margin: 0 120px; background-color: yellow; } .left { position: absolute; width: 100px; height: 200px; left: 0; top: 0; background-color: red; } .right { position: absolute; width: 100px; height: 200px; background-color: green; right: 0; top: 0; } 1 2 3 双飞翼布局 .content { float: left; width: 100%; } .main { height: 200px; margin-left: 110px; margin-right: 220px; background-color: yellow; } .left { float: left; height: 200px; width: 100px; margin-left: -100%; background-color: red; } .right { width: 200px; height: 200px; float: right; margin-left: -200px; background-color: green; } 圣杯布局 .container { margin-left: 120px; margin-right: 220px; } .main { float: left; width: 100%; height: 300px; background-color: yellow; } .left { float: left; width: 100px; height: 300px; margin-left: -100%; position: relative; left: -120px; background-color: blue; } .right { float: left; width: 200px; height: 300px; margin-left: -200px; position: relative; right: -220px; background-color: green; } 一边固定宽度，一边自适应 .wrap { display: flex; justify-content: space-between; } .div1 { min-width: 200px; } .div2 { width: 100%; background: #e6e6e6; } html, body, div { height: 100%; margin: 0; } 文本超出部分显示省略号 单行 overflow: hidden; text-overflow:ellipsis; white-space: nowrap; 多行 display: -webkit-box; -webkit-box-orient: vertical; -webkit-line-clamp: 3; // 最多显示几行 overflow: hidden; sort 方法对一个数组的对象进行排序 function compare(propertyName, index) { return function(a, b) { let value1 = a[propertyName]; let value2 = b[propertyName]; if (vm.reverse[index]) { return value2 - value1; } else { return value1 - value2; } }; } 随机打乱一个数组 function shuffle_simple(arr){ return arr.sort(()=>Math.random()- .5) } function fisher_yates_shuffle(arr){ for(let i=0;i "},"interview/个人面经.html":{"url":"interview/个人面经.html","title":"个人面经","keywords":"","body":"个人面经 阿里-钉钉 电话面（面试，笔试） 面试问题（1 小时） 做了哪些项目，项目用到了哪些东西 Ajax 为什么不用更新页面了（这个回答的有点懵） Vue拿到数据之后怎么渲染数据的（最近太忙，Vue还没来得及仔细看，这块崩了，还一直问，然后问的一些东西我都答非所问的，也没记住问题，惨败！） CSS 选择器权重（这个背了，看我vue回答的太差的，送我分的） const let var（同上） 写的代码 es6 怎么在浏览器中运行 apply，call，bind js 有哪些自己觉得算是理解的点（我giao，这真是送命题啊，我说了之后把我问死的意思吗） Cookie 有哪些属性 为什么有些网站不消除 Cookie就一直能登录（我就回答了一句，不消除发送的时候自动把Cookie也包进去了，感觉回答的很简单，，，） 实现历史回退前进（我回答了快照） TS VS JS （只回答了强弱类型，然后胡扯了一下） 为啥决定走前端了 前端占你学习比重有多大，可以多了解一点底层的东西（当时就觉得凉凉了） 现在觉得前端有哪些不好的问题，最想做啥（好的我准备了，不好的地方还真没想到） 笔试（4 选 3，1小时） 操作DOM（这个自己就很少写，直接pass） 递归将一个对象数组排序（这个有一点问题，网页的编译器判断 Array.isArray 这个函数不能用，然后我就不知道怎么判断这个变量是不是一个数组了） 比较版本号（正则用的有点不熟练啊，其它没啥问题） 节流函数 "}}